{
  "file_path": "/work/external-deps/helix-db/helix-db/src/helix_gateway/tests/worker_pool_tests.rs",
  "file_hash": "ef5c34c9c48d5f01c543153f0aeee6ca4b712d1d",
  "updated_at": "2025-12-26T17:34:20.869654",
  "symbols": {
    "function_create_test_graph_15": {
      "name": "create_test_graph",
      "type": "function",
      "start_line": 15,
      "end_line": 29,
      "content_hash": "83dd2bb23230f4b9e279897f1e835dfda21c0bdc",
      "content": "fn create_test_graph() -> (Arc<HelixGraphEngine>, TempDir) {\n    let temp_dir = TempDir::new().unwrap();\n    let mut config = Config::default();\n    // Use very minimal DB size for tests (0 means use minimum)\n    // This reduces memory mapping requirements when running many tests in parallel\n    config.db_max_size_gb = Some(0);\n    let opts = HelixGraphEngineOpts {\n        path: temp_dir.path().to_str().unwrap().to_string(),\n        config,\n        version_info: Default::default(),\n    };\n    let graph = Arc::new(HelixGraphEngine::new(opts).unwrap());\n    (graph, temp_dir)\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_handler_30": {
      "name": "test_handler",
      "type": "function",
      "start_line": 30,
      "end_line": 36,
      "content_hash": "ef3c05cd18bc3f4b9de82bbb7c47e455539963c4",
      "content": "fn test_handler(_input: HandlerInput) -> Result<Response, GraphError> {\n    Ok(Response {\n        body: b\"test response\".to_vec(),\n        fmt: Format::Json,\n    })\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_error_handler_37": {
      "name": "error_handler",
      "type": "function",
      "start_line": 37,
      "end_line": 40,
      "content_hash": "af65ae330424454476187153b155c3a41683ff80",
      "content": "fn error_handler(_input: HandlerInput) -> Result<Response, GraphError> {\n    Err(GraphError::New(\"handler error\".to_string()))\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_create_test_request_41": {
      "name": "create_test_request",
      "type": "function",
      "start_line": 41,
      "end_line": 56,
      "content_hash": "fc8a1ff14788867fcf4d8ab15cbfae97d0263ff1",
      "content": "fn create_test_request(name: &str, req_type: RequestType) -> Request {\n    Request {\n        name: name.to_string(),\n        req_type,\n        api_key: None,\n        body: Bytes::new(),\n        in_fmt: Format::Json,\n        out_fmt: Format::Json,\n    }\n}\n\n// ============================================================================\n// WorkerPool Creation Tests\n// ============================================================================\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_worker_pool_new_57": {
      "name": "test_worker_pool_new",
      "type": "function",
      "start_line": 57,
      "end_line": 77,
      "content_hash": "991ef0103abe64ee5451b930a38dd8bc110f71a1",
      "content": "fn test_worker_pool_new() {\n    let (graph, _temp_dir) = create_test_graph();\n    let router = Arc::new(HelixRouter::new(None, None, None));\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores =\n        core_affinity::get_core_ids().unwrap_or_else(|| vec![core_affinity::CoreId { id: 0 }]);\n    // Need at least 2 workers: use 2 threads per core to ensure num_workers = cores.len() * 2 >= 2\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let _pool = WorkerPool::new(core_setter, graph, router, rt);\n    // If we reach here, pool was created successfully\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_worker_pool_with_single_core_78": {
      "name": "test_worker_pool_with_single_core",
      "type": "function",
      "start_line": 78,
      "end_line": 96,
      "content_hash": "64f2aa85e4a07ca645494efeafd62f6fe9902644",
      "content": "fn test_worker_pool_with_single_core() {\n    let (graph, _temp_dir) = create_test_graph();\n    let router = Arc::new(HelixRouter::new(None, None, None));\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let _pool = WorkerPool::new(core_setter, graph, router, rt);\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_worker_pool_with_multiple_cores_97": {
      "name": "test_worker_pool_with_multiple_cores",
      "type": "function",
      "start_line": 97,
      "end_line": 117,
      "content_hash": "aa74290bf486838076ff5aa8be02bb091dd01e92",
      "content": "fn test_worker_pool_with_multiple_cores() {\n    let (graph, _temp_dir) = create_test_graph();\n    let router = Arc::new(HelixRouter::new(None, None, None));\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(2)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![\n        core_affinity::CoreId { id: 0 },\n        core_affinity::CoreId { id: 1 },\n    ];\n    let core_setter = Arc::new(CoreSetter::new(cores, 1));\n\n    let _pool = WorkerPool::new(core_setter, graph, router, rt);\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_worker_pool_with_multiple_workers_per_core_118": {
      "name": "test_worker_pool_with_multiple_workers_per_core",
      "type": "function",
      "start_line": 118,
      "end_line": 135,
      "content_hash": "926d76eb05ea465bb92996c34eaa80802ec31774",
      "content": "fn test_worker_pool_with_multiple_workers_per_core() {\n    let (graph, _temp_dir) = create_test_graph();\n    let router = Arc::new(HelixRouter::new(None, None, None));\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(4)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    let core_setter = Arc::new(CoreSetter::new(cores, 4));\n\n    let _pool = WorkerPool::new(core_setter, graph, router, rt);\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_worker_pool_channel_capacity_136": {
      "name": "test_worker_pool_channel_capacity",
      "type": "function",
      "start_line": 136,
      "end_line": 663,
      "content_hash": "5cfdf80ae14b5ca05f766270624874aecb4cd349",
      "content": "fn test_worker_pool_channel_capacity() {\n    let (graph, _temp_dir) = create_test_graph();\n    let router = Arc::new(HelixRouter::new(None, None, None));\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    // WorkerPool uses bounded(1000) for channels\n    let _pool = WorkerPool::new(core_setter, graph, router, rt);\n    // Verify it doesn't panic during creation\n}\n\n// ============================================================================\n// Request Processing Tests\n// ============================================================================\n\n#[tokio::test]\nasync fn test_process_request_success() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"test_query\".to_string(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    let request = create_test_request(\"test_query\", RequestType::Query);\n    let result = pool.process(request).await;\n\n    assert!(result.is_ok());\n    let response = result.unwrap();\n    assert_eq!(response.body, b\"test response\");\n}\n\n#[tokio::test]\nasync fn test_process_request_handler_error() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"error_query\".to_string(), Arc::new(error_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    let request = create_test_request(\"error_query\", RequestType::Query);\n    let result = pool.process(request).await;\n\n    assert!(result.is_err());\n}\n\n#[tokio::test]\nasync fn test_process_request_not_found() {\n    let (graph, _temp_dir) = create_test_graph();\n    let router = Arc::new(HelixRouter::new(None, None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    let request = create_test_request(\"nonexistent\", RequestType::Query);\n    let result = pool.process(request).await;\n\n    assert!(result.is_err());\n    match result.unwrap_err() {\n        HelixError::NotFound { ty, name } => {\n            assert_eq!(ty, RequestType::Query);\n            assert_eq!(name, \"nonexistent\");\n        }\n        _ => panic!(\"Expected NotFound error\"),\n    }\n}\n\n#[tokio::test]\nasync fn test_process_multiple_requests_sequentially() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"test_query\".to_string(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    for _ in 0..5 {\n        let request = create_test_request(\"test_query\", RequestType::Query);\n        let result = pool.process(request).await;\n        assert!(result.is_ok());\n    }\n}\n\n#[tokio::test]\nasync fn test_process_requests_parallel() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"test_query\".to_string(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(2)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![\n        core_affinity::CoreId { id: 0 },\n        core_affinity::CoreId { id: 1 },\n    ];\n    let core_setter = Arc::new(CoreSetter::new(cores, 1));\n\n    let pool = Arc::new(WorkerPool::new(core_setter, graph, router, rt));\n\n    let mut handles = vec![];\n    for _ in 0..5 {\n        let pool_clone = Arc::clone(&pool);\n        let handle = tokio::spawn(async move {\n            let request = create_test_request(\"test_query\", RequestType::Query);\n            pool_clone.process(request).await\n        });\n        handles.push(handle);\n    }\n\n    for handle in handles {\n        let result = handle.await.unwrap();\n        assert!(result.is_ok());\n    }\n}\n\n// ============================================================================\n// Request Type Routing Tests\n// ============================================================================\n\n#[tokio::test]\nasync fn test_route_query_request() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"query1\".to_string(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    let request = create_test_request(\"query1\", RequestType::Query);\n    let result = pool.process(request).await;\n\n    assert!(result.is_ok());\n}\n\n#[tokio::test]\nasync fn test_route_query_not_found() {\n    let (graph, _temp_dir) = create_test_graph();\n    let router = Arc::new(HelixRouter::new(None, None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    let request = create_test_request(\"unknown\", RequestType::Query);\n    let result = pool.process(request).await;\n\n    assert!(result.is_err());\n    assert!(matches!(result.unwrap_err(), HelixError::NotFound { .. }));\n}\n\n#[tokio::test]\nasync fn test_multiple_query_routes() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"query1\".to_string(), Arc::new(test_handler) as Arc<_>);\n    routes.insert(\"query2\".to_string(), Arc::new(test_handler) as Arc<_>);\n    routes.insert(\"query3\".to_string(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    for query_name in [\"query1\", \"query2\", \"query3\"] {\n        let request = create_test_request(query_name, RequestType::Query);\n        let result = pool.process(request).await;\n        assert!(result.is_ok());\n    }\n}\n\n#[tokio::test]\nasync fn test_route_with_special_characters() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\n        \"query-with-dash\".to_string(),\n        Arc::new(test_handler) as Arc<_>,\n    );\n    routes.insert(\n        \"query_with_underscore\".to_string(),\n        Arc::new(test_handler) as Arc<_>,\n    );\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    let request1 = create_test_request(\"query-with-dash\", RequestType::Query);\n    assert!(pool.process(request1).await.is_ok());\n\n    let request2 = create_test_request(\"query_with_underscore\", RequestType::Query);\n    assert!(pool.process(request2).await.is_ok());\n}\n\n// ============================================================================\n// Error Handling Tests\n// ============================================================================\n\n#[tokio::test]\nasync fn test_handler_error_propagation() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"error\".to_string(), Arc::new(error_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    let request = create_test_request(\"error\", RequestType::Query);\n    let result = pool.process(request).await;\n\n    assert!(result.is_err());\n}\n\n#[tokio::test]\nasync fn test_not_found_error_contains_request_name() {\n    let (graph, _temp_dir) = create_test_graph();\n    let router = Arc::new(HelixRouter::new(None, None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    let request = create_test_request(\"specific_name\", RequestType::Query);\n    let result = pool.process(request).await;\n\n    match result {\n        Err(HelixError::NotFound { name, .. }) => {\n            assert_eq!(name, \"specific_name\");\n        }\n        _ => panic!(\"Expected NotFound error\"),\n    }\n}\n\n#[tokio::test]\nasync fn test_not_found_error_contains_request_type() {\n    let (graph, _temp_dir) = create_test_graph();\n    let router = Arc::new(HelixRouter::new(None, None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    let request = create_test_request(\"test\", RequestType::Query);\n    let result = pool.process(request).await;\n\n    match result {\n        Err(HelixError::NotFound { ty, .. }) => {\n            assert_eq!(ty, RequestType::Query);\n        }\n        _ => panic!(\"Expected NotFound error\"),\n    }\n}\n\n#[tokio::test]\nasync fn test_mixed_success_and_error_requests() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"success\".to_string(), Arc::new(test_handler) as Arc<_>);\n    routes.insert(\"error\".to_string(), Arc::new(error_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    let success_req = create_test_request(\"success\", RequestType::Query);\n    assert!(pool.process(success_req).await.is_ok());\n\n    let error_req = create_test_request(\"error\", RequestType::Query);\n    assert!(pool.process(error_req).await.is_err());\n\n    let not_found_req = create_test_request(\"missing\", RequestType::Query);\n    assert!(pool.process(not_found_req).await.is_err());\n}\n\n// ============================================================================\n// Request Body and Format Tests\n// ============================================================================\n\n#[tokio::test]\nasync fn test_request_with_body_data() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"test\".to_string(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    let request = Request {\n        name: \"test\".to_string(),\n        req_type: RequestType::Query,\n        body: Bytes::from(vec![1, 2, 3, 4]),\n        in_fmt: Format::Json,\n        out_fmt: Format::Json,\n        api_key: None,\n    };\n\n    let result = pool.process(request).await;\n    assert!(result.is_ok());\n}\n\n#[tokio::test]\nasync fn test_request_with_empty_body() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"test\".to_string(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    let request = create_test_request(\"test\", RequestType::Query);\n    let result = pool.process(request).await;\n    assert!(result.is_ok());\n}\n\n#[tokio::test]\nasync fn test_request_format_json() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"test\".to_string(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    let request = Request {\n        name: \"test\".to_string(),\n        req_type: RequestType::Query,\n        body: Bytes::new(),\n        in_fmt: Format::Json,\n        out_fmt: Format::Json,\n        api_key: None,\n    };\n\n    let result = pool.process(request).await;\n    assert!(result.is_ok());\n    assert_eq!(result.unwrap().fmt, Format::Json);\n}\n\n// ============================================================================\n// Worker Thread Tests\n// ============================================================================\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_worker_thread_creation_664": {
      "name": "test_worker_thread_creation",
      "type": "function",
      "start_line": 664,
      "end_line": 686,
      "content_hash": "0d59e6bdefefe2fb5d1db5be14a008efa235954f",
      "content": "fn test_worker_thread_creation() {\n    let (graph, _temp_dir) = create_test_graph();\n    let router = Arc::new(HelixRouter::new(None, None, None));\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    // This creates workers internally\n    let _pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    // If we reach here, worker threads were created successfully\n    std::thread::sleep(std::time::Duration::from_millis(10));\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_multiple_worker_threads_687": {
      "name": "test_multiple_worker_threads",
      "type": "function",
      "start_line": 687,
      "end_line": 791,
      "content_hash": "99ab851f7bd8b32d0369db131e6d5b5d0a801063",
      "content": "fn test_multiple_worker_threads() {\n    let (graph, _temp_dir) = create_test_graph();\n    let router = Arc::new(HelixRouter::new(None, None, None));\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(4)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![\n        core_affinity::CoreId { id: 0 },\n        core_affinity::CoreId { id: 1 },\n    ];\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    // This creates 4 worker threads (2 cores \u00d7 2 threads per core)\n    let _pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    std::thread::sleep(std::time::Duration::from_millis(10));\n}\n\n// ============================================================================\n// Channel and Communication Tests\n// ============================================================================\n\n#[tokio::test]\nasync fn test_channel_communication() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"test\".to_string(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    // Test that channel communication works\n    let request = create_test_request(\"test\", RequestType::Query);\n    let result = pool.process(request).await;\n    assert!(result.is_ok());\n}\n\n#[tokio::test]\nasync fn test_high_volume_requests() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"test\".to_string(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(2)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![\n        core_affinity::CoreId { id: 0 },\n        core_affinity::CoreId { id: 1 },\n    ];\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = Arc::new(WorkerPool::new(core_setter, graph, router, rt));\n\n    // Test 50 requests\n    let mut handles = vec![];\n    for i in 0..50 {\n        let pool_clone = Arc::clone(&pool);\n        let handle = tokio::spawn(async move {\n            let request = create_test_request(\"test\", RequestType::Query);\n            (i, pool_clone.process(request).await)\n        });\n        handles.push(handle);\n    }\n\n    let mut success_count = 0;\n    for handle in handles {\n        let (_, result) = handle.await.unwrap();\n        if result.is_ok() {\n            success_count += 1;\n        }\n    }\n\n    assert_eq!(success_count, 50);\n}\n\n// ============================================================================\n// Handler Input Tests\n// ============================================================================\n\n#[tokio::test]\nasync fn test_handler_receives_correct_request() {",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_check_request_handler_792": {
      "name": "check_request_handler",
      "type": "function",
      "start_line": 792,
      "end_line": 831,
      "content_hash": "d86c5f7083905ab80cf6c19811cfbade5c435344",
      "content": "    fn check_request_handler(input: HandlerInput) -> Result<Response, GraphError> {\n        assert_eq!(input.request.name, \"check_name\");\n        Ok(Response {\n            body: input.request.name.as_bytes().to_vec(),\n            fmt: Format::Json,\n        })\n    }\n\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\n        \"check_name\".to_string(),\n        Arc::new(check_request_handler) as Arc<_>,\n    );\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    let request = create_test_request(\"check_name\", RequestType::Query);\n    let result = pool.process(request).await;\n\n    assert!(result.is_ok());\n    let response = result.unwrap();\n    assert_eq!(response.body, b\"check_name\");\n}\n\n#[tokio::test]\nasync fn test_handler_receives_graph_access() {",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_graph_access_handler_832": {
      "name": "graph_access_handler",
      "type": "function",
      "start_line": 832,
      "end_line": 1257,
      "content_hash": "5773ed76168e72b931be0fc2e81fb54e1cbdfd03",
      "content": "    fn graph_access_handler(input: HandlerInput) -> Result<Response, GraphError> {\n        // Verify we have access to the graph\n        let _graph = input.graph;\n        Ok(Response {\n            body: b\"graph_accessed\".to_vec(),\n            fmt: Format::Json,\n        })\n    }\n\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"test\".to_string(), Arc::new(graph_access_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    let request = create_test_request(\"test\", RequestType::Query);\n    let result = pool.process(request).await;\n\n    assert!(result.is_ok());\n}\n\n// ============================================================================\n// Response Format Tests\n// ============================================================================\n\n#[tokio::test]\nasync fn test_response_body_content() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"test\".to_string(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    let request = create_test_request(\"test\", RequestType::Query);\n    let result = pool.process(request).await;\n\n    assert!(result.is_ok());\n    let response = result.unwrap();\n    assert_eq!(response.body, b\"test response\");\n    assert_eq!(response.fmt, Format::Json);\n}\n\n#[tokio::test]\nasync fn test_response_format_preserved() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"test\".to_string(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    let request = create_test_request(\"test\", RequestType::Query);\n    let result = pool.process(request).await;\n\n    let response = result.unwrap();\n    assert_eq!(response.fmt, Format::Json);\n}\n\n// ============================================================================\n// Edge Case Tests\n// ============================================================================\n\n#[tokio::test]\nasync fn test_empty_route_name() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"\".to_string(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    let request = create_test_request(\"\", RequestType::Query);\n    let result = pool.process(request).await;\n\n    assert!(result.is_ok());\n}\n\n#[tokio::test]\nasync fn test_very_long_route_name() {\n    let (graph, _temp_dir) = create_test_graph();\n    let long_name = \"a\".repeat(1000);\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(long_name.clone(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    let request = create_test_request(&long_name, RequestType::Query);\n    let result = pool.process(request).await;\n\n    assert!(result.is_ok());\n}\n\n#[tokio::test]\nasync fn test_concurrent_different_routes() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"route_a\".to_string(), Arc::new(test_handler) as Arc<_>);\n    routes.insert(\"route_b\".to_string(), Arc::new(test_handler) as Arc<_>);\n    routes.insert(\"route_c\".to_string(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(2)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![\n        core_affinity::CoreId { id: 0 },\n        core_affinity::CoreId { id: 1 },\n    ];\n    let core_setter = Arc::new(CoreSetter::new(cores, 1));\n\n    let pool = Arc::new(WorkerPool::new(core_setter, graph, router, rt));\n\n    let mut handles = vec![];\n    for route in [\"route_a\", \"route_b\", \"route_c\"] {\n        let pool_clone = Arc::clone(&pool);\n        let route_name = route.to_string();\n        let handle = tokio::spawn(async move {\n            let request = create_test_request(&route_name, RequestType::Query);\n            pool_clone.process(request).await\n        });\n        handles.push(handle);\n    }\n\n    for handle in handles {\n        assert!(handle.await.unwrap().is_ok());\n    }\n}\n\n#[tokio::test]\nasync fn test_sequential_different_routes() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"first\".to_string(), Arc::new(test_handler) as Arc<_>);\n    routes.insert(\"second\".to_string(), Arc::new(test_handler) as Arc<_>);\n    routes.insert(\"third\".to_string(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    for route in [\"first\", \"second\", \"third\"] {\n        let request = create_test_request(route, RequestType::Query);\n        assert!(pool.process(request).await.is_ok());\n    }\n}\n\n#[tokio::test]\nasync fn test_repeated_requests_same_route() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"repeat\".to_string(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    for _ in 0..10 {\n        let request = create_test_request(\"repeat\", RequestType::Query);\n        assert!(pool.process(request).await.is_ok());\n    }\n}\n\n#[tokio::test]\nasync fn test_alternating_success_error() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"success\".to_string(), Arc::new(test_handler) as Arc<_>);\n    routes.insert(\"error\".to_string(), Arc::new(error_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    for i in 0..5 {\n        let route = if i % 2 == 0 { \"success\" } else { \"error\" };\n        let request = create_test_request(route, RequestType::Query);\n        let result = pool.process(request).await;\n        if i % 2 == 0 {\n            assert!(result.is_ok());\n        } else {\n            assert!(result.is_err());\n        }\n    }\n}\n\n#[tokio::test]\nasync fn test_request_with_large_body() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"test\".to_string(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    let large_body = vec![0u8; 100_000];\n    let request = Request {\n        name: \"test\".to_string(),\n        req_type: RequestType::Query,\n        body: Bytes::from(large_body),\n        in_fmt: Format::Json,\n        out_fmt: Format::Json,\n        api_key: None,\n    };\n\n    let result = pool.process(request).await;\n    assert!(result.is_ok());\n}\n\n#[tokio::test]\nasync fn test_many_parallel_requests() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"test\".to_string(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(4)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![\n        core_affinity::CoreId { id: 0 },\n        core_affinity::CoreId { id: 1 },\n    ];\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = Arc::new(WorkerPool::new(core_setter, graph, router, rt));\n\n    let mut handles = vec![];\n    for _ in 0..100 {\n        let pool_clone = Arc::clone(&pool);\n        let handle = tokio::spawn(async move {\n            let request = create_test_request(\"test\", RequestType::Query);\n            pool_clone.process(request).await\n        });\n        handles.push(handle);\n    }\n\n    let mut success_count = 0;\n    for handle in handles {\n        if handle.await.unwrap().is_ok() {\n            success_count += 1;\n        }\n    }\n\n    assert_eq!(success_count, 100);\n}\n\n#[tokio::test]\nasync fn test_worker_pool_no_routes() {\n    let (graph, _temp_dir) = create_test_graph();\n    let router = Arc::new(HelixRouter::new(None, None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    let request = create_test_request(\"any\", RequestType::Query);\n    let result = pool.process(request).await;\n\n    assert!(result.is_err());\n    assert!(matches!(result.unwrap_err(), HelixError::NotFound { .. }));\n}\n\n#[tokio::test]\nasync fn test_request_type_query_explicit() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"query\".to_string(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    let request = Request {\n        name: \"query\".to_string(),\n        req_type: RequestType::Query,\n        body: Bytes::new(),\n        in_fmt: Format::Json,\n        out_fmt: Format::Json,\n        api_key: None,\n    };\n\n    let result = pool.process(request).await;\n    assert!(result.is_ok());\n}\n\n#[test]\n#[should_panic(expected = \"The number of workers must be at least 2\")]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_worker_pool_with_empty_cores_1258": {
      "name": "test_worker_pool_with_empty_cores",
      "type": "function",
      "start_line": 1258,
      "end_line": 1277,
      "content_hash": "ed05120ed49ee8f06acde3870e514f9771b680cb",
      "content": "fn test_worker_pool_with_empty_cores() {\n    let (graph, _temp_dir) = create_test_graph();\n    let router = Arc::new(HelixRouter::new(None, None, None));\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![];\n    let core_setter = Arc::new(CoreSetter::new(cores, 1));\n\n    // Should panic: 0 cores \u00d7 1 thread per core = 0 workers (< 2)\n    let _pool = WorkerPool::new(core_setter, graph, router, rt);\n}\n\n#[test]\n#[should_panic(expected = \"The number of workers should be a multiple of 2\")]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_worker_pool_with_odd_workers_1278": {
      "name": "test_worker_pool_with_odd_workers",
      "type": "function",
      "start_line": 1278,
      "end_line": 1297,
      "content_hash": "9b16043b2591de26ef3e88ec0817063bd924e563",
      "content": "fn test_worker_pool_with_odd_workers() {\n    let (graph, _temp_dir) = create_test_graph();\n    let router = Arc::new(HelixRouter::new(None, None, None));\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    let core_setter = Arc::new(CoreSetter::new(cores, 3));\n\n    // Should panic: 1 core \u00d7 3 threads = 3 workers (odd number)\n    let _pool = WorkerPool::new(core_setter, graph, router, rt);\n}\n\n#[test]\n#[should_panic(expected = \"The number of workers must be at least 2\")]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_worker_pool_with_single_worker_1298": {
      "name": "test_worker_pool_with_single_worker",
      "type": "function",
      "start_line": 1298,
      "end_line": 1317,
      "content_hash": "a27ecd226348201a467bb4fdd07b363c5d936447",
      "content": "fn test_worker_pool_with_single_worker() {\n    let (graph, _temp_dir) = create_test_graph();\n    let router = Arc::new(HelixRouter::new(None, None, None));\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    let core_setter = Arc::new(CoreSetter::new(cores, 1));\n\n    // Should panic: 1 core \u00d7 1 thread = 1 worker (< 2)\n    let _pool = WorkerPool::new(core_setter, graph, router, rt);\n}\n\n#[tokio::test]\nasync fn test_response_with_custom_body() {",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_custom_handler_1318": {
      "name": "custom_handler",
      "type": "function",
      "start_line": 1318,
      "end_line": 1678,
      "content_hash": "398dd90437d5b19c97f0a41c9c257e6b385a5082",
      "content": "    fn custom_handler(_input: HandlerInput) -> Result<Response, GraphError> {\n        Ok(Response {\n            body: b\"custom response data\".to_vec(),\n            fmt: Format::Json,\n        })\n    }\n\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"custom\".to_string(), Arc::new(custom_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    let request = create_test_request(\"custom\", RequestType::Query);\n    let result = pool.process(request).await;\n\n    assert!(result.is_ok());\n    let response = result.unwrap();\n    assert_eq!(response.body, b\"custom response data\");\n}\n\n#[tokio::test]\nasync fn test_error_then_success() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"success\".to_string(), Arc::new(test_handler) as Arc<_>);\n    routes.insert(\"error\".to_string(), Arc::new(error_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    // First, an error\n    let error_req = create_test_request(\"error\", RequestType::Query);\n    assert!(pool.process(error_req).await.is_err());\n\n    // Then, a success\n    let success_req = create_test_request(\"success\", RequestType::Query);\n    assert!(pool.process(success_req).await.is_ok());\n}\n\n#[tokio::test]\nasync fn test_success_then_not_found() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"exists\".to_string(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    // First, a success\n    let success_req = create_test_request(\"exists\", RequestType::Query);\n    assert!(pool.process(success_req).await.is_ok());\n\n    // Then, not found\n    let not_found_req = create_test_request(\"does_not_exist\", RequestType::Query);\n    assert!(pool.process(not_found_req).await.is_err());\n}\n\n#[tokio::test]\nasync fn test_multiple_errors_in_sequence() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"error\".to_string(), Arc::new(error_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    for _ in 0..5 {\n        let request = create_test_request(\"error\", RequestType::Query);\n        assert!(pool.process(request).await.is_err());\n    }\n}\n\n#[tokio::test]\nasync fn test_worker_pool_stress_test() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"stress\".to_string(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(4)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![\n        core_affinity::CoreId { id: 0 },\n        core_affinity::CoreId { id: 1 },\n    ];\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = Arc::new(WorkerPool::new(core_setter, graph, router, rt));\n\n    let mut handles = vec![];\n    for i in 0..200 {\n        let pool_clone = Arc::clone(&pool);\n        let handle = tokio::spawn(async move {\n            let request = create_test_request(\"stress\", RequestType::Query);\n            (i, pool_clone.process(request).await)\n        });\n        handles.push(handle);\n    }\n\n    let mut results = vec![];\n    for handle in handles {\n        results.push(handle.await.unwrap());\n    }\n\n    let success_count = results.iter().filter(|(_, r)| r.is_ok()).count();\n    assert_eq!(success_count, 200);\n}\n\n#[tokio::test]\nasync fn test_route_case_sensitive() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"Query\".to_string(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    // Exact case matches\n    let exact_req = create_test_request(\"Query\", RequestType::Query);\n    assert!(pool.process(exact_req).await.is_ok());\n\n    // Different case doesn't match\n    let wrong_case_req = create_test_request(\"query\", RequestType::Query);\n    assert!(pool.process(wrong_case_req).await.is_err());\n}\n\n#[tokio::test]\nasync fn test_route_with_numbers() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"query123\".to_string(), Arc::new(test_handler) as Arc<_>);\n    routes.insert(\"123query\".to_string(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    let req1 = create_test_request(\"query123\", RequestType::Query);\n    assert!(pool.process(req1).await.is_ok());\n\n    let req2 = create_test_request(\"123query\", RequestType::Query);\n    assert!(pool.process(req2).await.is_ok());\n}\n\n#[tokio::test]\nasync fn test_worker_pool_multiple_workers_same_route() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"shared\".to_string(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(4)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![\n        core_affinity::CoreId { id: 0 },\n        core_affinity::CoreId { id: 1 },\n    ];\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = Arc::new(WorkerPool::new(core_setter, graph, router, rt));\n\n    // Multiple workers processing the same route concurrently\n    let mut handles = vec![];\n    for _ in 0..20 {\n        let pool_clone = Arc::clone(&pool);\n        let handle = tokio::spawn(async move {\n            let request = create_test_request(\"shared\", RequestType::Query);\n            pool_clone.process(request).await\n        });\n        handles.push(handle);\n    }\n\n    for handle in handles {\n        assert!(handle.await.unwrap().is_ok());\n    }\n}\n\n#[tokio::test]\nasync fn test_request_name_with_unicode() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"query_\u4e16\u754c\".to_string(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(1)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    // Need at least 2 workers: 1 core \u00d7 2 threads = 2 workers\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = WorkerPool::new(core_setter, graph, router, rt);\n\n    let request = create_test_request(\"query_\u4e16\u754c\", RequestType::Query);\n    let result = pool.process(request).await;\n\n    assert!(result.is_ok());\n}\n\n#[tokio::test]\nasync fn test_rapid_fire_requests() {\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"rapid\".to_string(), Arc::new(test_handler) as Arc<_>);\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(2)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![\n        core_affinity::CoreId { id: 0 },\n        core_affinity::CoreId { id: 1 },\n    ];\n    let core_setter = Arc::new(CoreSetter::new(cores, 1));\n\n    let pool = Arc::new(WorkerPool::new(core_setter, graph, router, rt));\n\n    // Fire off 30 requests as fast as possible\n    let mut handles = vec![];\n    for _ in 0..30 {\n        let pool_clone = Arc::clone(&pool);\n        let handle = tokio::spawn(async move {\n            let request = create_test_request(\"rapid\", RequestType::Query);\n            pool_clone.process(request).await\n        });\n        handles.push(handle);\n    }\n\n    let mut all_ok = true;\n    for handle in handles {\n        if handle.await.unwrap().is_err() {\n            all_ok = false;\n            break;\n        }\n    }\n\n    assert!(all_ok);\n}\n\n// ============================================================================\n// Writer Continuation Priority Tests\n// ============================================================================\n\n/// Test that write handler continuations are processed before new write requests.\n/// This prevents hangs when multiple write requests with async IO arrive rapidly.\n///\n/// Scenario being tested:\n/// 1. Write request A arrives, needs async IO, spawns continuation\n/// 2. Write request B arrives before A's continuation completes\n/// 3. Continuation from A must be processed before B starts\n/// 4. If continuations aren't prioritized, this would hang or process out of order\n#[tokio::test]\nasync fn test_writer_continuation_priority() {\n    use std::sync::atomic::{AtomicU32, Ordering};\n\n    // Track the order of operations\n    static ORDER_COUNTER: AtomicU32 = AtomicU32::new(0);\n    static CONTINUATION_A_ORDER: AtomicU32 = AtomicU32::new(0);\n    static REQUEST_B_START_ORDER: AtomicU32 = AtomicU32::new(0);\n\n    // Reset counters\n    ORDER_COUNTER.store(0, Ordering::SeqCst);\n    CONTINUATION_A_ORDER.store(0, Ordering::SeqCst);\n    REQUEST_B_START_ORDER.store(0, Ordering::SeqCst);\n\n    // Handler that returns IoNeeded - simulates async operation like embedding fetch",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_io_handler_a_1679": {
      "name": "io_handler_a",
      "type": "function",
      "start_line": 1679,
      "end_line": 1707,
      "content_hash": "20e96c7f6100d33371140fca0bec3bcb75348a83",
      "content": "    fn io_handler_a(_input: HandlerInput) -> Result<Response, GraphError> {\n        Err(IoContFn::create_err(\n            move |cont_tx, ret_chan| {\n                Box::pin(async move {\n                    // Very short async delay - continuation will be ready quickly\n                    tokio::time::sleep(std::time::Duration::from_millis(5)).await;\n\n                    // Send continuation\n                    cont_tx\n                        .send_async((\n                            ret_chan,\n                            Box::new(move || {\n                                // Record when continuation executes\n                                let order = ORDER_COUNTER.fetch_add(1, Ordering::SeqCst);\n                                CONTINUATION_A_ORDER.store(order, Ordering::SeqCst);\n                                Ok(Response {\n                                    body: b\"continuation_a\".to_vec(),\n                                    fmt: Format::Json,\n                                })\n                            }) as Box<dyn FnOnce() -> Result<Response, GraphError> + Send + Sync>,\n                        ))\n                        .await\n                        .expect(\"cont channel should be alive\");\n                })\n            },\n        ))\n    }\n\n    // Handler B - records when it starts processing",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_handler_b_1708": {
      "name": "handler_b",
      "type": "function",
      "start_line": 1708,
      "end_line": 1810,
      "content_hash": "32903a0b26551d5f19a43fb3d3a25a25e4f1b215",
      "content": "    fn handler_b(_input: HandlerInput) -> Result<Response, GraphError> {\n        // Record when request B starts\n        let order = ORDER_COUNTER.fetch_add(1, Ordering::SeqCst);\n        REQUEST_B_START_ORDER.store(order, Ordering::SeqCst);\n        Ok(Response {\n            body: b\"handler_b\".to_vec(),\n            fmt: Format::Json,\n        })\n    }\n\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"io_write_a\".to_string(), Arc::new(io_handler_a) as Arc<_>);\n    routes.insert(\"write_b\".to_string(), Arc::new(handler_b) as Arc<_>);\n\n    // Mark both as write routes so they go through the single writer worker\n    let mut write_routes = std::collections::HashSet::new();\n    write_routes.insert(\"io_write_a\".to_string());\n    write_routes.insert(\"write_b\".to_string());\n\n    let router = Arc::new(HelixRouter::new(Some(routes), None, Some(write_routes)));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(2)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = Arc::new(WorkerPool::new(core_setter, graph, router, rt));\n\n    // Send request A (will need async IO)\n    let pool_a = Arc::clone(&pool);\n    let handle_a = tokio::spawn(async move {\n        let request = Request {\n            name: \"io_write_a\".to_string(),\n            req_type: RequestType::Query,\n            body: Bytes::new(),\n            in_fmt: Format::Json,\n            out_fmt: Format::Json,\n            api_key: None,\n        };\n        pool_a.process(request).await\n    });\n\n    // Wait long enough for A's async to complete and send its continuation\n    // A's async takes 5ms, so 50ms should be plenty\n    tokio::time::sleep(std::time::Duration::from_millis(50)).await;\n\n    // Send request B while A's continuation is pending\n    let pool_b = Arc::clone(&pool);\n    let handle_b = tokio::spawn(async move {\n        let request = Request {\n            name: \"write_b\".to_string(),\n            req_type: RequestType::Query,\n            body: Bytes::new(),\n            in_fmt: Format::Json,\n            out_fmt: Format::Json,\n            api_key: None,\n        };\n        pool_b.process(request).await\n    });\n\n    // Both should complete with a reasonable timeout (hang detection)\n    let timeout = std::time::Duration::from_secs(5);\n    let result_a = tokio::time::timeout(timeout, handle_a).await;\n    let result_b = tokio::time::timeout(timeout, handle_b).await;\n\n    // Verify both completed (didn't hang)\n    assert!(result_a.is_ok(), \"Request A timed out - possible hang\");\n    assert!(result_b.is_ok(), \"Request B timed out - possible hang\");\n\n    let response_a = result_a.unwrap().unwrap();\n    let response_b = result_b.unwrap().unwrap();\n\n    assert!(response_a.is_ok(), \"Request A failed: {:?}\", response_a);\n    assert!(response_b.is_ok(), \"Request B failed: {:?}\", response_b);\n\n    // Verify continuation A was processed before request B started\n    let cont_a_order = CONTINUATION_A_ORDER.load(Ordering::SeqCst);\n    let req_b_order = REQUEST_B_START_ORDER.load(Ordering::SeqCst);\n\n    assert!(\n        cont_a_order < req_b_order,\n        \"Continuation A (order {}) should be processed before Request B (order {})\",\n        cont_a_order,\n        req_b_order\n    );\n}\n\n// ============================================================================\n// Read Continuation Channel Tests\n// ============================================================================\n\n/// Test that read handlers can use continuation channels properly.\n/// This verifies the parity-based continuation handling works for readers.\n#[tokio::test]\nasync fn test_read_continuation_channel_basic() {\n    // Handler that returns IoNeeded - simulates async operation",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_io_read_handler_1811": {
      "name": "io_read_handler",
      "type": "function",
      "start_line": 1811,
      "end_line": 1883,
      "content_hash": "09546cfa61306ecc727f17124a12778cb8a7beec",
      "content": "    fn io_read_handler(_input: HandlerInput) -> Result<Response, GraphError> {\n        Err(IoContFn::create_err(move |cont_tx, ret_chan| {\n            Box::pin(async move {\n                // Simulate async IO (e.g., fetching embeddings)\n                tokio::time::sleep(std::time::Duration::from_millis(10)).await;\n\n                // Send continuation back to worker\n                cont_tx\n                    .send_async((\n                        ret_chan,\n                        Box::new(move || {\n                            Ok(Response {\n                                body: b\"read_continuation_result\".to_vec(),\n                                fmt: Format::Json,\n                            })\n                        }) as Box<dyn FnOnce() -> Result<Response, GraphError> + Send + Sync>,\n                    ))\n                    .await\n                    .expect(\"cont channel should be alive\");\n            })\n        }))\n    }\n\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\n        \"io_read\".to_string(),\n        Arc::new(io_read_handler) as Arc<_>,\n    );\n    // Not in write_routes, so it goes to reader workers\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(2)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = Arc::new(WorkerPool::new(core_setter, graph, router, rt));\n\n    let request = Request {\n        name: \"io_read\".to_string(),\n        req_type: RequestType::Query,\n        body: Bytes::new(),\n        in_fmt: Format::Json,\n        out_fmt: Format::Json,\n        api_key: None,\n    };\n\n    let timeout = std::time::Duration::from_secs(5);\n    let result = tokio::time::timeout(timeout, pool.process(request)).await;\n\n    assert!(result.is_ok(), \"Request timed out - possible hang\");\n    let response = result.unwrap();\n    assert!(response.is_ok(), \"Request failed: {:?}\", response);\n    assert_eq!(\n        response.unwrap().body,\n        b\"read_continuation_result\".to_vec()\n    );\n}\n\n/// Test multiple concurrent read requests with continuation channels.\n#[tokio::test]\nasync fn test_read_continuation_channel_concurrent() {\n    use std::sync::atomic::{AtomicUsize, Ordering};\n\n    static CONTINUATION_COUNT: AtomicUsize = AtomicUsize::new(0);\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_io_read_handler_1884": {
      "name": "io_read_handler",
      "type": "function",
      "start_line": 1884,
      "end_line": 1984,
      "content_hash": "eb3fe217f588f659101a5af4ea575a2575d16715",
      "content": "    fn io_read_handler(_input: HandlerInput) -> Result<Response, GraphError> {\n        Err(IoContFn::create_err(move |cont_tx, ret_chan| {\n            Box::pin(async move {\n                // Variable delay to test concurrent handling\n                let delay = rand::random::<u64>() % 20 + 5;\n                tokio::time::sleep(std::time::Duration::from_millis(delay)).await;\n\n                cont_tx\n                    .send_async((\n                        ret_chan,\n                        Box::new(move || {\n                            CONTINUATION_COUNT.fetch_add(1, Ordering::SeqCst);\n                            Ok(Response {\n                                body: b\"concurrent_read\".to_vec(),\n                                fmt: Format::Json,\n                            })\n                        }) as Box<dyn FnOnce() -> Result<Response, GraphError> + Send + Sync>,\n                    ))\n                    .await\n                    .expect(\"cont channel should be alive\");\n            })\n        }))\n    }\n\n    // Reset counter\n    CONTINUATION_COUNT.store(0, Ordering::SeqCst);\n\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\n        \"io_read_concurrent\".to_string(),\n        Arc::new(io_read_handler) as Arc<_>,\n    );\n    let router = Arc::new(HelixRouter::new(Some(routes), None, None));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(4)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = Arc::new(WorkerPool::new(core_setter, graph, router, rt));\n\n    // Send 20 concurrent read requests with continuations\n    let num_requests = 20;\n    let mut handles = vec![];\n\n    for _ in 0..num_requests {\n        let pool_clone = Arc::clone(&pool);\n        let handle = tokio::spawn(async move {\n            let request = Request {\n                name: \"io_read_concurrent\".to_string(),\n                req_type: RequestType::Query,\n                body: Bytes::new(),\n                in_fmt: Format::Json,\n                out_fmt: Format::Json,\n                api_key: None,\n            };\n            pool_clone.process(request).await\n        });\n        handles.push(handle);\n    }\n\n    let timeout = std::time::Duration::from_secs(10);\n    let mut success_count = 0;\n\n    for handle in handles {\n        let result = tokio::time::timeout(timeout, handle).await;\n        assert!(result.is_ok(), \"Request timed out\");\n        let join_result = result.unwrap();\n        assert!(join_result.is_ok(), \"Task panicked\");\n        let response = join_result.unwrap();\n        assert!(response.is_ok(), \"Request failed: {:?}\", response);\n        success_count += 1;\n    }\n\n    assert_eq!(success_count, num_requests);\n    assert_eq!(\n        CONTINUATION_COUNT.load(Ordering::SeqCst),\n        num_requests,\n        \"All continuations should have been processed\"\n    );\n}\n\n// ============================================================================\n// Parallel Write Request Tests\n// ============================================================================\n\n/// Test that parallel write requests are handled sequentially without crashing.\n/// Write requests go through a single writer thread, so they should be serialized.\n#[tokio::test]\nasync fn test_parallel_write_requests_no_crash() {\n    use std::sync::atomic::{AtomicUsize, Ordering};\n\n    static WRITE_COUNT: AtomicUsize = AtomicUsize::new(0);\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_write_handler_1985": {
      "name": "write_handler",
      "type": "function",
      "start_line": 1985,
      "end_line": 2068,
      "content_hash": "f81602cdd471155b41aa1cfd64b46bbeb68bfff3",
      "content": "    fn write_handler(_input: HandlerInput) -> Result<Response, GraphError> {\n        WRITE_COUNT.fetch_add(1, Ordering::SeqCst);\n        // Small delay to simulate write operation\n        std::thread::sleep(std::time::Duration::from_millis(1));\n        Ok(Response {\n            body: b\"write_ok\".to_vec(),\n            fmt: Format::Json,\n        })\n    }\n\n    // Reset counter\n    WRITE_COUNT.store(0, Ordering::SeqCst);\n\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\"write_op\".to_string(), Arc::new(write_handler) as Arc<_>);\n\n    let mut write_routes = std::collections::HashSet::new();\n    write_routes.insert(\"write_op\".to_string());\n\n    let router = Arc::new(HelixRouter::new(Some(routes), None, Some(write_routes)));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(4)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = Arc::new(WorkerPool::new(core_setter, graph, router, rt));\n\n    // Fire off 50 parallel write requests\n    let num_requests = 50;\n    let mut handles = vec![];\n\n    for _ in 0..num_requests {\n        let pool_clone = Arc::clone(&pool);\n        let handle = tokio::spawn(async move {\n            let request = Request {\n                name: \"write_op\".to_string(),\n                req_type: RequestType::Query,\n                body: Bytes::new(),\n                in_fmt: Format::Json,\n                out_fmt: Format::Json,\n                api_key: None,\n            };\n            pool_clone.process(request).await\n        });\n        handles.push(handle);\n    }\n\n    let timeout = std::time::Duration::from_secs(10);\n    let mut success_count = 0;\n\n    for handle in handles {\n        let result = tokio::time::timeout(timeout, handle).await;\n        assert!(result.is_ok(), \"Write request timed out - possible deadlock\");\n        let join_result = result.unwrap();\n        assert!(join_result.is_ok(), \"Task panicked\");\n        let response = join_result.unwrap();\n        assert!(response.is_ok(), \"Write request failed: {:?}\", response);\n        success_count += 1;\n    }\n\n    assert_eq!(success_count, num_requests);\n    assert_eq!(\n        WRITE_COUNT.load(Ordering::SeqCst),\n        num_requests,\n        \"All writes should have been processed\"\n    );\n}\n\n/// Test parallel write requests with continuation channels.\n/// Each write request requires async IO before completion.\n#[tokio::test]\nasync fn test_parallel_write_requests_with_continuations() {\n    use std::sync::atomic::{AtomicUsize, Ordering};\n\n    static CONTINUATION_COUNT: AtomicUsize = AtomicUsize::new(0);\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_io_write_handler_2069": {
      "name": "io_write_handler",
      "type": "function",
      "start_line": 2069,
      "end_line": 2176,
      "content_hash": "d0586fa5e8d0b361e62f5b1ed3446b0c47c5c5f8",
      "content": "    fn io_write_handler(_input: HandlerInput) -> Result<Response, GraphError> {\n        Err(IoContFn::create_err(move |cont_tx, ret_chan| {\n            Box::pin(async move {\n                // Simulate async IO\n                tokio::time::sleep(std::time::Duration::from_millis(5)).await;\n\n                cont_tx\n                    .send_async((\n                        ret_chan,\n                        Box::new(move || {\n                            CONTINUATION_COUNT.fetch_add(1, Ordering::SeqCst);\n                            Ok(Response {\n                                body: b\"write_with_cont\".to_vec(),\n                                fmt: Format::Json,\n                            })\n                        }) as Box<dyn FnOnce() -> Result<Response, GraphError> + Send + Sync>,\n                    ))\n                    .await\n                    .expect(\"cont channel should be alive\");\n            })\n        }))\n    }\n\n    // Reset counter\n    CONTINUATION_COUNT.store(0, Ordering::SeqCst);\n\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\n        \"io_write\".to_string(),\n        Arc::new(io_write_handler) as Arc<_>,\n    );\n\n    let mut write_routes = std::collections::HashSet::new();\n    write_routes.insert(\"io_write\".to_string());\n\n    let router = Arc::new(HelixRouter::new(Some(routes), None, Some(write_routes)));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(4)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = Arc::new(WorkerPool::new(core_setter, graph, router, rt));\n\n    // Fire off 30 parallel write requests with continuations\n    let num_requests = 30;\n    let mut handles = vec![];\n\n    for _ in 0..num_requests {\n        let pool_clone = Arc::clone(&pool);\n        let handle = tokio::spawn(async move {\n            let request = Request {\n                name: \"io_write\".to_string(),\n                req_type: RequestType::Query,\n                body: Bytes::new(),\n                in_fmt: Format::Json,\n                out_fmt: Format::Json,\n                api_key: None,\n            };\n            pool_clone.process(request).await\n        });\n        handles.push(handle);\n    }\n\n    let timeout = std::time::Duration::from_secs(15);\n    let mut success_count = 0;\n\n    for handle in handles {\n        let result = tokio::time::timeout(timeout, handle).await;\n        assert!(\n            result.is_ok(),\n            \"Write request with continuation timed out - possible hang\"\n        );\n        let join_result = result.unwrap();\n        assert!(join_result.is_ok(), \"Task panicked\");\n        let response = join_result.unwrap();\n        assert!(\n            response.is_ok(),\n            \"Write request with continuation failed: {:?}\",\n            response\n        );\n        success_count += 1;\n    }\n\n    assert_eq!(success_count, num_requests);\n    assert_eq!(\n        CONTINUATION_COUNT.load(Ordering::SeqCst),\n        num_requests,\n        \"All write continuations should have been processed\"\n    );\n}\n\n/// Test that write requests maintain sequential ordering even under parallel load.\n#[tokio::test]\nasync fn test_parallel_writes_maintain_order() {\n    use std::sync::atomic::{AtomicUsize, Ordering};\n    use std::sync::Mutex;\n\n    static ORDER_COUNTER: AtomicUsize = AtomicUsize::new(0);\n    static EXECUTION_ORDER: Mutex<Vec<usize>> = Mutex::new(Vec::new());\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_ordering_write_handler_2177": {
      "name": "ordering_write_handler",
      "type": "function",
      "start_line": 2177,
      "end_line": 2271,
      "content_hash": "54600cb7b1258faa52f3a42720aa859a222647b3",
      "content": "    fn ordering_write_handler(input: HandlerInput) -> Result<Response, GraphError> {\n        // Parse request ID from body\n        let id: usize = String::from_utf8_lossy(&input.request.body)\n            .parse()\n            .unwrap_or(0);\n\n        // Record execution order\n        let order = ORDER_COUNTER.fetch_add(1, Ordering::SeqCst);\n        EXECUTION_ORDER.lock().unwrap().push(id);\n\n        Ok(Response {\n            body: format!(\"order_{}\", order).into_bytes(),\n            fmt: Format::Json,\n        })\n    }\n\n    // Reset state\n    ORDER_COUNTER.store(0, Ordering::SeqCst);\n    EXECUTION_ORDER.lock().unwrap().clear();\n\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\n        \"order_write\".to_string(),\n        Arc::new(ordering_write_handler) as Arc<_>,\n    );\n\n    let mut write_routes = std::collections::HashSet::new();\n    write_routes.insert(\"order_write\".to_string());\n\n    let router = Arc::new(HelixRouter::new(Some(routes), None, Some(write_routes)));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(4)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = Arc::new(WorkerPool::new(core_setter, graph, router, rt));\n\n    // Send requests in order but concurrently\n    let num_requests = 20;\n    let mut handles = vec![];\n\n    for i in 0..num_requests {\n        let pool_clone = Arc::clone(&pool);\n        let handle = tokio::spawn(async move {\n            let request = Request {\n                name: \"order_write\".to_string(),\n                req_type: RequestType::Query,\n                body: Bytes::from(format!(\"{}\", i)),\n                in_fmt: Format::Json,\n                out_fmt: Format::Json,\n                api_key: None,\n            };\n            pool_clone.process(request).await\n        });\n        handles.push(handle);\n        // Small delay to encourage order\n        tokio::time::sleep(std::time::Duration::from_micros(100)).await;\n    }\n\n    let timeout = std::time::Duration::from_secs(10);\n    for handle in handles {\n        let result = tokio::time::timeout(timeout, handle).await;\n        assert!(result.is_ok(), \"Request timed out\");\n        let join_result = result.unwrap();\n        assert!(join_result.is_ok(), \"Task panicked\");\n    }\n\n    // Verify all were processed\n    let execution_order = EXECUTION_ORDER.lock().unwrap();\n    assert_eq!(\n        execution_order.len(),\n        num_requests,\n        \"All writes should have been processed\"\n    );\n\n    // Note: We can't guarantee exact order due to channel timing,\n    // but we verify all requests completed without crashes or hangs\n}\n\n/// Test multiple sequential continuations from a single write request.\n/// This simulates a handler that needs multiple async IO operations.\n#[tokio::test]\nasync fn test_write_multiple_continuations_in_sequence() {\n    use std::sync::atomic::{AtomicUsize, Ordering};\n\n    static CONTINUATION_COUNT: AtomicUsize = AtomicUsize::new(0);\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_multi_cont_handler_2272": {
      "name": "multi_cont_handler",
      "type": "function",
      "start_line": 2272,
      "end_line": 2357,
      "content_hash": "7b1add133fe691a7a5f4d63cbce73f83587dcbf9",
      "content": "    fn multi_cont_handler(_input: HandlerInput) -> Result<Response, GraphError> {\n        Err(IoContFn::create_err(move |cont_tx, ret_chan| {\n            Box::pin(async move {\n                // First async operation\n                tokio::time::sleep(std::time::Duration::from_millis(5)).await;\n                CONTINUATION_COUNT.fetch_add(1, Ordering::SeqCst);\n\n                // Send final continuation\n                cont_tx\n                    .send_async((\n                        ret_chan,\n                        Box::new(move || {\n                            CONTINUATION_COUNT.fetch_add(1, Ordering::SeqCst);\n                            Ok(Response {\n                                body: b\"multi_cont_done\".to_vec(),\n                                fmt: Format::Json,\n                            })\n                        }) as Box<dyn FnOnce() -> Result<Response, GraphError> + Send + Sync>,\n                    ))\n                    .await\n                    .expect(\"cont channel should be alive\");\n            })\n        }))\n    }\n\n    // Reset counter\n    CONTINUATION_COUNT.store(0, Ordering::SeqCst);\n\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\n        \"multi_cont\".to_string(),\n        Arc::new(multi_cont_handler) as Arc<_>,\n    );\n\n    let mut write_routes = std::collections::HashSet::new();\n    write_routes.insert(\"multi_cont\".to_string());\n\n    let router = Arc::new(HelixRouter::new(Some(routes), None, Some(write_routes)));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(2)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = Arc::new(WorkerPool::new(core_setter, graph, router, rt));\n\n    let request = Request {\n        name: \"multi_cont\".to_string(),\n        req_type: RequestType::Query,\n        body: Bytes::new(),\n        in_fmt: Format::Json,\n        out_fmt: Format::Json,\n        api_key: None,\n    };\n\n    let timeout = std::time::Duration::from_secs(5);\n    let result = tokio::time::timeout(timeout, pool.process(request)).await;\n\n    assert!(result.is_ok(), \"Request timed out\");\n    let response = result.unwrap();\n    assert!(response.is_ok(), \"Request failed: {:?}\", response);\n    assert_eq!(response.unwrap().body, b\"multi_cont_done\".to_vec());\n\n    // Verify both continuation phases executed\n    assert_eq!(\n        CONTINUATION_COUNT.load(Ordering::SeqCst),\n        2,\n        \"Both continuation phases should have executed\"\n    );\n}\n\n/// Test mixed read and write requests with continuations running concurrently.\n#[tokio::test]\nasync fn test_mixed_read_write_with_continuations() {\n    use std::sync::atomic::{AtomicUsize, Ordering};\n\n    static READ_CONT_COUNT: AtomicUsize = AtomicUsize::new(0);\n    static WRITE_CONT_COUNT: AtomicUsize = AtomicUsize::new(0);\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_io_read_handler_2358": {
      "name": "io_read_handler",
      "type": "function",
      "start_line": 2358,
      "end_line": 2378,
      "content_hash": "47bc1456a62fab85691b675d3177b57267ada39e",
      "content": "    fn io_read_handler(_input: HandlerInput) -> Result<Response, GraphError> {\n        Err(IoContFn::create_err(move |cont_tx, ret_chan| {\n            Box::pin(async move {\n                tokio::time::sleep(std::time::Duration::from_millis(10)).await;\n                cont_tx\n                    .send_async((\n                        ret_chan,\n                        Box::new(move || {\n                            READ_CONT_COUNT.fetch_add(1, Ordering::SeqCst);\n                            Ok(Response {\n                                body: b\"read_done\".to_vec(),\n                                fmt: Format::Json,\n                            })\n                        }) as Box<dyn FnOnce() -> Result<Response, GraphError> + Send + Sync>,\n                    ))\n                    .await\n                    .expect(\"cont channel should be alive\");\n            })\n        }))\n    }\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_io_write_handler_2379": {
      "name": "io_write_handler",
      "type": "function",
      "start_line": 2379,
      "end_line": 2500,
      "content_hash": "ebd065e65d9c767366ce68532a1498ee6d853d9c",
      "content": "    fn io_write_handler(_input: HandlerInput) -> Result<Response, GraphError> {\n        Err(IoContFn::create_err(move |cont_tx, ret_chan| {\n            Box::pin(async move {\n                tokio::time::sleep(std::time::Duration::from_millis(10)).await;\n                cont_tx\n                    .send_async((\n                        ret_chan,\n                        Box::new(move || {\n                            WRITE_CONT_COUNT.fetch_add(1, Ordering::SeqCst);\n                            Ok(Response {\n                                body: b\"write_done\".to_vec(),\n                                fmt: Format::Json,\n                            })\n                        }) as Box<dyn FnOnce() -> Result<Response, GraphError> + Send + Sync>,\n                    ))\n                    .await\n                    .expect(\"cont channel should be alive\");\n            })\n        }))\n    }\n\n    // Reset counters\n    READ_CONT_COUNT.store(0, Ordering::SeqCst);\n    WRITE_CONT_COUNT.store(0, Ordering::SeqCst);\n\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\n        \"io_read_mixed\".to_string(),\n        Arc::new(io_read_handler) as Arc<_>,\n    );\n    routes.insert(\n        \"io_write_mixed\".to_string(),\n        Arc::new(io_write_handler) as Arc<_>,\n    );\n\n    let mut write_routes = std::collections::HashSet::new();\n    write_routes.insert(\"io_write_mixed\".to_string());\n\n    let router = Arc::new(HelixRouter::new(Some(routes), None, Some(write_routes)));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(4)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = Arc::new(WorkerPool::new(core_setter, graph, router, rt));\n\n    let num_reads = 15;\n    let num_writes = 15;\n    let mut handles = vec![];\n\n    // Interleave read and write requests\n    for i in 0..(num_reads + num_writes) {\n        let pool_clone = Arc::clone(&pool);\n        let is_write = i % 2 == 0 && (i / 2) < num_writes;\n        let route_name = if is_write {\n            \"io_write_mixed\"\n        } else {\n            \"io_read_mixed\"\n        };\n\n        let handle = tokio::spawn(async move {\n            let request = Request {\n                name: route_name.to_string(),\n                req_type: RequestType::Query,\n                body: Bytes::new(),\n                in_fmt: Format::Json,\n                out_fmt: Format::Json,\n                api_key: None,\n            };\n            pool_clone.process(request).await\n        });\n        handles.push(handle);\n    }\n\n    let timeout = std::time::Duration::from_secs(15);\n    let mut success_count = 0;\n\n    for handle in handles {\n        let result = tokio::time::timeout(timeout, handle).await;\n        assert!(result.is_ok(), \"Request timed out\");\n        let join_result = result.unwrap();\n        assert!(join_result.is_ok(), \"Task panicked\");\n        let response = join_result.unwrap();\n        assert!(response.is_ok(), \"Request failed: {:?}\", response);\n        success_count += 1;\n    }\n\n    assert_eq!(success_count, num_reads + num_writes);\n\n    let read_count = READ_CONT_COUNT.load(Ordering::SeqCst);\n    let write_count = WRITE_CONT_COUNT.load(Ordering::SeqCst);\n\n    assert!(\n        read_count > 0,\n        \"Some read continuations should have been processed\"\n    );\n    assert!(\n        write_count > 0,\n        \"Some write continuations should have been processed\"\n    );\n    assert_eq!(\n        read_count + write_count,\n        num_reads + num_writes,\n        \"All continuations should have been processed\"\n    );\n}\n\n/// Stress test: Many parallel writes with continuations to ensure no crashes or hangs.\n#[tokio::test]\nasync fn test_stress_parallel_writes_with_continuations() {\n    use std::sync::atomic::{AtomicUsize, Ordering};\n\n    static SUCCESS_COUNT: AtomicUsize = AtomicUsize::new(0);\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_stress_write_handler_2501": {
      "name": "stress_write_handler",
      "type": "function",
      "start_line": 2501,
      "end_line": 2601,
      "content_hash": "9aa39c6875269e928b54e7008259bff8603a241a",
      "content": "    fn stress_write_handler(_input: HandlerInput) -> Result<Response, GraphError> {\n        Err(IoContFn::create_err(move |cont_tx, ret_chan| {\n            Box::pin(async move {\n                // Random delay to stress test timing\n                let delay = rand::random::<u64>() % 10 + 1;\n                tokio::time::sleep(std::time::Duration::from_millis(delay)).await;\n\n                cont_tx\n                    .send_async((\n                        ret_chan,\n                        Box::new(move || {\n                            SUCCESS_COUNT.fetch_add(1, Ordering::SeqCst);\n                            Ok(Response {\n                                body: b\"stress_ok\".to_vec(),\n                                fmt: Format::Json,\n                            })\n                        }) as Box<dyn FnOnce() -> Result<Response, GraphError> + Send + Sync>,\n                    ))\n                    .await\n                    .expect(\"cont channel should be alive\");\n            })\n        }))\n    }\n\n    // Reset counter\n    SUCCESS_COUNT.store(0, Ordering::SeqCst);\n\n    let (graph, _temp_dir) = create_test_graph();\n    let mut routes = std::collections::HashMap::new();\n    routes.insert(\n        \"stress_write\".to_string(),\n        Arc::new(stress_write_handler) as Arc<_>,\n    );\n\n    let mut write_routes = std::collections::HashSet::new();\n    write_routes.insert(\"stress_write\".to_string());\n\n    let router = Arc::new(HelixRouter::new(Some(routes), None, Some(write_routes)));\n\n    let rt = Arc::new(\n        tokio::runtime::Builder::new_multi_thread()\n            .worker_threads(8)\n            .enable_all()\n            .build()\n            .unwrap(),\n    );\n\n    let cores = vec![core_affinity::CoreId { id: 0 }];\n    let core_setter = Arc::new(CoreSetter::new(cores, 2));\n\n    let pool = Arc::new(WorkerPool::new(core_setter, graph, router, rt));\n\n    // Fire off 100 parallel write requests\n    let num_requests = 100;\n    let mut handles = vec![];\n\n    for _ in 0..num_requests {\n        let pool_clone = Arc::clone(&pool);\n        let handle = tokio::spawn(async move {\n            let request = Request {\n                name: \"stress_write\".to_string(),\n                req_type: RequestType::Query,\n                body: Bytes::new(),\n                in_fmt: Format::Json,\n                out_fmt: Format::Json,\n                api_key: None,\n            };\n            pool_clone.process(request).await\n        });\n        handles.push(handle);\n    }\n\n    let timeout = std::time::Duration::from_secs(30);\n    let mut completed = 0;\n\n    for handle in handles {\n        let result = tokio::time::timeout(timeout, handle).await;\n        assert!(\n            result.is_ok(),\n            \"Stress test request timed out after {} completed\",\n            completed\n        );\n        let join_result = result.unwrap();\n        assert!(join_result.is_ok(), \"Task panicked after {} completed\", completed);\n        let response = join_result.unwrap();\n        assert!(\n            response.is_ok(),\n            \"Request failed after {} completed: {:?}\",\n            completed,\n            response\n        );\n        completed += 1;\n    }\n\n    assert_eq!(completed, num_requests);\n    assert_eq!(\n        SUCCESS_COUNT.load(Ordering::SeqCst),\n        num_requests,\n        \"All stress test continuations should have completed\"\n    );\n}",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}