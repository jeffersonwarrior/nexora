{
  "file_path": "/work/internal/agent/tools/grep.go",
  "file_hash": "b1e8bef5b6075e235673781113b86bc4bcf57d19",
  "updated_at": "2025-12-26T17:34:21.055661",
  "symbols": {
    "struct_regexCache_26": {
      "name": "regexCache",
      "type": "struct",
      "start_line": 26,
      "end_line": 31,
      "content_hash": "31a7d56fcf83bf7c0f1939d3d4333999a113846e",
      "content": "type regexCache struct {\n\tcache map[string]*regexp.Regexp\n\tmu    sync.RWMutex\n}\n\n// newRegexCache creates a new regex cache",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_newRegexCache_32": {
      "name": "newRegexCache",
      "type": "function",
      "start_line": 32,
      "end_line": 38,
      "content_hash": "b266a4ed33ff646eec8f79478da6c4ac0e156f19",
      "content": "func newRegexCache() *regexCache {\n\treturn &regexCache{\n\t\tcache: make(map[string]*regexp.Regexp),\n\t}\n}\n\n// get retrieves a compiled regex from cache or compiles and caches it",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_get_39": {
      "name": "get",
      "type": "method",
      "start_line": 39,
      "end_line": 74,
      "content_hash": "765a37c8bfd389b5327e8f1c66a35475c3449fa3",
      "content": "func (rc *regexCache) get(pattern string) (*regexp.Regexp, error) {\n\t// Try to get from cache first (read lock)\n\trc.mu.RLock()\n\tif regex, exists := rc.cache[pattern]; exists {\n\t\trc.mu.RUnlock()\n\t\treturn regex, nil\n\t}\n\trc.mu.RUnlock()\n\n\t// Compile the regex (write lock)\n\trc.mu.Lock()\n\tdefer rc.mu.Unlock()\n\n\t// Double-check in case another goroutine compiled it while we waited\n\tif regex, exists := rc.cache[pattern]; exists {\n\t\treturn regex, nil\n\t}\n\n\t// Compile and cache the regex\n\tregex, err := regexp.Compile(pattern)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\trc.cache[pattern] = regex\n\treturn regex, nil\n}\n\n// Global regex cache instances\nvar (\n\tsearchRegexCache = newRegexCache()\n\tglobRegexCache   = newRegexCache()\n\t// Pre-compiled regex for glob conversion (used frequently)\n\tglobBraceRegex = regexp.MustCompile(`\\{([^}]+)\\}`)\n)\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "struct_GrepParams_75": {
      "name": "GrepParams",
      "type": "struct",
      "start_line": 75,
      "end_line": 81,
      "content_hash": "f7053a070aa0a0654d541937d1ecdb043aaeab3f",
      "content": "type GrepParams struct {\n\tPattern     string `json:\"pattern\" description:\"The regex pattern to search for in file contents\"`\n\tPath        string `json:\"path,omitempty\" description:\"The directory to search in. Defaults to the current working directory.\"`\n\tInclude     string `json:\"include,omitempty\" description:\"File pattern to include in the search (e.g. \\\"*.js\\\", \\\"*.{ts,tsx}\\\")\"`\n\tLiteralText bool   `json:\"literal_text,omitempty\" description:\"If true, the pattern will be treated as literal text with special regex characters escaped. Default is false.\"`\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "struct_grepMatch_82": {
      "name": "grepMatch",
      "type": "struct",
      "start_line": 82,
      "end_line": 89,
      "content_hash": "f115a761fdd6f286f15e8c85b56f5220ae37e666",
      "content": "type grepMatch struct {\n\tpath     string\n\tmodTime  time.Time\n\tlineNum  int\n\tcharNum  int\n\tlineText string\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "struct_GrepResponseMetadata_90": {
      "name": "GrepResponseMetadata",
      "type": "struct",
      "start_line": 90,
      "end_line": 103,
      "content_hash": "45a3fcdb13825591b0ed9c2b5c82acf6d74e3142",
      "content": "type GrepResponseMetadata struct {\n\tNumberOfMatches int  `json:\"number_of_matches\"`\n\tTruncated       bool `json:\"truncated\"`\n}\n\nconst (\n\tGrepToolName        = \"grep\"\n\tmaxGrepContentWidth = 500\n)\n\n//go:embed grep.md\nvar grepDescription []byte\n\n// escapeRegexPattern escapes special regex characters so they're treated as literal characters",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_escapeRegexPattern_104": {
      "name": "escapeRegexPattern",
      "type": "function",
      "start_line": 104,
      "end_line": 114,
      "content_hash": "6fa56558e1f1bec8ba2735b725265abf392e485f",
      "content": "func escapeRegexPattern(pattern string) string {\n\tspecialChars := []string{\"\\\\\", \".\", \"+\", \"*\", \"?\", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \"^\", \"$\", \"|\"}\n\tescaped := pattern\n\n\tfor _, char := range specialChars {\n\t\tescaped = strings.ReplaceAll(escaped, char, \"\\\\\"+char)\n\t}\n\n\treturn escaped\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_NewGrepTool_115": {
      "name": "NewGrepTool",
      "type": "function",
      "start_line": 115,
      "end_line": 194,
      "content_hash": "820e93773ee5936de63540e9b0c56c8cb9d07541",
      "content": "func NewGrepTool(workingDir string) fantasy.AgentTool {\n\treturn fantasy.NewAgentTool(\n\t\tGrepToolName,\n\t\tstring(grepDescription),\n\t\tfunc(ctx context.Context, params GrepParams, call fantasy.ToolCall) (fantasy.ToolResponse, error) {\n\t\t\tif params.Pattern == \"\" {\n\t\t\t\treturn fantasy.NewTextErrorResponse(\"pattern is required\"), nil\n\t\t\t}\n\n\t\t\t// If literal_text is true, escape the pattern\n\t\t\tsearchPattern := params.Pattern\n\t\t\tif params.LiteralText {\n\t\t\t\tsearchPattern = escapeRegexPattern(params.Pattern)\n\t\t\t}\n\n\t\t\tsearchPath := params.Path\n\t\t\tif searchPath == \"\" {\n\t\t\t\tsearchPath = workingDir\n\t\t\t}\n\n\t\t\t// Create a child context with timeout for the entire search operation\n\t\t\tsearchCtx, cancel := context.WithTimeout(ctx, 90*time.Second)\n\t\t\tdefer cancel()\n\n\t\t\tmatches, truncated, err := searchFiles(searchCtx, searchPattern, searchPath, params.Include, 100)\n\t\t\tif err != nil {\n\t\t\t\tif searchCtx.Err() == context.DeadlineExceeded {\n\t\t\t\t\treturn fantasy.NewTextErrorResponse(\"search timed out after 90 seconds - the search area may be too large or contain problematic files\"), nil\n\t\t\t\t}\n\t\t\t\tif searchCtx.Err() == context.Canceled {\n\t\t\t\t\treturn fantasy.NewTextErrorResponse(\"search was cancelled\"), nil\n\t\t\t\t}\n\t\t\t\treturn fantasy.NewTextErrorResponse(fmt.Sprintf(\"error searching files: %v\", err)), nil\n\t\t\t}\n\n\t\t\tvar output strings.Builder\n\t\t\tif len(matches) == 0 {\n\t\t\t\toutput.WriteString(\"No files found\")\n\t\t\t} else {\n\t\t\t\tfmt.Fprintf(&output, \"Found %d matches\\n\", len(matches))\n\n\t\t\t\tcurrentFile := \"\"\n\t\t\t\tfor _, match := range matches {\n\t\t\t\t\tif currentFile != match.path {\n\t\t\t\t\t\tif currentFile != \"\" {\n\t\t\t\t\t\t\toutput.WriteString(\"\\n\")\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcurrentFile = match.path\n\t\t\t\t\t\tfmt.Fprintf(&output, \"%s:\\n\", filepath.ToSlash(match.path))\n\t\t\t\t\t}\n\t\t\t\t\tif match.lineNum > 0 {\n\t\t\t\t\t\tlineText := match.lineText\n\t\t\t\t\t\tif len(lineText) > maxGrepContentWidth {\n\t\t\t\t\t\t\tlineText = lineText[:maxGrepContentWidth] + \"...\"\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif match.charNum > 0 {\n\t\t\t\t\t\t\tfmt.Fprintf(&output, \"  Line %d, Char %d: %s\\n\", match.lineNum, match.charNum, lineText)\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tfmt.Fprintf(&output, \"  Line %d: %s\\n\", match.lineNum, lineText)\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tfmt.Fprintf(&output, \"  %s\\n\", match.path)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif truncated {\n\t\t\t\t\toutput.WriteString(\"\\n(Results are truncated. Consider using a more specific path or pattern.)\")\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn fantasy.WithResponseMetadata(\n\t\t\t\tfantasy.NewTextResponse(output.String()),\n\t\t\t\tGrepResponseMetadata{\n\t\t\t\t\tNumberOfMatches: len(matches),\n\t\t\t\t\tTruncated:       truncated,\n\t\t\t\t},\n\t\t\t), nil\n\t\t})\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_searchFiles_195": {
      "name": "searchFiles",
      "type": "function",
      "start_line": 195,
      "end_line": 215,
      "content_hash": "13c489a61d7d2348d14986518fe7cc8b6910295b",
      "content": "func searchFiles(ctx context.Context, pattern, rootPath, include string, limit int) ([]grepMatch, bool, error) {\n\tmatches, err := searchWithRipgrep(ctx, pattern, rootPath, include)\n\tif err != nil {\n\t\tmatches, err = searchFilesWithRegex(pattern, rootPath, include)\n\t\tif err != nil {\n\t\t\treturn nil, false, err\n\t\t}\n\t}\n\n\tsort.Slice(matches, func(i, j int) bool {\n\t\treturn matches[i].modTime.After(matches[j].modTime)\n\t})\n\n\ttruncated := len(matches) > limit\n\tif truncated {\n\t\tmatches = matches[:limit]\n\t}\n\n\treturn matches, truncated, nil\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_searchWithRipgrep_216": {
      "name": "searchWithRipgrep",
      "type": "function",
      "start_line": 216,
      "end_line": 299,
      "content_hash": "89cb2dbbff6c9ecd49907a35d3bcbab5f5087658",
      "content": "func searchWithRipgrep(ctx context.Context, pattern, path, include string) ([]grepMatch, error) {\n\t// Create timeout context specifically for ripgrep command\n\tripgrepCtx, cancel := context.WithTimeout(ctx, 30*time.Second)\n\tdefer cancel()\n\n\tcmd := getRgSearchCmd(ripgrepCtx, pattern, path, include)\n\tif cmd == nil {\n\t\treturn nil, fmt.Errorf(\"ripgrep not found in $PATH\")\n\t}\n\n\t// Set safer parameters\n\tcmd.Args = append(cmd.Args, \"--max-filesize\", \"50M\")\n\tcmd.Args = append(cmd.Args, \"--max-columns\", \"500\")\n\n\t// Only add ignore files if they exist\n\tfor _, ignoreFile := range []string{\".gitignore\", \".nexoraignore\"} {\n\t\tignorePath := filepath.Join(path, ignoreFile)\n\t\tif _, err := os.Stat(ignorePath); err == nil {\n\t\t\tcmd.Args = append(cmd.Args, \"--ignore-file\", ignorePath)\n\t\t}\n\t}\n\n\t// Use a separate goroutine to handle the command with timeout\n\tdone := make(chan struct{})\n\tvar (\n\t\toutput []byte\n\t\terr    error\n\t)\n\n\tgo func() {\n\t\tdefer close(done)\n\t\toutput, err = cmd.Output()\n\t}()\n\n\t// Wait for either completion, timeout, or cancellation\n\tselect {\n\tcase <-done:\n\t\t// Command completed normally\n\tcase <-ripgrepCtx.Done():\n\t\t// Context was cancelled or timed out\n\t\tif cmd.Process != nil {\n\t\t\t_ = cmd.Process.Kill() // Force kill the process\n\t\t}\n\t\treturn nil, fmt.Errorf(\"ripgrep search %w\", ripgrepCtx.Err())\n\t}\n\n\tif err != nil {\n\t\tif exitErr, ok := err.(*exec.ExitError); ok && exitErr.ExitCode() == 1 {\n\t\t\treturn []grepMatch{}, nil\n\t\t}\n\t\treturn nil, err\n\t}\n\n\tvar matches []grepMatch\n\tfor line := range bytes.SplitSeq(bytes.TrimSpace(output), []byte{'\\n'}) {\n\t\tif len(line) == 0 {\n\t\t\tcontinue\n\t\t}\n\t\tvar match ripgrepMatch\n\t\tif err := json.Unmarshal(line, &match); err != nil {\n\t\t\tcontinue\n\t\t}\n\t\tif match.Type != \"match\" {\n\t\t\tcontinue\n\t\t}\n\t\tfor _, m := range match.Data.Submatches {\n\t\t\tfi, err := os.Stat(match.Data.Path.Text)\n\t\t\tif err != nil {\n\t\t\t\tcontinue // Skip files we can't access\n\t\t\t}\n\t\t\tmatches = append(matches, grepMatch{\n\t\t\t\tpath:     match.Data.Path.Text,\n\t\t\t\tmodTime:  fi.ModTime(),\n\t\t\t\tlineNum:  match.Data.LineNumber,\n\t\t\t\tcharNum:  m.Start + 1, // ensure 1-based\n\t\t\t\tlineText: strings.TrimSpace(match.Data.Lines.Text),\n\t\t\t})\n\t\t\t// only get the first match of each line\n\t\t\tbreak\n\t\t}\n\t}\n\treturn matches, nil\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "struct_ripgrepMatch_300": {
      "name": "ripgrepMatch",
      "type": "struct",
      "start_line": 300,
      "end_line": 315,
      "content_hash": "04d8a34cf37524c5236cf60a1cffc24ebc07109b",
      "content": "type ripgrepMatch struct {\n\tType string `json:\"type\"`\n\tData struct {\n\t\tPath struct {\n\t\t\tText string `json:\"text\"`\n\t\t} `json:\"path\"`\n\t\tLines struct {\n\t\t\tText string `json:\"text\"`\n\t\t} `json:\"lines\"`\n\t\tLineNumber int `json:\"line_number\"`\n\t\tSubmatches []struct {\n\t\t\tStart int `json:\"start\"`\n\t\t} `json:\"submatches\"`\n\t} `json:\"data\"`\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_searchFilesWithRegex_316": {
      "name": "searchFilesWithRegex",
      "type": "function",
      "start_line": 316,
      "end_line": 323,
      "content_hash": "b9e0e7a0b201924cd9812a257e8aa8b4e8ea5126",
      "content": "func searchFilesWithRegex(pattern, rootPath, include string) ([]grepMatch, error) {\n\tctx, cancel := context.WithTimeout(context.Background(), 60*time.Second)\n\tdefer cancel()\n\n\treturn searchFilesWithRegexContext(ctx, pattern, rootPath, include)\n}\n\n// Separate function that accepts context",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_searchFilesWithRegexContext_324": {
      "name": "searchFilesWithRegexContext",
      "type": "function",
      "start_line": 324,
      "end_line": 419,
      "content_hash": "26439cffda04a01ad1776c0b04c7be15906e0700",
      "content": "func searchFilesWithRegexContext(ctx context.Context, pattern, rootPath, include string) ([]grepMatch, error) {\n\tmatches := []grepMatch{}\n\n\t// Use cached regex compilation\n\tregex, err := searchRegexCache.get(pattern)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"invalid regex pattern: %w\", err)\n\t}\n\n\tvar includePattern *regexp.Regexp\n\tif include != \"\" {\n\t\tregexPattern := globToRegex(include)\n\t\tincludePattern, err = globRegexCache.get(regexPattern)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"invalid include pattern: %w\", err)\n\t\t}\n\t}\n\n\t// Create walker with gitignore and nexoraignore support\n\twalker := fsext.NewFastGlobWalker(rootPath)\n\n\terr = filepath.Walk(rootPath, func(path string, info os.FileInfo, err error) error {\n\t\t// Check context cancellation first\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t}\n\n\t\tif err != nil {\n\t\t\treturn nil // Skip errors\n\t\t}\n\n\t\tif info.IsDir() {\n\t\t\t// Check if directory should be skipped\n\t\t\tif walker.ShouldSkip(path) {\n\t\t\t\treturn filepath.SkipDir\n\t\t\t}\n\t\t\treturn nil // Continue into directory\n\t\t}\n\n\t\t// Use walker's shouldSkip method for files\n\t\tif walker.ShouldSkip(path) {\n\t\t\treturn nil\n\t\t}\n\n\t\t// Skip hidden files (starting with a dot) to match ripgrep's default behavior\n\t\tbase := filepath.Base(path)\n\t\tif base != \".\" && strings.HasPrefix(base, \".\") {\n\t\t\treturn nil\n\t\t}\n\n\t\t// Skip very large files\n\t\tif info.Size() > 50*1024*1024 { // 50MB\n\t\t\treturn nil\n\t\t}\n\n\t\tif includePattern != nil && !includePattern.MatchString(path) {\n\t\t\treturn nil\n\t\t}\n\n\t\t// Check file with timeout\n\t\tfileCtx, fileCancel := context.WithTimeout(ctx, 5*time.Second)\n\t\tmatch, lineNum, charNum, lineText, err := fileContainsPatternWithContext(fileCtx, path, regex)\n\t\tfileCancel()\n\n\t\tif err != nil {\n\t\t\treturn nil // Skip files we can't read\n\t\t}\n\n\t\tif match {\n\t\t\tmatches = append(matches, grepMatch{\n\t\t\t\tpath:     path,\n\t\t\t\tmodTime:  info.ModTime(),\n\t\t\t\tlineNum:  lineNum,\n\t\t\t\tcharNum:  charNum,\n\t\t\t\tlineText: lineText,\n\t\t\t})\n\n\t\t\tif len(matches) >= 200 {\n\t\t\t\treturn filepath.SkipAll\n\t\t\t}\n\t\t}\n\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\tif ctx.Err() == context.DeadlineExceeded {\n\t\t\treturn nil, fmt.Errorf(\"file walk timed out after 60 seconds\")\n\t\t}\n\t\treturn nil, err\n\t}\n\n\treturn matches, nil\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_fileContainsPattern_420": {
      "name": "fileContainsPattern",
      "type": "function",
      "start_line": 420,
      "end_line": 425,
      "content_hash": "92950fb412b05105d96e4550542669cbc3c2760b",
      "content": "func fileContainsPattern(filePath string, pattern *regexp.Regexp) (bool, int, int, string, error) {\n\treturn fileContainsPatternWithContext(context.Background(), filePath, pattern)\n}\n\n// fileContainsMultiLinePattern searches for a pattern that may span multiple lines\n// This is used for edit validation where the old_string might be a multi-line block",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_fileContainsMultiLinePattern_426": {
      "name": "fileContainsMultiLinePattern",
      "type": "function",
      "start_line": 426,
      "end_line": 470,
      "content_hash": "22cfc689cbc804da9c7600ea26f898a1bf8973fc",
      "content": "func fileContainsMultiLinePattern(filePath string, pattern *regexp.Regexp) (bool, int, int, string, error) {\n\t// Only search text files.\n\tif !isTextFile(filePath) {\n\t\treturn false, 0, 0, \"\", nil\n\t}\n\n\tcontent, err := os.ReadFile(filePath)\n\tif err != nil {\n\t\treturn false, 0, 0, \"\", err\n\t}\n\n\t// Convert to string for regex matching\n\tfileContent := string(content)\n\n\t// Find the pattern in the entire content\n\tloc := pattern.FindStringIndex(fileContent)\n\tif loc == nil {\n\t\treturn false, 0, 0, \"\", nil\n\t}\n\n\t// Find the line numbers where the match starts and ends\n\tlines := strings.Split(fileContent, \"\\n\")\n\tstartLine := 0\n\tendLine := 0\n\tcharPos := 0\n\n\tfor i, line := range lines {\n\t\tlineLength := len(line) + 1 // +1 for newline character\n\t\tif charPos <= loc[0] && loc[0] < charPos+lineLength {\n\t\t\tstartLine = i + 1 // 1-based line number\n\t\t}\n\t\tif charPos <= loc[1] && loc[1] < charPos+lineLength {\n\t\t\tendLine = i + 1 // 1-based line number\n\t\t}\n\t\tcharPos += lineLength\n\t}\n\n\t// Get the actual matched text\n\tmatchedText := fileContent[loc[0]:loc[1]]\n\n\treturn true, startLine, endLine, matchedText, nil\n}\n\n// ValidateEditString confirms that old_string exists in the file before edit\n// Returns error with detailed information if the pattern is not found or found multiple times",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_ValidateEditString_471": {
      "name": "ValidateEditString",
      "type": "function",
      "start_line": 471,
      "end_line": 513,
      "content_hash": "e2cbdcd7202340f896cc3fc93d3594527ee98526",
      "content": "func ValidateEditString(filePath string, oldString string, replaceAll bool) error {\n\tif oldString == \"\" {\n\t\treturn nil // No validation needed for empty old_string (file creation)\n\t}\n\n\t// Create a literal pattern that matches the exact string\n\tpattern := regexp.MustCompile(regexp.QuoteMeta(oldString))\n\n\t// First try multi-line pattern matching for edit operations\n\tfound, _, _, _, err := fileContainsMultiLinePattern(filePath, pattern)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to validate edit string in file %s: %w\", filePath, err)\n\t}\n\n\tif !found {\n\t\treturn fmt.Errorf(\"old_string not found in file %s\", filePath)\n\t}\n\n\tif !replaceAll {\n\t\t// Check for multiple occurrences using multi-line search\n\t\t// Read the entire file content to count occurrences\n\t\tcontent, err := os.ReadFile(filePath)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to read file for multiple occurrence check: %w\", err)\n\t\t}\n\n\t\tfileContent := string(content)\n\t\toccurrences := pattern.FindAllStringIndex(fileContent, -1)\n\n\t\tif len(occurrences) > 1 {\n\t\t\t// Get a sample of the second occurrence for the error message\n\t\t\tsampleText := fileContent[occurrences[1][0]:occurrences[1][1]]\n\t\t\t// Count lines to the second occurrence\n\t\t\tlines := strings.Split(fileContent[:occurrences[1][0]], \"\\n\")\n\t\t\treturn fmt.Errorf(\"old_string appears multiple times in file %s. Found at line %d: %s\",\n\t\t\t\tfilePath, len(lines), strings.TrimSpace(sampleText))\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// fileContainsPatternFromLine starts searching from a specific line number",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_fileContainsPatternFromLine_514": {
      "name": "fileContainsPatternFromLine",
      "type": "function",
      "start_line": 514,
      "end_line": 541,
      "content_hash": "c12494c95f8539267a867cf10c0ae0035f7fb104",
      "content": "func fileContainsPatternFromLine(filePath string, pattern *regexp.Regexp, startLine int) (bool, int, int, string, error) {\n\tfile, err := os.Open(filePath)\n\tif err != nil {\n\t\treturn false, 0, 0, \"\", err\n\t}\n\tdefer file.Close()\n\n\tscanner := bufio.NewScanner(file)\n\tlineNum := 0\n\n\tfor scanner.Scan() {\n\t\tlineNum++\n\t\tif lineNum < startLine {\n\t\t\tcontinue // Skip lines before startLine\n\t\t}\n\n\t\tlineContent := scanner.Text()\n\t\tif pattern.MatchString(lineContent) {\n\t\t\tcolIndex := pattern.FindStringIndex(lineContent)\n\t\t\tif len(colIndex) > 0 {\n\t\t\t\treturn true, lineNum, colIndex[0], lineContent, nil\n\t\t\t}\n\t\t}\n\t}\n\n\treturn false, 0, 0, \"\", nil\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_fileContainsPatternWithContext_542": {
      "name": "fileContainsPatternWithContext",
      "type": "function",
      "start_line": 542,
      "end_line": 579,
      "content_hash": "38e1b4bac21f45ee2b4e940d4f38bcbfe3111bd3",
      "content": "func fileContainsPatternWithContext(ctx context.Context, filePath string, pattern *regexp.Regexp) (bool, int, int, string, error) {\n\t// Only search text files.\n\tif !isTextFile(filePath) {\n\t\treturn false, 0, 0, \"\", nil\n\t}\n\n\tfile, err := os.Open(filePath)\n\tif err != nil {\n\t\treturn false, 0, 0, \"\", err\n\t}\n\tdefer file.Close()\n\n\t// Use scanner with buffer size limits to handle very long lines\n\tscanner := bufio.NewScanner(file)\n\tbuffer := make([]byte, 0, 64*1024) // 64KB initial buffer\n\tscanner.Buffer(buffer, 1024*1024)  // Max 1MB per line\n\n\tlineNum := 0\n\tfor scanner.Scan() {\n\t\t// Check context cancellation frequently\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn false, 0, 0, \"\", ctx.Err()\n\t\tdefault:\n\t\t}\n\n\t\tlineNum++\n\t\tline := scanner.Text()\n\t\tif loc := pattern.FindStringIndex(line); loc != nil {\n\t\t\tcharNum := loc[0] + 1\n\t\t\treturn true, lineNum, charNum, line, nil\n\t\t}\n\t}\n\n\treturn false, 0, 0, \"\", scanner.Err()\n}\n\n// isTextFile checks if a file is a text file by examining its MIME type.",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_isTextFile_580": {
      "name": "isTextFile",
      "type": "function",
      "start_line": 580,
      "end_line": 604,
      "content_hash": "af7868e9025f3873ccea389d7e611c7d63d5d171",
      "content": "func isTextFile(filePath string) bool {\n\tfile, err := os.Open(filePath)\n\tif err != nil {\n\t\treturn false\n\t}\n\tdefer file.Close()\n\n\t// Read first 512 bytes for MIME type detection.\n\tbuffer := make([]byte, 512)\n\tn, err := file.Read(buffer)\n\tif err != nil && err != io.EOF {\n\t\treturn false\n\t}\n\n\t// Detect content type.\n\tcontentType := http.DetectContentType(buffer[:n])\n\n\t// Check if it's a text MIME type.\n\treturn strings.HasPrefix(contentType, \"text/\") ||\n\t\tcontentType == \"application/json\" ||\n\t\tcontentType == \"application/xml\" ||\n\t\tcontentType == \"application/javascript\" ||\n\t\tcontentType == \"application/x-sh\"\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_globToRegex_605": {
      "name": "globToRegex",
      "type": "function",
      "start_line": 605,
      "end_line": 617,
      "content_hash": "764ff443be385d34c8fe3b7e27d48150e5dc959e",
      "content": "func globToRegex(glob string) string {\n\tregexPattern := strings.ReplaceAll(glob, \".\", \"\\\\.\")\n\tregexPattern = strings.ReplaceAll(regexPattern, \"*\", \".*\")\n\tregexPattern = strings.ReplaceAll(regexPattern, \"?\", \".\")\n\n\t// Use pre-compiled regex instead of compiling each time\n\tregexPattern = globBraceRegex.ReplaceAllStringFunc(regexPattern, func(match string) string {\n\t\tinner := match[1 : len(match)-1]\n\t\treturn \"(\" + strings.ReplaceAll(inner, \",\", \"|\") + \")\"\n\t})\n\n\treturn regexPattern\n}",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}