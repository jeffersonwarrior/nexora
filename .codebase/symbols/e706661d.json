{
  "file_path": "/work/context-engine/scripts/memory_restore.py",
  "file_hash": "5597c0c9bfdd0a912c31548664c599b77d7b0420",
  "updated_at": "2025-12-26T17:34:23.316342",
  "symbols": {
    "function_get_qdrant_client_48": {
      "name": "get_qdrant_client",
      "type": "function",
      "start_line": 48,
      "end_line": 53,
      "content_hash": "879aa7743f523b2a5158e0e5a71abe2b7992363f",
      "content": "def get_qdrant_client() -> QdrantClient:\n    \"\"\"Initialize Qdrant client with environment configuration.\"\"\"\n    qdrant_url = os.environ.get(\"QDRANT_URL\", \"http://localhost:6333\")\n    api_key = os.environ.get(\"QDRANT_API_KEY\")\n\n    return QdrantClient(url=qdrant_url, api_key=api_key or None)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_get_embedding_model_56": {
      "name": "get_embedding_model",
      "type": "function",
      "start_line": 56,
      "end_line": 69,
      "content_hash": "f60e06a0ae7a70c4466fa8b760a34af426c7efa2",
      "content": "def get_embedding_model(model_name: str):\n    \"\"\"Initialize embedding model with Qwen3 support via embedder factory.\"\"\"\n    # Try centralized embedder factory first (supports Qwen3 feature flag)\n    if _EMBEDDER_FACTORY:\n        return _get_embedding_model(model_name)\n    # Fallback to direct fastembed\n    if TextEmbedding is not None:\n        try:\n            return TextEmbedding(model_name=model_name)\n        except Exception as e:\n            raise RuntimeError(f\"Failed to load embedding model '{model_name}': {e}\")\n    raise RuntimeError(\n        \"No embedding model available. Install fastembed: pip install fastembed\"\n    )",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_ensure_collection_exists_72": {
      "name": "ensure_collection_exists",
      "type": "function",
      "start_line": 72,
      "end_line": 110,
      "content_hash": "27790180cdad437f4bbb8d7e773a49e099c6a4d0",
      "content": "def ensure_collection_exists(\n    client: QdrantClient,\n    collection_name: str,\n    vector_dimension: int,\n    vector_name: str = \"memory\"\n) -> None:\n    \"\"\"\n    Ensure the target collection exists with appropriate vector configuration.\n\n    Args:\n        client: Qdrant client instance\n        collection_name: Collection name\n        vector_dimension: Vector dimensions for memories\n        vector_name: Name for the memory vector\n    \"\"\"\n    try:\n        # Check if collection exists\n        collections = client.get_collections().collections\n        if collection_name in [c.name for c in collections]:\n            print(f\"Collection '{collection_name}' already exists\")\n            return\n    except Exception as e:\n        print(f\"Warning: Could not check collection existence: {e}\")\n\n    # Create collection with memory vector\n    try:\n        client.create_collection(\n            collection_name=collection_name,\n            vectors_config={\n                vector_name: VectorParams(\n                    size=vector_dimension,\n                    distance=Distance.COSINE\n                )\n            },\n            hnsw_config=HnswConfigDiff(m=16, ef_construct=256),\n        )\n        print(f\"Created collection '{collection_name}' with {vector_dimension}-dim vectors\")\n    except Exception as e:\n        raise RuntimeError(f\"Failed to create collection '{collection_name}': {e}\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_restore_memories_113": {
      "name": "restore_memories",
      "type": "function",
      "start_line": 113,
      "end_line": 314,
      "content_hash": "81459aa6dcbf860f0e1b381472192100846322a1",
      "content": "def restore_memories(\n    backup_file: str,\n    collection_name: str,\n    client: Optional[QdrantClient] = None,\n    embedding_model_name: Optional[str] = None,\n    vector_name: str = \"memory\",\n    batch_size: int = 100,\n    skip_existing: bool = True,\n    skip_collection_creation: bool = False\n) -> Dict[str, Any]:\n    \"\"\"\n    Restore memories from backup file to Qdrant collection.\n\n    Args:\n        backup_file: Path to backup JSON file\n        collection_name: Target collection name\n        client: Qdrant client instance (will create if None)\n        embedding_model_name: Model name for re-embedding (if vectors not in backup)\n        vector_name: Name for the memory vector in collection\n        batch_size: Number of memories to upload per batch\n        skip_existing: Skip memories that already exist in collection\n        skip_collection_creation: Skip collection creation (useful when collection is already configured)\n\n    Returns:\n        Dict with restore statistics\n    \"\"\"\n    if client is None:\n        client = get_qdrant_client()\n\n    # Load backup file\n    backup_path = Path(backup_file)\n    if not backup_path.exists():\n        raise FileNotFoundError(f\"Backup file not found: {backup_file}\")\n\n    try:\n        with open(backup_path, 'r') as f:\n            backup_data = json.load(f)\n    except Exception as e:\n        raise ValueError(f\"Invalid backup file format: {e}\")\n\n    # Validate backup structure\n    if \"memories\" not in backup_data:\n        raise ValueError(\"Invalid backup file: missing 'memories' section\")\n\n    memories = backup_data[\"memories\"]\n    backup_info = backup_data.get(\"backup_info\", {})\n\n    print(f\"Restoring memories from: {backup_file}\")\n    print(f\"Target collection: {collection_name}\")\n    print(f\"Memories in backup: {len(memories)}\")\n\n    if backup_info:\n        print(f\"Original collection: {backup_info.get('collection_name', 'unknown')}\")\n        print(f\"Backup date: {backup_info.get('export_date', 'unknown')}\")\n        print(f\"Vector dimension: {backup_info.get('vector_dimension', 'unknown')}\")\n\n    # Determine vector configuration\n    vectors_included = backup_info.get(\"include_vectors\", True) and memories and \"vector\" in memories[0]\n\n    if not vectors_included:\n        if not embedding_model_name:\n            # Use default model\n            embedding_model_name = os.environ.get(\"EMBEDDING_MODEL\", \"BAAI/bge-base-en-v1.5\")\n\n        print(f\"Vectors not included in backup, will re-embed with: {embedding_model_name}\")\n        embedding_model = get_embedding_model(embedding_model_name)\n\n        # Get vector dimension from model\n        test_vector = next(embedding_model.embed([\"test\"])).tolist()\n        vector_dimension = len(test_vector)\n        print(f\"Embedding model vector dimension: {vector_dimension}\")\n    else:\n        # Use dimension from backup\n        vector_dimension = backup_info.get(\"vector_dimension\", len(memories[0][\"vector\"]))\n        embedding_model = None\n        print(f\"Using vectors from backup, dimension: {vector_dimension}\")\n\n    # Ensure collection exists (unless skipped)\n    if not skip_collection_creation:\n        ensure_collection_exists(client, collection_name, vector_dimension, vector_name)\n    else:\n        print(f\"Skipping collection creation for '{collection_name}' (as requested)\")\n\n        # Verify collection actually exists when skipping creation\n        try:\n            client.get_collection(collection_name)\n            print(f\"Confirmed collection '{collection_name}' exists\")\n        except Exception:\n            raise RuntimeError(f\"Collection '{collection_name}' does not exist but creation was skipped\")\n\n    # Check for existing memories if skip_existing is True\n    existing_ids = set()\n    if skip_existing:\n        try:\n            # Get all existing point IDs\n            all_points, _ = client.scroll(\n                collection_name=collection_name,\n                limit=None,\n                with_payload=False,\n                with_vectors=False\n            )\n            existing_ids = {str(point.id) for point in all_points}\n            print(f\"Found {len(existing_ids)} existing points in collection\")\n        except Exception as e:\n            print(f\"Warning: Could not check existing points: {e}\")\n            skip_existing = False\n\n    # Process and upload memories in batches\n    restored_count = 0\n    skipped_count = 0\n    error_count = 0\n\n    for i in range(0, len(memories), batch_size):\n        batch = memories[i:i + batch_size]\n        batch_points = []\n\n        for memory in batch:\n            raw_id = memory.get(\"id\", \"\")\n\n            # Qdrant HTTP API expects point IDs to be either an unsigned integer\n            # or a UUID string. Backups store IDs as strings, so we convert\n            # purely numeric IDs back to integers to match the original type.\n            memory_id = raw_id\n            try:\n                if isinstance(raw_id, str) and raw_id.isdigit():\n                    memory_id = int(raw_id)\n            except Exception:\n                memory_id = raw_id\n\n            # Skip if already exists\n            if skip_existing and memory_id in existing_ids:\n                skipped_count += 1\n                continue\n\n            try:\n                # Prepare vector\n                if vectors_included:\n                    vector = memory.get(\"vector\")\n                    if not vector:\n                        raise ValueError(\"Memory missing vector data\")\n                    # Vector from backup is already in the correct format: {\"memory\": [values]}\n                else:\n                    # Re-embed content\n                    content = memory.get(\"content\", \"\")\n                    if not content:\n                        raise ValueError(\"Memory missing content for embedding\")\n\n                    vector = next(embedding_model.embed([content])).tolist()\n                    # For re-embedded vectors, we need to structure them with the vector name\n                    vector = {vector_name: vector}\n\n                # Prepare point data\n                point_data = {\n                    \"id\": memory_id,\n                    \"vector\": vector,\n                    \"payload\": {\n                        \"information\": memory.get(\"content\", \"\"),\n                        \"metadata\": memory.get(\"metadata\", {})\n                    }\n                }\n\n                batch_points.append(point_data)\n\n            except Exception as e:\n                print(f\"Error processing memory {memory_id}: {e}\")\n                error_count += 1\n                continue\n\n        # Upload batch\n        if batch_points:\n            try:\n                client.upsert(collection_name=collection_name, points=batch_points)\n                restored_count += len(batch_points)\n                print(f\"  Uploaded batch {i//batch_size + 1}: +{len(batch_points)} memories (total: {restored_count})\")\n            except Exception as e:\n                print(f\"Error uploading batch {i//batch_size + 1}: {e}\")\n                error_count += len(batch_points)\n\n    # Final statistics\n    print(f\"\\n Memory restore completed!\")\n    print(f\"   Total memories in backup: {len(memories)}\")\n    print(f\"   Successfully restored: {restored_count}\")\n    print(f\"   Skipped (already exists): {skipped_count}\")\n    print(f\"   Errors: {error_count}\")\n    print(f\"   Target collection: {collection_name}\")\n\n    # Verify final count\n    try:\n        final_count = client.count(collection_name).count\n        print(f\"   Final collection size: {final_count:,} points\")\n    except Exception as e:\n        print(f\"   Warning: Could not get final count: {e}\")\n\n    return {\n        \"collection\": collection_name,\n        \"backup_file\": backup_file,\n        \"total_memories\": len(memories),\n        \"restored\": restored_count,\n        \"skipped\": skipped_count,\n        \"errors\": error_count,\n        \"success\": True\n    }",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_main_317": {
      "name": "main",
      "type": "function",
      "start_line": 317,
      "end_line": 423,
      "content_hash": "a0e41d6e7ad8a8e46a4d1e7c734169e82fe0a0ed",
      "content": "def main():\n    parser = argparse.ArgumentParser(\n        description=\"Restore memories from backup to Qdrant collections\",\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        epilog=\"\"\"\nExamples:\n  %(prog)s --backup memories_backup.json --collection test-repo-58ecbbc8\n  %(prog)s --backup memories_backup.json --collection new-test-repo --embedding-model BAAI/bge-large-en-v1.5\n  %(prog)s --backup memories_backup.json --collection new-collection --new-collection --no-skip-existing\n        \"\"\"\n    )\n\n    parser.add_argument(\n        \"--backup\", \"-b\",\n        required=True,\n        help=\"Path to backup JSON file\"\n    )\n\n    parser.add_argument(\n        \"--collection\", \"-c\",\n        required=True,\n        help=\"Target Qdrant collection name\"\n    )\n\n    parser.add_argument(\n        \"--embedding-model\", \"-m\",\n        help=\"Embedding model for re-embedding (if vectors not in backup)\"\n    )\n\n    parser.add_argument(\n        \"--vector-name\",\n        default=\"memory\",\n        help=\"Name for the memory vector in collection (default: memory)\"\n    )\n\n    parser.add_argument(\n        \"--batch-size\",\n        type=int,\n        default=100,\n        help=\"Number of memories to upload per batch (default: 100)\"\n    )\n\n    parser.add_argument(\n        \"--no-skip-existing\",\n        action=\"store_true\",\n        help=\"Don't skip memories that already exist in collection\"\n    )\n\n    parser.add_argument(\n        \"--list-backup-info\",\n        action=\"store_true\",\n        help=\"Show backup file information without restoring\"\n    )\n\n    parser.add_argument(\n        \"--skip-collection-creation\",\n        action=\"store_true\",\n        help=\"Skip collection creation (useful when collection is already configured by other processes)\"\n    )\n\n    args = parser.parse_args()\n\n    try:\n        # Load backup to show info\n        with open(args.backup, 'r') as f:\n            backup_data = json.load(f)\n\n        if args.list_backup_info:\n            print(\"Backup Information:\")\n            print(\"=\" * 50)\n            backup_info = backup_data.get(\"backup_info\", {})\n            for key, value in backup_info.items():\n                print(f\"  {key}: {value}\")\n\n            memories = backup_data.get(\"memories\", [])\n            print(f\"  Memory count: {len(memories)}\")\n\n            if memories:\n                sample = memories[0]\n                has_vector = \"vector\" in sample\n                print(f\"  Has vectors: {has_vector}\")\n                if has_vector:\n                    vector_dim = len(sample[\"vector\"])\n                    print(f\"  Vector dimension: {vector_dim}\")\n\n            return\n\n        # Restore memories\n        result = restore_memories(\n            backup_file=args.backup,\n            collection_name=args.collection,\n            embedding_model_name=args.embedding_model,\n            vector_name=args.vector_name,\n            batch_size=args.batch_size,\n            skip_existing=not args.no_skip_existing,\n            skip_collection_creation=args.skip_collection_creation\n        )\n\n        if result[\"success\"]:\n            print(f\"\\n  Memory restoration completed successfully!\")\n        else:\n            print(f\"\\n  Memory restoration failed!\")\n            sys.exit(1)\n\n    except Exception as e:\n        print(f\"\\n  Error during restoration: {e}\")\n        sys.exit(1)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}