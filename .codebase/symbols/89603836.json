{
  "file_path": "/work/external-deps/helix-db/helix-db/src/helix_engine/bm25/bm25.rs",
  "file_hash": "3018316d6cf01e07a12c97d1ea25b5d53a03e758",
  "updated_at": "2025-12-26T17:34:24.026212",
  "symbols": {
    "struct_BM25Metadata_27": {
      "name": "BM25Metadata",
      "type": "struct",
      "start_line": 27,
      "end_line": 35,
      "content_hash": "2f349dbf34ba3880958a2626946a919ec0d16bba",
      "content": "pub struct BM25Metadata {\n    pub total_docs: u64,\n    pub avgdl: f64,\n    pub k1: f32, // controls term frequency saturation\n    pub b: f32,  // controls document length normalization\n}\n\n/// For inverted index\n#[derive(Serialize, Deserialize, Clone, Debug)]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "struct_PostingListEntry_36": {
      "name": "PostingListEntry",
      "type": "struct",
      "start_line": 36,
      "end_line": 40,
      "content_hash": "743c995c173d04de23af6103c9cfb8b09010a7ca",
      "content": "pub struct PostingListEntry {\n    pub doc_id: u128,\n    pub term_frequency: u32,\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "trait_BM25_41": {
      "name": "BM25",
      "type": "trait",
      "start_line": 41,
      "end_line": 43,
      "content_hash": "c9a4104fe4e59bdf5d2e649c964e3cb9c624bda4",
      "content": "pub trait BM25 {\n    fn tokenize<const SHOULD_FILTER: bool>(&self, text: &str) -> Vec<String>;\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_insert_doc_44": {
      "name": "insert_doc",
      "type": "function",
      "start_line": 44,
      "end_line": 45,
      "content_hash": "7db97685b89b8ed023b3b1bd6cb6f34a9f291bc0",
      "content": "    fn insert_doc(&self, txn: &mut RwTxn, doc_id: u128, doc: &str) -> Result<(), GraphError>;\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_delete_doc_46": {
      "name": "delete_doc",
      "type": "function",
      "start_line": 46,
      "end_line": 47,
      "content_hash": "007efd340b1d310ee7cfcaf7c1d2a91800de2fbc",
      "content": "    fn delete_doc(&self, txn: &mut RwTxn, doc_id: u128) -> Result<(), GraphError>;\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_update_doc_48": {
      "name": "update_doc",
      "type": "function",
      "start_line": 48,
      "end_line": 50,
      "content_hash": "8a10977a95b529ad9105661a17e5edf1395ac0de",
      "content": "    fn update_doc(&self, txn: &mut RwTxn, doc_id: u128, doc: &str) -> Result<(), GraphError>;\n\n    /// Calculate the BM25 score for a single term of a query (no sum)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_calculate_bm25_score_51": {
      "name": "calculate_bm25_score",
      "type": "function",
      "start_line": 51,
      "end_line": 59,
      "content_hash": "c13d4bfce4758cba90ca38699e4d46117710ac58",
      "content": "    fn calculate_bm25_score(\n        &self,\n        tf: u32,         // term frequency\n        doc_len: u32,    // document length\n        df: u32,         // document frequency\n        total_docs: u64, // total documents\n        avgdl: f64,      // average document length\n    ) -> f32;\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_search_60": {
      "name": "search",
      "type": "function",
      "start_line": 60,
      "end_line": 68,
      "content_hash": "eb5ca929279549b8273ba26c5ee5d0b6f3779e93",
      "content": "    fn search(\n        &self,\n        txn: &RoTxn,\n        query: &str,\n        limit: usize,\n        arena: &Bump,\n    ) -> Result<Vec<(u128, f32)>, GraphError>;\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "struct_HBM25Config_69": {
      "name": "HBM25Config",
      "type": "struct",
      "start_line": 69,
      "end_line": 78,
      "content_hash": "cde66de528a85985aec90abdf19711994c081c79",
      "content": "pub struct HBM25Config {\n    pub graph_env: Env,\n    pub inverted_index_db: Database<Bytes, Bytes>,\n    pub doc_lengths_db: Database<U128<heed3::byteorder::BE>, U32<heed3::byteorder::BE>>,\n    pub term_frequencies_db: Database<Bytes, U32<heed3::byteorder::BE>>,\n    pub metadata_db: Database<Bytes, Bytes>,\n    k1: f64,\n    b: f64,\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "impl_HBM25Config_79": {
      "name": "HBM25Config",
      "type": "impl",
      "start_line": 79,
      "end_line": 79,
      "content_hash": "a84684af955d62d219a95a71d2f9d89ff7475e69",
      "content": "impl HBM25Config {",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_new_80": {
      "name": "new",
      "type": "method",
      "start_line": 80,
      "end_line": 117,
      "content_hash": "b9dcf44b418dea7e23c0244d817c97d302d8a08c",
      "content": "    pub fn new(graph_env: &Env, wtxn: &mut RwTxn) -> Result<HBM25Config, GraphError> {\n        let inverted_index_db: Database<Bytes, Bytes> = graph_env\n            .database_options()\n            .types::<Bytes, Bytes>()\n            .flags(heed3::DatabaseFlags::DUP_SORT)\n            .name(DB_BM25_INVERTED_INDEX)\n            .create(wtxn)?;\n\n        let doc_lengths_db: Database<U128<heed3::byteorder::BE>, U32<heed3::byteorder::BE>> =\n            graph_env\n                .database_options()\n                .types::<U128<heed3::byteorder::BE>, U32<heed3::byteorder::BE>>()\n                .name(DB_BM25_DOC_LENGTHS)\n                .create(wtxn)?;\n\n        let term_frequencies_db: Database<Bytes, U32<heed3::byteorder::BE>> = graph_env\n            .database_options()\n            .types::<Bytes, U32<heed3::byteorder::BE>>()\n            .name(DB_BM25_TERM_FREQUENCIES)\n            .create(wtxn)?;\n\n        let metadata_db: Database<Bytes, Bytes> = graph_env\n            .database_options()\n            .types::<Bytes, Bytes>()\n            .name(DB_BM25_METADATA)\n            .create(wtxn)?;\n\n        Ok(HBM25Config {\n            graph_env: graph_env.clone(),\n            inverted_index_db,\n            doc_lengths_db,\n            term_frequencies_db,\n            metadata_db,\n            k1: 1.2,\n            b: 0.75,\n        })\n    }\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_new_temp_118": {
      "name": "new_temp",
      "type": "method",
      "start_line": 118,
      "end_line": 160,
      "content_hash": "2f9fa6b9d3e3395c7d443b8b1a6e959ca732af81",
      "content": "    pub fn new_temp(\n        graph_env: &Env,\n        wtxn: &mut RwTxn,\n        uuid: &str,\n    ) -> Result<HBM25Config, GraphError> {\n        let inverted_index_db: Database<Bytes, Bytes> = graph_env\n            .database_options()\n            .types::<Bytes, Bytes>()\n            .flags(heed3::DatabaseFlags::DUP_SORT)\n            .name(format!(\"{DB_BM25_INVERTED_INDEX}_{uuid}\").as_str())\n            .create(wtxn)?;\n\n        let doc_lengths_db: Database<U128<heed3::byteorder::BE>, U32<heed3::byteorder::BE>> =\n            graph_env\n                .database_options()\n                .types::<U128<heed3::byteorder::BE>, U32<heed3::byteorder::BE>>()\n                .name(format!(\"{DB_BM25_DOC_LENGTHS}_{uuid}\").as_str())\n                .create(wtxn)?;\n\n        let term_frequencies_db: Database<Bytes, U32<heed3::byteorder::BE>> = graph_env\n            .database_options()\n            .types::<Bytes, U32<heed3::byteorder::BE>>()\n            .name(format!(\"{DB_BM25_TERM_FREQUENCIES}_{uuid}\").as_str())\n            .create(wtxn)?;\n\n        let metadata_db: Database<Bytes, Bytes> = graph_env\n            .database_options()\n            .types::<Bytes, Bytes>()\n            .name(format!(\"{DB_BM25_METADATA}_{uuid}\").as_str())\n            .create(wtxn)?;\n\n        Ok(HBM25Config {\n            graph_env: graph_env.clone(),\n            inverted_index_db,\n            doc_lengths_db,\n            term_frequencies_db,\n            metadata_db,\n            k1: 1.2,\n            b: 0.75,\n        })\n    }\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "impl_BM25_161": {
      "name": "BM25",
      "type": "impl",
      "start_line": 161,
      "end_line": 172,
      "content_hash": "5852f2760e11378d7da70fd7e274e51380ed56ed",
      "content": "impl BM25 for HBM25Config {\n    /// Converts text to lowercase, removes non-alphanumeric chars, splits into words\n    fn tokenize<const SHOULD_FILTER: bool>(&self, text: &str) -> Vec<String> {\n        text.to_lowercase()\n            .split(|c: char| !c.is_alphanumeric())\n            .filter(|s| !s.is_empty())\n            .filter_map(|s| (!SHOULD_FILTER || s.len() > 2).then_some(s.to_string()))\n            .collect()\n    }\n\n    /// Inserts needed information into doc_lengths_db, inverted_index_db, term_frequencies_db, and\n    /// metadata_db",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_insert_doc_173": {
      "name": "insert_doc",
      "type": "method",
      "start_line": 173,
      "end_line": 223,
      "content_hash": "90220ee440b0f0881ff430eb5fe5258c326298e2",
      "content": "    fn insert_doc(&self, txn: &mut RwTxn, doc_id: u128, doc: &str) -> Result<(), GraphError> {\n        let tokens = self.tokenize::<true>(doc);\n        let doc_length = tokens.len() as u32;\n\n        let mut term_counts: HashMap<String, u32> = HashMap::new();\n        for token in tokens {\n            *term_counts.entry(token).or_insert(0) += 1;\n        }\n\n        self.doc_lengths_db.put(txn, &doc_id, &doc_length)?;\n\n        for (term, tf) in term_counts {\n            let term_bytes = term.as_bytes();\n\n            let posting_entry = PostingListEntry {\n                doc_id,\n                term_frequency: tf,\n            };\n\n            let posting_bytes = bincode::serialize(&posting_entry)?;\n\n            self.inverted_index_db\n                .put(txn, term_bytes, &posting_bytes)?;\n\n            let current_df = self.term_frequencies_db.get(txn, term_bytes)?.unwrap_or(0);\n            self.term_frequencies_db\n                .put(txn, term_bytes, &(current_df + 1))?;\n        }\n\n        let mut metadata = if let Some(data) = self.metadata_db.get(txn, METADATA_KEY)? {\n            bincode::deserialize::<BM25Metadata>(data)?\n        } else {\n            BM25Metadata {\n                total_docs: 0,\n                avgdl: 0.0,\n                k1: 1.2,\n                b: 0.75,\n            }\n        };\n\n        let old_total_docs = metadata.total_docs;\n        metadata.total_docs += 1;\n        metadata.avgdl = (metadata.avgdl * old_total_docs as f64 + doc_length as f64)\n            / metadata.total_docs as f64;\n\n        let metadata_bytes = bincode::serialize(&metadata)?;\n        self.metadata_db.put(txn, METADATA_KEY, &metadata_bytes)?;\n\n        Ok(())\n    }\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_delete_doc_224": {
      "name": "delete_doc",
      "type": "method",
      "start_line": 224,
      "end_line": 299,
      "content_hash": "010041ef23c88ef9edcae7425730962f63116a83",
      "content": "    fn delete_doc(&self, txn: &mut RwTxn, doc_id: u128) -> Result<(), GraphError> {\n        let terms_to_update = {\n            let mut terms = Vec::new();\n            let mut iter = self.inverted_index_db.iter(txn)?;\n\n            while let Some((term_bytes, posting_bytes)) = iter.next().transpose()? {\n                let posting: PostingListEntry = bincode::deserialize(posting_bytes)?;\n                if posting.doc_id == doc_id {\n                    terms.push(term_bytes.to_vec());\n                }\n            }\n            terms\n        };\n\n        // remove postings and update term frequencies\n        for term_bytes in terms_to_update {\n            // collect entries to keep\n            let entries_to_keep = {\n                let mut entries = Vec::new();\n                if let Some(duplicates) = self.inverted_index_db.get_duplicates(txn, &term_bytes)? {\n                    for result in duplicates {\n                        let (_, posting_bytes) = result?;\n                        let posting: PostingListEntry = bincode::deserialize(posting_bytes)?;\n                        if posting.doc_id != doc_id {\n                            entries.push(posting_bytes.to_vec());\n                        }\n                    }\n                }\n                entries\n            };\n\n            // delete all entries for this term\n            self.inverted_index_db.delete(txn, &term_bytes)?;\n\n            // re-add the entries we want to keep\n            for entry_bytes in entries_to_keep {\n                self.inverted_index_db.put(txn, &term_bytes, &entry_bytes)?;\n            }\n\n            let current_df = self.term_frequencies_db.get(txn, &term_bytes)?.unwrap_or(0);\n            if current_df > 0 {\n                self.term_frequencies_db\n                    .put(txn, &term_bytes, &(current_df - 1))?;\n            }\n        }\n\n        let doc_length = self.doc_lengths_db.get(txn, &doc_id)?.unwrap_or(0);\n\n        self.doc_lengths_db.delete(txn, &doc_id)?;\n\n        let metadata_data = self\n            .metadata_db\n            .get(txn, METADATA_KEY)?\n            .map(|data| data.to_vec());\n\n        if let Some(data) = metadata_data {\n            let mut metadata: BM25Metadata = bincode::deserialize(&data)?;\n            if metadata.total_docs > 0 {\n                // update average document length\n                metadata.avgdl = if metadata.total_docs > 1 {\n                    (metadata.avgdl * metadata.total_docs as f64 - doc_length as f64)\n                        / (metadata.total_docs - 1) as f64\n                } else {\n                    0.0\n                };\n                metadata.total_docs -= 1;\n\n                let metadata_bytes = bincode::serialize(&metadata)?;\n                self.metadata_db.put(txn, METADATA_KEY, &metadata_bytes)?;\n            }\n        }\n\n        Ok(())\n    }\n\n    /// Simply delete doc_id and then re-insert new doc with same doc-id",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_update_doc_300": {
      "name": "update_doc",
      "type": "method",
      "start_line": 300,
      "end_line": 304,
      "content_hash": "ae16ad67cf482a1d542bdeab93dd31440259ac65",
      "content": "    fn update_doc(&self, txn: &mut RwTxn, doc_id: u128, doc: &str) -> Result<(), GraphError> {\n        self.delete_doc(txn, doc_id)?;\n        self.insert_doc(txn, doc_id, doc)\n    }\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_calculate_bm25_score_305": {
      "name": "calculate_bm25_score",
      "type": "method",
      "start_line": 305,
      "end_line": 332,
      "content_hash": "93ed788f3c956bd03aca78fdc8aad36797b5b884",
      "content": "    fn calculate_bm25_score(\n        &self,\n        tf: u32,\n        doc_len: u32,\n        df: u32,\n        total_docs: u64,\n        avgdl: f64,\n    ) -> f32 {\n        // ensure we don't have division by zero\n        let df = df.max(1) as f64;\n        let total_docs = total_docs.max(1) as f64;\n\n        // calculate IDF: ln((N - df + 0.5) / (df + 0.5) + 1)\n        // this can be negative when df is high relative to N, which is mathematically correct\n        let idf = (((total_docs - df + 0.5) / (df + 0.5)) + 1.0).ln();\n\n        // ensure avgdl is not zero\n        let avgdl = if avgdl > 0.0 { avgdl } else { doc_len as f64 };\n\n        // calculate BM25 score\n        let tf = tf as f64;\n        let doc_len = doc_len as f64;\n        let tf_component = (tf * (self.k1 + 1.0))\n            / (tf + self.k1 * (1.0 - self.b + self.b * (doc_len.abs() / avgdl)));\n\n        (idf * tf_component) as f32\n    }\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_search_333": {
      "name": "search",
      "type": "method",
      "start_line": 333,
      "end_line": 400,
      "content_hash": "00e68ecda7a6419863027de281d6111557c39729",
      "content": "    fn search(\n        &self,\n        txn: &RoTxn,\n        query: &str,\n        limit: usize,\n        arena: &Bump,\n    ) -> Result<Vec<(u128, f32)>, GraphError> {\n        let query_terms: BVec<BString> = BVec::from_iter_in(\n            self.tokenize::<true>(query)\n                .into_iter()\n                .map(|s| BString::from_str_in(&s, arena)),\n            arena,\n        );\n        // (node uuid, score)\n        let estimated_capacity = (query_terms.len() * 50).min(limit * 4);\n        let mut doc_scores: HashMap<u128, f32> = HashMap::with_capacity(estimated_capacity);\n\n        let metadata = self\n            .metadata_db\n            .get(txn, METADATA_KEY)?\n            .ok_or(GraphError::New(\"BM25 metadata not found\".to_string()))?;\n        let metadata: BM25Metadata = bincode::deserialize(metadata)?;\n\n        // for each query term, calculate scores\n        for term in query_terms {\n            let term_bytes = term.as_bytes();\n\n            let doc_frequency = self.term_frequencies_db.get(txn, term_bytes)?.unwrap_or(0);\n            if doc_frequency == 0 {\n                continue;\n            }\n\n            // Get all documents containing this term\n            if let Some(duplicates) = self.inverted_index_db.get_duplicates(txn, term_bytes)? {\n                for result in duplicates {\n                    let (_, posting_bytes) = result?;\n                    let posting: PostingListEntry = bincode::deserialize(posting_bytes)?;\n\n                    // Get document length\n                    let doc_length = self.doc_lengths_db.get(txn, &posting.doc_id)?.unwrap_or(0);\n\n                    // Calculate BM25 score for this term in this document\n                    let score = self.calculate_bm25_score(\n                        posting.term_frequency,\n                        doc_length,\n                        doc_frequency,\n                        metadata.total_docs,\n                        metadata.avgdl,\n                    );\n\n                    *doc_scores.entry(posting.doc_id).or_insert(0.0) += score;\n                }\n            }\n        }\n\n        // Sort by score and return top results\n        // Pre-allocate with exact capacity to avoid reallocation during collection\n        let mut results: Vec<(u128, f32)> = Vec::with_capacity(doc_scores.len());\n        results.extend(doc_scores);\n        results.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));\n        results.truncate(limit);\n\n        debug_println!(\"found {} results in bm25 search\", results.len());\n\n        Ok(results)\n    }\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "trait_HybridSearch_401": {
      "name": "HybridSearch",
      "type": "trait",
      "start_line": 401,
      "end_line": 402,
      "content_hash": "dc160cb0f6bf1c6bd8482ec6d13f43fa3c0393d3",
      "content": "pub trait HybridSearch {\n    /// Search both hnsw index and bm25 docs",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_hybrid_search_403": {
      "name": "hybrid_search",
      "type": "method",
      "start_line": 403,
      "end_line": 411,
      "content_hash": "6acc4daf2427da6b287919afcf0fc9bb741f289c",
      "content": "    fn hybrid_search(\n        self,\n        query: &str,\n        query_vector: &[f64],\n        alpha: f32,\n        limit: usize,\n    ) -> impl std::future::Future<Output = Result<Vec<(u128, f32)>, GraphError>> + Send;\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "impl_HybridSearch_412": {
      "name": "HybridSearch",
      "type": "impl",
      "start_line": 412,
      "end_line": 487,
      "content_hash": "b5c41952e7cc0c43b96741eead2474b156ccbc75",
      "content": "impl HybridSearch for HelixGraphStorage {\n    async fn hybrid_search(\n        self,\n        query: &str,\n        query_vector: &[f64],\n        alpha: f32,\n        limit: usize,\n    ) -> Result<Vec<(u128, f32)>, GraphError> {\n        let query_owned = query.to_string();\n        let query_vector_owned = query_vector.to_vec();\n\n        let graph_env_bm25 = self.graph_env.clone();\n        let graph_env_vector = self.graph_env.clone();\n\n        let bm25_handle = task::spawn_blocking(move || -> Result<Vec<(u128, f32)>, GraphError> {\n            let txn = graph_env_bm25.read_txn()?;\n            let arena = Bump::new();\n            match self.bm25.as_ref() {\n                Some(s) => s.search(&txn, &query_owned, limit * 2, &arena),\n                None => Err(GraphError::from(\"BM25 not enabled!\")),\n            }\n        });\n\n        let vector_handle =\n            task::spawn_blocking(move || -> Result<Option<Vec<(u128, f64)>>, GraphError> {\n                let txn = graph_env_vector.read_txn()?;\n                let arena = Bump::new(); // MOVE\n                let query_slice = arena.alloc_slice_copy(query_vector_owned.as_slice());\n                let results = self.vectors.search::<fn(&HVector, &RoTxn) -> bool>(\n                    &txn,\n                    query_slice,\n                    limit * 2,\n                    \"vector\",\n                    None,\n                    false,\n                    &arena,\n                )?;\n                let scores = results\n                    .into_iter()\n                    .map(|vec| (vec.id, vec.distance.unwrap_or(0.0)))\n                    .collect::<Vec<(u128, f64)>>();\n                Ok(Some(scores))\n            });\n\n        let (bm25_results, vector_results) = match tokio::try_join!(bm25_handle, vector_handle) {\n            Ok((a, b)) => (a, b),\n            Err(e) => return Err(GraphError::from(e.to_string())),\n        };\n\n        let mut combined_scores: HashMap<u128, f32> = HashMap::new();\n\n        for (doc_id, score) in bm25_results? {\n            combined_scores.insert(doc_id, alpha * score);\n        }\n\n        // correct_score = alpha * bm25_score + (1.0 - alpha) * vector_score\n        if let Some(vector_results) = vector_results? {\n            for (doc_id, score) in vector_results {\n                let similarity = (1.0 / (1.0 + score)) as f32;\n                combined_scores\n                    .entry(doc_id)\n                    .and_modify(|existing_score| *existing_score += (1.0 - alpha) * similarity)\n                    .or_insert((1.0 - alpha) * similarity); // correction made here from score as f32 to similarity\n            }\n        }\n\n        // Pre-allocate with exact capacity to avoid reallocation during collection\n        let mut results = Vec::with_capacity(combined_scores.len());\n        results.extend(combined_scores);\n        results.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));\n        results.truncate(limit);\n\n        Ok(results)\n    }\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "trait_BM25Flatten_488": {
      "name": "BM25Flatten",
      "type": "trait",
      "start_line": 488,
      "end_line": 489,
      "content_hash": "caa19dbbb5c8cfe6acf3fb909ae5d62c51906f7f",
      "content": "pub trait BM25Flatten {\n    /// util func to flatten array of strings to a single string",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_flatten_bm25_490": {
      "name": "flatten_bm25",
      "type": "method",
      "start_line": 490,
      "end_line": 492,
      "content_hash": "869b83b1694256c3eb0acf7d42ad666c9fc27c59",
      "content": "    fn flatten_bm25(&self) -> String;\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "impl_BM25Flatten_493": {
      "name": "BM25Flatten",
      "type": "impl",
      "start_line": 493,
      "end_line": 493,
      "content_hash": "141b8415b08ee9e55da91c8d34ab1bffa2a87d4d",
      "content": "impl BM25Flatten for ImmutablePropertiesMap<'_> {",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_flatten_bm25_494": {
      "name": "flatten_bm25",
      "type": "method",
      "start_line": 494,
      "end_line": 504,
      "content_hash": "ec90a18725f8cf216ad0412b166029edeb06952c",
      "content": "    fn flatten_bm25(&self) -> String {\n        self.iter()\n            .fold(String::with_capacity(self.len() * 4), |mut s, (k, v)| {\n                s.push_str(k);\n                s.push(' ');\n                s.push_str(&v.inner_stringify());\n                s.push(' ');\n                s\n            })\n    }\n}",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}