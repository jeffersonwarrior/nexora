{
  "file_path": "/work/internal/agent/recovery/integration_test.go",
  "file_hash": "bc0ffad5a5519356cf4e18763000212af74ec89a",
  "updated_at": "2025-12-26T17:34:23.915624",
  "symbols": {
    "function_TestRecoverySystemIntegration_15": {
      "name": "TestRecoverySystemIntegration",
      "type": "function",
      "start_line": 15,
      "end_line": 175,
      "content_hash": "c3b4af22afdd760a05a89575bdf5df268c26a8d4",
      "content": "func TestRecoverySystemIntegration(t *testing.T) {\n\tctx := context.Background()\n\n\t// Test 1: File outdated recovery with actual file\n\tt.Run(\"FileOutdatedIntegration\", func(t *testing.T) {\n\t\t// Create a test file\n\t\ttestFile := \"/tmp/test_integration.txt\"\n\t\tinitialContent := \"initial content\"\n\t\terr := os.WriteFile(testFile, []byte(initialContent), 0644)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"Failed to create test file: %v\", err)\n\t\t}\n\t\tdefer os.Remove(testFile)\n\n\t\tregistry := NewRecoveryRegistry()\n\t\texecCtx := &state.AgentExecutionContext{\n\t\t\tRetryCount: 0,\n\t\t\tErrorCount: 0,\n\t\t\tLastError:  nil,\n\t\t}\n\n\t\t// Simulate file outdated error\n\t\tfileErr := NewFileOutdatedError(errors.New(\"file was modified\"), testFile)\n\n\t\t// Attempt recovery\n\t\trecoveryErr := registry.AttemptRecovery(ctx, fileErr, execCtx)\n\t\tif recoveryErr != nil {\n\t\t\tt.Errorf(\"Recovery should succeed: %v\", recoveryErr)\n\t\t}\n\n\t\tif execCtx.RetryCount != 1 {\n\t\t\tt.Errorf(\"Expected retry count 1, got %d\", execCtx.RetryCount)\n\t\t}\n\n\t\tif execCtx.LastError == nil {\n\t\t\tt.Error(\"Last error should be set after recovery\")\n\t\t}\n\t})\n\n\t// Test 2: Edit failed recovery with file operations\n\tt.Run(\"EditFailedIntegration\", func(t *testing.T) {\n\t\ttestFile := \"/tmp/test_edit.txt\"\n\t\tcontent := \"line 1\\nline 2\\nline 3\\n\"\n\t\terr := os.WriteFile(testFile, []byte(content), 0644)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"Failed to create test file: %v\", err)\n\t\t}\n\t\tdefer os.Remove(testFile)\n\n\t\tregistry := NewRecoveryRegistry()\n\t\texecCtx := &state.AgentExecutionContext{\n\t\t\tRetryCount: 0,\n\t\t\tErrorCount: 0,\n\t\t\tLastError:  nil,\n\t\t}\n\n\t\t// Simulate edit failed error\n\t\teditErr := NewEditFailedError(errors.New(\"whitespace mismatch\"), testFile, \"line 2\", \"line 2 updated\")\n\n\t\t// Attempt recovery\n\t\trecoveryErr := registry.AttemptRecovery(ctx, editErr, execCtx)\n\t\tif recoveryErr != nil {\n\t\t\t// Recovery may fail but should provide useful error\n\t\t\tt.Logf(\"Recovery failed as expected: %v\", recoveryErr)\n\t\t}\n\t})\n\n\t// Test 3: Loop detection should halt immediately\n\tt.Run(\"LoopDetectionIntegration\", func(t *testing.T) {\n\t\tregistry := NewRecoveryRegistry()\n\t\texecCtx := &state.AgentExecutionContext{\n\t\t\tRetryCount: 0,\n\t\t\tErrorCount: 0,\n\t\t\tLastError:  nil,\n\t\t}\n\n\t\tloopErr := NewLoopDetectedError(\"recursive processing\", 150)\n\n\t\t// Attempt recovery\n\t\trecoveryErr := registry.AttemptRecovery(ctx, loopErr, execCtx)\n\t\tif recoveryErr == nil {\n\t\t\tt.Error(\"Loop detection should halt execution\")\n\t\t}\n\n\t\t// Retry count should not increase for loops\n\t\tif execCtx.RetryCount > 0 {\n\t\t\tt.Errorf(\"Loop detection should not increment retry count, got %d\", execCtx.RetryCount)\n\t\t}\n\t})\n\n\t// Test 4: Timeout recovery\n\tt.Run(\"TimeoutIntegration\", func(t *testing.T) {\n\t\tregistry := NewRecoveryRegistry()\n\t\texecCtx := &state.AgentExecutionContext{\n\t\t\tRetryCount: 0,\n\t\t\tErrorCount: 0,\n\t\t\tLastError:  nil,\n\t\t}\n\n\t\ttimeoutErr := NewTimeoutError(\"long-running operation\", 5*time.Minute)\n\n\t\t// First recovery attempt\n\t\trecoveryErr := registry.AttemptRecovery(ctx, timeoutErr, execCtx)\n\t\tif recoveryErr == nil {\n\t\t\tt.Error(\"Timeout recovery should provide guidance, not silent success\")\n\t\t}\n\n\t\t// Second attempt should fail due to retry limit\n\t\trecoveryErr = registry.AttemptRecovery(ctx, timeoutErr, execCtx)\n\t\tif recoveryErr == nil {\n\t\t\tt.Error(\"Should fail due to retry limit\")\n\t\t}\n\t})\n\n\t// Test 5: Resource limit recovery\n\tt.Run(\"ResourceLimitIntegration\", func(t *testing.T) {\n\t\tregistry := NewRecoveryRegistry()\n\t\texecCtx := &state.AgentExecutionContext{\n\t\t\tRetryCount: 0,\n\t\t\tErrorCount: 0,\n\t\t\tLastError:  nil,\n\t\t}\n\n\t\t// Test multiple resource types\n\t\tresourceErrs := []error{\n\t\t\tNewResourceLimitError(\"memory\", \"14.2GB\", \"16GB\"),\n\t\t\tNewResourceLimitError(\"cpu\", \"85%\", \"80%\"),\n\t\t\tNewResourceLimitError(\"disk\", \"500MB\", \"1GB\"),\n\t\t}\n\n\t\tfor _, err := range resourceErrs {\n\t\t\trecoveryErr := registry.AttemptRecovery(ctx, err, execCtx)\n\t\t\tif recoveryErr == nil {\n\t\t\t\tt.Error(\"Resource recovery should provide guidance\")\n\t\t\t}\n\t\t}\n\t})\n\n\t// Test 6: Panic recovery\n\tt.Run(\"PanicRecoveryIntegration\", func(t *testing.T) {\n\t\tregistry := NewRecoveryRegistry()\n\t\texecCtx := &state.AgentExecutionContext{\n\t\t\tRetryCount: 0,\n\t\t\tErrorCount: 0,\n\t\t\tLastError:  nil,\n\t\t}\n\n\t\tpanicErr := NewPanicError(errors.New(\"runtime panic: index out of range\"), \"\")\n\n\t\trecoveryErr := registry.AttemptRecovery(ctx, panicErr, execCtx)\n\t\tif recoveryErr == nil {\n\t\t\tt.Error(\"Panic recovery should acknowledge but continue\")\n\t\t}\n\n\t\tif execCtx.LastError == nil {\n\t\t\tt.Error(\"Last error should be set after panic recovery\")\n\t\t}\n\t})\n}\n\n// Test recovery system under load",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_TestRecoverySystemLoad_176": {
      "name": "TestRecoverySystemLoad",
      "type": "function",
      "start_line": 176,
      "end_line": 231,
      "content_hash": "ac95a7d514e42097386b17481457cd5fe6574e4a",
      "content": "func TestRecoverySystemLoad(t *testing.T) {\n\t// Create temp files needed for recovery tests\n\ttmpFile := \"/tmp/test_recovery_load.txt\"\n\tdefer os.Remove(tmpFile)\n\tif err := os.WriteFile(tmpFile, []byte(\"test content\"), 0644); err != nil {\n\t\tt.Fatalf(\"Failed to create temp file: %v\", err)\n\t}\n\n\tctx := context.Background()\n\tregistry := NewRecoveryRegistry()\n\n\t// Simulate concurrent recovery attempts\n\tconst numConcurrent = 10\n\tresults := make(chan error, numConcurrent)\n\n\tfor i := 0; i < numConcurrent; i++ {\n\t\tgo func(id int) {\n\t\t\texecCtx := &state.AgentExecutionContext{\n\t\t\t\tRetryCount: 0,\n\t\t\t\tErrorCount: 0,\n\t\t\t\tLastError:  nil,\n\t\t\t}\n\n\t\t\tvar err error\n\t\t\tswitch id % 6 {\n\t\t\tcase 0:\n\t\t\t\terr = NewFileOutdatedError(errors.New(\"test\"), tmpFile)\n\t\t\tcase 1:\n\t\t\t\terr = NewEditFailedError(errors.New(\"test\"), tmpFile, \"old\", \"new\")\n\t\t\tcase 2:\n\t\t\t\terr = NewLoopDetectedError(\"test\", 100)\n\t\t\tcase 3:\n\t\t\t\terr = NewTimeoutError(\"test\", time.Second)\n\t\t\tcase 4:\n\t\t\t\terr = NewResourceLimitError(\"memory\", \"8GB\", \"16GB\")\n\t\t\tcase 5:\n\t\t\t\terr = NewPanicError(errors.New(\"test panic\"), \"\")\n\t\t\t}\n\n\t\t\tresults <- registry.AttemptRecovery(ctx, err, execCtx)\n\t\t}(i)\n\t}\n\n\t// Collect results\n\tsuccessCount := 0\n\tfor i := 0; i < numConcurrent; i++ {\n\t\terr := <-results\n\t\tif err == nil {\n\t\t\tsuccessCount++\n\t\t}\n\t}\n\n\tt.Logf(\"Load test: %d/%d recoveries succeeded\", successCount, numConcurrent)\n}\n\n// Test statistics tracking",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_TestRecoveryStatistics_232": {
      "name": "TestRecoveryStatistics",
      "type": "function",
      "start_line": 232,
      "end_line": 258,
      "content_hash": "b867b3d238047e89bfacbb5a87069ac82b5b8995",
      "content": "func TestRecoveryStatistics(t *testing.T) {\n\tstats := NewRecoveryStatistics()\n\n\t// Record various recovery attempts\n\tstats.RecordAttempt(\"File Outdated Recovery\", ErrorTypeFileOutdated, true, 1)\n\tstats.RecordAttempt(\"Edit Failed Recovery\", ErrorTypeEditFailed, false, 2)\n\tstats.RecordAttempt(\"Loop Detected Recovery\", ErrorTypeLoopDetected, true, 0)\n\n\t// Verify statistics\n\tif stats.TotalAttempts != 3 {\n\t\tt.Errorf(\"Expected 3 attempts, got %d\", stats.TotalAttempts)\n\t}\n\n\tif stats.SuccessCount != 2 {\n\t\tt.Errorf(\"Expected 2 successes, got %d\", stats.SuccessCount)\n\t}\n\n\tif stats.FailureCount != 1 {\n\t\tt.Errorf(\"Expected 1 failure, got %d\", stats.FailureCount)\n\t}\n\n\tif len(stats.StrategyCounts) != 3 {\n\t\tt.Errorf(\"Expected 3 strategy types, got %d\", len(stats.StrategyCounts))\n\t}\n}\n\n// Test registry diagnostics",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_TestRegistryDiagnostics_259": {
      "name": "TestRegistryDiagnostics",
      "type": "function",
      "start_line": 259,
      "end_line": 291,
      "content_hash": "aa6c9f8753d5e3ec4e795d825a6b19a4895e09e3",
      "content": "func TestRegistryDiagnostics(t *testing.T) {\n\tregistry := NewRecoveryRegistry()\n\n\t// Add custom strategy\n\tcustomStrategy := &CustomTestStrategy{}\n\tregistry.AddStrategy(customStrategy)\n\n\t// Get diagnostics\n\tdiagnostics := registry.GetDiagnostics()\n\n\tif diagnostics.TotalStrategies != 7 { // 6 default + 1 custom\n\t\tt.Errorf(\"Expected 7 strategies, got %d\", diagnostics.TotalStrategies)\n\t}\n\n\tif diagnostics.GlobalMaxAttempts != 3 {\n\t\tt.Errorf(\"Expected max attempts 3, got %d\", diagnostics.GlobalMaxAttempts)\n\t}\n\n\t// Verify strategy name is included\n\tfound := false\n\tfor _, name := range diagnostics.StrategyNames {\n\t\tif name == \"Custom Test Recovery\" {\n\t\t\tfound = true\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif !found {\n\t\tt.Error(\"Custom strategy not found in diagnostics\")\n\t}\n}\n\n// Error propagation test",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_TestErrorPropagation_292": {
      "name": "TestErrorPropagation",
      "type": "function",
      "start_line": 292,
      "end_line": 326,
      "content_hash": "952122d56825cf1443768ff6e3eac4df4a7e3cac",
      "content": "func TestErrorPropagation(t *testing.T) {\n\t// Create temp file for testing\n\ttmpFile := \"/tmp/test_error_propagation.txt\"\n\tdefer os.Remove(tmpFile)\n\tif err := os.WriteFile(tmpFile, []byte(\"test content\"), 0644); err != nil {\n\t\tt.Fatalf(\"Failed to create temp file: %v\", err)\n\t}\n\n\tregistry := NewRecoveryRegistry()\n\tctx := context.Background()\n\texecCtx := &state.AgentExecutionContext{\n\t\tRetryCount: 0,\n\t\tErrorCount: 0,\n\t\tLastError:  nil,\n\t}\n\n\t// Original error should be wrapped, not lost\n\toriginalErr := errors.New(\"something went wrong\")\n\twrappedErr := NewFileOutdatedError(originalErr, tmpFile)\n\n\trecoveryErr := registry.AttemptRecovery(ctx, wrappedErr, execCtx)\n\n\t// Recovery might succeed (nil) or fail with error, both valid\n\tif recoveryErr != nil {\n\t\t// Check that error contains original error information\n\t\tif !strings.Contains(recoveryErr.Error(), originalErr.Error()) {\n\t\t\tt.Errorf(\"Recovery error should contain original error: %v, got: %v\", originalErr, recoveryErr)\n\t\t}\n\t} else {\n\t\t// Successful recovery - verify retry count was incremented\n\t\tif execCtx.RetryCount == 0 {\n\t\t\tt.Error(\"Retry count should be incremented after successful recovery\")\n\t\t}\n\t}\n}",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}