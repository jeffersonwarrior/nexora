{
  "file_path": "/work/external-deps/Context-Engine/scripts/router_eval.py",
  "file_hash": "fac7be0d7c54af312274a351ef654528f87af77a",
  "updated_at": "2025-12-26T17:34:19.725164",
  "symbols": {
    "class_MockMCPHandler_7": {
      "name": "MockMCPHandler",
      "type": "class",
      "start_line": 7,
      "end_line": 107,
      "content_hash": "77e338b4a6d25b79184a9c96b47fbf9ed91e6661",
      "content": "class MockMCPHandler(BaseHTTPRequestHandler):\n    server_version = \"MockMCP/0.1\"\n\n    def _send_json(self, obj: Dict[str, Any], session: str | None = None, code: int = 200):\n        body = json.dumps(obj).encode(\"utf-8\")\n        self.send_response(code)\n        self.send_header(\"Content-Type\", \"application/json\")\n        if session:\n            self.send_header(\"Mcp-Session-Id\", session)\n        self.send_header(\"Content-Length\", str(len(body)))\n        self.end_headers()\n        self.wfile.write(body)\n\n    def do_POST(self):  # noqa: N802\n        raw = self.rfile.read(int(self.headers.get(\"Content-Length\", \"0\") or 0))\n        try:\n            j = json.loads(raw.decode(\"utf-8\", errors=\"ignore\"))\n        except Exception:\n            return self._send_json({\"jsonrpc\": \"2.0\", \"error\": {\"message\": \"bad json\"}}, code=400)\n        method = j.get(\"method\")\n        if method == \"initialize\":\n            # Return session via header; some clients also parse body\n            return self._send_json({\"jsonrpc\": \"2.0\", \"id\": j.get(\"id\"), \"result\": {\"ok\": True, \"server\": self.server.server_name}}, session=\"mock-session\")\n        if method == \"notifications/initialized\":\n            return self._send_json({\"jsonrpc\": \"2.0\", \"result\": {\"ok\": True}})\n        if method == \"tools/list\":\n            # Simulate flakiness once if flagged\n            if getattr(self.server, \"fail_list_once\", False) and not getattr(self.server, \"_fail_list_consumed\", False):\n                setattr(self.server, \"_fail_list_consumed\", True)\n                return self._send_json({\"jsonrpc\": \"2.0\", \"error\": {\"message\": \"flaky list\"}}, code=500)\n            tools = getattr(self.server, \"tools\", [])\n            return self._send_json({\"jsonrpc\": \"2.0\", \"id\": j.get(\"id\"), \"result\": {\"tools\": tools}})\n        if method == \"tools/call\":\n            params = j.get(\"params\") or {}\n            name = (params.get(\"name\") or \"\").strip()\n            args = params.get(\"arguments\") or {}\n            # Indexer tools\n            if name in {\"repo_search\", \"search_config_for\", \"search_tests_for\", \"search_callers_for\", \"search_importers_for\"}:\n                total = int(getattr(self.server, \"search_total\", 5))\n                # Cap returned items to avoid huge payloads; still report full total\n                shown = max(0, min(total, 3))\n                results = [\n                    {\"score\": 0.9 - (i * 0.1), \"path\": f\"/work/README_{i}.md\", \"start_line\": 1, \"end_line\": 2, \"snippet\": \"demo\"}\n                    for i in range(shown)\n                ]\n                res = {\n                    \"result\": {\n                        \"args\": {\n                            \"queries\": [str(args.get(\"query\") or \"\")],\n                            \"limit\": int(args.get(\"limit\") or 8),\n                            \"include_snippet\": bool(args.get(\"include_snippet\") or False),\n                            \"language\": str(args.get(\"language\") or \"\"),\n                            \"under\": str(args.get(\"under\") or \"\"),\n                            \"symbol\": str(args.get(\"symbol\") or \"\"),\n                            \"ext\": str(args.get(\"ext\") or \"\"),\n                            \"compact\": False,\n                        },\n                        \"total\": total,\n                        \"results\": results,\n                        \"ok\": True,\n                        \"code\": 0,\n                        \"stdout\": \"\",\n                        \"stderr\": \"\",\n                    }\n                }\n                return self._send_json({\"jsonrpc\": \"2.0\", \"id\": j.get(\"id\"), \"result\": {\"content\": [{\"type\": \"text\", \"text\": json.dumps(res)}], \"structuredContent\": res, \"isError\": False}})\n            if name == \"context_answer_compat\":\n                # Simulate failure if flagged so router should fall back to context_answer\n                if getattr(self.server, \"fail_context_compat\", False):\n                    return self._send_json({\"jsonrpc\": \"2.0\", \"id\": j.get(\"id\"), \"result\": {\"content\": [{\"type\": \"text\", \"text\": json.dumps({\"error\": \"compat failed\"})}], \"structuredContent\": {\"error\": \"compat failed\"}, \"isError\": True}})\n                # Require nested arguments wrapper\n                if not isinstance(args, dict) or \"arguments\" not in args:\n                    return self._send_json({\"jsonrpc\": \"2.0\", \"id\": j.get(\"id\"), \"result\": {\"content\": [{\"type\": \"text\", \"text\": json.dumps({\"error\": \"compat requires nested arguments\"})}], \"structuredContent\": {\"error\": \"compat requires nested arguments\"}, \"isError\": True}})\n                inner = args.get(\"arguments\") or {}\n                q = str(inner.get(\"query\") or \"\")\n                ans = {\n                    \"answer\": \"Short ok.\" if len(q) < 80 else \"Longer answer\",\n                    \"citations\": [{\"id\": 1, \"path\": \"/work/file.py\", \"start_line\": 1, \"end_line\": 2}],\n                    \"query\": [q],\n                    \"used\": {\"gate_first\": True, \"refrag\": True},\n                }\n                res = {\"result\": ans}\n                return self._send_json({\"jsonrpc\": \"2.0\", \"id\": j.get(\"id\"), \"result\": {\"content\": [{\"type\": \"text\", \"text\": json.dumps(res)}], \"structuredContent\": res, \"isError\": False}})\n            if name == \"context_answer\":\n                q = str(args.get(\"query\") or \"\")\n                ans = {\"answer\": \"Ok.\", \"citations\": []}\n                res = {\"result\": ans}\n                return self._send_json({\"jsonrpc\": \"2.0\", \"id\": j.get(\"id\"), \"result\": {\"content\": [{\"type\": \"text\", \"text\": json.dumps(res)}], \"structuredContent\": res, \"isError\": False}})\n            if name in {\"qdrant_status\", \"qdrant_list\"}:\n                res = {\"result\": {\"ok\": True}}\n                return self._send_json({\"jsonrpc\": \"2.0\", \"id\": j.get(\"id\"), \"result\": {\"content\": [{\"type\": \"text\", \"text\": json.dumps(res)}], \"structuredContent\": res, \"isError\": False}})\n            # Memory tools\n            if name == \"store\":\n                res = {\"result\": {\"ok\": True}}\n                return self._send_json({\"jsonrpc\": \"2.0\", \"id\": j.get(\"id\"), \"result\": {\"content\": [{\"type\": \"text\", \"text\": json.dumps(res)}], \"structuredContent\": res, \"isError\": False}})\n            if name == \"find\":\n                q = str(args.get(\"query\") or \"\")\n                res = {\"result\": {\"ok\": True, \"results\": [{\"information\": \"The MCP indexer uses hybrid search combining dense embeddings and lexical matching with optional reranking\", \"metadata\": {\"category\": \"architecture\"}}], \"count\": 1}}\n                return self._send_json({\"jsonrpc\": \"2.0\", \"id\": j.get(\"id\"), \"result\": {\"content\": [{\"type\": \"text\", \"text\": json.dumps(res)}], \"structuredContent\": res, \"isError\": False}})\n            return self._send_json({\"jsonrpc\": \"2.0\", \"id\": j.get(\"id\"), \"result\": {\"content\": [{\"type\": \"text\", \"text\": json.dumps({\"error\": f\"unknown tool {name}\"})}], \"structuredContent\": {\"error\": f\"unknown tool {name}\"}, \"isError\": True}})\n        return self._send_json({\"jsonrpc\": \"2.0\", \"error\": {\"message\": f\"unknown method {method}\"}}, code=400)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__send_json_10": {
      "name": "_send_json",
      "type": "method",
      "start_line": 10,
      "end_line": 18,
      "content_hash": "05a5cd3ef340d121f5d77072bbc2adf11d070a09",
      "content": "    def _send_json(self, obj: Dict[str, Any], session: str | None = None, code: int = 200):\n        body = json.dumps(obj).encode(\"utf-8\")\n        self.send_response(code)\n        self.send_header(\"Content-Type\", \"application/json\")\n        if session:\n            self.send_header(\"Mcp-Session-Id\", session)\n        self.send_header(\"Content-Length\", str(len(body)))\n        self.end_headers()\n        self.wfile.write(body)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_do_POST_20": {
      "name": "do_POST",
      "type": "method",
      "start_line": 20,
      "end_line": 107,
      "content_hash": "4e4e984574210292995a9c1da11447bcfc4e2c8f",
      "content": "    def do_POST(self):  # noqa: N802\n        raw = self.rfile.read(int(self.headers.get(\"Content-Length\", \"0\") or 0))\n        try:\n            j = json.loads(raw.decode(\"utf-8\", errors=\"ignore\"))\n        except Exception:\n            return self._send_json({\"jsonrpc\": \"2.0\", \"error\": {\"message\": \"bad json\"}}, code=400)\n        method = j.get(\"method\")\n        if method == \"initialize\":\n            # Return session via header; some clients also parse body\n            return self._send_json({\"jsonrpc\": \"2.0\", \"id\": j.get(\"id\"), \"result\": {\"ok\": True, \"server\": self.server.server_name}}, session=\"mock-session\")\n        if method == \"notifications/initialized\":\n            return self._send_json({\"jsonrpc\": \"2.0\", \"result\": {\"ok\": True}})\n        if method == \"tools/list\":\n            # Simulate flakiness once if flagged\n            if getattr(self.server, \"fail_list_once\", False) and not getattr(self.server, \"_fail_list_consumed\", False):\n                setattr(self.server, \"_fail_list_consumed\", True)\n                return self._send_json({\"jsonrpc\": \"2.0\", \"error\": {\"message\": \"flaky list\"}}, code=500)\n            tools = getattr(self.server, \"tools\", [])\n            return self._send_json({\"jsonrpc\": \"2.0\", \"id\": j.get(\"id\"), \"result\": {\"tools\": tools}})\n        if method == \"tools/call\":\n            params = j.get(\"params\") or {}\n            name = (params.get(\"name\") or \"\").strip()\n            args = params.get(\"arguments\") or {}\n            # Indexer tools\n            if name in {\"repo_search\", \"search_config_for\", \"search_tests_for\", \"search_callers_for\", \"search_importers_for\"}:\n                total = int(getattr(self.server, \"search_total\", 5))\n                # Cap returned items to avoid huge payloads; still report full total\n                shown = max(0, min(total, 3))\n                results = [\n                    {\"score\": 0.9 - (i * 0.1), \"path\": f\"/work/README_{i}.md\", \"start_line\": 1, \"end_line\": 2, \"snippet\": \"demo\"}\n                    for i in range(shown)\n                ]\n                res = {\n                    \"result\": {\n                        \"args\": {\n                            \"queries\": [str(args.get(\"query\") or \"\")],\n                            \"limit\": int(args.get(\"limit\") or 8),\n                            \"include_snippet\": bool(args.get(\"include_snippet\") or False),\n                            \"language\": str(args.get(\"language\") or \"\"),\n                            \"under\": str(args.get(\"under\") or \"\"),\n                            \"symbol\": str(args.get(\"symbol\") or \"\"),\n                            \"ext\": str(args.get(\"ext\") or \"\"),\n                            \"compact\": False,\n                        },\n                        \"total\": total,\n                        \"results\": results,\n                        \"ok\": True,\n                        \"code\": 0,\n                        \"stdout\": \"\",\n                        \"stderr\": \"\",\n                    }\n                }\n                return self._send_json({\"jsonrpc\": \"2.0\", \"id\": j.get(\"id\"), \"result\": {\"content\": [{\"type\": \"text\", \"text\": json.dumps(res)}], \"structuredContent\": res, \"isError\": False}})\n            if name == \"context_answer_compat\":\n                # Simulate failure if flagged so router should fall back to context_answer\n                if getattr(self.server, \"fail_context_compat\", False):\n                    return self._send_json({\"jsonrpc\": \"2.0\", \"id\": j.get(\"id\"), \"result\": {\"content\": [{\"type\": \"text\", \"text\": json.dumps({\"error\": \"compat failed\"})}], \"structuredContent\": {\"error\": \"compat failed\"}, \"isError\": True}})\n                # Require nested arguments wrapper\n                if not isinstance(args, dict) or \"arguments\" not in args:\n                    return self._send_json({\"jsonrpc\": \"2.0\", \"id\": j.get(\"id\"), \"result\": {\"content\": [{\"type\": \"text\", \"text\": json.dumps({\"error\": \"compat requires nested arguments\"})}], \"structuredContent\": {\"error\": \"compat requires nested arguments\"}, \"isError\": True}})\n                inner = args.get(\"arguments\") or {}\n                q = str(inner.get(\"query\") or \"\")\n                ans = {\n                    \"answer\": \"Short ok.\" if len(q) < 80 else \"Longer answer\",\n                    \"citations\": [{\"id\": 1, \"path\": \"/work/file.py\", \"start_line\": 1, \"end_line\": 2}],\n                    \"query\": [q],\n                    \"used\": {\"gate_first\": True, \"refrag\": True},\n                }\n                res = {\"result\": ans}\n                return self._send_json({\"jsonrpc\": \"2.0\", \"id\": j.get(\"id\"), \"result\": {\"content\": [{\"type\": \"text\", \"text\": json.dumps(res)}], \"structuredContent\": res, \"isError\": False}})\n            if name == \"context_answer\":\n                q = str(args.get(\"query\") or \"\")\n                ans = {\"answer\": \"Ok.\", \"citations\": []}\n                res = {\"result\": ans}\n                return self._send_json({\"jsonrpc\": \"2.0\", \"id\": j.get(\"id\"), \"result\": {\"content\": [{\"type\": \"text\", \"text\": json.dumps(res)}], \"structuredContent\": res, \"isError\": False}})\n            if name in {\"qdrant_status\", \"qdrant_list\"}:\n                res = {\"result\": {\"ok\": True}}\n                return self._send_json({\"jsonrpc\": \"2.0\", \"id\": j.get(\"id\"), \"result\": {\"content\": [{\"type\": \"text\", \"text\": json.dumps(res)}], \"structuredContent\": res, \"isError\": False}})\n            # Memory tools\n            if name == \"store\":\n                res = {\"result\": {\"ok\": True}}\n                return self._send_json({\"jsonrpc\": \"2.0\", \"id\": j.get(\"id\"), \"result\": {\"content\": [{\"type\": \"text\", \"text\": json.dumps(res)}], \"structuredContent\": res, \"isError\": False}})\n            if name == \"find\":\n                q = str(args.get(\"query\") or \"\")\n                res = {\"result\": {\"ok\": True, \"results\": [{\"information\": \"The MCP indexer uses hybrid search combining dense embeddings and lexical matching with optional reranking\", \"metadata\": {\"category\": \"architecture\"}}], \"count\": 1}}\n                return self._send_json({\"jsonrpc\": \"2.0\", \"id\": j.get(\"id\"), \"result\": {\"content\": [{\"type\": \"text\", \"text\": json.dumps(res)}], \"structuredContent\": res, \"isError\": False}})\n            return self._send_json({\"jsonrpc\": \"2.0\", \"id\": j.get(\"id\"), \"result\": {\"content\": [{\"type\": \"text\", \"text\": json.dumps({\"error\": f\"unknown tool {name}\"})}], \"structuredContent\": {\"error\": f\"unknown tool {name}\"}, \"isError\": True}})\n        return self._send_json({\"jsonrpc\": \"2.0\", \"error\": {\"message\": f\"unknown method {method}\"}}, code=400)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_start_mock_server_110": {
      "name": "start_mock_server",
      "type": "function",
      "start_line": 110,
      "end_line": 117,
      "content_hash": "d31d1324ff643d40d01d187981feec8df2a6646c",
      "content": "def start_mock_server(port: int, tools: List[Dict[str, Any]]) -> Tuple[HTTPServer, threading.Thread]:\n    httpd = HTTPServer((\"localhost\", port), MockMCPHandler)\n    httpd.tools = tools  # type: ignore\n    t = threading.Thread(target=httpd.serve_forever, daemon=True)\n    t.start()\n    # Warmup\n    time.sleep(0.05)\n    return httpd, t",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_tool_120": {
      "name": "tool",
      "type": "function",
      "start_line": 120,
      "end_line": 122,
      "content_hash": "944d44b51dbb895b41e3e10f9608f26ed97d1883",
      "content": "def tool(name: str, description: str, params: List[str] = None) -> Dict[str, Any]:\n    schema = {\"type\": \"object\", \"properties\": {p: {\"type\": \"string\"} for p in (params or [])}}\n    return {\"name\": name, \"description\": description, \"inputSchema\": schema}",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_run_eval_suite_125": {
      "name": "run_eval_suite",
      "type": "function",
      "start_line": 125,
      "end_line": 374,
      "content_hash": "f64854e2d3037caf55ac0904b1f40eb0f99a343b",
      "content": "def run_eval_suite(verbose: bool = False) -> int:\n    # Two mock servers: indexer and memory\n    indexer_tools = [\n        tool(\"repo_search\", \"General code search\", [\"query\", \"limit\", \"include_snippet\", \"language\", \"under\", \"symbol\", \"ext\"]),\n        tool(\"search_config_for\", \"Intent-specific search for configuration files\", [\"query\", \"limit\", \"include_snippet\"]),\n        tool(\"search_importers_for\", \"Find files importing a module or symbol\", [\"query\", \"limit\", \"language\", \"under\"]),\n        tool(\"context_answer_compat\", \"Answer a question using code context (compat)\", [\"arguments\"]),\n        tool(\"context_answer\", \"Answer a question using code context\", [\"query\", \"limit\"]),\n        tool(\"qdrant_status\", \"Qdrant status\"),\n        tool(\"qdrant_list\", \"Qdrant list\"),\n    ]\n    memory_tools = [tool(\"store\", \"Store memory\", [\"information\"]), tool(\"find\", \"Find memory\", [\"query\", \"limit\"])]\n    idx, _ = start_mock_server(18031, indexer_tools)\n    mem, _ = start_mock_server(18032, memory_tools)\n\n    try:\n        os.environ[\"MCP_INDEXER_HTTP_URL\"] = \"http://localhost:18031/mcp\"\n        os.environ[\"MCP_MEMORY_HTTP_URL\"] = \"http://localhost:18032/mcp\"\n        os.environ[\"ROUTER_SEARCH_LIMIT\"] = \"8\"\n        os.environ[\"ROUTER_INCLUDE_SNIPPET\"] = \"1\"\n\n        # Import router after env set so its defaults bind to mock URLs\n        import importlib.util as _ilu\n        _p = os.path.join(os.path.dirname(__file__), \"mcp_router.py\")\n        _spec = _ilu.spec_from_file_location(\"mcp_router\", _p)\n        router = _ilu.module_from_spec(_spec)\n        assert _spec and _spec.loader\n        _spec.loader.exec_module(router)  # type: ignore\n\n        failures = []\n        intent_logs: List[Dict[str, Any]] = []\n\n        def run_plan(q: str) -> List[Tuple[str, Dict[str, Any]]]:\n            plan = router.build_plan(q)\n            debug = getattr(router, \"_LAST_INTENT_DEBUG\", {})\n            if isinstance(debug, dict):\n                log_entry = copy.deepcopy(debug)\n            else:\n                log_entry = {\"debug\": debug}\n            log_entry[\"query\"] = q\n            log_entry[\"plan_first_tool\"] = plan[0][0] if plan else None\n            intent_logs.append(log_entry)\n            return plan\n\n        # 1) Signature selection: prefer search_config_for for config changes\n        p1 = run_plan(\"compare callers to config changes\")\n        if not p1 or p1[0][0] != \"search_config_for\":\n            failures.append(\"signature selection: expected search_config_for\")\n\n        # 2) Repo hints: language+under parsed\n        p2 = run_plan(\"who imports foo in python under src/lib\")\n        if not p2 or p2[0][0] != \"search_importers_for\":\n            failures.append(\"repo hints: expected search_importers_for\")\n        else:\n            args2 = p2[0][1]\n            if args2.get(\"language\") != \"python\":\n                failures.append(\"repo hints: language not parsed\")\n            if args2.get(\"under\") != \"src/lib\":\n                failures.append(\"repo hints: under not parsed\")\n\n        # 3) Design recap: memory find precedes answer\n        p3 = run_plan(\"recap our architecture decisions for the indexer\")\n        expect_order = [\"find\", \"context_answer_compat\"]\n        if not p3 or [p3[0][0], p3[1][0]] != expect_order:\n            failures.append(\"design recap plan: expected find -> context_answer_compat\")\n\n        # 4) Multi-intent: store + reindex\n        p4 = run_plan(\"remember this: prefer concise answers; then reindex fresh\")\n        if not p4 or [p4[0][0], p4[1][0]] != [\"store\", \"qdrant_index_root\"]:\n            failures.append(\"multi-intent: expected store then index\")\n        else:\n            store_args = p4[0][1] or {}\n            info4 = (store_args.get(\"information\") or \"\").lower()\n            if \"remember\" in info4:\n                failures.append(\"multi-intent: trigger phrase leaked into stored information\")\n            if \"reindex\" in info4:\n                failures.append(\"multi-intent: reindex fragment leaked into stored information\")\n            if not p4[1][1].get(\"recreate\"):\n                failures.append(\"multi-intent: expected recreate true\")\n\n        # 5) Memory metadata extraction\n        p_meta = run_plan(\"remember this [priority=high tags=ux,frontend]: update the signup banner copy\")\n        if not p_meta or p_meta[0][0] != \"store\":\n            failures.append(\"memory metadata: expected store intent\")\n        else:\n            store_args = p_meta[0][1] or {}\n            if store_args.get(\"information\") != \"update the signup banner copy\":\n                failures.append(\"memory metadata: information not cleaned\")\n            md = store_args.get(\"metadata\") or {}\n            if md.get(\"priority\") != \"high\":\n                failures.append(\"memory metadata: priority missing\")\n            if md.get(\"tags\") != [\"ux\", \"frontend\"]:\n                failures.append(\"memory metadata: tags mismatch\")\n\n        # 6) Glob/exclude filters\n        p5 = run_plan(\"search only *.py files exclude vendor\")\n        if not p5:\n            failures.append(\"glob: plan empty\")\n        else:\n            args5 = p5[0][1]\n            gl = (args5 or {}).get(\"path_glob\") or []\n            ng = (args5 or {}).get(\"not_glob\") or []\n            if \"**/*.py\" not in gl:\n                failures.append(\"glob: missing **/*.py\")\n            if \"**/vendor/**\" not in ng:\n                failures.append(\"glob: missing exclude vendor\")\n\n        # 7) Run end-to-end for recap and ensure compat accepted and short answers not rejected\n        # Capture stdout of router.main\n        def run_router(args: List[str]) -> str:\n            from io import StringIO\n            old = sys.stdout\n            try:\n                buf = StringIO()\n                sys.stdout = buf\n                router.main(args)\n                return buf.getvalue()\n            finally:\n                sys.stdout = old\n        out = run_router([\"--run\", \"recap our architecture decisions for the indexer\"])\n        def run_router_code(args: List[str]) -> int:\n            from io import StringIO\n            old = sys.stdout\n            try:\n                sys.stdout = StringIO()  # suppress stdout capture to avoid noise\n                return int(router.main(args))\n            finally:\n                sys.stdout = old\n\n        if \"compat requires nested arguments\" in out:\n            failures.append(\"compat: still sending flattened args\")\n        if \"Memory context:\" not in out:\n            failures.append(\"memory\u2192answer: query was not augmented with memory context\")\n            print(\"--- router stdout ---\\n\" + out + \"\\n--- end stdout ---\")\n\n\n        # 6b) Repeat immediately after recap should skip fresh memory.find step\n        out_repeat = run_router([\"--run\", \"repeat that\"])\n        if '\"skipped\": \"scratchpad_fresh\"' not in out_repeat:\n            failures.append(\"repeat: find step not skipped on fresh cache\")\n\n        # 7) Repeat last: persist then repeat\n        _ = run_router([\"--run\", \"who imports foo in python under src/lib\"])\n        p7a = run_plan(\"who imports foo in python under src/lib\")\n        p7b = run_plan(\"repeat that\")\n        if p7a != p7b:\n            failures.append(\"repeat: last plan not reused\")\n\n        # 7b) \"same filters\" carry-over in planning\n        p7c = run_plan(\"search with same filters for bar baz\")\n        if not p7c:\n            failures.append(\"same filters: plan empty\")\n        else:\n            args7c = p7c[0][1]\n            if (args7c or {}).get(\"language\") != \"python\" or (args7c or {}).get(\"under\") != \"src/lib\":\n                failures.append(\"same filters: did not reuse prior language/under\")\n\n\n\n        # 8) Fallback on compat failure\n        setattr(idx, \"fail_context_compat\", True)\n        out2 = run_router([\"--run\", \"recap our architecture decisions for the indexer\"])\n        if '\"tool\": \"context_answer\"' not in out2:\n            failures.append(\"fallback: did not call context_answer after compat failure\")\n        setattr(idx, \"fail_context_compat\", False)\n\n        # 9) tools/list flakiness toleration\n        setattr(idx, \"fail_list_once\", True)\n        p9 = run_plan(\"find config changes\")\n        if not p9:\n            failures.append(\"discovery flakiness: plan empty after retry\")\n        setattr(idx, \"fail_list_once\", False)\n\n\n        # 10) Expand on last summary uses prior summary and citations (fresh)\n        out3 = run_router([\"--run\", \"expand on that summary\"])\n        if \"Prior summary:\" not in out3 or \"/work/file.py\" not in out3:\n            failures.append(\"expand: prior summary/citations not injected when fresh\")\n\n        # 11) TTL expiry should suppress prior summary injection\n        os.environ[\"ROUTER_SCRATCHPAD_TTL_SEC\"] = \"0\"\n        out4 = run_router([\"--run\", \"expand on that summary\"])\n        if \"Prior summary:\" in out4:\n            failures.append(\"ttl: prior summary injected despite stale cache\")\n        os.environ.pop(\"ROUTER_SCRATCHPAD_TTL_SEC\", None)\n\n        # 13) Divergence fatal per-tool: repo_search set to fatal should cause nonzero exit\n        os.environ[\"ROUTER_DIVERGENCE_FATAL_TOOLS\"] = \"repo_search\"\n        setattr(idx, \"search_total\", 6)\n        _ = run_router([\"--run\", \"search for demo\"])\n        setattr(idx, \"search_total\", 2)\n        code_div = run_router_code([\"--run\", \"search for demo\"])\n        if code_div == 0:\n            failures.append(\"divergence fatal: router returned success despite fatal policy\")\n        os.environ.pop(\"ROUTER_DIVERGENCE_FATAL_TOOLS\", None)\n        setattr(idx, \"search_total\", 5)\n\n        # 12) Divergence detection: baseline high \u2192 lower later should print a divergence notice\n        setattr(idx, \"search_total\", 6)\n        _ = run_router([\"--run\", \"search for demo\"])\n        setattr(idx, \"search_total\", 2)\n        out_div = run_router([\"--run\", \"search for demo\"])\n        if '\"divergence\"' not in out_div:\n            failures.append(\"divergence: no divergence flagged on material drop\")\n\n        fallback_logs = []\n        for log in intent_logs:\n            if log.get(\"strategy\") == \"ml\":\n                if \"confidence\" not in log:\n                    failures.append(f\"intent log missing confidence for query: {log.get('query')}\")\n                if (\n                    log.get(\"intent\") == router.INTENT_SEARCH\n                    and log.get(\"top_candidate\")\n                    and log.get(\"top_candidate\") != router.INTENT_SEARCH\n                ):\n                    if log.get(\"confidence\", 0.0) >= log.get(\"threshold\", 0.25):\n                        failures.append(f\"intent fallback without low confidence for query: {log.get('query')}\")\n                    else:\n                        fallback_logs.append(log)\n        if fallback_logs:\n            print(\"Intent fallback diagnostics:\")\n            for item in fallback_logs:\n                try:\n                    score = float(item.get(\"confidence\") or 0.0)\n                except Exception:\n                    score = 0.0\n                print(\n                    f\"  query={item.get('query')!r} top={item.get('top_candidate')} \"\n                    f\"score={score:.3f} -> intent={item.get('intent')} first_tool={item.get('plan_first_tool')}\"\n                )\n        if verbose:\n            print(\"Intent diagnostics (all):\")\n            for item in intent_logs:\n                try:\n                    score = float(item.get(\"confidence\") or 0.0)\n                except Exception:\n                    score = 0.0\n                print(\n                    f\"  query={item.get('query')!r} strategy={item.get('strategy')} \"\n                    f\"intent={item.get('intent')} score={score:.3f} \"\n                    f\"top={item.get('top_candidate')} first_tool={item.get('plan_first_tool')}\"\n                )\n\n        if failures:\n            print(\"Router eval: FAIL\\n- \" + \"\\n- \".join(failures))\n            return 1\n        print(\"Router eval: PASS (all checks)\")\n        return 0\n    finally:\n        idx.shutdown(); mem.shutdown()",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_run_plan_157": {
      "name": "run_plan",
      "type": "function",
      "start_line": 157,
      "end_line": 167,
      "content_hash": "3074ef84be4d884899d4a6bbf8b9927f63a4d49c",
      "content": "        def run_plan(q: str) -> List[Tuple[str, Dict[str, Any]]]:\n            plan = router.build_plan(q)\n            debug = getattr(router, \"_LAST_INTENT_DEBUG\", {})\n            if isinstance(debug, dict):\n                log_entry = copy.deepcopy(debug)\n            else:\n                log_entry = {\"debug\": debug}\n            log_entry[\"query\"] = q\n            log_entry[\"plan_first_tool\"] = plan[0][0] if plan else None\n            intent_logs.append(log_entry)\n            return plan",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_run_router_234": {
      "name": "run_router",
      "type": "function",
      "start_line": 234,
      "end_line": 243,
      "content_hash": "ed400dd3634a9e76a48afe0e02591dc913c3a345",
      "content": "        def run_router(args: List[str]) -> str:\n            from io import StringIO\n            old = sys.stdout\n            try:\n                buf = StringIO()\n                sys.stdout = buf\n                router.main(args)\n                return buf.getvalue()\n            finally:\n                sys.stdout = old",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_run_router_code_245": {
      "name": "run_router_code",
      "type": "function",
      "start_line": 245,
      "end_line": 252,
      "content_hash": "e9866c3a7e03ff98625d33aedf8d16a74c6d0996",
      "content": "        def run_router_code(args: List[str]) -> int:\n            from io import StringIO\n            old = sys.stdout\n            try:\n                sys.stdout = StringIO()  # suppress stdout capture to avoid noise\n                return int(router.main(args))\n            finally:\n                sys.stdout = old",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}