{
  "file_path": "/work/external-deps/helix-db/hql-tests/src/main.rs",
  "file_hash": "c7e33c686c4604aa97902f8a33473289f9b2e79d",
  "updated_at": "2025-12-26T17:34:21.987149",
  "symbols": {
    "struct_GitHubConfig_13": {
      "name": "GitHubConfig",
      "type": "struct",
      "start_line": 13,
      "end_line": 18,
      "content_hash": "7a96a83f869a8def86a5907fbd2ecc257b76ae70",
      "content": "struct GitHubConfig {\n    token: String,\n    owner: String,\n    repo: String,\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "impl_GitHubConfig_19": {
      "name": "GitHubConfig",
      "type": "impl",
      "start_line": 19,
      "end_line": 19,
      "content_hash": "3996264c1a863db7e8f0a3bf3fa1fc3d32c80b85",
      "content": "impl GitHubConfig {",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_from_env_20": {
      "name": "from_env",
      "type": "method",
      "start_line": 20,
      "end_line": 29,
      "content_hash": "c512c71439db4975edd4289e3b569c3a11b46794",
      "content": "    fn from_env() -> Result<Self> {\n        let token =\n            env::var(\"GITHUB_TOKEN\").context(\"GITHUB_TOKEN environment variable not set\")?;\n        let owner = env::var(\"GITHUB_OWNER\").unwrap_or_else(|_| \"HelixDB\".to_string());\n        let repo = env::var(\"GITHUB_REPO\").unwrap_or_else(|_| \"helix-db\".to_string());\n\n        Ok(GitHubConfig { token, owner, repo })\n    }\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_generate_error_hash_30": {
      "name": "generate_error_hash",
      "type": "method",
      "start_line": 30,
      "end_line": 775,
      "content_hash": "6e18db8ea973561480538c0b86adb4fdf478c194",
      "content": "fn generate_error_hash(error_type: &str, error_message: &str, _test_name: &str) -> String {\n    let mut hasher = Sha256::new();\n    hasher.update(format!(\n        \"{}:{}\",\n        error_type,\n        error_message.lines().take(5).collect::<Vec<_>>().join(\"\\n\")\n    ));\n    let hash = hasher.finalize();\n    general_purpose::STANDARD.encode(hash)[0..12].to_string()\n}\n\n#[allow(unused)]\nasync fn check_issue_exists(github_config: &GitHubConfig, error_hash: &str) -> Result<bool> {\n    println!(\"DEBUG: Checking if issue exists with hash: {error_hash}\");\n\n    let octocrab = Octocrab::builder()\n        .personal_token(github_config.token.clone())\n        .build()?;\n\n    let search_query = format!(\n        \"repo:{}/{} is:issue ERROR_HASH:{}\",\n        github_config.owner, github_config.repo, error_hash\n    );\n\n    println!(\"DEBUG: GitHub search query: {search_query}\");\n\n    let issues = octocrab\n        .search()\n        .issues_and_pull_requests(&search_query)\n        .send()\n        .await?;\n\n    let count = issues.total_count.unwrap_or(0);\n    println!(\"DEBUG: Found {count} existing issues\");\n\n    Ok(count > 0)\n}\n\n#[allow(unused)]\nasync fn create_github_issue(\n    github_config: &GitHubConfig,\n    error_type: &str,\n    error_message: &str,\n    test_name: &str,\n    error_hash: &str,\n    query: &str,\n    schema: &str,\n    generated_rust_code: &str,\n) -> Result<()> {\n    println!(\n        \"DEBUG: Creating GitHub issue for {}/{}\",\n        github_config.owner, github_config.repo\n    );\n\n    let octocrab = Octocrab::builder()\n        .personal_token(github_config.token.clone())\n        .build()?;\n\n    let title = format!(\"Auto-generated: {error_type} Error in {test_name}\");\n\n    let body = format!(\n        \"## Automatic Error Report\\n\\n\\\n        **Error Type:** {error_type}\\n\\\n        **Test:** {test_name}\\n\\\n        **Error Hash:** ERROR_HASH:{error_hash}\\n\\n\\\n        ### Query\\n\\\n        ```js\\n{query}\\n```\\n\\n\\\n        ### Schema\\n\\\n        ```js\\n{schema}\\n```\\n\\n\\\n        ### Generated Rust Code\\n\\\n        ```rust\\n{generated_rust_code}\\n```\\n\\n\\\n        ### Error Details\\n\\\n        ```\\n{error_message}\\n```\\n\\n\\\n        ---\\n\\\n        *This issue was automatically generated by the hql-tests runner.*\"\n    );\n\n    let labels = vec![\n        \"bug\".to_string(),\n        \"automated\".to_string(),\n        \"hql-tests\".to_string(),\n    ];\n\n    println!(\"DEBUG: Issue title: {title}\");\n    println!(\"DEBUG: Issue body length: {} chars\", body.len());\n    println!(\"DEBUG: Issue labels: {labels:?}\");\n\n    let issue = octocrab\n        .issues(&github_config.owner, &github_config.repo)\n        .create(&title)\n        .body(&body)\n        .labels(Some(labels))\n        .send()\n        .await?;\n\n    println!(\n        \"Created GitHub issue #{} for {} error in {}\",\n        issue.number, error_type, test_name\n    );\n    Ok(())\n}\n\nasync fn handle_error_with_github(\n    _github_config: &GitHubConfig,\n    error_type: &str,\n    error_message: &str,\n    test_name: &str,\n    _query: &str,\n    _schema: &str,\n    _generated_rust_code: &str,\n) -> Result<()> {\n    let error_hash = generate_error_hash(error_type, error_message, test_name);\n\n    println!(\n        \"DEBUG: Handling error with GitHub - Type: {error_type}, Test: {test_name}, Hash: {error_hash}\"\n    );\n\n    // match check_issue_exists(github_config, &error_hash).await {\n    //     Ok(exists) => {\n    //         println!(\"DEBUG: Issue exists check result: {exists}\");\n    //         if !exists {\n    //             println!(\"DEBUG: Creating new GitHub issue...\");\n    //             if let Err(e) = create_github_issue(\n    //                 github_config,\n    //                 error_type,\n    //                 error_message,\n    //                 test_name,\n    //                 &error_hash,\n    //                 query,\n    //                 schema,\n    //                 generated_rust_code,\n    //             )\n    //             .await\n    //             {\n    //                 eprintln!(\"Failed to create GitHub issue: {e}\");\n    //             }\n    //         } else {\n    //             println!(\n    //                 \"Issue already exists for {error_type} error in {test_name} (hash: {error_hash})\"\n    //             );\n    //         }\n    //     }\n    //     Err(e) => {\n    //         eprintln!(\"Failed to check existing issues: {e}\");\n    //         // Try to create the issue anyway if we can't check for duplicates\n    //         println!(\"DEBUG: Attempting to create issue despite check failure...\");\n    //         if let Err(e) = create_github_issue(\n    //             github_config,\n    //             error_type,\n    //             error_message,\n    //             test_name,\n    //             &error_hash,\n    //             query,\n    //             schema,\n    //             generated_rust_code,\n    //         )\n    //         .await\n    //         {\n    //             eprintln!(\"Failed to create GitHub issue: {e}\");\n    //         }\n    //     }\n    // }\n\n    Ok(())\n}\n\n#[tokio::main]\nasync fn main() -> Result<()> {\n    let matches = ClapCommand::new(\"queries-test\")\n        .about(\"Process helix test directories\")\n        .arg(\n            Arg::new(\"test_name\")\n                .help(\"Specific test directory name to process\")\n                .value_parser(clap::value_parser!(String))\n                .required(false),\n        )\n        .arg(\n            Arg::new(\"batch\")\n                .long(\"batch\")\n                .help(\"Enable batch processing with total batches and current batch\")\n                .num_args(2)\n                .value_names([\"TOTAL_BATCHES\", \"CURRENT_BATCH\"])\n                .value_parser(clap::value_parser!(u32))\n                .required(false),\n        )\n        .arg(\n            Arg::new(\"branch\")\n                .long(\"branch\")\n                .help(\"Branch to process\")\n                .value_parser(clap::value_parser!(String))\n                .required(false),\n        )\n        .get_matches();\n\n    let current_dir = env::current_dir().context(\"Failed to get current directory\")?;\n    let tests_dir = current_dir.join(\"tests\");\n\n    if !tests_dir.exists() {\n        bail!(\"Tests directory not found at: {}\", tests_dir.display());\n    }\n\n    // Initialize GitHub configuration (optional - will print warning if not available)\n    let github_config = match GitHubConfig::from_env() {\n        Ok(config) => {\n            println!(\n                \"GitHub integration enabled for {}/{}\",\n                config.owner, config.repo\n            );\n            Some(config)\n        }\n        Err(e) => {\n            println!(\"GitHub integration disabled: {e}\");\n            println!(\"Set GITHUB_TOKEN environment variable to enable automatic issue creation\");\n            None\n        }\n    };\n\n    // pull repo to copy to all folders\n    let temp_repo = env::temp_dir().join(\"temp_repo\");\n    if !temp_repo.exists() {\n        fs::create_dir_all(&temp_repo)\n            .await\n            .context(\"Failed to create temp directory\")?;\n    }\n\n    // copy source code from project root to temp_repo\n    let project_root = match current_dir.parent() {\n        Some(parent) if parent.join(\"helix-cli\").exists() => parent.to_path_buf(),\n        Some(_) if current_dir.join(\"helix-cli\").exists() => current_dir.to_path_buf(),\n        Some(parent) => bail!(\"Error: Failed to get project root: {}\", parent.display()),\n        None => bail!(\"Error: Failed to get project root\"),\n    };\n    copy_dir_recursive(&project_root, &temp_repo).await?;\n\n    // build rust cli from ./helix-db/helix-cli with sh build.sh dev\n    println!(\"DEBUG: Building rust cli from ./helix-db/helix-cli with sh build.sh dev\");\n    let build_script_path = project_root.join(\"helix-cli/build.sh\");\n    println!(\"DEBUG: Build script path: {}\", build_script_path.display());\n    println!(\"DEBUG: Build script exists: {}\", build_script_path.exists());\n\n    let helix_cli_dir = project_root.join(\"helix-cli\");\n    println!(\"DEBUG: Helix CLI dir: {}\", helix_cli_dir.display());\n    println!(\"DEBUG: Helix CLI dir exists: {}\", helix_cli_dir.exists());\n\n    // Check if helix is already available\n    let helix_check = Command::new(\"helix\").arg(\"--version\").output();\n\n    match helix_check {\n        Ok(output) => {\n            if output.status.success() {\n                println!(\n                    \"DEBUG: Helix already available: {}\",\n                    String::from_utf8_lossy(&output.stdout)\n                );\n            } else {\n                println!(\"DEBUG: Helix not available or failed version check\");\n            }\n        }\n        Err(e) => {\n            println!(\"DEBUG: Helix command not found: {e}\");\n        }\n    }\n\n    let output = Command::new(\"sh\")\n        .arg(\"build.sh\")\n        .arg(\"dev\")\n        .current_dir(&helix_cli_dir) // Change to helix-cli directory first\n        .output()\n        .context(\"Failed to execute build.sh\")?;\n\n    println!(\"DEBUG: build.sh exit code: {:?}\", output.status.code());\n    println!(\n        \"DEBUG: build.sh stdout: {}\",\n        String::from_utf8_lossy(&output.stdout)\n    );\n    println!(\n        \"DEBUG: build.sh stderr: {}\",\n        String::from_utf8_lossy(&output.stderr)\n    );\n\n    if !output.status.success() {\n        bail!(\n            \"[FAILED] BUILD FAILED: helix-cli build.sh failed\\nStderr: {}\\nStdout: {}\",\n            String::from_utf8_lossy(&output.stderr),\n            String::from_utf8_lossy(&output.stdout)\n        );\n    } else {\n        println!(\"DEBUG: build.sh dev succeeded\");\n\n        // Check if helix is available after build\n        let helix_check_after = Command::new(\"helix\").arg(\"--version\").output();\n\n        match helix_check_after {\n            Ok(output) => {\n                if output.status.success() {\n                    println!(\n                        \"DEBUG: Helix available after build: {}\",\n                        String::from_utf8_lossy(&output.stdout)\n                    );\n                } else {\n                    println!(\"DEBUG: Helix still not available after build\");\n                    println!(\n                        \"DEBUG: Helix version check stderr: {}\",\n                        String::from_utf8_lossy(&output.stderr)\n                    );\n                }\n            }\n            Err(e) => {\n                println!(\"DEBUG: Helix command still not found after build: {e}\");\n            }\n        }\n    }\n\n    // Get all test directories\n    let mut test_dirs = Vec::new();\n    let mut entries = fs::read_dir(&tests_dir).await?;\n    while let Some(entry) = entries.next_entry().await? {\n        let path = entry.path();\n        if path.is_dir()\n            && let Some(dir_name) = path.file_name()\n            && let Some(name_str) = dir_name.to_str()\n        {\n            test_dirs.push(name_str.to_string());\n        }\n    }\n    test_dirs.sort();\n    println!(\"Found {} test directories\", test_dirs.len());\n\n    if let Some(test_name) = matches.get_one::<String>(\"test_name\") {\n        // Process single test directory\n        if !test_dirs.contains(test_name) {\n            bail!(\n                \"Error: Test directory '{}' not found. Available tests: {:?}\",\n                test_name,\n                test_dirs\n            );\n        }\n\n        process_test_directory(test_name, &tests_dir, &temp_repo, &github_config).await?;\n        println!(\"[SUCCESS] Successfully processed {test_name}\");\n    } else if let Some(batch_args) = matches.get_many::<u32>(\"batch\") {\n        // Process in batch mode\n        let batch_values: Vec<u32> = batch_args.copied().collect();\n        if batch_values.len() != 2 {\n            bail!(\"Error: --batch requires exactly 2 arguments: total_batches current_batch\");\n        }\n\n        let total_batches = batch_values[0];\n        let current_batch = batch_values[1];\n\n        if current_batch < 1 || current_batch > total_batches {\n            bail!(\n                \"Error: Current batch ({}) must be between 1 and {}\",\n                current_batch,\n                total_batches\n            );\n        }\n\n        if total_batches == 0 {\n            bail!(\"Error: Total batches must be greater than 0\");\n        }\n\n        // Calculate which tests this batch should process\n        let total_tests = test_dirs.len();\n        let tests_per_batch = total_tests / total_batches as usize;\n        let remainder = total_tests % total_batches as usize;\n\n        // Calculate start and end for this batch\n        let start_idx = (current_batch - 1) as usize * tests_per_batch;\n        let mut end_idx = current_batch as usize * tests_per_batch;\n\n        // Add remainder tests to the last batch\n        if current_batch == total_batches {\n            end_idx += remainder;\n        }\n\n        // Ensure we don't go out of bounds\n        end_idx = end_idx.min(total_tests);\n\n        println!(\n            \"Processing batch {current_batch}/{total_batches}: tests {}-{} ({})\",\n            start_idx + 1,\n            end_idx,\n            test_dirs[start_idx..end_idx].join(\", \")\n        );\n\n        let tasks: Vec<_> = test_dirs[start_idx..end_idx]\n            .iter()\n            .map(|test_name| {\n                let test_name = test_name.clone();\n                let tests_dir = tests_dir.clone();\n                let temp_repo = temp_repo.clone();\n                let github_config = github_config.clone();\n                tokio::spawn(async move {\n                    process_test_directory(&test_name, &tests_dir, &temp_repo, &github_config).await\n                })\n            })\n            .collect();\n\n        // Wait for all tasks to complete and collect results\n        let mut failed_tests = Vec::new();\n        for (i, task) in tasks.into_iter().enumerate() {\n            let test_name = &test_dirs[start_idx + i];\n            match task.await {\n                Ok(Ok(())) => {\n                    println!(\"Successfully processed {test_name}\");\n                }\n                Ok(Err(e)) => {\n                    eprintln!(\"Error processing {test_name}: {e}\");\n                    failed_tests.push(test_name.clone());\n                }\n                Err(e) => {\n                    eprintln!(\"Task error for {test_name}: {e}\");\n                    failed_tests.push(test_name.clone());\n                }\n            }\n        }\n\n        if !failed_tests.is_empty() {\n            bail!(\n                \"[FAILED] BATCH PROCESSING FAILED: {} out of {} tests failed compilation/check: {:?}\",\n                failed_tests.len(),\n                end_idx - start_idx,\n                failed_tests\n            );\n        }\n\n        println!(\"[SUCCESS] Finished processing batch {current_batch}/{total_batches} successfully\");\n    } else {\n        // Process all test directories in parallel (default behavior)\n        println!(\n            \"Processing all {} test directories in parallel...\",\n            test_dirs.len()\n        );\n\n        let tasks: Vec<_> = test_dirs\n            .iter()\n            .map(|test_name| {\n                let test_name = test_name.clone();\n                let tests_dir = tests_dir.clone();\n                let temp_repo = temp_repo.clone();\n                let github_config = github_config.clone();\n                tokio::spawn(async move {\n                    process_test_directory(&test_name, &tests_dir, &temp_repo, &github_config).await\n                })\n            })\n            .collect();\n\n        // Wait for all tasks to complete and collect results\n        let mut failed_tests = Vec::new();\n        for (i, task) in tasks.into_iter().enumerate() {\n            let test_name = &test_dirs[i];\n            match task.await {\n                Ok(Ok(())) => {\n                    println!(\"Successfully processed {test_name}\");\n                }\n                Ok(Err(e)) => {\n                    eprintln!(\"Error processing {test_name}: {e}\");\n                    failed_tests.push(test_name.clone());\n                }\n                Err(e) => {\n                    eprintln!(\"Task error for {test_name}: {e}\");\n                    failed_tests.push(test_name.clone());\n                }\n            }\n        }\n\n        if !failed_tests.is_empty() {\n            bail!(\n                \"[FAILED] PROCESSING FAILED: {} out of {} tests failed compilation/check: {:?}\",\n                failed_tests.len(),\n                test_dirs.len(),\n                failed_tests\n            );\n        }\n\n        println!(\n            \"[SUCCESS] Finished processing all {} tests successfully\",\n            test_dirs.len()\n        );\n    }\n\n    Ok(())\n}\n\nasync fn process_test_directory(\n    test_name: &str,\n    tests_dir: &Path,\n    temp_repo: &Path,\n    github_config: &Option<GitHubConfig>,\n) -> Result<()> {\n    let folder_path = tests_dir.join(test_name);\n\n    if !folder_path.exists() {\n        // Skip non-existent directories silently in parallel mode\n        return Ok(());\n    }\n\n\n    // Find the query file - could be queries.hx or file*.hx\n    let mut query_file_path = None;\n    let schema_hx_path = folder_path.join(\"schema.hx\");\n\n    // First check for queries.hx\n    let queries_hx_path = folder_path.join(\"queries.hx\");\n    if queries_hx_path.exists() && queries_hx_path.is_file() {\n        query_file_path = Some(queries_hx_path);\n    } else {\n        // Look for file*.hx pattern\n        let entries = fs::read_dir(&folder_path).await?;\n        let mut entries = entries;\n        while let Some(entry) = entries.next_entry().await? {\n            let path = entry.path();\n            if let Some(file_name) = path.file_name()\n                && let Some(name_str) = file_name.to_str()\n                && name_str.starts_with(\"file\")\n                && name_str.ends_with(\".hx\")\n                && !name_str.contains(\"schema\")\n            {\n                query_file_path = Some(path);\n                break;\n            }\n        }\n    }\n\n    // Skip if no query file found or if it's empty\n    if let Some(ref query_path) = query_file_path {\n        let content = fs::read_to_string(query_path).await?;\n        if content.is_empty() {\n            return Ok(());\n        }\n    } else {\n        // No query file found, skip this test\n        return Ok(());\n    }\n\n    // Create a temporary directory for this test\n    let temp_dir = env::temp_dir().join(format!(\"helix_temp_{test_name}\"));\n    if temp_dir.exists() {\n        fs::remove_dir_all(&temp_dir)\n            .await\n            .context(\"Failed to remove existing temp directory\")?;\n    }\n    fs::create_dir_all(&temp_dir)\n        .await\n        .context(\"Failed to create temp directory\")?;\n\n    // Copy the test files (queries.hx, schema.hx, helix.toml, etc.) to temp directory\n    copy_dir_recursive(&folder_path, &temp_dir).await?;\n\n    // Copy the entire helix-db project structure for cargo check\n    // But skip .helix directory to avoid conflicts\n    let helix_db_dir = temp_dir.join(\"helix-db\");\n    fs::create_dir_all(&helix_db_dir).await?;\n\n    // Copy all project crates and dependencies (excluding hql-tests to avoid conflicts)\n    let crates_to_copy = vec![\n        \"helix-container\",\n        \"helix-db\",\n        \"helix-macros\",\n        \"helix-cli\",\n        \"metrics\",\n    ];\n\n    for crate_name in crates_to_copy {\n        let src = temp_repo.join(crate_name);\n        let dst = helix_db_dir.join(crate_name);\n        if src.exists() {\n            copy_dir_recursive(&src, &dst).await?;\n        }\n    }\n\n    // Copy root Cargo.toml and Cargo.lock, but remove hql-tests from workspace\n    let cargo_toml_src = temp_repo.join(\"Cargo.toml\");\n    let cargo_toml_dst = helix_db_dir.join(\"Cargo.toml\");\n    if cargo_toml_src.exists() {\n        // Read the Cargo.toml and remove hql-tests from workspace members\n        let cargo_content = fs::read_to_string(&cargo_toml_src).await?;\n        let modified_content = cargo_content.replace(\"    \\\"hql-tests\\\",\\n\", \"\");\n        fs::write(&cargo_toml_dst, modified_content).await?;\n    }\n\n    let cargo_lock_src = temp_repo.join(\"Cargo.lock\");\n    let cargo_lock_dst = helix_db_dir.join(\"Cargo.lock\");\n    if cargo_lock_src.exists() {\n        fs::copy(&cargo_lock_src, &cargo_lock_dst).await?;\n    }\n\n    // Run helix compile command\n    let compile_output_path = temp_dir.join(\"helix-db/helix-container/src\");\n    fs::create_dir_all(&compile_output_path)\n        .await\n        .context(\"Failed to create compile output directory\")?;\n\n    let output = Command::new(\"helix\")\n        .arg(\"compile\")\n        .arg(\"--path\")\n        .arg(&temp_dir)\n        .arg(\"--output\")\n        .arg(&compile_output_path)\n        .output()\n        .context(\"Failed to execute helix compile command\")?;\n\n    println!(\n        \"DEBUG: Helix compile output: {}\",\n        String::from_utf8_lossy(&output.stdout)\n    );\n    println!(\n        \"DEBUG: Helix compile stderr: {}\",\n        String::from_utf8_lossy(&output.stderr)\n    );\n    if !output.status.success() {\n        fs::remove_dir_all(&temp_dir).await.ok();\n        let stderr = String::from_utf8_lossy(&output.stderr);\n        let stdout = String::from_utf8_lossy(&output.stdout);\n        // For helix compilation, we'll show the raw output since it's not cargo format\n        let error_message =\n            format!(\"[FAILED] HELIX COMPILE FAILED for {test_name}\\nStderr: {stderr}\\nStdout: {stdout}\");\n\n        // Create GitHub issue if configuration is available\n        if let Some(config) = github_config {\n            println!(\"DEBUG: Helix compilation failed in parallel mode, creating GitHub issue...\");\n            let query_content = if let Some(ref query_path) = query_file_path {\n                fs::read_to_string(query_path).await.map_err(|e| {\n                    println!(\"DEBUG: Failed to read query file: {e}\");\n                    e\n                })?\n            } else {\n                String::new()\n            };\n            let schema_content = fs::read_to_string(&schema_hx_path).await.map_err(|e| {\n                println!(\"DEBUG: Failed to read schema.hx: {e}\");\n                e\n            })?;\n            let generated_rust_code = fs::read_to_string(&compile_output_path.join(\"queries.rs\"))\n                .await\n                .unwrap_or_else(|_| String::from(\"Failed to read generated queries.rs\"));\n            handle_error_with_github(\n                config,\n                \"Helix Compilation\",\n                &error_message,\n                test_name,\n                &query_content,\n                &schema_content,\n                &generated_rust_code,\n            )\n            .await?;\n        } else {\n            println!(\"DEBUG: GitHub integration not configured, skipping issue creation\");\n        }\n\n        bail!(\"Error: {}\", error_message);\n    }\n\n    // Run cargo check on the helix container path\n    let helix_container_path = temp_dir.join(\"helix-db/helix-container\");\n    if helix_container_path.exists() {\n        let output = Command::new(\"cargo\")\n            .arg(\"check\")\n            .current_dir(&helix_container_path)\n            .output()\n            .context(\"Failed to execute cargo check\")?;\n\n        if !output.status.success() {\n            let stderr = String::from_utf8_lossy(&output.stderr);\n            let _stdout = String::from_utf8_lossy(&output.stdout);\n            // let filtered_errors = extract_cargo_errors(&stderr, &stdout);\n            let error_message = format!(\"[FAILED] CARGO CHECK FAILED for {test_name}\\n{stderr}\");\n\n            // Create GitHub issue if configuration is available\n            if let Some(config) = github_config {\n                println!(\"DEBUG: Cargo check failed in parallel mode, creating GitHub issue...\");\n                let query_content = if let Some(ref query_path) = query_file_path {\n                    fs::read_to_string(query_path).await.map_err(|e| {\n                        println!(\"DEBUG: Failed to read query file: {e}\");\n                        e\n                    })?\n                } else {\n                    String::new()\n                };\n                let schema_content = fs::read_to_string(&schema_hx_path).await.map_err(|e| {\n                    println!(\"DEBUG: Failed to read schema.hx: {e}\");\n                    e\n                })?;\n                let generated_rust_code =\n                    fs::read_to_string(&compile_output_path.join(\"queries.rs\"))\n                        .await\n                        .unwrap_or_else(|_| String::from(\"Failed to read generated queries.rs\"));\n                handle_error_with_github(\n                    config,\n                    \"Cargo Check\",\n                    &error_message,\n                    test_name,\n                    &query_content,\n                    &schema_content,\n                    &generated_rust_code,\n                )\n                .await?;\n            } else {\n                println!(\"DEBUG: GitHub integration not configured, skipping issue creation\");\n            }\n            fs::remove_dir_all(&temp_dir).await.ok();\n            bail!(\"Error: {}\", error_message);\n        }\n    }\n\n    println!(\"Cargo check passed for {test_name}\");\n    // Clean up temp directory\n    fs::remove_dir_all(&temp_dir).await.ok();\n\n    Ok(())\n}\n\nasync fn copy_dir_recursive(src: &Path, dst: &Path) -> Result<()> {\n    if !dst.exists() {\n        fs::create_dir_all(dst).await?;\n    }\n\n    let mut entries = fs::read_dir(src).await?;\n    while let Some(entry) = entries.next_entry().await? {\n        let path = entry.path();\n        let file_name = path.file_name().unwrap();\n        let dest_path = dst.join(file_name);\n\n        if path.is_dir() {\n            if IGNORE_DIRS.contains(&path.file_name().unwrap().to_str().unwrap()) {\n                continue;\n            }\n            Box::pin(copy_dir_recursive(&path, &dest_path))\n                .await\n                .map_err(|e| {\n                    println!(\"DEBUG: Failed to copy directory {}: {}\", path.display(), e);\n                    e\n                })?;\n        } else {\n            fs::copy(&path, &dest_path).await.map_err(|e| {\n                println!(\"DEBUG: Failed to copy file {}: {}\", path.display(), e);\n                e\n            })?;\n        }\n    }\n\n    Ok(())\n}\n\nconst IGNORE_DIRS: [&str; 3] = [\"target\", \".git\", \".helix\"];",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}