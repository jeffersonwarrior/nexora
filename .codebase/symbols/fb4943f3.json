{
  "file_path": "/work/context-engine/scripts/mcp_impl/query_expand.py",
  "file_hash": "20a274ddcaa193a1800be64e4174fea68fab1482",
  "updated_at": "2025-12-26T17:34:19.963486",
  "symbols": {
    "function__expand_query_impl_31": {
      "name": "_expand_query_impl",
      "type": "function",
      "start_line": 31,
      "end_line": 295,
      "content_hash": "b7b111c08f941c1388323d1a01e1000e4bb1e817",
      "content": "async def _expand_query_impl(query: Any = None, max_new: Any = None, session: Optional[str] = None) -> Dict[str, Any]:\n    \"\"\"LLM-assisted query expansion (local llama.cpp, if enabled).\n\n    When to use:\n    - Generate 1\u20132 compact alternates before repo_search/context_answer\n\n    Parameters:\n    - query: str or list[str]\n    - max_new: int in [0,5] (default 3)\n\n    Returns:\n    - {\"alternates\": list[str]} or {\"alternates\": [], \"hint\": \"...\"} if decoder disabled\n    \"\"\"\n    # NOTE: Do not print to stdout/stderr in MCP stdio mode; it can corrupt the JSON-RPC stream.\n    # Use logger at DEBUG level when explicitly enabled.\n    debug_expand = str(os.environ.get(\"DEBUG_EXPAND\", \"\")).strip().lower() in (\"1\", \"true\", \"yes\")\n    if debug_expand:\n        logger.debug(\"expand_query called\", extra={\"query\": repr(query), \"max_new\": repr(max_new)})\n    try:\n        qlist: list[str] = []\n        if isinstance(query, (list, tuple)):\n            qlist = [str(x) for x in query if str(x).strip()]\n        elif query is not None:\n            qlist = [str(query)] if str(query).strip() else []\n        cap = 3\n        if max_new not in (None, \"\"):\n            try:\n                cap = max(0, min(5, int(max_new)))\n            except (ValueError, TypeError):\n                cap = 3\n\n        if not qlist or cap <= 0:\n            return {\n                \"ok\": True,\n                \"original_query\": qlist[0] if qlist else \"\",\n                \"alternates\": [],\n                \"total_queries\": 1 if qlist else 0,\n                \"decoder_used\": \"none\",\n            }\n        original_q = qlist[0] if qlist else \"\"\n        # Select decoder runtime: explicit REFRAG_RUNTIME takes priority,\n        # otherwise fall back to llamacpp (local).\n        # GLM requires explicit REFRAG_RUNTIME=glm to avoid accidental API calls.\n        runtime_kind = str(os.environ.get(\"REFRAG_RUNTIME\", \"\")).strip().lower()\n        if not runtime_kind:\n            # Default to llamacpp when no runtime is specified\n            runtime_kind = \"llamacpp\"\n\n        # Only llama.cpp expansion requires the local decoder to be enabled.\n        if runtime_kind == \"llamacpp\":\n            from scripts.refrag_llamacpp import is_decoder_enabled  # type: ignore\n\n            if not is_decoder_enabled():\n                return {\n                    \"ok\": True,\n                    \"original_query\": original_q,\n                    \"alternates\": [],\n                    \"total_queries\": 1,\n                    \"decoder_used\": \"none\",\n                    \"hint\": \"decoder disabled: set REFRAG_DECODER=1 to enable local llamacpp expansion\",\n                }\n\n        # Build prompt per runtime - each model needs different prompting style\n        extra_kwargs = {}\n        use_force_json = False\n        stop_tokens = [\"\\n\\n\"]\n        if runtime_kind == \"minimax\":\n            from scripts.refrag_minimax import MiniMaxRefragClient  # type: ignore\n            client = MiniMaxRefragClient()\n            extra_kwargs[\"system\"] = f\"You rewrite code search queries. Output a JSON array with exactly {cap} alternative queries. Use different terminology - do NOT repeat any words from the original.\"\n            prompt = f'Rewrite \"{original_q}\" using completely different technical terms:'\n        elif runtime_kind == \"glm\":\n            from scripts.refrag_glm import GLMRefragClient  # type: ignore\n            client = GLMRefragClient()\n            # no_thinking=True: use configured GLM_MODEL but skip thinking for fast response\n            # All GLM models (4.5, 4.6, 4.7) support thinking: {type: \"disabled\"}\n            extra_kwargs[\"no_thinking\"] = True\n            use_force_json = True  # GLM works best with response_format: json_object\n            # Focus on IMPLEMENTATIONS not concepts - gets more diverse results\n            prompt = (\n                f'For code search \"{original_q}\", suggest {cap} alternative queries focusing on:\\n'\n                f'- Library/package names (e.g., \"nltk wordnet\", \"gensim vectors\")\\n'\n                f'- Specific algorithms/techniques used internally\\n'\n                f'- Data structures or patterns\\n\\n'\n                f'Output JSON array with {cap} implementation-focused queries:'\n            )\n        else:\n            from scripts.refrag_llamacpp import LlamaCppRefragClient  # type: ignore\n            client = LlamaCppRefragClient()\n            # llama.cpp / Granite: structured prompt with stop tokens\n            stop_tokens = [\"\\n\\n\", \"```\", \"]\"]  # Stop after first array closes\n            prompt = (\n                f'Rewrite this code search query using different technical terms.\\n'\n                f'Do NOT repeat words from the original. Use alternative concepts.\\n'\n                f'Original: {original_q}\\n\\n'\n                f'Output {cap} alternatives as JSON array:\\n['\n            )\n\n        out = client.generate_with_soft_embeddings(\n            prompt=prompt,\n            max_tokens=int(os.environ.get(\"EXPAND_MAX_TOKENS\", \"256\") or 256),\n            # Some creativity needed for diverse expansions\n            temperature=float(os.environ.get(\"EXPAND_TEMPERATURE\", \"0.7\") or 0.7),\n            top_k=int(os.environ.get(\"EXPAND_TOP_K\", \"40\") or 40),\n            top_p=float(os.environ.get(\"EXPAND_TOP_P\", \"0.9\") or 0.9),\n            stop=stop_tokens,\n            force_json=use_force_json,\n            **extra_kwargs,\n        )\n        import json as _json\n        import re as _re\n\n        if debug_expand:\n            logger.debug(\"expand_query raw output\", extra={\"runtime\": runtime_kind, \"out\": repr(out)})\n\n        alts: list[str] = []\n        seen = {q.strip() for q in qlist if isinstance(q, str)}\n        max_len = int(os.environ.get(\"EXPAND_MAX_CHARS\", \"240\") or 240)\n\n        def _maybe_add(s: str) -> None:\n            ss = (s or \"\").strip()\n            if not ss:\n                return\n            # Trim extreme outputs and collapse whitespace\n            ss = _re.sub(r\"\\s+\", \" \", ss)\n            if max_len and len(ss) > max_len:\n                ss = ss[:max_len].rstrip()\n            if ss in seen:\n                return\n            seen.add(ss)\n            alts.append(ss)\n\n        # For llama.cpp, prompt ends with '[' so we need to prepend it and append ']'\n        if runtime_kind == \"llamacpp\" and out:\n            out = out.strip()\n            if not out.startswith(\"[\"):\n                out = \"[\" + out\n            if not out.endswith(\"]\"):\n                out = out + \"]\"\n        # Strip markdown code blocks if present\n        out = _re.sub(r'^```(?:json)?\\s*', '', out.strip())\n        out = _re.sub(r'\\s*```$', '', out)\n\n        def _extract_strings_from_parsed(parsed: Any) -> None:\n            \"\"\"Extract strings from parsed JSON - handles list or dict with common keys.\"\"\"\n            nonlocal alts\n            # If it's a list, iterate directly\n            if isinstance(parsed, list):\n                for s in parsed:\n                    if isinstance(s, str):\n                        _maybe_add(s)\n                        if len(alts) >= cap:\n                            return\n            # If it's a dict, look for common keys that contain the array\n            elif isinstance(parsed, dict):\n                for key in [\"answer\", \"alternatives\", \"queries\", \"results\", \"data\"]:\n                    if key in parsed and isinstance(parsed[key], list):\n                        for s in parsed[key]:\n                            if isinstance(s, str):\n                                _maybe_add(s)\n                                if len(alts) >= cap:\n                                    return\n                        return  # Found and processed a key\n                # Last resort: try any list value in the dict\n                for v in parsed.values():\n                    if isinstance(v, list):\n                        for s in v:\n                            if isinstance(s, str):\n                                _maybe_add(s)\n                                if len(alts) >= cap:\n                                    return\n                        return  # Used first list found\n\n        try:\n            # First try direct JSON parse\n            parsed = _json.loads(out)\n            _extract_strings_from_parsed(parsed)\n        except Exception as parse_err:\n            logger.debug(f\"expand_query direct parse failed: {parse_err}\")\n            # Fallback: try Python literal eval for single-quoted lists\n            try:\n                import ast\n                parsed = ast.literal_eval(out)\n                if isinstance(parsed, list):\n                    for s in parsed:\n                        if isinstance(s, str):\n                            _maybe_add(s)\n                            if len(alts) >= cap:\n                                break\n            except Exception:\n                pass\n            # Fallback: extract JSON array from text (model may prepend text like \"Alternates:\\n\")\n            if not alts:\n                try:\n                    # Find first [ and last ] to extract the array\n                    match = _re.search(r'\\[[\\s\\S]*\\]', out)\n                    if match:\n                        arr_text = match.group(0)\n                        logger.debug(f\"expand_query found array: {repr(arr_text)}\")\n                        # Try JSON first, then Python literal eval\n                        try:\n                            parsed = _json.loads(arr_text)\n                        except Exception:\n                            import ast\n                            parsed = ast.literal_eval(arr_text)\n                        if isinstance(parsed, list):\n                            for s in parsed:\n                                if isinstance(s, str):\n                                    _maybe_add(s)\n                                    if len(alts) >= cap:\n                                        break\n                    else:\n                        logger.debug(\"expand_query no array match found\")\n                        # Fallback: extract quoted strings from numbered lists\n                        # Pattern matches: 1. \"text\" or - \"text\" or * \"text\"\n                        quoted_matches = _re.findall(r'(?:^|\\n)\\s*(?:\\d+\\.|\\-|\\*)\\s*[\"\\']([^\"\\']+)[\"\\']', out)\n                        if quoted_matches:\n                            logger.debug(f\"expand_query found quoted strings: {quoted_matches}\")\n                            for s in quoted_matches:\n                                _maybe_add(s)\n                                if len(alts) >= cap:\n                                    break\n                except Exception as fallback_err:\n                    logger.debug(f\"expand_query fallback parse failed: {fallback_err}\")\n        if debug_expand:\n            logger.debug(\"expand_query returning alts\", extra={\"alts\": alts})\n        capped = alts[:cap]\n        return {\n            \"ok\": True,\n            \"original_query\": qlist[0] if qlist else \"\",\n            \"alternates\": capped,\n            \"total_queries\": 1 + len(capped),\n            \"decoder_used\": runtime_kind,\n        }\n    except Exception as e:\n        fallback_alts: list[str] = []\n        for q in qlist:\n            q = q.strip()\n            if not q:\n                continue\n            for suffix in (\" implementation\", \" usage\", \" example\", \" test\"):\n                cand = f\"{q}{suffix}\"\n                if cand not in qlist and cand not in fallback_alts:\n                    fallback_alts.append(cand)\n                    if len(fallback_alts) >= cap:\n                        break\n            if len(fallback_alts) >= cap:\n                break\n        if fallback_alts:\n            return {\n                \"ok\": True,\n                \"original_query\": qlist[0] if qlist else \"\",\n                \"alternates\": fallback_alts[:cap],\n                \"total_queries\": 1 + len(fallback_alts[:cap]),\n                \"decoder_used\": \"fallback\",\n                \"hint\": f\"decoder error: {e}\",\n            }\n        return {\n            \"ok\": False,\n            \"original_query\": qlist[0] if qlist else \"\",\n            \"alternates\": [],\n            \"total_queries\": 1,\n            \"decoder_used\": \"none\",\n            \"error\": str(e),\n        }",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function__maybe_add_150": {
      "name": "_maybe_add",
      "type": "function",
      "start_line": 150,
      "end_line": 161,
      "content_hash": "ba60f8103bf56ef12b8996ec7dc178ffc83db52a",
      "content": "        def _maybe_add(s: str) -> None:\n            ss = (s or \"\").strip()\n            if not ss:\n                return\n            # Trim extreme outputs and collapse whitespace\n            ss = _re.sub(r\"\\s+\", \" \", ss)\n            if max_len and len(ss) > max_len:\n                ss = ss[:max_len].rstrip()\n            if ss in seen:\n                return\n            seen.add(ss)\n            alts.append(ss)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function__extract_strings_from_parsed_174": {
      "name": "_extract_strings_from_parsed",
      "type": "function",
      "start_line": 174,
      "end_line": 202,
      "content_hash": "1966dee129e3b0e8cc67473df9c85f4ed80afcb6",
      "content": "        def _extract_strings_from_parsed(parsed: Any) -> None:\n            \"\"\"Extract strings from parsed JSON - handles list or dict with common keys.\"\"\"\n            nonlocal alts\n            # If it's a list, iterate directly\n            if isinstance(parsed, list):\n                for s in parsed:\n                    if isinstance(s, str):\n                        _maybe_add(s)\n                        if len(alts) >= cap:\n                            return\n            # If it's a dict, look for common keys that contain the array\n            elif isinstance(parsed, dict):\n                for key in [\"answer\", \"alternatives\", \"queries\", \"results\", \"data\"]:\n                    if key in parsed and isinstance(parsed[key], list):\n                        for s in parsed[key]:\n                            if isinstance(s, str):\n                                _maybe_add(s)\n                                if len(alts) >= cap:\n                                    return\n                        return  # Found and processed a key\n                # Last resort: try any list value in the dict\n                for v in parsed.values():\n                    if isinstance(v, list):\n                        for s in v:\n                            if isinstance(s, str):\n                                _maybe_add(s)\n                                if len(alts) >= cap:\n                                    return\n                        return  # Used first list found",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}