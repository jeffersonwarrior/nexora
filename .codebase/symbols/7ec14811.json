{
  "file_path": "/work/context-engine/scripts/rerank_tools/query.py",
  "file_hash": "b85eac02fcde46a808d12f95521e683e2f9f0249",
  "updated_at": "2025-12-26T17:34:21.313276",
  "symbols": {
    "function_expand_queries_36": {
      "name": "expand_queries",
      "type": "function",
      "start_line": 36,
      "end_line": 48,
      "content_hash": "0e6138aef01c9f4ae1da70bd0d5a55f7242f7784",
      "content": "def expand_queries(\n    queries: List[str], language: str | None = None, max_extra: int = 2\n) -> List[str]:\n    out: List[str] = list(queries)\n    for q in list(queries):\n        ql = q.lower()\n        for word, syns in CODE_SYNONYMS.items():\n            if word in ql:\n                for s in syns[:max_extra]:\n                    exp = re.sub(rf\"\\b{re.escape(word)}\\b\", s, q, flags=re.IGNORECASE)\n                    if exp not in out:\n                        out.append(exp)\n    return out[: max(8, len(queries))]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function__env_truthy_51": {
      "name": "_env_truthy",
      "type": "function",
      "start_line": 51,
      "end_line": 54,
      "content_hash": "4ba8b911ad3c1e8506b914f7510f211af28fa4bb",
      "content": "def _env_truthy(val: str | None, default: bool) -> bool:\n    if val is None:\n        return default\n    return val.strip().lower() in {\"1\", \"true\", \"yes\", \"on\"}",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_derive_vector_name_57": {
      "name": "derive_vector_name",
      "type": "function",
      "start_line": 57,
      "end_line": 68,
      "content_hash": "215089831d48d96043055006225a7f24ad723053",
      "content": "def derive_vector_name(model_name: str) -> str:\n    name = model_name.strip().lower()\n    if \"bge-base-en-v1.5\" in name:\n        return \"fast-bge-base-en-v1.5\"\n    if \"minilm\" in name:\n        return \"fast-all-minilm-l6-v2\"\n    # fallback sanitize\n    for ch in [\"/\", \".\", \" \", \"_\"]:\n        name = name.replace(ch, \"-\")\n    while \"--\" in name:\n        name = name.replace(\"--\", \"-\")\n    return name",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_score_candidate_71": {
      "name": "score_candidate",
      "type": "function",
      "start_line": 71,
      "end_line": 84,
      "content_hash": "00014cd938871b12e09c478c412b0eb3d54a0e77",
      "content": "def score_candidate(\n    base_score: float, count: int, md: Dict[str, Any], want_lang: str, want_prefix: str\n) -> float:\n    s = base_score\n    # Encourage consensus across multiple phrasings\n    s += 0.02 * max(0, count - 1)\n    # Boosts for metadata matches\n    lang = (md or {}).get(\"language\") or \"\"\n    if want_lang and lang.lower() == want_lang.lower():\n        s += 0.03\n    prefix = (md or {}).get(\"path_prefix\") or \"\"\n    if want_prefix and str(prefix).startswith(want_prefix):\n        s += 0.03\n    return s",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_main_87": {
      "name": "main",
      "type": "function",
      "start_line": 87,
      "end_line": 275,
      "content_hash": "5d4947f63642d0d541dfa8523ce249744955e876",
      "content": "def main():\n    parser = argparse.ArgumentParser(\n        description=\"Multi-query re-ranker for Qdrant code search (no new deps)\"\n    )\n    parser.add_argument(\n        \"--query\",\n        \"-q\",\n        action=\"append\",\n        required=True,\n        help=\"Query text; repeat flag to add variants\",\n    )\n    parser.add_argument(\n        \"--limit\", type=int, default=8, help=\"Final top-N to print after re-ranking\"\n    )\n    parser.add_argument(\n        \"--per-query\",\n        type=int,\n        default=12,\n        help=\"How many results to pull per query before fusing\",\n    )\n    parser.add_argument(\n        \"--language\", type=str, default=\"\", help=\"Preferred language (boost)\"\n    )\n    parser.add_argument(\n        \"--under\",\n        type=str,\n        default=\"\",\n        help=\"Preferred path_prefix (boost), e.g. /work/scripts\",\n    )\n    parser.add_argument(\n        \"--symbol\",\n        type=str,\n        default=\"\",\n        help=\"Optional server-side symbol filter (exact)\",\n    )\n    # Expansion enabled by default; allow disabling via --no-expand or RERANK_EXPAND=0\n    parser.add_argument(\n        \"--expand\",\n        dest=\"expand\",\n        action=\"store_true\",\n        default=_env_truthy(os.environ.get(\"RERANK_EXPAND\"), True),\n        help=\"Enable simple query expansion\",\n    )\n    parser.add_argument(\n        \"--no-expand\",\n        dest=\"expand\",\n        action=\"store_false\",\n        help=\"Disable query expansion\",\n    )\n\n    args = parser.parse_args()\n\n    client = QdrantClient(url=QDRANT_URL)\n    if _EMBEDDER_FACTORY:\n        model = _get_embedding_model(MODEL)\n    else:\n        model = TextEmbedding(model_name=MODEL)\n    vec_name = derive_vector_name(MODEL)\n\n    # Build query list (optionally expanded)\n    queries = list(args.query)\n    if args.expand:\n        queries = expand_queries(queries, args.language or None)\n\n    cand: Dict[str, Dict[str, Any]] = {}\n    counts: Dict[str, int] = defaultdict(int)\n\n    for q in queries:\n        v = next(model.embed([q]))\n        # Optional server-side filter to reduce bandwidth\n        flt = None\n        if args.language or args.under or args.symbol:\n            must = []\n            if args.language:\n                must.append(\n                    models.FieldCondition(\n                        key=\"metadata.language\",\n                        match=models.MatchValue(value=args.language),\n                    )\n                )\n            if args.under:\n                must.append(\n                    models.FieldCondition(\n                        key=\"metadata.path_prefix\",\n                        match=models.MatchValue(value=args.under),\n                    )\n                )\n            if args.symbol:\n                must.append(\n                    models.FieldCondition(\n                        key=\"metadata.symbol\",\n                        match=models.MatchValue(value=args.symbol),\n                    )\n                )\n            flt = models.Filter(must=must)\n\n        # Prefer modern query_points API with 'using' for named vector\n        try:\n            qp = client.query_points(\n                collection_name=COLLECTION,\n                query=v.tolist(),\n                using=vec_name,\n                query_filter=flt,\n                search_params=models.SearchParams(hnsw_ef=128),\n                limit=args.per_query,\n                with_payload=True,\n            )\n            res_points = getattr(qp, \"points\", qp)\n        except Exception:\n            # Fallback to deprecated search API\n            res_points = client.search(\n                collection_name=COLLECTION,\n                query_vector={\"name\": vec_name, \"vector\": v.tolist()},\n                limit=args.per_query,\n                with_payload=True,\n                query_filter=flt,\n            )\n        for p in res_points:\n            pid = str(p.id)\n            counts[pid] += 1\n            if pid not in cand or p.score > cand[pid][\"base_score\"]:\n                cand[pid] = {\n                    \"base_score\": float(p.score),\n                    \"payload\": p.payload or {},\n                }\n\n    # Prepare recency normalization\n    timestamps: List[int] = []\n    for data in cand.values():\n        md = (data.get(\"payload\") or {}).get(\"metadata\") or {}\n        ts = md.get(\"ingested_at\")\n        if isinstance(ts, int):\n            timestamps.append(ts)\n    has_ts = len(timestamps) > 0\n    if has_ts:\n        tmin, tmax = min(timestamps), max(timestamps)\n        span = max(1, tmax - tmin)\n\n    # Auto-infer dominant language if none provided (no config needed)\n    want_lang = args.language\n    if not want_lang and cand:\n        lang_counts: Dict[str, int] = defaultdict(int)\n        for data in cand.values():\n            md = (data.get(\"payload\") or {}).get(\"metadata\") or {}\n            l = (md.get(\"language\") or \"\").lower()\n            if l:\n                lang_counts[l] += 1\n        if lang_counts:\n            want_lang = max(lang_counts.items(), key=lambda x: x[1])[0]\n\n    fused = []\n    for pid, data in cand.items():\n        md = (data[\"payload\"] or {}).get(\"metadata\") or {}\n        final = score_candidate(\n            data[\"base_score\"], counts[pid], md, want_lang, args.under\n        )\n        # Symbol/path match boost using expanded queries\n        sym_text = \" \".join(\n            [str(md.get(\"symbol\") or \"\"), str(md.get(\"symbol_path\") or \"\")]\n        ).lower()\n        if any((q.lower() in sym_text) for q in queries):\n            final += SYMBOL_BOOST\n        # Recency bump (normalized)\n        if \"span\" in locals() and has_ts:\n            ts = md.get(\"ingested_at\")\n            if isinstance(ts, int):\n                norm = (ts - tmin) / span if span else 0.0\n                final += RECENCY_WEIGHT * norm\n        fused.append((final, pid, data))\n\n    fused.sort(key=lambda x: x[0], reverse=True)\n\n    print(f\"Multi-query rerank: queries={len(args.query)} model={MODEL} vec={vec_name}\")\n    for i, (final, pid, data) in enumerate(fused[: args.limit], 1):\n        md = (data[\"payload\"] or {}).get(\"metadata\") or {}\n        info = (data[\"payload\"] or {}).get(\"information\") or (\n            data[\"payload\"] or {}\n        ).get(\"document\")\n        path = md.get(\"path\")\n        lang = md.get(\"language\")\n        print(\n            {\n                \"rank\": i,\n                \"score\": round(final, 4),\n                \"path\": path,\n                \"language\": lang,\n                \"information\": info,\n            }\n        )",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}