{
  "file_path": "/work/external-deps/helix-db/helix-db/src/helix_engine/bm25/bm25_tests.rs",
  "file_hash": "57bc0b201e0b0f8f8e39258c284ad1db8526e664",
  "updated_at": "2025-12-26T17:34:22.771024",
  "symbols": {
    "function_setup_test_env_22": {
      "name": "setup_test_env",
      "type": "function",
      "start_line": 22,
      "end_line": 36,
      "content_hash": "606161a43a46b9be748599a0339e027cd704f239",
      "content": "    fn setup_test_env() -> (Env, tempfile::TempDir) {\n        let temp_dir = tempdir().unwrap();\n        let path = temp_dir.path();\n\n        let env = unsafe {\n            EnvOpenOptions::new()\n                .map_size(4 * 1024 * 1024 * 1024) // 4GB\n                .max_dbs(20)\n                .open(path)\n                .unwrap()\n        };\n\n        (env, temp_dir)\n    }\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_setup_bm25_config_37": {
      "name": "setup_bm25_config",
      "type": "function",
      "start_line": 37,
      "end_line": 44,
      "content_hash": "300958da0de62c8fdba8be500530ea977848a0f4",
      "content": "    fn setup_bm25_config() -> (HBM25Config, tempfile::TempDir) {\n        let (env, temp_dir) = setup_test_env();\n        let mut wtxn = env.write_txn().unwrap();\n        let config = HBM25Config::new(&env, &mut wtxn).unwrap();\n        wtxn.commit().unwrap();\n        (config, temp_dir)\n    }\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_setup_helix_storage_45": {
      "name": "setup_helix_storage",
      "type": "function",
      "start_line": 45,
      "end_line": 52,
      "content_hash": "cd44dc0ad19acc6c38d5c79a776e63f39f86d861",
      "content": "    fn setup_helix_storage() -> (HelixGraphStorage, tempfile::TempDir) {\n        let temp_dir = tempdir().unwrap();\n        let path = temp_dir.path().to_str().unwrap();\n        let config = Config::default();\n        let storage = HelixGraphStorage::new(path, config, VersionInfo::default()).unwrap();\n        (storage, temp_dir)\n    }\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_generate_random_vectors_53": {
      "name": "generate_random_vectors",
      "type": "function",
      "start_line": 53,
      "end_line": 68,
      "content_hash": "11c9175fba698a0ee296117d14cede2f40aae397",
      "content": "    fn generate_random_vectors(n: usize, d: usize) -> Vec<Vec<f64>> {\n        let mut rng = rand::rng();\n        let mut vectors = Vec::with_capacity(n);\n\n        for _ in 0..n {\n            let mut vector = Vec::with_capacity(d);\n            for _ in 0..d {\n                vector.push(rng.random::<f64>());\n            }\n            vectors.push(vector);\n        }\n\n        vectors\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_tokenize_with_filter_69": {
      "name": "test_tokenize_with_filter",
      "type": "function",
      "start_line": 69,
      "end_line": 86,
      "content_hash": "ec9103c1866b000dbfcb2e0c06a9c3b304f79957",
      "content": "    fn test_tokenize_with_filter() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n\n        let text = \"The quick brown fox jumps over the lazy dog! It was amazing.\";\n        let tokens = bm25.tokenize::<true>(text);\n\n        // should filter out words with length <= 2 and normalize to lowercase\n        let expected = [\n            \"the\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\", \"was\", \"amazing\",\n        ];\n        assert_eq!(tokens.len(), expected.len());\n\n        for (i, token) in tokens.iter().enumerate() {\n            assert_eq!(token, expected[i]);\n        }\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_tokenize_without_filter_87": {
      "name": "test_tokenize_without_filter",
      "type": "function",
      "start_line": 87,
      "end_line": 102,
      "content_hash": "e756587be58b5eb73aeceaac1037cee2ace3d561",
      "content": "    fn test_tokenize_without_filter() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n\n        let text = \"A B CD efg!\";\n        let tokens = bm25.tokenize::<false>(text);\n\n        // should not filter out short words\n        let expected = [\"a\", \"b\", \"cd\", \"efg\"];\n        assert_eq!(tokens.len(), expected.len());\n\n        for (i, token) in tokens.iter().enumerate() {\n            assert_eq!(token, expected[i]);\n        }\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_tokenize_edge_cases_punctuation_only_103": {
      "name": "test_tokenize_edge_cases_punctuation_only",
      "type": "function",
      "start_line": 103,
      "end_line": 110,
      "content_hash": "dd0d93caa5076389d1d49ad5e6eeea3eb81aa252",
      "content": "    fn test_tokenize_edge_cases_punctuation_only() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n\n        let tokens = bm25.tokenize::<true>(\"!@#$%^&*()\");\n        assert_eq!(tokens.len(), 0);\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_insert_document_111": {
      "name": "test_insert_document",
      "type": "function",
      "start_line": 111,
      "end_line": 137,
      "content_hash": "90dbdbe18748ae31f1e7d97e97ce4f98702ba167",
      "content": "    fn test_insert_document() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        let mut wtxn = bm25.graph_env.write_txn().unwrap();\n\n        let doc_id = 123u128;\n        let doc = \"The quick brown fox jumps over the lazy dog\";\n\n        let result = bm25.insert_doc(&mut wtxn, doc_id, doc);\n        assert!(result.is_ok());\n\n        // check that document length was stored\n        let doc_length = bm25.doc_lengths_db.get(&wtxn, &doc_id).unwrap();\n        assert!(doc_length.is_some());\n        assert!(doc_length.unwrap() > 0);\n\n        // check that metadata was updated\n        let metadata_bytes = bm25.metadata_db.get(&wtxn, METADATA_KEY).unwrap();\n        assert!(metadata_bytes.is_some());\n\n        let metadata: BM25Metadata = bincode::deserialize(metadata_bytes.unwrap()).unwrap();\n        assert_eq!(metadata.total_docs, 1);\n        assert!(metadata.avgdl > 0.0);\n\n        wtxn.commit().unwrap();\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_insert_multiple_documents_138": {
      "name": "test_insert_multiple_documents",
      "type": "function",
      "start_line": 138,
      "end_line": 161,
      "content_hash": "0376ad558a7deab99e4dcac87ebacc4b835c0a77",
      "content": "    fn test_insert_multiple_documents() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        let mut wtxn = bm25.graph_env.write_txn().unwrap();\n\n        let docs = vec![\n            (1u128, \"The quick brown fox\"),\n            (2u128, \"jumps over the lazy dog\"),\n            (3u128, \"machine learning algorithms\"),\n        ];\n\n        for (doc_id, doc) in &docs {\n            let result = bm25.insert_doc(&mut wtxn, *doc_id, doc);\n            assert!(result.is_ok());\n        }\n\n        // check metadata\n        let metadata_bytes = bm25.metadata_db.get(&wtxn, METADATA_KEY).unwrap().unwrap();\n        let metadata: BM25Metadata = bincode::deserialize(metadata_bytes).unwrap();\n        assert_eq!(metadata.total_docs, 3);\n\n        wtxn.commit().unwrap();\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_search_single_term_162": {
      "name": "test_search_single_term",
      "type": "function",
      "start_line": 162,
      "end_line": 236,
      "content_hash": "532105926d6302c1fb25242ae7cbb96c38c684e2",
      "content": "    fn test_search_single_term() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        let mut wtxn = bm25.graph_env.write_txn().unwrap();\n        let arena = Bump::new();\n\n        // model properties list stored in nodes\n        let props1: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"Swift shadow leaps\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"Idle fox wolf rests\".to_string()),\n            ),\n        ]);\n\n        let props2: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"Rapid hare bounds\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"Quiet bear naps\".to_string()),\n            ),\n        ]);\n\n        let props3: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"Fleet deer fox sprints\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"Calm owl dozes\".to_string()),\n            ),\n        ]);\n\n        let nodes = [props1, props2, props3];\n\n        for (i, props) in nodes.iter().enumerate() {\n            let props_map = ImmutablePropertiesMap::new(\n                props.len(),\n                props\n                    .iter()\n                    .map(|(k, v)| (arena.alloc_str(k) as &str, v.clone())),\n                &arena,\n            );\n            let data = props_map.flatten_bm25();\n            bm25.insert_doc(&mut wtxn, i as u128, &data).unwrap();\n        }\n        wtxn.commit().unwrap();\n\n        // search for \"fox\"\n        let rtxn = bm25.graph_env.read_txn().unwrap();\n        let arena = Bump::new();\n        let results = bm25.search(&rtxn, \"fox\", 10, &arena).unwrap();\n\n        println!(\"results: {results:?}\");\n\n        // should return documents 1 and 3 (both contain \"fox\")\n        assert_eq!(results.len(), 2);\n\n        let doc_ids: Vec<u128> = results.iter().map(|(id, _)| *id).collect();\n        assert!(doc_ids.contains(&0u128));\n        assert!(doc_ids.contains(&2u128));\n\n        // scores should be positive\n        for (_, score) in &results {\n            assert!(*score != 0.0);\n        }\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_search_multiple_terms_237": {
      "name": "test_search_multiple_terms",
      "type": "function",
      "start_line": 237,
      "end_line": 302,
      "content_hash": "4bd8779066eda204dfb63725f07457eaaf42e12d",
      "content": "    fn test_search_multiple_terms() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        let mut wtxn = bm25.graph_env.write_txn().unwrap();\n        let arena = Bump::new();\n\n        let props1: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"machine learning algorithms for data science\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"deep learning\".to_string()),\n            ),\n        ]);\n\n        let props2: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"deep learning neural networks\".to_string()),\n            ),\n            (\"label2\".to_string(), Value::I64(6969)),\n        ]);\n\n        let props3: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"data analysis and machine learning\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"natural language processing\".to_string()),\n            ),\n        ]);\n\n        let nodes = [props1, props2, props3];\n\n        for (i, props) in nodes.iter().enumerate() {\n            let props_map = ImmutablePropertiesMap::new(\n                props.len(),\n                props\n                    .iter()\n                    .map(|(k, v)| (arena.alloc_str(k) as &str, v.clone())),\n                &arena,\n            );\n            let data = props_map.flatten_bm25();\n            bm25.insert_doc(&mut wtxn, i as u128, &data).unwrap();\n        }\n        wtxn.commit().unwrap();\n\n        let rtxn = bm25.graph_env.read_txn().unwrap();\n        let arena = Bump::new();\n        let results = bm25.search(&rtxn, \"machine learning\", 10, &arena).unwrap();\n\n        println!(\"results: {results:?}\");\n\n        // documents 1 and 3 should score highest (contain both terms)\n        assert!(results.len() >= 2);\n\n        let doc_ids: Vec<u128> = results.iter().map(|(id, _)| *id).collect();\n        assert!(doc_ids.contains(&0u128));\n        assert!(doc_ids.contains(&1u128));\n        assert!(doc_ids.contains(&2u128));\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_search_many_terms_303": {
      "name": "test_search_many_terms",
      "type": "function",
      "start_line": 303,
      "end_line": 1298,
      "content_hash": "011a247e3b1e99bfdaa65643f1fe80da3525db42",
      "content": "    fn test_search_many_terms() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        let mut wtxn = bm25.graph_env.write_txn().unwrap();\n        let arena = Bump::new();\n\n        let props1: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"machine learning algorithms for data science\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"deep learning\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"neural networks optimization\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"data analysis techniques\".to_string()),\n            ),\n        ]);\n\n        let props2: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"deep learning neural networks\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"computer vision models\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"reinforcement learning\".to_string()),\n            ),\n        ]);\n\n        let props3: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"data analysis and machine learning\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"natural language processing\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"sentiment analysis\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"text mining\".to_string()),\n            ),\n        ]);\n\n        let props4: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"machine learning for predictive analytics\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"deep learning frameworks\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"image recognition\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"data preprocessing\".to_string()),\n            ),\n        ]);\n\n        let props5: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"neural networks for data science\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning pipelines\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"feature engineering\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"model evaluation\".to_string()),\n            ),\n        ]);\n\n        let props6: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"deep learning for image processing\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning models\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"clustering algorithms\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"dimensionality reduction\".to_string()),\n            ),\n        ]);\n\n        let props7: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"natural language processing techniques\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning applications\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"text classification\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"data visualization\".to_string()),\n            ),\n        ]);\n\n        let props8: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"machine learning for time series\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"deep learning architectures\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"anomaly detection\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"predictive modeling\".to_string()),\n            ),\n        ]);\n\n        let props9: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"data science with machine learning\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"neural networks training\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"regression analysis\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"model optimization\".to_string()),\n            ),\n        ]);\n\n        let props10: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"deep learning for speech recognition\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning workflows\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"audio processing\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"data augmentation\".to_string()),\n            ),\n        ]);\n\n        let props11: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"machine learning for fraud detection\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"deep learning systems\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"pattern recognition\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"data cleaning\".to_string()),\n            ),\n        ]);\n\n        let props12: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"natural language processing models\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning algorithms\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"topic modeling\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"text analytics\".to_string()),\n            ),\n        ]);\n\n        let props13: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"machine learning for recommendation systems\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"deep learning techniques\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"collaborative filtering\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"user profiling\".to_string()),\n            ),\n        ]);\n\n        let props14: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"data science and neural networks\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning strategies\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"classification models\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"data exploration\".to_string()),\n            ),\n        ]);\n\n        let props15: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"deep learning for object detection\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning tools\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"image segmentation\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"feature extraction\".to_string()),\n            ),\n        ]);\n\n        let props16: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"machine learning for customer segmentation\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"deep learning applications\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"market analysis\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"data clustering\".to_string()),\n            ),\n        ]);\n\n        let props17: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"natural language processing for chatbots\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning frameworks\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"dialogue systems\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"text generation\".to_string()),\n            ),\n        ]);\n\n        let props18: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"machine learning for predictive maintenance\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"deep learning models\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"equipment monitoring\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"failure prediction\".to_string()),\n            ),\n        ]);\n\n        let props19: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"data science with deep learning\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning techniques\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"statistical modeling\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"data interpretation\".to_string()),\n            ),\n        ]);\n\n        let props20: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"deep learning for facial recognition\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning processes\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"biometric analysis\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"identity verification\".to_string()),\n            ),\n        ]);\n\n        let props21: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"machine learning for supply chain\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"deep learning optimization\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"inventory management\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"demand forecasting\".to_string()),\n            ),\n        ]);\n\n        let props22: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"natural language processing for sentiment\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning solutions\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"opinion mining\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"text processing\".to_string()),\n            ),\n        ]);\n\n        let props23: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"machine learning for risk assessment\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"deep learning algorithms\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"probability analysis\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"data modeling\".to_string()),\n            ),\n        ]);\n\n        let props24: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"data science for business intelligence\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning insights\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"decision support\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"data reporting\".to_string()),\n            ),\n        ]);\n\n        let props25: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"deep learning for autonomous vehicles\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning systems\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"path planning\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"sensor fusion\".to_string()),\n            ),\n        ]);\n\n        let props26: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"machine learning for healthcare\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"deep learning diagnostics\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"medical imaging\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"patient data analysis\".to_string()),\n            ),\n        ]);\n\n        let props27: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"natural language processing for translation\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning models\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"language models\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"text translation\".to_string()),\n            ),\n        ]);\n\n        let props28: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"machine learning for energy optimization\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"deep learning strategies\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"energy forecasting\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"resource allocation\".to_string()),\n            ),\n        ]);\n\n        let props29: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"data science for marketing\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning analytics\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"customer insights\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"campaign analysis\".to_string()),\n            ),\n        ]);\n\n        let props30: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"deep learning for video analysis\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning pipelines\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"motion detection\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"frame analysis\".to_string()),\n            ),\n        ]);\n\n        let props31: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"machine learning for cybersecurity\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"deep learning detection\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"threat analysis\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"network security\".to_string()),\n            ),\n        ]);\n\n        let props32: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"natural language processing for summarization\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning techniques\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"text summarization\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"content analysis\".to_string()),\n            ),\n        ]);\n\n        let props33: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"machine learning for logistics\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"deep learning optimization\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"route planning\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"supply chain analytics\".to_string()),\n            ),\n        ]);\n\n        let props34: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"data science for finance\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning predictions\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"market forecasting\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"risk modeling\".to_string()),\n            ),\n        ]);\n\n        let props35: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"deep learning for robotics\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning algorithms\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"motion planning\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"sensor processing\".to_string()),\n            ),\n        ]);\n\n        let props36: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"machine learning for agriculture\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"deep learning applications\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"crop monitoring\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"yield prediction\".to_string()),\n            ),\n        ]);\n\n        let props37: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"natural language processing for search\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning systems\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"query processing\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"search optimization\".to_string()),\n            ),\n        ]);\n\n        let props38: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"machine learning for retail\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"deep learning models\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"sales forecasting\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"inventory optimization\".to_string()),\n            ),\n        ]);\n\n        let props39: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"data science for education\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning tools\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"student performance\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"learning analytics\".to_string()),\n            ),\n        ]);\n\n        let props40: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"deep learning for gaming\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning strategies\".to_string()),\n            ),\n            (\"label3\".to_string(), Value::String(\"game AI\".to_string())),\n            (\n                \"label4\".to_string(),\n                Value::String(\"player behavior\".to_string()),\n            ),\n        ]);\n\n        let props41: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"machine learning for transportation\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"deep learning frameworks\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"traffic prediction\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"route optimization\".to_string()),\n            ),\n        ]);\n\n        let props42: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"natural language processing for legal\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning applications\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"document analysis\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"contract review\".to_string()),\n            ),\n        ]);\n\n        let props43: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"machine learning for manufacturing\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"deep learning systems\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"quality control\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"process optimization\".to_string()),\n            ),\n        ]);\n\n        let props44: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"data science for e-commerce\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning insights\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"product recommendation\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"customer segmentation\".to_string()),\n            ),\n        ]);\n\n        let props45: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"deep learning for environmental monitoring\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning models\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"climate analysis\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"sensor data\".to_string()),\n            ),\n        ]);\n\n        let props46: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"machine learning for sports analytics\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"deep learning techniques\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"player performance\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"game strategy\".to_string()),\n            ),\n        ]);\n\n        let props47: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"natural language processing for news\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning algorithms\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"article classification\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"content summarization\".to_string()),\n            ),\n        ]);\n\n        let props48: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"machine learning for urban planning\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"deep learning applications\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"traffic modeling\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"resource planning\".to_string()),\n            ),\n        ]);\n\n        let props49: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"data science for telecommunications\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning systems\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"network optimization\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"customer analytics\".to_string()),\n            ),\n        ]);\n\n        let props50: HashMap<String, Value> = HashMap::from([\n            (\n                \"label1\".to_string(),\n                Value::String(\"deep learning for astronomy\".to_string()),\n            ),\n            (\n                \"label2\".to_string(),\n                Value::String(\"machine learning frameworks\".to_string()),\n            ),\n            (\n                \"label3\".to_string(),\n                Value::String(\"star classification\".to_string()),\n            ),\n            (\n                \"label4\".to_string(),\n                Value::String(\"cosmic data analysis\".to_string()),\n            ),\n        ]);\n\n        let nodes = [\n            props1, props2, props3, props4, props5, props6, props7, props8, props9, props10,\n            props11, props12, props13, props14, props15, props16, props17, props18, props19,\n            props20, props21, props22, props23, props24, props25, props26, props27, props28,\n            props29, props30, props31, props32, props33, props34, props35, props36, props37,\n            props38, props39, props40, props41, props42, props43, props44, props45, props46,\n            props47, props48, props49, props50,\n        ];\n\n        for (i, props) in nodes.iter().enumerate() {\n            let props_map = ImmutablePropertiesMap::new(\n                props.len(),\n                props\n                    .iter()\n                    .map(|(k, v)| (arena.alloc_str(k) as &str, v.clone())),\n                &arena,\n            );\n            let data = props_map.flatten_bm25();\n            bm25.insert_doc(&mut wtxn, i as u128, &data).unwrap();\n            println!(\"{data:?}\");\n        }\n        wtxn.commit().unwrap();\n\n        let rtxn = bm25.graph_env.read_txn().unwrap();\n        let arena = Bump::new();\n        let results = bm25.search(&rtxn, \"science\", 10, &arena).unwrap();\n\n        println!(\"results: {results:?}\");\n\n        assert!(results.len() >= 2);\n\n        let doc_ids: Vec<u128> = results.iter().map(|(id, _)| *id).collect();\n        assert!(doc_ids.contains(&38u128));\n        assert!(doc_ids.contains(&43u128));\n        assert!(doc_ids.contains(&28u128));\n        assert!(doc_ids.contains(&33u128));\n        assert!(doc_ids.contains(&48u128));\n        assert!(doc_ids.contains(&18u128));\n        assert!(doc_ids.contains(&8u128));\n        assert!(doc_ids.contains(&13u128));\n        assert!(doc_ids.contains(&23u128));\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_bm25_score_calculation_1299": {
      "name": "test_bm25_score_calculation",
      "type": "function",
      "start_line": 1299,
      "end_line": 1317,
      "content_hash": "cd071f77df68870baedb963a4b9b8a1812f7a179",
      "content": "    fn test_bm25_score_calculation() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n\n        let score = bm25.calculate_bm25_score(\n            2,   // term frequency\n            10,  // doc length\n            3,   // document frequency\n            100, // total docs\n            8.0, // average doc length\n        );\n\n        println!(\"score {score}\");\n\n        // Score should be finite and reasonable\n        assert!(score.is_finite());\n        assert!(score != 0.0);\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_update_document_1318": {
      "name": "test_update_document",
      "type": "function",
      "start_line": 1318,
      "end_line": 1346,
      "content_hash": "ad014378443b980f3da233b7ceea564b2833704f",
      "content": "    fn test_update_document() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        let mut wtxn = bm25.graph_env.write_txn().unwrap();\n\n        let doc_id = 1u128;\n\n        // insert original document\n        bm25.insert_doc(&mut wtxn, doc_id, \"original content\")\n            .unwrap();\n\n        // update document\n        bm25.update_doc(&mut wtxn, doc_id, \"updated content with more words\")\n            .unwrap();\n\n        // check that document length was updated\n        let doc_length = bm25.doc_lengths_db.get(&wtxn, &doc_id).unwrap().unwrap();\n        assert!(doc_length > 2); // Should reflect the new document length\n\n        wtxn.commit().unwrap();\n\n        // search should find the updated content\n        let rtxn = bm25.graph_env.read_txn().unwrap();\n        let arena = Bump::new();\n        let results = bm25.search(&rtxn, \"updated\", 10, &arena).unwrap();\n        assert_eq!(results.len(), 1);\n        assert_eq!(results[0].0, doc_id);\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_delete_document_1347": {
      "name": "test_delete_document",
      "type": "function",
      "start_line": 1347,
      "end_line": 1383,
      "content_hash": "9849608aa55633be1f4b3a912a33a8abb76a4f88",
      "content": "    fn test_delete_document() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        let mut wtxn = bm25.graph_env.write_txn().unwrap();\n\n        let docs = vec![\n            (1u128, \"document one content\"),\n            (2u128, \"document two content\"),\n            (3u128, \"document three content\"),\n        ];\n\n        // insert documents\n        for (doc_id, doc) in &docs {\n            bm25.insert_doc(&mut wtxn, *doc_id, doc).unwrap();\n        }\n\n        // delete document 2\n        bm25.delete_doc(&mut wtxn, 2u128).unwrap();\n\n        // check that document length was removed\n        let doc_length = bm25.doc_lengths_db.get(&wtxn, &2u128).unwrap();\n        assert!(doc_length.is_none());\n\n        // check that metadata was updated\n        let metadata_bytes = bm25.metadata_db.get(&wtxn, METADATA_KEY).unwrap().unwrap();\n        let metadata: BM25Metadata = bincode::deserialize(metadata_bytes).unwrap();\n        assert_eq!(metadata.total_docs, 2); // Should be reduced by 1\n\n        wtxn.commit().unwrap();\n\n        // search should not find the deleted document\n        let rtxn = bm25.graph_env.read_txn().unwrap();\n        let arena = Bump::new();\n        let results = bm25.search(&rtxn, \"two\", 10, &arena).unwrap();\n        assert_eq!(results.len(), 0);\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_search_with_limit_1384": {
      "name": "test_search_with_limit",
      "type": "function",
      "start_line": 1384,
      "end_line": 1408,
      "content_hash": "b47f23aff4048c3ef4725cb0bfd9a539d5d7d952",
      "content": "    fn test_search_with_limit() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        let mut wtxn = bm25.graph_env.write_txn().unwrap();\n\n        // insert many documents containing the same term\n        for i in 1..=10 {\n            let doc = format!(\"document {i} contains test content\");\n            bm25.insert_doc(&mut wtxn, i as u128, &doc).unwrap();\n        }\n        wtxn.commit().unwrap();\n\n        let rtxn = bm25.graph_env.read_txn().unwrap();\n        let arena = Bump::new();\n        let results = bm25.search(&rtxn, \"test\", 5, &arena).unwrap();\n\n        // should respect the limit\n        assert_eq!(results.len(), 5);\n\n        // results should be sorted by score (descending)\n        for i in 1..results.len() {\n            assert!(results[i - 1].1 >= results[i].1);\n        }\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_search_no_results_1409": {
      "name": "test_search_no_results",
      "type": "function",
      "start_line": 1409,
      "end_line": 1424,
      "content_hash": "efb7d2e4f1a43ae4a953ca6b0848febcb2db0cad",
      "content": "    fn test_search_no_results() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        let mut wtxn = bm25.graph_env.write_txn().unwrap();\n\n        bm25.insert_doc(&mut wtxn, 1u128, \"some document content\")\n            .unwrap();\n        wtxn.commit().unwrap();\n\n        let rtxn = bm25.graph_env.read_txn().unwrap();\n        let arena = Bump::new();\n        let results = bm25.search(&rtxn, \"nonexistent\", 10, &arena).unwrap();\n\n        assert_eq!(results.len(), 0);\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_edge_cases_empty_document_1425": {
      "name": "test_edge_cases_empty_document",
      "type": "function",
      "start_line": 1425,
      "end_line": 1575,
      "content_hash": "7395886d39b5ae92618b57c229f3b55777235910",
      "content": "    fn test_edge_cases_empty_document() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        let mut wtxn = bm25.graph_env.write_txn().unwrap();\n\n        // Insert empty document\n        let result = bm25.insert_doc(&mut wtxn, 1u128, \"\");\n        assert!(result.is_ok());\n\n        // document length should be 0\n        let doc_length = bm25.doc_lengths_db.get(&wtxn, &1u128).unwrap().unwrap();\n        assert_eq!(doc_length, 0);\n\n        wtxn.commit().unwrap();\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_search() {\n        let (storage, _temp_dir) = setup_helix_storage();\n\n        let mut wtxn = storage.graph_env.write_txn().unwrap();\n        let docs = vec![\n            (1u128, \"machine learning algorithms\"),\n            (2u128, \"deep learning neural networks\"),\n            (3u128, \"data science methods\"),\n        ];\n\n        let bm25 = storage.bm25.as_ref().unwrap();\n        for (doc_id, doc) in &docs {\n            bm25.insert_doc(&mut wtxn, *doc_id, doc).unwrap();\n        }\n        wtxn.commit().unwrap();\n\n        let mut wtxn = storage.graph_env.write_txn().unwrap();\n        let vectors = generate_random_vectors(800, 650);\n        let mut arena = Bump::new();\n        for vec in &vectors {\n            let slice = arena.alloc_slice_copy(vec.as_slice());\n            let _ = storage\n                .vectors\n                .insert::<fn(&HVector, &RoTxn) -> bool>(&mut wtxn, \"vector\", slice, None, &arena);\n            arena.reset();\n        }\n        wtxn.commit().unwrap();\n\n        let query = \"machine learning\";\n        let query_vector = generate_random_vectors(1, 650);\n        let alpha = 0.5; // equal weight between BM25 and vector\n        let limit = 10;\n\n        let result = storage\n            .hybrid_search(query, &query_vector[0], alpha, limit)\n            .await;\n\n        match result {\n            Ok(results) => assert!(results.len() <= limit),\n            Err(_) => println!(\"Vector search not available\"),\n        }\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_search_alpha_vectors() {\n        let (storage, _temp_dir) = setup_helix_storage();\n\n        // Insert some test documents first\n        let mut wtxn = storage.graph_env.write_txn().unwrap();\n        let docs = vec![\n            (1u128, \"machine learning algorithms\"),\n            (2u128, \"deep learning neural networks\"),\n            (3u128, \"data science methods\"),\n        ];\n\n        let bm25 = storage.bm25.as_ref().unwrap();\n        for (doc_id, doc) in &docs {\n            bm25.insert_doc(&mut wtxn, *doc_id, doc).unwrap();\n        }\n        wtxn.commit().unwrap();\n\n        let mut wtxn = storage.graph_env.write_txn().unwrap();\n        let vectors = generate_random_vectors(800, 650);\n        let mut arena = Bump::new();\n        for vec in &vectors {\n            let slice = arena.alloc_slice_copy(vec.as_slice());\n            let _ = storage\n                .vectors\n                .insert::<fn(&HVector, &RoTxn) -> bool>(&mut wtxn, \"vector\", slice, None, &arena);\n            arena.reset();\n        }\n        wtxn.commit().unwrap();\n\n        let query = \"machine learning\";\n        let query_vector = generate_random_vectors(1, 650);\n\n        // alpha = 0.0 (Vector only)\n        let results_vector_only = storage\n            .hybrid_search(query, &query_vector[0], 0.0, 10)\n            .await;\n\n        match results_vector_only {\n            Ok(results) => assert!(results.len() <= 10),\n            Err(_) => {\n                println!(\"Vector-only search failed\")\n            }\n        }\n    }\n\n    #[tokio::test]\n    async fn test_hybrid_search_alpha_bm25() {\n        let (storage, _temp_dir) = setup_helix_storage();\n\n        // Insert some test documents first\n        let mut wtxn = storage.graph_env.write_txn().unwrap();\n        let docs = vec![\n            (1u128, \"machine learning algorithms\"),\n            (2u128, \"deep learning neural networks\"),\n            (3u128, \"data science methods\"),\n        ];\n\n        let bm25 = storage.bm25.as_ref().unwrap();\n        for (doc_id, doc) in &docs {\n            bm25.insert_doc(&mut wtxn, *doc_id, doc).unwrap();\n        }\n        wtxn.commit().unwrap();\n\n        let mut wtxn = storage.graph_env.write_txn().unwrap();\n        let vectors = generate_random_vectors(800, 650);\n        let mut arena = Bump::new();\n        for vec in &vectors {\n            let slice = arena.alloc_slice_copy(vec.as_slice());\n            let _ = storage\n                .vectors\n                .insert::<fn(&HVector, &RoTxn) -> bool>(&mut wtxn, \"vector\", slice, None, &arena);\n            arena.reset();\n        }\n        wtxn.commit().unwrap();\n\n        let query = \"machine learning\";\n        let query_vector = generate_random_vectors(1, 650);\n\n        // alpha = 1.0 (BM25 only)\n        let results_bm25_only = storage\n            .hybrid_search(query, &query_vector[0], 1.0, 10)\n            .await;\n\n        // all should be valid results or acceptable errors\n        match results_bm25_only {\n            Ok(results) => assert!(results.len() <= 10),\n            Err(_) => println!(\"BM25-only search failed\"),\n        }\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_bm25_score_properties_1576": {
      "name": "test_bm25_score_properties",
      "type": "function",
      "start_line": 1576,
      "end_line": 1590,
      "content_hash": "0f35e613f85bb2f022b3708ea9d3c1839460ca4f",
      "content": "    fn test_bm25_score_properties() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n\n        // test that higher term frequency yields higher score\n        let score1 = bm25.calculate_bm25_score(1, 10, 5, 100, 10.0);\n        let score2 = bm25.calculate_bm25_score(3, 10, 5, 100, 10.0);\n        assert!(score2 > score1);\n\n        // test that rare terms (lower df) yield higher scores\n        let score_rare = bm25.calculate_bm25_score(1, 10, 2, 100, 10.0);\n        let score_common = bm25.calculate_bm25_score(1, 10, 50, 100, 10.0);\n        assert!(score_rare > score_common);\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_metadata_consistency_1591": {
      "name": "test_metadata_consistency",
      "type": "function",
      "start_line": 1591,
      "end_line": 1630,
      "content_hash": "363d51010cab99ae2fc3dcf9806c4fd77494f34e",
      "content": "    fn test_metadata_consistency() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        let mut wtxn = bm25.graph_env.write_txn().unwrap();\n\n        let docs = vec![\n            (1u128, \"short doc\"),\n            (2u128, \"this is a much longer document with many more words\"),\n            (3u128, \"medium length document\"),\n        ];\n\n        for (doc_id, doc) in &docs {\n            bm25.insert_doc(&mut wtxn, *doc_id, doc).unwrap();\n        }\n\n        let metadata_bytes = bm25.metadata_db.get(&wtxn, METADATA_KEY).unwrap().unwrap();\n        let metadata: BM25Metadata = bincode::deserialize(metadata_bytes).unwrap();\n\n        assert_eq!(metadata.total_docs, 3);\n        assert!(metadata.avgdl > 0.0);\n        assert_eq!(metadata.k1, 1.2);\n        assert_eq!(metadata.b, 0.75);\n\n        bm25.delete_doc(&mut wtxn, 2u128).unwrap();\n\n        // check updated metadata\n        let metadata_bytes = bm25.metadata_db.get(&wtxn, METADATA_KEY).unwrap().unwrap();\n        let updated_metadata: BM25Metadata = bincode::deserialize(metadata_bytes).unwrap();\n\n        assert_eq!(updated_metadata.total_docs, 2);\n        // average document length should be recalculated\n        assert_ne!(updated_metadata.avgdl, metadata.avgdl);\n\n        wtxn.commit().unwrap();\n    }\n\n    // ============================================================================\n    // Additional Edge Case Tests\n    // ============================================================================\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_tokenize_empty_string_1631": {
      "name": "test_tokenize_empty_string",
      "type": "function",
      "start_line": 1631,
      "end_line": 1637,
      "content_hash": "9045c897062d379894836ceae6952341a1130d20",
      "content": "    fn test_tokenize_empty_string() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        let tokens = bm25.tokenize::<true>(\"\");\n        assert_eq!(tokens.len(), 0);\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_tokenize_whitespace_only_1638": {
      "name": "test_tokenize_whitespace_only",
      "type": "function",
      "start_line": 1638,
      "end_line": 1644,
      "content_hash": "2fcd27cb8f4a6d3b75f3768c9c89864230fc3cce",
      "content": "    fn test_tokenize_whitespace_only() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        let tokens = bm25.tokenize::<true>(\"   \\t\\n   \");\n        assert_eq!(tokens.len(), 0);\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_tokenize_with_numbers_1645": {
      "name": "test_tokenize_with_numbers",
      "type": "function",
      "start_line": 1645,
      "end_line": 1652,
      "content_hash": "c9064d21339c7fd9692f61ba1890e52f81e0bb19",
      "content": "    fn test_tokenize_with_numbers() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        let tokens = bm25.tokenize::<true>(\"test123 456abc\");\n        assert!(tokens.contains(&\"test123\".to_string()));\n        assert!(tokens.contains(&\"456abc\".to_string()));\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_tokenize_unicode_1653": {
      "name": "test_tokenize_unicode",
      "type": "function",
      "start_line": 1653,
      "end_line": 1660,
      "content_hash": "df53ea1651aec1fabfd0409ccd5827555b4ef339",
      "content": "    fn test_tokenize_unicode() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        let tokens = bm25.tokenize::<false>(\"\u65e5\u672c\u8a9e \u0440\u0443\u0441\u0441\u043a\u0438\u0439 fran\u00e7ais\");\n        // Should handle unicode alphanumeric characters\n        assert!(!tokens.is_empty());\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_tokenize_mixed_case_1661": {
      "name": "test_tokenize_mixed_case",
      "type": "function",
      "start_line": 1661,
      "end_line": 1671,
      "content_hash": "045b92a0f997d9b1a697ea222af27cdf22734706",
      "content": "    fn test_tokenize_mixed_case() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        let tokens = bm25.tokenize::<false>(\"HELLO hello HeLLo\");\n        // All should be lowercase\n        for token in &tokens {\n            assert_eq!(token, \"hello\");\n        }\n        assert_eq!(tokens.len(), 3);\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_calculate_bm25_score_edge_case_zero_avgdl_1672": {
      "name": "test_calculate_bm25_score_edge_case_zero_avgdl",
      "type": "function",
      "start_line": 1672,
      "end_line": 1679,
      "content_hash": "7e480c76ce1457fb5d1b3aedf19cb1115a4da536",
      "content": "    fn test_calculate_bm25_score_edge_case_zero_avgdl() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        // When avgdl is 0, should use doc_len as fallback\n        let score = bm25.calculate_bm25_score(1, 10, 5, 100, 0.0);\n        assert!(score.is_finite());\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_calculate_bm25_score_edge_case_zero_total_docs_1680": {
      "name": "test_calculate_bm25_score_edge_case_zero_total_docs",
      "type": "function",
      "start_line": 1680,
      "end_line": 1687,
      "content_hash": "d698bacea9308bd1d194ab8fe4abfeec1a9eb3ca",
      "content": "    fn test_calculate_bm25_score_edge_case_zero_total_docs() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        // Edge case: 0 total docs (uses max(1))\n        let score = bm25.calculate_bm25_score(1, 10, 5, 0, 10.0);\n        assert!(score.is_finite());\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_calculate_bm25_score_edge_case_zero_df_1688": {
      "name": "test_calculate_bm25_score_edge_case_zero_df",
      "type": "function",
      "start_line": 1688,
      "end_line": 1695,
      "content_hash": "5890350ae9bb3d0b4f9f05b1d7f5440cb1be8908",
      "content": "    fn test_calculate_bm25_score_edge_case_zero_df() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        // Edge case: 0 document frequency (uses max(1))\n        let score = bm25.calculate_bm25_score(1, 10, 0, 100, 10.0);\n        assert!(score.is_finite());\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_calculate_bm25_score_high_df_low_idf_1696": {
      "name": "test_calculate_bm25_score_high_df_low_idf",
      "type": "function",
      "start_line": 1696,
      "end_line": 1704,
      "content_hash": "35bb4b76116ed7264e04a2a018cd3118416c7533",
      "content": "    fn test_calculate_bm25_score_high_df_low_idf() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        // When df is very high relative to total_docs, IDF can be negative\n        let score = bm25.calculate_bm25_score(1, 10, 95, 100, 10.0);\n        // Score should still be finite (may be negative with high df)\n        assert!(score.is_finite());\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_calculate_bm25_score_very_short_document_1705": {
      "name": "test_calculate_bm25_score_very_short_document",
      "type": "function",
      "start_line": 1705,
      "end_line": 1713,
      "content_hash": "3726576624344b3f63dc4377fab11033c271da5b",
      "content": "    fn test_calculate_bm25_score_very_short_document() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        // Very short document with doc_len = 1\n        let score = bm25.calculate_bm25_score(1, 1, 5, 100, 10.0);\n        assert!(score.is_finite());\n        assert!(score > 0.0);\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_calculate_bm25_score_very_long_document_1714": {
      "name": "test_calculate_bm25_score_very_long_document",
      "type": "function",
      "start_line": 1714,
      "end_line": 1721,
      "content_hash": "6281325cd1141774c953cf79b4144e9a0cad6e6f",
      "content": "    fn test_calculate_bm25_score_very_long_document() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        // Very long document\n        let score = bm25.calculate_bm25_score(5, 10000, 5, 100, 100.0);\n        assert!(score.is_finite());\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_search_with_limit_zero_1722": {
      "name": "test_search_with_limit_zero",
      "type": "function",
      "start_line": 1722,
      "end_line": 1738,
      "content_hash": "5f1aef85da0f695051723b1cfd74bb613d97f806",
      "content": "    fn test_search_with_limit_zero() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        let mut wtxn = bm25.graph_env.write_txn().unwrap();\n\n        bm25.insert_doc(&mut wtxn, 1u128, \"test document content\")\n            .unwrap();\n        wtxn.commit().unwrap();\n\n        let rtxn = bm25.graph_env.read_txn().unwrap();\n        let arena = Bump::new();\n        let results = bm25.search(&rtxn, \"test\", 0, &arena).unwrap();\n\n        // With limit 0, should return empty results\n        assert_eq!(results.len(), 0);\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_delete_last_document_avgdl_becomes_zero_1739": {
      "name": "test_delete_last_document_avgdl_becomes_zero",
      "type": "function",
      "start_line": 1739,
      "end_line": 1757,
      "content_hash": "4701d902f0c45dd55fbda25caf97503373c11910",
      "content": "    fn test_delete_last_document_avgdl_becomes_zero() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        let mut wtxn = bm25.graph_env.write_txn().unwrap();\n\n        // Insert and then delete the only document\n        bm25.insert_doc(&mut wtxn, 1u128, \"only document\").unwrap();\n        bm25.delete_doc(&mut wtxn, 1u128).unwrap();\n\n        // Check metadata after deleting last document\n        let metadata_bytes = bm25.metadata_db.get(&wtxn, METADATA_KEY).unwrap().unwrap();\n        let metadata: BM25Metadata = bincode::deserialize(metadata_bytes).unwrap();\n\n        assert_eq!(metadata.total_docs, 0);\n        assert_eq!(metadata.avgdl, 0.0);\n\n        wtxn.commit().unwrap();\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_insert_document_with_repeated_terms_1758": {
      "name": "test_insert_document_with_repeated_terms",
      "type": "function",
      "start_line": 1758,
      "end_line": 1780,
      "content_hash": "64b3487327ec9c418d429f285ac81753c5181bc8",
      "content": "    fn test_insert_document_with_repeated_terms() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        let mut wtxn = bm25.graph_env.write_txn().unwrap();\n\n        // Document with repeated terms\n        bm25.insert_doc(&mut wtxn, 1u128, \"test test test unique word word\")\n            .unwrap();\n\n        // Document length should count all tokens (including duplicates)\n        // \"test\", \"test\", \"test\", \"unique\", \"word\", \"word\" = 6 tokens\n        let doc_length = bm25.doc_lengths_db.get(&wtxn, &1u128).unwrap().unwrap();\n        assert_eq!(doc_length, 6);\n\n        wtxn.commit().unwrap();\n\n        // Search should still work\n        let rtxn = bm25.graph_env.read_txn().unwrap();\n        let arena = Bump::new();\n        let results = bm25.search(&rtxn, \"test\", 10, &arena).unwrap();\n        assert_eq!(results.len(), 1);\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_search_results_sorted_by_score_1781": {
      "name": "test_search_results_sorted_by_score",
      "type": "function",
      "start_line": 1781,
      "end_line": 1813,
      "content_hash": "ee2ca5c7fc3a3eb1f00a85676c55c58f0c5d4dc6",
      "content": "    fn test_search_results_sorted_by_score() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        let mut wtxn = bm25.graph_env.write_txn().unwrap();\n\n        // Insert documents with varying relevance to \"machine learning\"\n        let docs = vec![\n            (1u128, \"machine learning machine learning machine learning\"), // High relevance\n            (2u128, \"machine learning\"),                                    // Medium relevance\n            (3u128, \"learning about machines\"),                             // Lower relevance\n            (4u128, \"machine\"),                                             // Lowest\n        ];\n\n        for (doc_id, doc) in &docs {\n            bm25.insert_doc(&mut wtxn, *doc_id, doc).unwrap();\n        }\n        wtxn.commit().unwrap();\n\n        let rtxn = bm25.graph_env.read_txn().unwrap();\n        let arena = Bump::new();\n        let results = bm25.search(&rtxn, \"machine learning\", 10, &arena).unwrap();\n\n        // Results should be sorted by score (descending)\n        for i in 1..results.len() {\n            assert!(\n                results[i - 1].1 >= results[i].1,\n                \"Results not sorted: {} < {}\",\n                results[i - 1].1,\n                results[i].1\n            );\n        }\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_insert_first_document_initializes_metadata_1814": {
      "name": "test_insert_first_document_initializes_metadata",
      "type": "function",
      "start_line": 1814,
      "end_line": 1835,
      "content_hash": "22f36b9ad494e745add05d9dd570b9cfcaf5fdff",
      "content": "    fn test_insert_first_document_initializes_metadata() {\n        let (bm25, _temp_dir) = setup_bm25_config();\n        let mut wtxn = bm25.graph_env.write_txn().unwrap();\n\n        // Before inserting, metadata should not exist\n        let metadata_before = bm25.metadata_db.get(&wtxn, METADATA_KEY).unwrap();\n        assert!(metadata_before.is_none());\n\n        // Insert first document\n        bm25.insert_doc(&mut wtxn, 1u128, \"first document\").unwrap();\n\n        // After inserting, metadata should exist\n        let metadata_bytes = bm25.metadata_db.get(&wtxn, METADATA_KEY).unwrap().unwrap();\n        let metadata: BM25Metadata = bincode::deserialize(metadata_bytes).unwrap();\n\n        assert_eq!(metadata.total_docs, 1);\n        assert!(metadata.avgdl > 0.0);\n\n        wtxn.commit().unwrap();\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_bm25_temp_config_1836": {
      "name": "test_bm25_temp_config",
      "type": "function",
      "start_line": 1836,
      "end_line": 1853,
      "content_hash": "561344d0301ace42cce77acbf9f1eede81f67833",
      "content": "    fn test_bm25_temp_config() {\n        let (env, _temp_dir) = setup_test_env();\n        let mut wtxn = env.write_txn().unwrap();\n\n        // Create temp BM25 config with unique ID\n        let config = HBM25Config::new_temp(&env, &mut wtxn, \"test_unique_id\").unwrap();\n\n        // Should be able to insert and search\n        config.insert_doc(&mut wtxn, 1u128, \"test document\").unwrap();\n        wtxn.commit().unwrap();\n\n        let rtxn = env.read_txn().unwrap();\n        let arena = Bump::new();\n        let results = config.search(&rtxn, \"test\", 10, &arena).unwrap();\n        assert_eq!(results.len(), 1);\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_bm25_flatten_properties_1854": {
      "name": "test_bm25_flatten_properties",
      "type": "function",
      "start_line": 1854,
      "end_line": 1879,
      "content_hash": "6907c717867a4b6ffd8276de7ec1faa0e81374c1",
      "content": "    fn test_bm25_flatten_properties() {\n        let arena = Bump::new();\n\n        let props: HashMap<String, Value> = HashMap::from([\n            (\"title\".to_string(), Value::String(\"Test Document\".to_string())),\n            (\"content\".to_string(), Value::String(\"This is content\".to_string())),\n            (\"count\".to_string(), Value::I32(42)),\n        ]);\n\n        let props_map = ImmutablePropertiesMap::new(\n            props.len(),\n            props.iter().map(|(k, v)| (arena.alloc_str(k) as &str, v.clone())),\n            &arena,\n        );\n\n        let flattened = props_map.flatten_bm25();\n\n        // Should contain all keys and values\n        assert!(flattened.contains(\"title\"));\n        assert!(flattened.contains(\"Test Document\"));\n        assert!(flattened.contains(\"content\"));\n        assert!(flattened.contains(\"This is content\"));\n        assert!(flattened.contains(\"count\"));\n        assert!(flattened.contains(\"42\"));\n    }\n}",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}