{
  "file_path": "/work/external-deps/helix-db/helix-db/src/helix_engine/storage_core/storage_migration_tests.rs",
  "file_hash": "ecc3f0062329b561e5ab2972ebbf2e32b4b951ed",
  "updated_at": "2025-12-26T17:34:22.722264",
  "symbols": {
    "function_setup_test_storage_34": {
      "name": "setup_test_storage",
      "type": "function",
      "start_line": 34,
      "end_line": 45,
      "content_hash": "2e0ebd718a979ec1f8cbe32d0bd42d271f4674c4",
      "content": "fn setup_test_storage() -> (HelixGraphStorage, TempDir) {\n    let temp_dir = TempDir::new().unwrap();\n    let config = Config::default();\n    let version_info = VersionInfo::default();\n\n    let storage =\n        HelixGraphStorage::new(temp_dir.path().to_str().unwrap(), config, version_info).unwrap();\n\n    (storage, temp_dir)\n}\n\n/// Create test vector data in a specific endianness",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_create_test_vector_bytes_46": {
      "name": "create_test_vector_bytes",
      "type": "function",
      "start_line": 46,
      "end_line": 58,
      "content_hash": "59dfd27b50326eb79b0123bf41100c929d4c9b7e",
      "content": "fn create_test_vector_bytes(values: &[f64], endianness: VectorEndianness) -> Vec<u8> {\n    let mut bytes = Vec::with_capacity(values.len() * 8);\n    for &value in values {\n        let value_bytes = match endianness {\n            VectorEndianness::BigEndian => value.to_be_bytes(),\n            VectorEndianness::LittleEndian => value.to_le_bytes(),\n        };\n        bytes.extend_from_slice(&value_bytes);\n    }\n    bytes\n}\n\n/// Read f64 values from bytes in a specific endianness",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_read_f64_values_59": {
      "name": "read_f64_values",
      "type": "function",
      "start_line": 59,
      "end_line": 71,
      "content_hash": "4727a3fb021365f86117144bfeeeebdf78965ae2",
      "content": "fn read_f64_values(bytes: &[u8], endianness: VectorEndianness) -> Vec<f64> {\n    let mut values = Vec::with_capacity(bytes.len() / 8);\n    for chunk in bytes.chunks_exact(8) {\n        let value = match endianness {\n            VectorEndianness::BigEndian => f64::from_be_bytes(chunk.try_into().unwrap()),\n            VectorEndianness::LittleEndian => f64::from_le_bytes(chunk.try_into().unwrap()),\n        };\n        values.push(value);\n    }\n    values\n}\n\n/// Create old-format vector properties (HashMap-based)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_create_old_properties_72": {
      "name": "create_old_properties",
      "type": "function",
      "start_line": 72,
      "end_line": 88,
      "content_hash": "41bf972a2bcfeb53da578e279d514c1c927d36a8",
      "content": "fn create_old_properties(\n    label: &str,\n    is_deleted: bool,\n    extra_props: HashMap<String, Value>,\n) -> Vec<u8> {\n    let mut props = HashMap::new();\n    props.insert(\"label\".to_string(), Value::String(label.to_string()));\n    props.insert(\"is_deleted\".to_string(), Value::Boolean(is_deleted));\n\n    for (k, v) in extra_props {\n        props.insert(k, v);\n    }\n\n    bincode::serialize(&props).unwrap()\n}\n\n/// Populate storage with test vectors in a specific endianness",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_populate_test_vectors_89": {
      "name": "populate_test_vectors",
      "type": "function",
      "start_line": 89,
      "end_line": 113,
      "content_hash": "ae628c2ad34cea2c856efaa5974d8ef53e0ccc12",
      "content": "fn populate_test_vectors(\n    storage: &mut HelixGraphStorage,\n    count: usize,\n    endianness: VectorEndianness,\n) -> Result<(), GraphError> {\n    let mut txn = storage.graph_env.write_txn()?;\n\n    for i in 0..count {\n        let id = i as u128;\n        let vector_data = create_test_vector_bytes(\n            &[i as f64, (i + 1) as f64, (i + 2) as f64],\n            endianness,\n        );\n\n        storage\n            .vectors\n            .vectors_db\n            .put(&mut txn, &id.to_be_bytes(), &vector_data)?;\n    }\n\n    txn.commit()?;\n    Ok(())\n}\n\n/// Populate storage with old-format properties",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_populate_old_properties_114": {
      "name": "populate_old_properties",
      "type": "function",
      "start_line": 114,
      "end_line": 139,
      "content_hash": "5750b496c509561f284fd72c328a1d38c350d565",
      "content": "fn populate_old_properties(\n    storage: &mut HelixGraphStorage,\n    count: usize,\n) -> Result<(), GraphError> {\n    let mut txn = storage.graph_env.write_txn()?;\n\n    for i in 0..count {\n        let id = i as u128;\n        let mut extra_props = HashMap::new();\n        extra_props.insert(\"test_prop\".to_string(), Value::F64(i as f64));\n\n        let property_bytes =\n            create_old_properties(&format!(\"label_{}\", i), i % 2 == 0, extra_props);\n\n        storage\n            .vectors\n            .vector_properties_db\n            .put(&mut txn, &id, &property_bytes)?;\n    }\n\n    txn.commit()?;\n    Ok(())\n}\n\n/// Set storage metadata to a specific state\n#[allow(dead_code)]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_set_metadata_140": {
      "name": "set_metadata",
      "type": "function",
      "start_line": 140,
      "end_line": 150,
      "content_hash": "0059c222a9f1a7734406d35932a2c6d905e55ce5",
      "content": "fn set_metadata(\n    storage: &mut HelixGraphStorage,\n    metadata: StorageMetadata,\n) -> Result<(), GraphError> {\n    let mut txn = storage.graph_env.write_txn()?;\n    metadata.save(&mut txn, &storage.metadata_db)?;\n    txn.commit()?;\n    Ok(())\n}\n\n/// Read all vectors from storage and return as f64 values",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_read_all_vectors_151": {
      "name": "read_all_vectors",
      "type": "function",
      "start_line": 151,
      "end_line": 167,
      "content_hash": "5b0c7e605aafd1c9731682940551cc4e3151c277",
      "content": "fn read_all_vectors(\n    storage: &HelixGraphStorage,\n    endianness: VectorEndianness,\n) -> Result<Vec<Vec<f64>>, GraphError> {\n    let txn = storage.graph_env.read_txn()?;\n    let mut all_vectors = Vec::new();\n\n    for kv in storage.vectors.vectors_db.iter(&txn)? {\n        let (_, value) = kv?;\n        let values = read_f64_values(value, endianness);\n        all_vectors.push(values);\n    }\n\n    Ok(all_vectors)\n}\n\n/// Clear all metadata from storage (simulates PreMetadata state)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_clear_metadata_168": {
      "name": "clear_metadata",
      "type": "function",
      "start_line": 168,
      "end_line": 179,
      "content_hash": "cfaa4855d1194a4fb2eb0242a0bc8a34e65c1851",
      "content": "fn clear_metadata(storage: &mut HelixGraphStorage) -> Result<(), GraphError> {\n    let mut txn = storage.graph_env.write_txn()?;\n    storage.metadata_db.clear(&mut txn)?;\n    txn.commit()?;\n    Ok(())\n}\n\n// ============================================================================\n// Unit Tests: Endianness Conversion\n// ============================================================================\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_convert_vector_endianness_empty_input_180": {
      "name": "test_convert_vector_endianness_empty_input",
      "type": "function",
      "start_line": 180,
      "end_line": 188,
      "content_hash": "6248477a824b7068df4a6482d07f5b2c55ff8538",
      "content": "fn test_convert_vector_endianness_empty_input() {\n    let arena = bumpalo::Bump::new();\n    let result = convert_vector_endianness(&[], VectorEndianness::BigEndian, &arena);\n\n    assert!(result.is_ok());\n    assert_eq!(result.unwrap(), &[] as &[u8]);\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_convert_vector_endianness_single_f64_189": {
      "name": "test_convert_vector_endianness_single_f64",
      "type": "function",
      "start_line": 189,
      "end_line": 202,
      "content_hash": "749e0d88bc3b4871781b4b38ae2a4cb83478125e",
      "content": "fn test_convert_vector_endianness_single_f64() {\n    let arena = bumpalo::Bump::new();\n    let value: f64 = 3.14159;\n    let big_endian_bytes = value.to_be_bytes();\n\n    let result =\n        convert_vector_endianness(&big_endian_bytes, VectorEndianness::BigEndian, &arena).unwrap();\n\n    // Result should be in native endianness\n    let native_value = f64::from_ne_bytes(result.try_into().unwrap());\n    assert_eq!(native_value, value);\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_convert_vector_endianness_multiple_f64s_203": {
      "name": "test_convert_vector_endianness_multiple_f64s",
      "type": "function",
      "start_line": 203,
      "end_line": 222,
      "content_hash": "3699e54936a9483a8680e9e31a1519dd6a00595f",
      "content": "fn test_convert_vector_endianness_multiple_f64s() {\n    let arena = bumpalo::Bump::new();\n    let values = vec![1.0, 2.5, -3.7, 4.2, 5.9];\n    let big_endian_bytes = create_test_vector_bytes(&values, VectorEndianness::BigEndian);\n\n    let result =\n        convert_vector_endianness(&big_endian_bytes, VectorEndianness::BigEndian, &arena).unwrap();\n\n    // Read back values in native endianness\n    let result_values: Vec<f64> = result\n        .chunks_exact(8)\n        .map(|chunk| f64::from_ne_bytes(chunk.try_into().unwrap()))\n        .collect();\n\n    for (original, converted) in values.iter().zip(result_values.iter()) {\n        assert_eq!(original, converted);\n    }\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_convert_vector_endianness_invalid_length_223": {
      "name": "test_convert_vector_endianness_invalid_length",
      "type": "function",
      "start_line": 223,
      "end_line": 234,
      "content_hash": "dc1c8de61529b0431793fcd663c0406219b0fc32",
      "content": "fn test_convert_vector_endianness_invalid_length() {\n    let arena = bumpalo::Bump::new();\n    let invalid_bytes = vec![1, 2, 3, 4, 5]; // Not a multiple of 8\n\n    let result = convert_vector_endianness(&invalid_bytes, VectorEndianness::BigEndian, &arena);\n\n    assert!(result.is_err());\n    let err_msg = result.unwrap_err().to_string();\n    assert!(err_msg.contains(\"not a multiple\"));\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_convert_vector_endianness_roundtrip_235": {
      "name": "test_convert_vector_endianness_roundtrip",
      "type": "function",
      "start_line": 235,
      "end_line": 257,
      "content_hash": "a9a066819a8f4634ce3b825211bbe8f710dff285",
      "content": "fn test_convert_vector_endianness_roundtrip() {\n    let arena = bumpalo::Bump::new();\n    let values = vec![1.0, 2.5, -3.7, 100.123, -999.999];\n\n    // Start with big endian\n    let big_endian_bytes = create_test_vector_bytes(&values, VectorEndianness::BigEndian);\n\n    // Convert big -> native\n    let native_bytes =\n        convert_vector_endianness(&big_endian_bytes, VectorEndianness::BigEndian, &arena).unwrap();\n\n    // Read values back\n    let result_values: Vec<f64> = native_bytes\n        .chunks_exact(8)\n        .map(|chunk| f64::from_ne_bytes(chunk.try_into().unwrap()))\n        .collect();\n\n    for (original, converted) in values.iter().zip(result_values.iter()) {\n        assert_eq!(original, converted);\n    }\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_convert_vector_endianness_special_values_258": {
      "name": "test_convert_vector_endianness_special_values",
      "type": "function",
      "start_line": 258,
      "end_line": 286,
      "content_hash": "babfadefd8aa6dae73bff980909e1d698156ee21",
      "content": "fn test_convert_vector_endianness_special_values() {\n    let arena = bumpalo::Bump::new();\n    let special_values = vec![\n        0.0,\n        -0.0,\n        f64::INFINITY,\n        f64::NEG_INFINITY,\n        f64::MIN,\n        f64::MAX,\n        f64::EPSILON,\n    ];\n\n    let big_endian_bytes = create_test_vector_bytes(&special_values, VectorEndianness::BigEndian);\n\n    let result =\n        convert_vector_endianness(&big_endian_bytes, VectorEndianness::BigEndian, &arena).unwrap();\n\n    let result_values: Vec<f64> = result\n        .chunks_exact(8)\n        .map(|chunk| f64::from_ne_bytes(chunk.try_into().unwrap()))\n        .collect();\n\n    for (original, converted) in special_values.iter().zip(result_values.iter()) {\n        // Use bit equality for special values like NaN and -0.0\n        assert_eq!(original.to_bits(), converted.to_bits());\n    }\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_convert_vector_endianness_from_little_endian_287": {
      "name": "test_convert_vector_endianness_from_little_endian",
      "type": "function",
      "start_line": 287,
      "end_line": 313,
      "content_hash": "29331586370f078844da0484530c3f6372c7ec2f",
      "content": "fn test_convert_vector_endianness_from_little_endian() {\n    let arena = bumpalo::Bump::new();\n    let values = vec![1.1, 2.2, 3.3];\n    let little_endian_bytes = create_test_vector_bytes(&values, VectorEndianness::LittleEndian);\n\n    let result = convert_vector_endianness(\n        &little_endian_bytes,\n        VectorEndianness::LittleEndian,\n        &arena,\n    )\n    .unwrap();\n\n    let result_values: Vec<f64> = result\n        .chunks_exact(8)\n        .map(|chunk| f64::from_ne_bytes(chunk.try_into().unwrap()))\n        .collect();\n\n    for (original, converted) in values.iter().zip(result_values.iter()) {\n        assert_eq!(original, converted);\n    }\n}\n\n// ============================================================================\n// Unit Tests: Property Conversion\n// ============================================================================\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_convert_old_properties_basic_314": {
      "name": "test_convert_old_properties_basic",
      "type": "function",
      "start_line": 314,
      "end_line": 326,
      "content_hash": "e02ebbf03cbfd9b814aad94dd0768f4c6fcc1c74",
      "content": "fn test_convert_old_properties_basic() {\n    let arena = bumpalo::Bump::new();\n    let old_bytes = create_old_properties(\"test_label\", false, HashMap::new());\n\n    let result = convert_old_vector_properties_to_new_format(&old_bytes, &arena);\n    assert!(result.is_ok());\n\n    // We can't directly deserialize HVector, but we can verify the conversion succeeded\n    let new_bytes = result.unwrap();\n    assert!(!new_bytes.is_empty());\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_convert_old_properties_with_deleted_flag_327": {
      "name": "test_convert_old_properties_with_deleted_flag",
      "type": "function",
      "start_line": 327,
      "end_line": 336,
      "content_hash": "f228a602f4f4cd57688b90fb84bb939c39e427da",
      "content": "fn test_convert_old_properties_with_deleted_flag() {\n    let arena = bumpalo::Bump::new();\n    let old_bytes = create_old_properties(\"deleted_vector\", true, HashMap::new());\n\n    let result = convert_old_vector_properties_to_new_format(&old_bytes, &arena);\n    assert!(result.is_ok());\n    assert!(!result.unwrap().is_empty());\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_convert_old_properties_with_extra_props_337": {
      "name": "test_convert_old_properties_with_extra_props",
      "type": "function",
      "start_line": 337,
      "end_line": 351,
      "content_hash": "4ba3b136984c5c09f77c0fe9b1dfaf8a43101a55",
      "content": "fn test_convert_old_properties_with_extra_props() {\n    let arena = bumpalo::Bump::new();\n    let mut extra = HashMap::new();\n    extra.insert(\"name\".to_string(), Value::String(\"test\".to_string()));\n    extra.insert(\"count\".to_string(), Value::F64(42.0));\n    extra.insert(\"active\".to_string(), Value::Boolean(true));\n\n    let old_bytes = create_old_properties(\"test_label\", false, extra);\n\n    let result = convert_old_vector_properties_to_new_format(&old_bytes, &arena);\n    assert!(result.is_ok());\n    assert!(!result.unwrap().is_empty());\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_convert_old_properties_empty_extra_props_352": {
      "name": "test_convert_old_properties_empty_extra_props",
      "type": "function",
      "start_line": 352,
      "end_line": 362,
      "content_hash": "2175412497ba01c607aedaf17b79ae7b3cb4f06b",
      "content": "fn test_convert_old_properties_empty_extra_props() {\n    let arena = bumpalo::Bump::new();\n    let old_bytes = create_old_properties(\"minimal\", false, HashMap::new());\n\n    let result = convert_old_vector_properties_to_new_format(&old_bytes, &arena);\n    assert!(result.is_ok());\n    assert!(!result.unwrap().is_empty());\n}\n\n#[test]\n#[should_panic(expected = \"all old vectors should have label\")]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_convert_old_properties_missing_label_363": {
      "name": "test_convert_old_properties_missing_label",
      "type": "function",
      "start_line": 363,
      "end_line": 374,
      "content_hash": "e77ee5a9245f5306624e34845327af9ba89543ea",
      "content": "fn test_convert_old_properties_missing_label() {\n    let arena = bumpalo::Bump::new();\n    let mut props = HashMap::new();\n    props.insert(\"is_deleted\".to_string(), Value::Boolean(false));\n    // Missing \"label\"\n\n    let bytes = bincode::serialize(&props).unwrap();\n    let _ = convert_old_vector_properties_to_new_format(&bytes, &arena);\n}\n\n#[test]\n#[should_panic(expected = \"all old vectors should have deleted\")]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_convert_old_properties_missing_is_deleted_375": {
      "name": "test_convert_old_properties_missing_is_deleted",
      "type": "function",
      "start_line": 375,
      "end_line": 385,
      "content_hash": "cc11f18946c9cd71991d2859ad099bd003eb8395",
      "content": "fn test_convert_old_properties_missing_is_deleted() {\n    let arena = bumpalo::Bump::new();\n    let mut props = HashMap::new();\n    props.insert(\"label\".to_string(), Value::String(\"test\".to_string()));\n    // Missing \"is_deleted\"\n\n    let bytes = bincode::serialize(&props).unwrap();\n    let _ = convert_old_vector_properties_to_new_format(&bytes, &arena);\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_convert_old_properties_invalid_bincode_386": {
      "name": "test_convert_old_properties_invalid_bincode",
      "type": "function",
      "start_line": 386,
      "end_line": 398,
      "content_hash": "422a04084f48302af48ca3267b3a42f3f2f3638d",
      "content": "fn test_convert_old_properties_invalid_bincode() {\n    let arena = bumpalo::Bump::new();\n    let invalid_bytes = vec![1, 2, 3, 4, 5]; // Not valid bincode\n\n    let result = convert_old_vector_properties_to_new_format(&invalid_bytes, &arena);\n    assert!(result.is_err());\n}\n\n// ============================================================================\n// Integration Tests: Full Migration Scenarios\n// ============================================================================\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_migrate_empty_database_399": {
      "name": "test_migrate_empty_database",
      "type": "function",
      "start_line": 399,
      "end_line": 412,
      "content_hash": "a028c9bc486f21245f11f6684ccdb36ca41ff81a",
      "content": "fn test_migrate_empty_database() {\n    let (storage, _temp_dir) = setup_test_storage();\n\n    // Storage is already created with migrations run, but let's verify the state\n    let txn = storage.graph_env.read_txn().unwrap();\n    let metadata = StorageMetadata::read(&txn, &storage.metadata_db).unwrap();\n\n    assert!(matches!(\n        metadata,\n        StorageMetadata::VectorNativeEndianness { .. }\n    ));\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_migrate_pre_metadata_to_native_413": {
      "name": "test_migrate_pre_metadata_to_native",
      "type": "function",
      "start_line": 413,
      "end_line": 450,
      "content_hash": "ec697264387a81974ce29e128de5c829db807bf3",
      "content": "fn test_migrate_pre_metadata_to_native() {\n    let (mut storage, _temp_dir) = setup_test_storage();\n\n    // Clear metadata to simulate PreMetadata state\n    clear_metadata(&mut storage).unwrap();\n\n    // Populate with vectors in big-endian format (PreMetadata default)\n    populate_test_vectors(&mut storage, 10, VectorEndianness::BigEndian).unwrap();\n    populate_old_properties(&mut storage, 10).unwrap();\n\n    // Run migration\n    let result = migrate(&mut storage);\n    assert!(result.is_ok());\n\n    // Verify metadata was updated\n    {\n        let txn = storage.graph_env.read_txn().unwrap();\n        let metadata = StorageMetadata::read(&txn, &storage.metadata_db).unwrap();\n\n        match metadata {\n            StorageMetadata::VectorNativeEndianness { vector_endianness } => {\n                assert_eq!(vector_endianness, NATIVE_VECTOR_ENDIANNESS);\n            }\n            _ => panic!(\"Expected VectorNativeEndianness metadata\"),\n        }\n    } // txn dropped here\n\n    // Verify vectors are readable in native endianness\n    let vectors = read_all_vectors(&storage, NATIVE_VECTOR_ENDIANNESS).unwrap();\n    assert_eq!(vectors.len(), 10);\n\n    for (i, vector) in vectors.iter().enumerate() {\n        let expected = vec![i as f64, (i + 1) as f64, (i + 2) as f64];\n        assert_eq!(vector, &expected);\n    }\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_migrate_single_vector_451": {
      "name": "test_migrate_single_vector",
      "type": "function",
      "start_line": 451,
      "end_line": 466,
      "content_hash": "c03a03cce7713ffdf647f42c4a12de9b187d4267",
      "content": "fn test_migrate_single_vector() {\n    let (mut storage, _temp_dir) = setup_test_storage();\n\n    // Clear and repopulate\n    clear_metadata(&mut storage).unwrap();\n    populate_test_vectors(&mut storage, 1, VectorEndianness::BigEndian).unwrap();\n\n    let result = migrate(&mut storage);\n    assert!(result.is_ok());\n\n    let vectors = read_all_vectors(&storage, NATIVE_VECTOR_ENDIANNESS).unwrap();\n    assert_eq!(vectors.len(), 1);\n    assert_eq!(vectors[0], vec![0.0, 1.0, 2.0]);\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_migrate_exact_batch_size_467": {
      "name": "test_migrate_exact_batch_size",
      "type": "function",
      "start_line": 467,
      "end_line": 484,
      "content_hash": "e4941df0a6936afd2761b4355ccc48d596d2d36e",
      "content": "fn test_migrate_exact_batch_size() {\n    let (mut storage, _temp_dir) = setup_test_storage();\n\n    clear_metadata(&mut storage).unwrap();\n    populate_test_vectors(&mut storage, 1024, VectorEndianness::BigEndian).unwrap();\n\n    let result = migrate(&mut storage);\n    assert!(result.is_ok());\n\n    let vectors = read_all_vectors(&storage, NATIVE_VECTOR_ENDIANNESS).unwrap();\n    assert_eq!(vectors.len(), 1024);\n\n    // Verify first and last vectors\n    assert_eq!(vectors[0], vec![0.0, 1.0, 2.0]);\n    assert_eq!(vectors[1023], vec![1023.0, 1024.0, 1025.0]);\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_migrate_multiple_batches_485": {
      "name": "test_migrate_multiple_batches",
      "type": "function",
      "start_line": 485,
      "end_line": 504,
      "content_hash": "a85f5f728ddb86a6115320a22d40cc5ac3ab467e",
      "content": "fn test_migrate_multiple_batches() {\n    let (mut storage, _temp_dir) = setup_test_storage();\n\n    clear_metadata(&mut storage).unwrap();\n    populate_test_vectors(&mut storage, 2500, VectorEndianness::BigEndian).unwrap();\n\n    let result = migrate(&mut storage);\n    assert!(result.is_ok());\n\n    let vectors = read_all_vectors(&storage, NATIVE_VECTOR_ENDIANNESS).unwrap();\n    assert_eq!(vectors.len(), 2500);\n\n    // Verify vectors across batch boundaries\n    assert_eq!(vectors[0], vec![0.0, 1.0, 2.0]);\n    assert_eq!(vectors[1023], vec![1023.0, 1024.0, 1025.0]);\n    assert_eq!(vectors[1024], vec![1024.0, 1025.0, 1026.0]);\n    assert_eq!(vectors[2499], vec![2499.0, 2500.0, 2501.0]);\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_migrate_already_native_endianness_505": {
      "name": "test_migrate_already_native_endianness",
      "type": "function",
      "start_line": 505,
      "end_line": 520,
      "content_hash": "b3c37ed83132f2e16570e12920fcafa7da6602a5",
      "content": "fn test_migrate_already_native_endianness() {\n    let (mut storage, _temp_dir) = setup_test_storage();\n\n    // Add vectors already in native endianness\n    populate_test_vectors(&mut storage, 10, NATIVE_VECTOR_ENDIANNESS).unwrap();\n\n    // Migration should be a no-op (already done during setup_test_storage)\n    let result = migrate(&mut storage);\n    assert!(result.is_ok());\n\n    // Vectors should remain unchanged\n    let vectors = read_all_vectors(&storage, NATIVE_VECTOR_ENDIANNESS).unwrap();\n    assert_eq!(vectors.len(), 10);\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_migrate_idempotency_521": {
      "name": "test_migrate_idempotency",
      "type": "function",
      "start_line": 521,
      "end_line": 542,
      "content_hash": "448c416e365271ed28672ff527db75a14a5ed9ee",
      "content": "fn test_migrate_idempotency() {\n    let (mut storage, _temp_dir) = setup_test_storage();\n\n    clear_metadata(&mut storage).unwrap();\n    populate_test_vectors(&mut storage, 100, VectorEndianness::BigEndian).unwrap();\n\n    // Run migration multiple times\n    migrate(&mut storage).unwrap();\n    let vectors_after_first = read_all_vectors(&storage, NATIVE_VECTOR_ENDIANNESS).unwrap();\n\n    migrate(&mut storage).unwrap();\n    let vectors_after_second = read_all_vectors(&storage, NATIVE_VECTOR_ENDIANNESS).unwrap();\n\n    migrate(&mut storage).unwrap();\n    let vectors_after_third = read_all_vectors(&storage, NATIVE_VECTOR_ENDIANNESS).unwrap();\n\n    // All should be identical\n    assert_eq!(vectors_after_first, vectors_after_second);\n    assert_eq!(vectors_after_second, vectors_after_third);\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_migrate_with_properties_543": {
      "name": "test_migrate_with_properties",
      "type": "function",
      "start_line": 543,
      "end_line": 563,
      "content_hash": "711cfbb9a2e72b069eb976c93f0d0e95a296c01b",
      "content": "fn test_migrate_with_properties() {\n    let (mut storage, _temp_dir) = setup_test_storage();\n\n    clear_metadata(&mut storage).unwrap();\n    populate_test_vectors(&mut storage, 50, VectorEndianness::BigEndian).unwrap();\n    populate_old_properties(&mut storage, 50).unwrap();\n\n    let result = migrate(&mut storage);\n    assert!(result.is_ok());\n\n    // Verify both vectors and properties were migrated\n    let vectors = read_all_vectors(&storage, NATIVE_VECTOR_ENDIANNESS).unwrap();\n    assert_eq!(vectors.len(), 50);\n\n    // Check properties count\n    let txn = storage.graph_env.read_txn().unwrap();\n    let prop_count = storage.vectors.vector_properties_db.len(&txn).unwrap();\n    assert_eq!(prop_count, 50);\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_migrate_cognee_vector_string_dates_error_564": {
      "name": "test_migrate_cognee_vector_string_dates_error",
      "type": "function",
      "start_line": 564,
      "end_line": 728,
      "content_hash": "b729f398d697a450d82e0b7955aea46596491a55",
      "content": "fn test_migrate_cognee_vector_string_dates_error() {\n    // This test reproduces a bincode I/O error that occurs when migrating\n    // CogneeVector data where dates were stored as RFC3339 strings instead\n    // of proper Date types.\n    //\n    // Old schema had:\n    //   created_at: String (RFC3339 format via chrono::Utc::now().to_rfc3339())\n    //   updated_at: String (RFC3339 format)\n    //\n    // New schema expects:\n    //   created_at: Date\n    //   updated_at: Date\n    //\n    // This mismatch can cause bincode deserialization errors during migration.\n\n    let (mut storage, _temp_dir) = setup_test_storage();\n\n    // Clear metadata to simulate PreMetadata state\n    clear_metadata(&mut storage).unwrap();\n\n    // Create old-format CogneeVector properties with dates as strings\n    // (matching how they were actually created in the old format)\n    let mut extra_props = HashMap::new();\n\n    // Add CogneeVector-specific fields\n    extra_props.insert(\n        \"collection_name\".to_string(),\n        Value::String(\"test_collection\".to_string()),\n    );\n    extra_props.insert(\n        \"data_point_id\".to_string(),\n        Value::String(\"dp_001\".to_string()),\n    );\n    extra_props.insert(\n        \"payload\".to_string(),\n        Value::String(r#\"{\"id\":\"123\",\"created_at\":\"2024-01-01\",\"updated_at\":\"2024-01-01\",\"ontology_valid\":true,\"version\":1,\"topological_rank\":0,\"type\":\"DataPoint\"}\"#.to_string()),\n    );\n    extra_props.insert(\n        \"content\".to_string(),\n        Value::String(\"Test content for CogneeVector\".to_string()),\n    );\n\n    // Add dates as strings (RFC3339) - this is the problematic part\n    // In the old format, these were created as:\n    //   Value::from(chrono::Utc::now().to_rfc3339())\n    // which creates Value::String, not Value::Date\n    extra_props.insert(\n        \"created_at\".to_string(),\n        Value::String(\"2024-01-01T12:00:00.000000000Z\".to_string()),\n    );\n    extra_props.insert(\n        \"updated_at\".to_string(),\n        Value::String(\"2024-01-01T12:00:00.000000000Z\".to_string()),\n    );\n\n    // Create old properties with CogneeVector label\n    let old_bytes = create_old_properties(\"CogneeVector\", false, extra_props);\n\n    // Insert into storage\n    {\n        let mut txn = storage.graph_env.write_txn().unwrap();\n        let id = 123u128;\n        storage\n            .vectors\n            .vector_properties_db\n            .put(&mut txn, &id, &old_bytes)\n            .unwrap();\n        txn.commit().unwrap();\n    }\n\n    // Verify the data was inserted\n    {\n        let txn = storage.graph_env.read_txn().unwrap();\n        let stored_bytes = storage\n            .vectors\n            .vector_properties_db\n            .get(&txn, &123u128)\n            .unwrap();\n        assert!(stored_bytes.is_some());\n\n        // Verify we can deserialize it as old format\n        let old_props: HashMap<String, Value> = bincode::deserialize(stored_bytes.unwrap()).unwrap();\n        assert_eq!(old_props.get(\"label\").unwrap(), &Value::String(\"CogneeVector\".to_string()));\n        assert_eq!(old_props.get(\"collection_name\").unwrap(), &Value::String(\"test_collection\".to_string()));\n\n        // Verify dates are strings, not Date types\n        match old_props.get(\"created_at\").unwrap() {\n            Value::String(s) => assert!(s.contains(\"2024-01-01\")),\n            _ => panic!(\"Expected created_at to be Value::String in old format\"),\n        }\n    }\n\n    // Run migration - this preserves the data as-is\n    let result = migrate(&mut storage);\n\n    // Migration succeeds because it just copies the HashMap to the new format\n    match result {\n        Ok(_) => {\n            println!(\"\u2705 Migration succeeded (preserves old data as-is)\");\n\n            // The real error occurs when trying to deserialize the migrated data\n            // This simulates what v_from_type does when querying by label\n            let txn = storage.graph_env.read_txn().unwrap();\n            let migrated_bytes = storage\n                .vectors\n                .vector_properties_db\n                .get(&txn, &123u128)\n                .unwrap()\n                .unwrap();\n\n            println!(\"Migrated data exists: {} bytes\", migrated_bytes.len());\n\n            // Try to deserialize as VectorWithoutData (what v_from_type does)\n            use crate::helix_engine::vector_core::vector_without_data::VectorWithoutData;\n            let arena2 = bumpalo::Bump::new();\n            let deserialize_result = VectorWithoutData::from_bincode_bytes(&arena2, migrated_bytes, 123u128);\n\n            match deserialize_result {\n                Ok(vector) => {\n                    println!(\"\u26a0\ufe0f  Deserialization succeeded!\");\n                    println!(\"Vector label: {}\", vector.label);\n                    println!(\"This means bincode preserved the string dates in properties.\");\n\n                    // Check if dates are accessible\n                    if let Some(created_at) = vector.get_property(\"created_at\") {\n                        println!(\"created_at type: {:?}\", created_at);\n                        match created_at {\n                            Value::String(s) => println!(\"  Still a string: {}\", s),\n                            Value::Date(d) => println!(\"  Converted to Date: {:?}\", d),\n                            _ => println!(\"  Other type: {:?}\", created_at),\n                        }\n                    }\n                }\n                Err(e) => {\n                    println!(\"\u2705 REPRODUCED THE ERROR during deserialization!\");\n                    println!(\"Error: {}\", e);\n                    println!();\n                    println!(\"This error occurs in the v_from_type query path:\");\n                    println!(\"  1. Migration preserves dates as Value::String\");\n                    println!(\"  2. v_from_type calls VectorWithoutData::from_bincode_bytes\");\n                    println!(\"  3. Bincode deserialization expects specific value types\");\n                    println!(\"  4. Type mismatch causes ConversionError\");\n\n                    // Verify it's the expected error type\n                    let error_str = e.to_string();\n                    assert!(\n                        error_str.contains(\"deserializ\") || error_str.contains(\"Conversion\"),\n                        \"Expected deserialization/conversion error, got: {}\",\n                        e\n                    );\n                }\n            }\n        }\n        Err(e) => {\n            println!(\"\u274c Migration failed unexpectedly: {}\", e);\n            panic!(\"Migration should succeed but preserve old data\");\n        }\n    }\n}\n\n// ============================================================================\n// Integration Tests: Batch Boundary Conditions\n// ============================================================================\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_migrate_batch_boundary_1023_729": {
      "name": "test_migrate_batch_boundary_1023",
      "type": "function",
      "start_line": 729,
      "end_line": 741,
      "content_hash": "d1a6c68db0a7386e0ca4d38432aea62532b7ec65",
      "content": "fn test_migrate_batch_boundary_1023() {\n    let (mut storage, _temp_dir) = setup_test_storage();\n    clear_metadata(&mut storage).unwrap();\n    populate_test_vectors(&mut storage, 1023, VectorEndianness::BigEndian).unwrap();\n\n    let result = migrate(&mut storage);\n    assert!(result.is_ok());\n\n    let vectors = read_all_vectors(&storage, NATIVE_VECTOR_ENDIANNESS).unwrap();\n    assert_eq!(vectors.len(), 1023);\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_migrate_batch_boundary_1025_742": {
      "name": "test_migrate_batch_boundary_1025",
      "type": "function",
      "start_line": 742,
      "end_line": 754,
      "content_hash": "2fcebd47a3f1cc2dc917800839a5322929febe70",
      "content": "fn test_migrate_batch_boundary_1025() {\n    let (mut storage, _temp_dir) = setup_test_storage();\n    clear_metadata(&mut storage).unwrap();\n    populate_test_vectors(&mut storage, 1025, VectorEndianness::BigEndian).unwrap();\n\n    let result = migrate(&mut storage);\n    assert!(result.is_ok());\n\n    let vectors = read_all_vectors(&storage, NATIVE_VECTOR_ENDIANNESS).unwrap();\n    assert_eq!(vectors.len(), 1025);\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_migrate_batch_boundary_2047_755": {
      "name": "test_migrate_batch_boundary_2047",
      "type": "function",
      "start_line": 755,
      "end_line": 767,
      "content_hash": "865b3cf5a5930da518326ea4050366584179aa6c",
      "content": "fn test_migrate_batch_boundary_2047() {\n    let (mut storage, _temp_dir) = setup_test_storage();\n    clear_metadata(&mut storage).unwrap();\n    populate_test_vectors(&mut storage, 2047, VectorEndianness::BigEndian).unwrap();\n\n    let result = migrate(&mut storage);\n    assert!(result.is_ok());\n\n    let vectors = read_all_vectors(&storage, NATIVE_VECTOR_ENDIANNESS).unwrap();\n    assert_eq!(vectors.len(), 2047);\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_migrate_batch_boundary_2048_768": {
      "name": "test_migrate_batch_boundary_2048",
      "type": "function",
      "start_line": 768,
      "end_line": 787,
      "content_hash": "48608816c2f68bffb4df736a6a90d3bedb6c9b55",
      "content": "fn test_migrate_batch_boundary_2048() {\n    let (mut storage, _temp_dir) = setup_test_storage();\n    clear_metadata(&mut storage).unwrap();\n    populate_test_vectors(&mut storage, 2048, VectorEndianness::BigEndian).unwrap();\n\n    let result = migrate(&mut storage);\n    assert!(result.is_ok());\n\n    let vectors = read_all_vectors(&storage, NATIVE_VECTOR_ENDIANNESS).unwrap();\n    assert_eq!(vectors.len(), 2048);\n}\n\n// ============================================================================\n// Property-Based Tests\n// ============================================================================\n\nuse proptest::prelude::*;\n\nproptest! {\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_proptest_endianness_conversion_preserves_values_788": {
      "name": "proptest_endianness_conversion_preserves_values",
      "type": "function",
      "start_line": 788,
      "end_line": 819,
      "content_hash": "5dc89d35fd8f181d4447a5e61c31a0a6774c1480",
      "content": "    fn proptest_endianness_conversion_preserves_values(\n        values in prop::collection::vec(prop::num::f64::ANY, 1..100)\n    ) {\n        let arena = bumpalo::Bump::new();\n\n        // Filter out NaN for equality comparison\n        let values: Vec<f64> = values.into_iter().filter(|v| !v.is_nan()).collect();\n        if values.is_empty() {\n            return Ok(());\n        }\n\n        // Test both endianness conversions\n        for source_endianness in [VectorEndianness::BigEndian, VectorEndianness::LittleEndian] {\n            let source_bytes = create_test_vector_bytes(&values, source_endianness);\n\n            let result = convert_vector_endianness(&source_bytes, source_endianness, &arena)\n                .expect(\"conversion should succeed\");\n\n            let result_values: Vec<f64> = result\n                .chunks_exact(8)\n                .map(|chunk| f64::from_ne_bytes(chunk.try_into().unwrap()))\n                .collect();\n\n            prop_assert_eq!(values.len(), result_values.len());\n\n            for (original, converted) in values.iter().zip(result_values.iter()) {\n                prop_assert_eq!(original, converted);\n            }\n        }\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_proptest_endianness_conversion_valid_length_820": {
      "name": "proptest_endianness_conversion_valid_length",
      "type": "function",
      "start_line": 820,
      "end_line": 835,
      "content_hash": "dbb6d6080e1a2da2db18230f1946dbf70ae76f0b",
      "content": "    fn proptest_endianness_conversion_valid_length(\n        byte_count in 1usize..200\n    ) {\n        let arena = bumpalo::Bump::new();\n        let bytes = vec![0u8; byte_count];\n\n        let result = convert_vector_endianness(&bytes, VectorEndianness::BigEndian, &arena);\n\n        if byte_count % 8 == 0 {\n            prop_assert!(result.is_ok());\n        } else {\n            prop_assert!(result.is_err());\n        }\n    }\n\n    #[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_proptest_property_migration_preserves_data_836": {
      "name": "proptest_property_migration_preserves_data",
      "type": "function",
      "start_line": 836,
      "end_line": 864,
      "content_hash": "753d45f6ff2cdc66db9cb8e05320431959086ad7",
      "content": "    fn proptest_property_migration_preserves_data(\n        label in \"[a-z]{1,20}\",\n        is_deleted in any::<bool>(),\n        prop_count in 0usize..10\n    ) {\n        let arena = bumpalo::Bump::new();\n        let mut extra_props = HashMap::new();\n\n        for i in 0..prop_count {\n            extra_props.insert(\n                format!(\"prop_{}\", i),\n                Value::F64(i as f64),\n            );\n        }\n\n        let old_bytes = create_old_properties(&label, is_deleted, extra_props);\n        let result = convert_old_vector_properties_to_new_format(&old_bytes, &arena)\n            .expect(\"property conversion should succeed\");\n\n        // Verify conversion succeeded by checking result is not empty\n        prop_assert!(!result.is_empty());\n    }\n}\n\n// ============================================================================\n// Error Handling Tests\n// ============================================================================\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_error_invalid_vector_data_length_865": {
      "name": "test_error_invalid_vector_data_length",
      "type": "function",
      "start_line": 865,
      "end_line": 880,
      "content_hash": "f9051742b8f28057c84dbad674293b58f01501f6",
      "content": "fn test_error_invalid_vector_data_length() {\n    let arena = bumpalo::Bump::new();\n    let invalid_bytes = vec![1, 2, 3, 4, 5, 6, 7]; // 7 bytes, not multiple of 8\n\n    let result = convert_vector_endianness(&invalid_bytes, VectorEndianness::BigEndian, &arena);\n\n    assert!(result.is_err());\n    match result {\n        Err(GraphError::New(msg)) => {\n            assert!(msg.contains(\"not a multiple\"));\n        }\n        _ => panic!(\"Expected GraphError::New with length error\"),\n    }\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_error_corrupted_property_data_881": {
      "name": "test_error_corrupted_property_data",
      "type": "function",
      "start_line": 881,
      "end_line": 890,
      "content_hash": "23613bf5f5f01018e316be92f3a20a019fd71933",
      "content": "fn test_error_corrupted_property_data() {\n    let arena = bumpalo::Bump::new();\n    let corrupted = vec![255u8; 100]; // Random bytes, not valid bincode\n\n    let result = convert_old_vector_properties_to_new_format(&corrupted, &arena);\n    assert!(result.is_err());\n}\n\n#[test]\n#[ignore]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_date_bincode_serialization_891": {
      "name": "test_date_bincode_serialization",
      "type": "function",
      "start_line": 891,
      "end_line": 927,
      "content_hash": "b02e48d9025e0c88f9d0fe58d01c159106da1c6d",
      "content": "fn test_date_bincode_serialization() {\n    // Test that Date values serialize/deserialize correctly with bincode\n    use crate::protocol::date::Date;\n\n    // Create a Date and wrap it in Value::Date\n    let date = Date::new(&Value::I64(1609459200)).unwrap(); // 2021-01-01\n    let value = Value::Date(date);\n\n    // Serialize with bincode\n    let serialized = bincode::serialize(&value).unwrap();\n    println!(\"\\nValue::Date serialized to {} bytes\", serialized.len());\n    println!(\"Format: [variant=12] [i64 timestamp]\");\n    println!(\"Bytes: {:?}\", serialized);\n\n    // Deserialize\n    let deserialized: Value = bincode::deserialize(&serialized).unwrap();\n\n    // Verify it's a Date variant with correct value\n    match deserialized {\n        Value::Date(d) => {\n            assert_eq!(d.timestamp(), 1609459200);\n            assert!(d.to_rfc3339().starts_with(\"2021-01-01\"));\n            println!(\"\u2705 Bincode serialization works correctly!\");\n            println!(\"   Date: {}\", d.to_rfc3339());\n        }\n        _ => panic!(\"Expected Value::Date variant\"),\n    }\n\n    // Also test JSON serialization still works\n    let json = sonic_rs::to_string(&value).unwrap();\n    let from_json: Value = sonic_rs::from_str(&json).unwrap();\n    // JSON deserializes dates as strings, which is expected\n    assert!(matches!(from_json, Value::String(_)));\n    println!(\"\u2705 JSON serialization also works (deserializes as Value::String as expected)!\");\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_error_handling_graceful_failure_928": {
      "name": "test_error_handling_graceful_failure",
      "type": "function",
      "start_line": 928,
      "end_line": 967,
      "content_hash": "70f6173d06b4a1a530300de7f89d9bf4985dcbd1",
      "content": "fn test_error_handling_graceful_failure() {\n    // Test that errors don't corrupt the database\n    let (mut storage, _temp_dir) = setup_test_storage();\n\n    clear_metadata(&mut storage).unwrap();\n\n    // Add valid data\n    populate_test_vectors(&mut storage, 10, VectorEndianness::BigEndian).unwrap();\n\n    // Now add invalid data manually\n    {\n        let mut txn = storage.graph_env.write_txn().unwrap();\n        let bad_id = 9999u128;\n        let bad_data = vec![1, 2, 3]; // Invalid length\n\n        storage\n            .vectors\n            .vectors_db\n            .put(&mut txn, &bad_id.to_be_bytes(), &bad_data)\n            .unwrap();\n\n        txn.commit().unwrap();\n    }\n\n    // Migration should fail on invalid data\n    let result = migrate(&mut storage);\n    assert!(result.is_err());\n\n    // But the 10 valid vectors should still be there\n    let txn = storage.graph_env.read_txn().unwrap();\n    let count = storage.vectors.vectors_db.len(&txn).unwrap();\n    assert_eq!(count, 11); // 10 valid + 1 invalid\n}\n\n// ============================================================================\n// Performance Tests\n// ============================================================================\n\n#[test]\n#[ignore] // Run with: cargo test --release -- --ignored --nocapture",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_performance_large_dataset_968": {
      "name": "test_performance_large_dataset",
      "type": "function",
      "start_line": 968,
      "end_line": 1000,
      "content_hash": "9158299ba631904dad8a311e2a1b752fc69b6259",
      "content": "fn test_performance_large_dataset() {\n    use std::time::Instant;\n\n    let (mut storage, _temp_dir) = setup_test_storage();\n\n    clear_metadata(&mut storage).unwrap();\n\n    // Create 100K vectors\n    println!(\"Populating 100K vectors...\");\n    let start = Instant::now();\n    populate_test_vectors(&mut storage, 100_000, VectorEndianness::BigEndian).unwrap();\n    println!(\"Population took: {:?}\", start.elapsed());\n\n    // Migrate\n    println!(\"Running migration...\");\n    let start = Instant::now();\n    let result = migrate(&mut storage);\n    let duration = start.elapsed();\n\n    assert!(result.is_ok());\n    println!(\"Migration of 100K vectors took: {:?}\", duration);\n    println!(\"Average: {:?} per vector\", duration / 100_000);\n\n    // Verify a sample\n    let vectors = read_all_vectors(&storage, NATIVE_VECTOR_ENDIANNESS).unwrap();\n    assert_eq!(vectors.len(), 100_000);\n    assert_eq!(vectors[0], vec![0.0, 1.0, 2.0]);\n    assert_eq!(vectors[50_000], vec![50_000.0, 50_001.0, 50_002.0]);\n    assert_eq!(vectors[99_999], vec![99_999.0, 100_000.0, 100_001.0]);\n}\n\n#[test]\n#[ignore]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_performance_property_migration_1001": {
      "name": "test_performance_property_migration",
      "type": "function",
      "start_line": 1001,
      "end_line": 1021,
      "content_hash": "015ab312b3235f6d6c55fcd781e40455aea0e2a5",
      "content": "fn test_performance_property_migration() {\n    use std::time::Instant;\n\n    let (mut storage, _temp_dir) = setup_test_storage();\n\n    clear_metadata(&mut storage).unwrap();\n\n    println!(\"Populating 50K properties...\");\n    populate_old_properties(&mut storage, 50_000).unwrap();\n\n    println!(\"Running property migration...\");\n    let start = Instant::now();\n    let result = convert_all_vector_properties(&mut storage);\n    let duration = start.elapsed();\n\n    assert!(result.is_ok());\n    println!(\"Property migration of 50K items took: {:?}\", duration);\n    println!(\"Average: {:?} per property\", duration / 50_000);\n}\n\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_memory_efficiency_batch_processing_1022": {
      "name": "test_memory_efficiency_batch_processing",
      "type": "function",
      "start_line": 1022,
      "end_line": 1037,
      "content_hash": "43d5b5f083f3b37dc861bdd0a944bf94c638cd47",
      "content": "fn test_memory_efficiency_batch_processing() {\n    // This test verifies that batch processing doesn't cause memory issues\n    let (mut storage, _temp_dir) = setup_test_storage();\n\n    clear_metadata(&mut storage).unwrap();\n\n    // Create 5000 vectors (multiple batches)\n    populate_test_vectors(&mut storage, 5000, VectorEndianness::BigEndian).unwrap();\n\n    // Migration should complete without OOM\n    let result = migrate(&mut storage);\n    assert!(result.is_ok());\n\n    let vectors = read_all_vectors(&storage, NATIVE_VECTOR_ENDIANNESS).unwrap();\n    assert_eq!(vectors.len(), 5000);\n}",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}