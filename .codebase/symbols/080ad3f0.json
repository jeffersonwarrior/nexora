{
  "file_path": "/work/context-engine/scripts/rerank_recursive/recursive.py",
  "file_hash": "ea2ca2e8fc2c9bb662a0f55e4f76ac061c3b5796",
  "updated_at": "2025-12-26T17:34:21.245488",
  "symbols": {
    "class_RecursiveReranker_38": {
      "name": "RecursiveReranker",
      "type": "class",
      "start_line": 38,
      "end_line": 277,
      "content_hash": "6038f85b78c992fa77664327f65da048a04e3469",
      "content": "class RecursiveReranker:\n    \"\"\"\n    Main recursive reranking pipeline.\n\n    Key insight: Multiple passes through tiny networks > one pass through large network\n    \"\"\"\n\n    def __init__(\n        self,\n        n_iterations: int = 3,\n        dim: int = 256,\n        hidden_dim: int = 512,\n        early_stop: bool = True,\n        blend_with_initial: float = 0.3,\n        alpha_scheduler: Optional[Any] = None,\n    ):\n        self.n_iterations = n_iterations\n        self.dim = dim\n        self.early_stop = early_stop\n        self.blend_with_initial = blend_with_initial\n\n        # Alpha scheduler: if None, use CosineAlphaScheduler by default\n        if alpha_scheduler is None:\n            from scripts.rerank_recursive.alpha_scheduler import CosineAlphaScheduler\n            self.alpha_scheduler = CosineAlphaScheduler(n_iterations=n_iterations)\n        else:\n            self.alpha_scheduler = alpha_scheduler\n\n        self.scorer = TinyScorer(dim=dim, hidden_dim=hidden_dim)\n        self.refiner = LatentRefiner(dim=dim)\n\n        from scripts.embedder import get_model_dimension\n        embed_dim = get_model_dimension()\n        self._learned_projection = LearnedProjection(input_dim=embed_dim, output_dim=dim, lr=0.0)\n        self._embedder = None\n        self._embedder_lock = threading.Lock()\n        self._proj_cache: Dict[int, np.ndarray] = {}\n        self._proj_cache_lock = threading.Lock()\n\n    def _get_embedder(self):\n        if self._embedder is not None:\n            return self._embedder\n        with self._embedder_lock:\n            if self._embedder is not None:\n                return self._embedder\n            try:\n                from scripts.embedder import get_embedding_model\n                model_name = os.environ.get(\"EMBEDDING_MODEL\", \"BAAI/bge-base-en-v1.5\")\n                self._embedder = get_embedding_model(model_name)\n            except Exception:\n                self._embedder = None\n            return self._embedder\n\n    def _encode(self, texts: List[str]) -> np.ndarray:\n        cached_results = []\n        texts_to_encode = []\n        text_indices = []\n\n        for i, text in enumerate(texts):\n            cached = _get_cached_embedding(text)\n            if cached is not None:\n                cached_results.append((i, cached))\n            else:\n                texts_to_encode.append(text)\n                text_indices.append(i)\n\n        new_embeddings = []\n        if texts_to_encode:\n            embedder = self._get_embedder()\n            if embedder is not None:\n                try:\n                    embeddings = list(embedder.embed(texts_to_encode))\n                    if len(embeddings) != len(texts_to_encode):\n                        raise ValueError(\"Embedding count mismatch\")\n                    for text, emb in zip(texts_to_encode, embeddings):\n                        emb_arr = np.array(emb, dtype=np.float32)\n                        if emb_arr.shape[0] != self.dim:\n                            emb_arr = self._project_to_dim(emb_arr.reshape(1, -1))[0]\n                        _cache_embedding(text, emb_arr)\n                        new_embeddings.append(emb_arr)\n                except Exception:\n                    new_embeddings = []\n\n            if not new_embeddings:\n                import hashlib\n                fallback_dim = self.dim\n                if cached_results:\n                    fallback_dim = cached_results[0][1].shape[0]\n                for text in texts_to_encode:\n                    text_hash = hashlib.sha256(text.encode(\"utf-8\", errors=\"replace\")).digest()\n                    seed = int.from_bytes(text_hash[:4], \"big\")\n                    rng = np.random.RandomState(seed)\n                    vec = rng.randn(fallback_dim).astype(np.float32)\n                    vec = vec / (np.linalg.norm(vec) + 1e-8)\n                    _cache_embedding(text, vec)\n                    new_embeddings.append(vec)\n\n        result = [None] * len(texts)\n        for i, emb in cached_results:\n            result[i] = emb\n        for i, idx in enumerate(text_indices):\n            result[idx] = new_embeddings[i]\n        return np.array(result, dtype=np.float32)\n\n    def _encode_raw(self, texts: List[str]) -> np.ndarray:\n        from scripts.embedder import get_model_dimension\n        fallback_dim = get_model_dimension()\n        embedder = self._get_embedder()\n        if embedder is None:\n            import hashlib\n            result = []\n            for text in texts:\n                text_hash = hashlib.sha256(text.encode(\"utf-8\", errors=\"replace\")).digest()\n                seed = int.from_bytes(text_hash[:4], \"big\")\n                rng = np.random.RandomState(seed)\n                vec = rng.randn(fallback_dim).astype(np.float32)\n                vec = vec / (np.linalg.norm(vec) + 1e-8)\n                result.append(vec)\n            return np.array(result, dtype=np.float32)\n        try:\n            embeddings = list(embedder.embed(texts))\n            result = [np.array(emb, dtype=np.float32) for emb in embeddings]\n            return np.array(result, dtype=np.float32)\n        except Exception:\n            import hashlib\n            result = []\n            for text in texts:\n                text_hash = hashlib.sha256(text.encode(\"utf-8\", errors=\"replace\")).digest()\n                seed = int.from_bytes(text_hash[:4], \"big\")\n                rng = np.random.RandomState(seed)\n                vec = rng.randn(fallback_dim).astype(np.float32)\n                vec = vec / (np.linalg.norm(vec) + 1e-8)\n                result.append(vec)\n            return np.array(result, dtype=np.float32)\n\n    def _project_to_dim(self, embeddings: np.ndarray) -> np.ndarray:\n        if embeddings.shape[-1] == self.dim:\n            return embeddings\n        input_dim = embeddings.shape[-1]\n        if (hasattr(self, '_learned_projection') and\n            self._learned_projection._weights_loaded and\n            self._learned_projection.input_dim == input_dim):\n            return self._learned_projection.forward(embeddings)\n        with self._proj_cache_lock:\n            if input_dim not in self._proj_cache:\n                rng = np.random.RandomState(44)\n                proj_matrix = rng.randn(input_dim, self.dim).astype(np.float32) * np.float32(0.01)\n                self._proj_cache[input_dim] = proj_matrix\n            proj_matrix = self._proj_cache[input_dim]\n        projected = embeddings @ proj_matrix\n        norms = np.linalg.norm(projected, axis=-1, keepdims=True) + 1e-8\n        return projected / norms\n\n    def rerank(\n        self,\n        query: str,\n        candidates: List[Dict[str, Any]],\n        initial_scores: Optional[List[float]] = None,\n    ) -> List[Dict[str, Any]]:\n        if not candidates:\n            return []\n\n        confidence = ConfidenceEstimator()\n        n_docs = len(candidates)\n\n        doc_texts = []\n        for c in candidates:\n            text_parts = []\n            if c.get(\"symbol\"):\n                text_parts.append(str(c[\"symbol\"]))\n            if c.get(\"path\"):\n                text_parts.append(str(c[\"path\"]))\n            code = c.get(\"code\") or c.get(\"snippet\") or c.get(\"text\") or \"\"\n            if code:\n                text_parts.append(str(code)[:500])\n            doc_texts.append(\" \".join(text_parts) if text_parts else \"empty\")\n\n        query_emb = self._encode([query])[0]\n        doc_embs = self._encode(doc_texts)\n        query_emb = self._project_to_dim(query_emb.reshape(1, -1))[0]\n        doc_embs = self._project_to_dim(doc_embs)\n\n        z = query_emb.copy()\n        if initial_scores is not None:\n            scores = np.array(initial_scores, dtype=np.float32)\n        else:\n            scores = np.zeros(n_docs, dtype=np.float32)\n\n        state = RefinementState(z=z, scores=scores, iteration=0)\n        state.score_history.append(scores.copy())\n        alpha_trajectory = []  # Track alpha values used\n\n        for i in range(self.n_iterations):\n            state.iteration = i + 1\n            new_scores = self.scorer.forward(query_emb, doc_embs, state.z)\n            alpha = self.alpha_scheduler.get_alpha(i)\n            alpha_trajectory.append(alpha)\n            state.scores = alpha * new_scores + (1 - alpha) * state.scores\n            state.score_history.append(state.scores.copy())\n            state.z = self.refiner.refine(state.z, query_emb, doc_embs, state.scores)\n            if self.early_stop and confidence.should_stop(state):\n                break\n\n        final_scores = state.scores\n        if initial_scores is not None and self.blend_with_initial > 0:\n            init_arr = np.array(initial_scores, dtype=np.float32)\n            std = final_scores.std()\n            if std > 1e-6:\n                final_norm = (final_scores - final_scores.mean()) / std\n            else:\n                final_norm = final_scores - final_scores.mean()\n            std = init_arr.std()\n            if std > 1e-6:\n                init_norm = (init_arr - init_arr.mean()) / std\n            else:\n                init_norm = init_arr - init_arr.mean()\n            final_scores = (1 - self.blend_with_initial) * final_norm + self.blend_with_initial * init_norm\n\n        ranked_indices = np.argsort(-final_scores)\n        reranked = []\n        fname_boost_factor = float(os.environ.get(\"FNAME_BOOST\", \"0.15\") or 0.15)\n\n        for rank, idx in enumerate(ranked_indices):\n            candidate = candidates[idx].copy()\n            candidate[\"recursive_score\"] = float(final_scores[idx])\n            candidate[\"recursive_rank\"] = rank\n            candidate[\"recursive_iterations\"] = state.iteration\n            trajectory = [float(h[idx]) for h in state.score_history]\n            candidate[\"score_trajectory\"] = trajectory\n            candidate[\"alpha_trajectory\"] = alpha_trajectory[:state.iteration]  # Alpha values used\n            fname_boost = _compute_fname_boost(query, candidate, fname_boost_factor)\n            candidate[\"score\"] = float(final_scores[idx]) + fname_boost\n            if fname_boost > 0:\n                candidate[\"fname_boost\"] = fname_boost\n            reranked.append(candidate)\n\n        if fname_boost_factor > 0 and any(c.get(\"fname_boost\", 0) > 0 for c in reranked):\n            reranked.sort(key=lambda x: -x[\"score\"])\n\n        return reranked",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___init___45": {
      "name": "__init__",
      "type": "method",
      "start_line": 45,
      "end_line": 75,
      "content_hash": "3accad80f7a7335784aacb2b1a8c697de210e585",
      "content": "    def __init__(\n        self,\n        n_iterations: int = 3,\n        dim: int = 256,\n        hidden_dim: int = 512,\n        early_stop: bool = True,\n        blend_with_initial: float = 0.3,\n        alpha_scheduler: Optional[Any] = None,\n    ):\n        self.n_iterations = n_iterations\n        self.dim = dim\n        self.early_stop = early_stop\n        self.blend_with_initial = blend_with_initial\n\n        # Alpha scheduler: if None, use CosineAlphaScheduler by default\n        if alpha_scheduler is None:\n            from scripts.rerank_recursive.alpha_scheduler import CosineAlphaScheduler\n            self.alpha_scheduler = CosineAlphaScheduler(n_iterations=n_iterations)\n        else:\n            self.alpha_scheduler = alpha_scheduler\n\n        self.scorer = TinyScorer(dim=dim, hidden_dim=hidden_dim)\n        self.refiner = LatentRefiner(dim=dim)\n\n        from scripts.embedder import get_model_dimension\n        embed_dim = get_model_dimension()\n        self._learned_projection = LearnedProjection(input_dim=embed_dim, output_dim=dim, lr=0.0)\n        self._embedder = None\n        self._embedder_lock = threading.Lock()\n        self._proj_cache: Dict[int, np.ndarray] = {}\n        self._proj_cache_lock = threading.Lock()",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__get_embedder_77": {
      "name": "_get_embedder",
      "type": "method",
      "start_line": 77,
      "end_line": 89,
      "content_hash": "07d1e38e2e63c19f8d0436386e6cd46b713aff5c",
      "content": "    def _get_embedder(self):\n        if self._embedder is not None:\n            return self._embedder\n        with self._embedder_lock:\n            if self._embedder is not None:\n                return self._embedder\n            try:\n                from scripts.embedder import get_embedding_model\n                model_name = os.environ.get(\"EMBEDDING_MODEL\", \"BAAI/bge-base-en-v1.5\")\n                self._embedder = get_embedding_model(model_name)\n            except Exception:\n                self._embedder = None\n            return self._embedder",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__encode_91": {
      "name": "_encode",
      "type": "method",
      "start_line": 91,
      "end_line": 140,
      "content_hash": "3e63c3200eb2c7ed51cfd637f773795e34f0c68d",
      "content": "    def _encode(self, texts: List[str]) -> np.ndarray:\n        cached_results = []\n        texts_to_encode = []\n        text_indices = []\n\n        for i, text in enumerate(texts):\n            cached = _get_cached_embedding(text)\n            if cached is not None:\n                cached_results.append((i, cached))\n            else:\n                texts_to_encode.append(text)\n                text_indices.append(i)\n\n        new_embeddings = []\n        if texts_to_encode:\n            embedder = self._get_embedder()\n            if embedder is not None:\n                try:\n                    embeddings = list(embedder.embed(texts_to_encode))\n                    if len(embeddings) != len(texts_to_encode):\n                        raise ValueError(\"Embedding count mismatch\")\n                    for text, emb in zip(texts_to_encode, embeddings):\n                        emb_arr = np.array(emb, dtype=np.float32)\n                        if emb_arr.shape[0] != self.dim:\n                            emb_arr = self._project_to_dim(emb_arr.reshape(1, -1))[0]\n                        _cache_embedding(text, emb_arr)\n                        new_embeddings.append(emb_arr)\n                except Exception:\n                    new_embeddings = []\n\n            if not new_embeddings:\n                import hashlib\n                fallback_dim = self.dim\n                if cached_results:\n                    fallback_dim = cached_results[0][1].shape[0]\n                for text in texts_to_encode:\n                    text_hash = hashlib.sha256(text.encode(\"utf-8\", errors=\"replace\")).digest()\n                    seed = int.from_bytes(text_hash[:4], \"big\")\n                    rng = np.random.RandomState(seed)\n                    vec = rng.randn(fallback_dim).astype(np.float32)\n                    vec = vec / (np.linalg.norm(vec) + 1e-8)\n                    _cache_embedding(text, vec)\n                    new_embeddings.append(vec)\n\n        result = [None] * len(texts)\n        for i, emb in cached_results:\n            result[i] = emb\n        for i, idx in enumerate(text_indices):\n            result[idx] = new_embeddings[i]\n        return np.array(result, dtype=np.float32)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__encode_raw_142": {
      "name": "_encode_raw",
      "type": "method",
      "start_line": 142,
      "end_line": 171,
      "content_hash": "56e88fd974007b17d04306788a3808d62b6b1d83",
      "content": "    def _encode_raw(self, texts: List[str]) -> np.ndarray:\n        from scripts.embedder import get_model_dimension\n        fallback_dim = get_model_dimension()\n        embedder = self._get_embedder()\n        if embedder is None:\n            import hashlib\n            result = []\n            for text in texts:\n                text_hash = hashlib.sha256(text.encode(\"utf-8\", errors=\"replace\")).digest()\n                seed = int.from_bytes(text_hash[:4], \"big\")\n                rng = np.random.RandomState(seed)\n                vec = rng.randn(fallback_dim).astype(np.float32)\n                vec = vec / (np.linalg.norm(vec) + 1e-8)\n                result.append(vec)\n            return np.array(result, dtype=np.float32)\n        try:\n            embeddings = list(embedder.embed(texts))\n            result = [np.array(emb, dtype=np.float32) for emb in embeddings]\n            return np.array(result, dtype=np.float32)\n        except Exception:\n            import hashlib\n            result = []\n            for text in texts:\n                text_hash = hashlib.sha256(text.encode(\"utf-8\", errors=\"replace\")).digest()\n                seed = int.from_bytes(text_hash[:4], \"big\")\n                rng = np.random.RandomState(seed)\n                vec = rng.randn(fallback_dim).astype(np.float32)\n                vec = vec / (np.linalg.norm(vec) + 1e-8)\n                result.append(vec)\n            return np.array(result, dtype=np.float32)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__project_to_dim_173": {
      "name": "_project_to_dim",
      "type": "method",
      "start_line": 173,
      "end_line": 189,
      "content_hash": "67a9496eb2d199506cf4fe8ed445606dc67a81f8",
      "content": "    def _project_to_dim(self, embeddings: np.ndarray) -> np.ndarray:\n        if embeddings.shape[-1] == self.dim:\n            return embeddings\n        input_dim = embeddings.shape[-1]\n        if (hasattr(self, '_learned_projection') and\n            self._learned_projection._weights_loaded and\n            self._learned_projection.input_dim == input_dim):\n            return self._learned_projection.forward(embeddings)\n        with self._proj_cache_lock:\n            if input_dim not in self._proj_cache:\n                rng = np.random.RandomState(44)\n                proj_matrix = rng.randn(input_dim, self.dim).astype(np.float32) * np.float32(0.01)\n                self._proj_cache[input_dim] = proj_matrix\n            proj_matrix = self._proj_cache[input_dim]\n        projected = embeddings @ proj_matrix\n        norms = np.linalg.norm(projected, axis=-1, keepdims=True) + 1e-8\n        return projected / norms",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_rerank_191": {
      "name": "rerank",
      "type": "method",
      "start_line": 191,
      "end_line": 277,
      "content_hash": "9708e1d80359b2b06eb5c479f33cdc1d51a6cccf",
      "content": "    def rerank(\n        self,\n        query: str,\n        candidates: List[Dict[str, Any]],\n        initial_scores: Optional[List[float]] = None,\n    ) -> List[Dict[str, Any]]:\n        if not candidates:\n            return []\n\n        confidence = ConfidenceEstimator()\n        n_docs = len(candidates)\n\n        doc_texts = []\n        for c in candidates:\n            text_parts = []\n            if c.get(\"symbol\"):\n                text_parts.append(str(c[\"symbol\"]))\n            if c.get(\"path\"):\n                text_parts.append(str(c[\"path\"]))\n            code = c.get(\"code\") or c.get(\"snippet\") or c.get(\"text\") or \"\"\n            if code:\n                text_parts.append(str(code)[:500])\n            doc_texts.append(\" \".join(text_parts) if text_parts else \"empty\")\n\n        query_emb = self._encode([query])[0]\n        doc_embs = self._encode(doc_texts)\n        query_emb = self._project_to_dim(query_emb.reshape(1, -1))[0]\n        doc_embs = self._project_to_dim(doc_embs)\n\n        z = query_emb.copy()\n        if initial_scores is not None:\n            scores = np.array(initial_scores, dtype=np.float32)\n        else:\n            scores = np.zeros(n_docs, dtype=np.float32)\n\n        state = RefinementState(z=z, scores=scores, iteration=0)\n        state.score_history.append(scores.copy())\n        alpha_trajectory = []  # Track alpha values used\n\n        for i in range(self.n_iterations):\n            state.iteration = i + 1\n            new_scores = self.scorer.forward(query_emb, doc_embs, state.z)\n            alpha = self.alpha_scheduler.get_alpha(i)\n            alpha_trajectory.append(alpha)\n            state.scores = alpha * new_scores + (1 - alpha) * state.scores\n            state.score_history.append(state.scores.copy())\n            state.z = self.refiner.refine(state.z, query_emb, doc_embs, state.scores)\n            if self.early_stop and confidence.should_stop(state):\n                break\n\n        final_scores = state.scores\n        if initial_scores is not None and self.blend_with_initial > 0:\n            init_arr = np.array(initial_scores, dtype=np.float32)\n            std = final_scores.std()\n            if std > 1e-6:\n                final_norm = (final_scores - final_scores.mean()) / std\n            else:\n                final_norm = final_scores - final_scores.mean()\n            std = init_arr.std()\n            if std > 1e-6:\n                init_norm = (init_arr - init_arr.mean()) / std\n            else:\n                init_norm = init_arr - init_arr.mean()\n            final_scores = (1 - self.blend_with_initial) * final_norm + self.blend_with_initial * init_norm\n\n        ranked_indices = np.argsort(-final_scores)\n        reranked = []\n        fname_boost_factor = float(os.environ.get(\"FNAME_BOOST\", \"0.15\") or 0.15)\n\n        for rank, idx in enumerate(ranked_indices):\n            candidate = candidates[idx].copy()\n            candidate[\"recursive_score\"] = float(final_scores[idx])\n            candidate[\"recursive_rank\"] = rank\n            candidate[\"recursive_iterations\"] = state.iteration\n            trajectory = [float(h[idx]) for h in state.score_history]\n            candidate[\"score_trajectory\"] = trajectory\n            candidate[\"alpha_trajectory\"] = alpha_trajectory[:state.iteration]  # Alpha values used\n            fname_boost = _compute_fname_boost(query, candidate, fname_boost_factor)\n            candidate[\"score\"] = float(final_scores[idx]) + fname_boost\n            if fname_boost > 0:\n                candidate[\"fname_boost\"] = fname_boost\n            reranked.append(candidate)\n\n        if fname_boost_factor > 0 and any(c.get(\"fname_boost\", 0) > 0 for c in reranked):\n            reranked.sort(key=lambda x: -x[\"score\"])\n\n        return reranked",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_ONNXRecursiveReranker_280": {
      "name": "ONNXRecursiveReranker",
      "type": "class",
      "start_line": 280,
      "end_line": 452,
      "content_hash": "2da28b46e44c4150b8c8019cc10f164fa33e2948",
      "content": "class ONNXRecursiveReranker(RecursiveReranker):\n    \"\"\"Recursive reranker using ONNX cross-encoder for scoring.\"\"\"\n\n    def __init__(\n        self,\n        n_iterations: int = 3,\n        onnx_path: Optional[str] = None,\n        tokenizer_path: Optional[str] = None,\n        **kwargs\n    ):\n        super().__init__(n_iterations=n_iterations, **kwargs)\n        self.onnx_path = onnx_path or os.environ.get(\"RERANKER_ONNX_PATH\", \"\")\n        self.tokenizer_path = tokenizer_path or os.environ.get(\"RERANKER_TOKENIZER_PATH\", \"\")\n        self._session = None\n        self._tokenizer = None\n        self._onnx_lock = threading.Lock()\n\n    def _get_onnx_session(self):\n        if self._session is not None:\n            return self._session, self._tokenizer\n        if not HAS_ONNX or not self.onnx_path or not self.tokenizer_path:\n            return None, None\n        with self._onnx_lock:\n            if self._session is not None:\n                return self._session, self._tokenizer\n            try:\n                tok = Tokenizer.from_file(self.tokenizer_path)\n                try:\n                    tok.enable_truncation(max_length=512)\n                except Exception:\n                    pass\n                sess = ort.InferenceSession(self.onnx_path, providers=[\"CPUExecutionProvider\"])\n                self._session, self._tokenizer = sess, tok\n            except Exception:\n                self._session, self._tokenizer = None, None\n            return self._session, self._tokenizer\n\n    def _onnx_score(self, query: str, docs: List[str]) -> Optional[np.ndarray]:\n        sess, tok = self._get_onnx_session()\n        if sess is None or tok is None:\n            return None\n        try:\n            pairs = [(query, doc) for doc in docs]\n            enc = tok.encode_batch(pairs)\n            input_ids = [e.ids for e in enc]\n            attn = [e.attention_mask for e in enc]\n            max_len = max((len(ids) for ids in input_ids), default=0)\n            if max_len == 0:\n                return None\n            pad_id = 0\n            try:\n                pad_token_id = tok.token_to_id(\"[PAD]\")\n                if pad_token_id is not None:\n                    pad_id = int(pad_token_id)\n            except Exception:\n                pad_id = 0\n\n            def pad(seq, pad_val):\n                return seq + [pad_val] * (max_len - len(seq))\n\n            input_ids_padded = [pad(s, pad_id) for s in input_ids]\n            attn_padded = [pad(s, 0) for s in attn]\n            input_ids_arr = np.array(input_ids_padded, dtype=np.int64)\n            attn_arr = np.array(attn_padded, dtype=np.int64)\n            input_names = [i.name for i in sess.get_inputs()]\n            feeds = {}\n            if \"input_ids\" in input_names:\n                feeds[\"input_ids\"] = input_ids_arr\n            if \"attention_mask\" in input_names:\n                feeds[\"attention_mask\"] = attn_arr\n            if \"token_type_ids\" in input_names:\n                token_type_arr = np.zeros((len(input_ids_padded), max_len), dtype=np.int64)\n                feeds[\"token_type_ids\"] = token_type_arr\n            out = sess.run(None, feeds)\n            logits = out[0]\n            scores = []\n            for row in logits:\n                try:\n                    if hasattr(row, \"__len__\") and len(row) >= 2:\n                        scores.append(float(row[1]))\n                    elif hasattr(row, \"__len__\") and len(row) == 1:\n                        scores.append(float(row[0]))\n                    else:\n                        scores.append(float(row))\n                except Exception:\n                    scores.append(0.0)\n            return np.array(scores, dtype=np.float32)\n        except Exception:\n            return None\n\n    def rerank(\n        self,\n        query: str,\n        candidates: List[Dict[str, Any]],\n        initial_scores: Optional[List[float]] = None,\n    ) -> List[Dict[str, Any]]:\n        if not candidates:\n            return []\n\n        confidence = ConfidenceEstimator()\n\n        doc_texts = []\n        for c in candidates:\n            parts = []\n            if c.get(\"symbol\"):\n                parts.append(str(c[\"symbol\"]))\n            if c.get(\"path\"):\n                parts.append(str(c[\"path\"]))\n            code = c.get(\"code\") or c.get(\"snippet\") or c.get(\"text\") or \"\"\n            if code:\n                parts.append(str(code)[:400])\n            doc_texts.append(\" \".join(parts) if parts else \"empty\")\n\n        onnx_scores = self._onnx_score(query, doc_texts)\n        if onnx_scores is None:\n            return super().rerank(query, candidates, initial_scores)\n\n        scores = onnx_scores.copy()\n        query_emb = self._encode([query])[0]\n        doc_embs = self._encode(doc_texts)\n        query_emb = self._project_to_dim(query_emb.reshape(1, -1))[0]\n        doc_embs = self._project_to_dim(doc_embs)\n\n        z = query_emb.copy()\n        state = RefinementState(z=z, scores=scores, iteration=0)\n        state.score_history.append(scores.copy())\n\n        for i in range(self.n_iterations - 1):\n            state.iteration = i + 1\n            state.z = self.refiner.refine(state.z, query_emb, doc_embs, state.scores)\n            adjustment = self.scorer.forward(query_emb, doc_embs, state.z)\n            try:\n                metrics = self.scorer.get_metrics()\n                if metrics.get(\"converged\", False) and metrics.get(\"avg_loss\", 1.0) < 0.3:\n                    alpha = 0.5\n                elif metrics.get(\"update_count\", 0) > 100:\n                    alpha = 0.35\n                else:\n                    alpha = 0.2\n            except Exception:\n                alpha = 0.2\n            state.scores = (1 - alpha) * state.scores + alpha * adjustment\n            state.score_history.append(state.scores.copy())\n            if self.early_stop and confidence.should_stop(state):\n                break\n\n        final_scores = state.scores\n        if initial_scores is not None and self.blend_with_initial > 0:\n            init_arr = np.array(initial_scores, dtype=np.float32)\n            std = final_scores.std()\n            if std > 1e-6:\n                final_norm = (final_scores - final_scores.mean()) / std\n            else:\n                final_norm = final_scores - final_scores.mean()\n            std = init_arr.std()\n            if std > 1e-6:\n                init_norm = (init_arr - init_arr.mean()) / std\n            else:\n                init_norm = init_arr - init_arr.mean()\n            final_scores = (1 - self.blend_with_initial) * final_norm + self.blend_with_initial * init_norm\n\n        ranked_indices = np.argsort(-final_scores)\n        reranked = []\n        for rank, idx in enumerate(ranked_indices):\n            candidate = candidates[idx].copy()\n            candidate[\"recursive_score\"] = float(final_scores[idx])\n            candidate[\"onnx_score\"] = float(onnx_scores[idx])\n            candidate[\"recursive_rank\"] = rank\n            candidate[\"recursive_iterations\"] = state.iteration + 1\n            candidate[\"score_trajectory\"] = [float(h[idx]) for h in state.score_history]\n            candidate[\"score\"] = float(final_scores[idx])\n            reranked.append(candidate)\n        return reranked",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___init___283": {
      "name": "__init__",
      "type": "method",
      "start_line": 283,
      "end_line": 295,
      "content_hash": "0306eb021b80cbb81ef2e72dd141b059646dbdcb",
      "content": "    def __init__(\n        self,\n        n_iterations: int = 3,\n        onnx_path: Optional[str] = None,\n        tokenizer_path: Optional[str] = None,\n        **kwargs\n    ):\n        super().__init__(n_iterations=n_iterations, **kwargs)\n        self.onnx_path = onnx_path or os.environ.get(\"RERANKER_ONNX_PATH\", \"\")\n        self.tokenizer_path = tokenizer_path or os.environ.get(\"RERANKER_TOKENIZER_PATH\", \"\")\n        self._session = None\n        self._tokenizer = None\n        self._onnx_lock = threading.Lock()",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__get_onnx_session_297": {
      "name": "_get_onnx_session",
      "type": "method",
      "start_line": 297,
      "end_line": 315,
      "content_hash": "16450650823beee39cbcfba658cc27d83045b05f",
      "content": "    def _get_onnx_session(self):\n        if self._session is not None:\n            return self._session, self._tokenizer\n        if not HAS_ONNX or not self.onnx_path or not self.tokenizer_path:\n            return None, None\n        with self._onnx_lock:\n            if self._session is not None:\n                return self._session, self._tokenizer\n            try:\n                tok = Tokenizer.from_file(self.tokenizer_path)\n                try:\n                    tok.enable_truncation(max_length=512)\n                except Exception:\n                    pass\n                sess = ort.InferenceSession(self.onnx_path, providers=[\"CPUExecutionProvider\"])\n                self._session, self._tokenizer = sess, tok\n            except Exception:\n                self._session, self._tokenizer = None, None\n            return self._session, self._tokenizer",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__onnx_score_317": {
      "name": "_onnx_score",
      "type": "method",
      "start_line": 317,
      "end_line": 368,
      "content_hash": "316e539daf9abad752f02f8e26cdf2c827dde596",
      "content": "    def _onnx_score(self, query: str, docs: List[str]) -> Optional[np.ndarray]:\n        sess, tok = self._get_onnx_session()\n        if sess is None or tok is None:\n            return None\n        try:\n            pairs = [(query, doc) for doc in docs]\n            enc = tok.encode_batch(pairs)\n            input_ids = [e.ids for e in enc]\n            attn = [e.attention_mask for e in enc]\n            max_len = max((len(ids) for ids in input_ids), default=0)\n            if max_len == 0:\n                return None\n            pad_id = 0\n            try:\n                pad_token_id = tok.token_to_id(\"[PAD]\")\n                if pad_token_id is not None:\n                    pad_id = int(pad_token_id)\n            except Exception:\n                pad_id = 0\n\n            def pad(seq, pad_val):\n                return seq + [pad_val] * (max_len - len(seq))\n\n            input_ids_padded = [pad(s, pad_id) for s in input_ids]\n            attn_padded = [pad(s, 0) for s in attn]\n            input_ids_arr = np.array(input_ids_padded, dtype=np.int64)\n            attn_arr = np.array(attn_padded, dtype=np.int64)\n            input_names = [i.name for i in sess.get_inputs()]\n            feeds = {}\n            if \"input_ids\" in input_names:\n                feeds[\"input_ids\"] = input_ids_arr\n            if \"attention_mask\" in input_names:\n                feeds[\"attention_mask\"] = attn_arr\n            if \"token_type_ids\" in input_names:\n                token_type_arr = np.zeros((len(input_ids_padded), max_len), dtype=np.int64)\n                feeds[\"token_type_ids\"] = token_type_arr\n            out = sess.run(None, feeds)\n            logits = out[0]\n            scores = []\n            for row in logits:\n                try:\n                    if hasattr(row, \"__len__\") and len(row) >= 2:\n                        scores.append(float(row[1]))\n                    elif hasattr(row, \"__len__\") and len(row) == 1:\n                        scores.append(float(row[0]))\n                    else:\n                        scores.append(float(row))\n                except Exception:\n                    scores.append(0.0)\n            return np.array(scores, dtype=np.float32)\n        except Exception:\n            return None",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_pad_337": {
      "name": "pad",
      "type": "method",
      "start_line": 337,
      "end_line": 338,
      "content_hash": "d22793858162f0eca252a14c6ac715eb22ccf468",
      "content": "            def pad(seq, pad_val):\n                return seq + [pad_val] * (max_len - len(seq))",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_rerank_370": {
      "name": "rerank",
      "type": "method",
      "start_line": 370,
      "end_line": 452,
      "content_hash": "5af43139216172f64c1f795873a6ebadeda1fa42",
      "content": "    def rerank(\n        self,\n        query: str,\n        candidates: List[Dict[str, Any]],\n        initial_scores: Optional[List[float]] = None,\n    ) -> List[Dict[str, Any]]:\n        if not candidates:\n            return []\n\n        confidence = ConfidenceEstimator()\n\n        doc_texts = []\n        for c in candidates:\n            parts = []\n            if c.get(\"symbol\"):\n                parts.append(str(c[\"symbol\"]))\n            if c.get(\"path\"):\n                parts.append(str(c[\"path\"]))\n            code = c.get(\"code\") or c.get(\"snippet\") or c.get(\"text\") or \"\"\n            if code:\n                parts.append(str(code)[:400])\n            doc_texts.append(\" \".join(parts) if parts else \"empty\")\n\n        onnx_scores = self._onnx_score(query, doc_texts)\n        if onnx_scores is None:\n            return super().rerank(query, candidates, initial_scores)\n\n        scores = onnx_scores.copy()\n        query_emb = self._encode([query])[0]\n        doc_embs = self._encode(doc_texts)\n        query_emb = self._project_to_dim(query_emb.reshape(1, -1))[0]\n        doc_embs = self._project_to_dim(doc_embs)\n\n        z = query_emb.copy()\n        state = RefinementState(z=z, scores=scores, iteration=0)\n        state.score_history.append(scores.copy())\n\n        for i in range(self.n_iterations - 1):\n            state.iteration = i + 1\n            state.z = self.refiner.refine(state.z, query_emb, doc_embs, state.scores)\n            adjustment = self.scorer.forward(query_emb, doc_embs, state.z)\n            try:\n                metrics = self.scorer.get_metrics()\n                if metrics.get(\"converged\", False) and metrics.get(\"avg_loss\", 1.0) < 0.3:\n                    alpha = 0.5\n                elif metrics.get(\"update_count\", 0) > 100:\n                    alpha = 0.35\n                else:\n                    alpha = 0.2\n            except Exception:\n                alpha = 0.2\n            state.scores = (1 - alpha) * state.scores + alpha * adjustment\n            state.score_history.append(state.scores.copy())\n            if self.early_stop and confidence.should_stop(state):\n                break\n\n        final_scores = state.scores\n        if initial_scores is not None and self.blend_with_initial > 0:\n            init_arr = np.array(initial_scores, dtype=np.float32)\n            std = final_scores.std()\n            if std > 1e-6:\n                final_norm = (final_scores - final_scores.mean()) / std\n            else:\n                final_norm = final_scores - final_scores.mean()\n            std = init_arr.std()\n            if std > 1e-6:\n                init_norm = (init_arr - init_arr.mean()) / std\n            else:\n                init_norm = init_arr - init_arr.mean()\n            final_scores = (1 - self.blend_with_initial) * final_norm + self.blend_with_initial * init_norm\n\n        ranked_indices = np.argsort(-final_scores)\n        reranked = []\n        for rank, idx in enumerate(ranked_indices):\n            candidate = candidates[idx].copy()\n            candidate[\"recursive_score\"] = float(final_scores[idx])\n            candidate[\"onnx_score\"] = float(onnx_scores[idx])\n            candidate[\"recursive_rank\"] = rank\n            candidate[\"recursive_iterations\"] = state.iteration + 1\n            candidate[\"score_trajectory\"] = [float(h[idx]) for h in state.score_history]\n            candidate[\"score\"] = float(final_scores[idx])\n            reranked.append(candidate)\n        return reranked",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_SessionAwareReranker_455": {
      "name": "SessionAwareReranker",
      "type": "class",
      "start_line": 455,
      "end_line": 600,
      "content_hash": "e95da69afd09dc7fe76676894c7db2e7a50a898a",
      "content": "class SessionAwareReranker:\n    \"\"\"Session-aware recursive reranker with latent state carryover.\"\"\"\n\n    def __init__(\n        self,\n        n_iterations: int = 3,\n        dim: int = 256,\n        session_decay: float = 0.9,\n        max_session_age: float = 3600.0,\n        max_sessions: int = 1000,\n    ):\n        self.n_iterations = n_iterations\n        self.dim = dim\n        self.session_decay = session_decay\n        self.max_session_age = max_session_age\n        self.max_sessions = max_sessions\n        self.reranker = RecursiveReranker(n_iterations=n_iterations, dim=dim)\n        self._sessions: Dict[str, tuple] = {}\n        self._session_lock = threading.Lock()\n\n    def _cleanup_old_sessions(self):\n        now = time.time()\n        expired = [sid for sid, (_, last_access) in self._sessions.items() if now - last_access > self.max_session_age]\n        for sid in expired:\n            del self._sessions[sid]\n        if len(self._sessions) > self.max_sessions:\n            sorted_sessions = sorted(self._sessions.items(), key=lambda x: x[1][1])\n            to_remove = len(self._sessions) - self.max_sessions\n            for sid, _ in sorted_sessions[:to_remove]:\n                del self._sessions[sid]\n\n    def get_session_latent(self, session_id: str) -> Optional[np.ndarray]:\n        with self._session_lock:\n            if session_id not in self._sessions:\n                return None\n            latent, last_access = self._sessions[session_id]\n            if time.time() - last_access > self.max_session_age:\n                del self._sessions[session_id]\n                return None\n            return latent\n\n    def update_session_latent(self, session_id: str, new_latent: np.ndarray):\n        with self._session_lock:\n            self._cleanup_old_sessions()\n            if session_id in self._sessions:\n                old_latent, _ = self._sessions[session_id]\n                blended = self.session_decay * old_latent + (1 - self.session_decay) * new_latent\n                blended = blended / (np.linalg.norm(blended) + 1e-8)\n                self._sessions[session_id] = (blended, time.time())\n            else:\n                self._sessions[session_id] = (new_latent.copy(), time.time())\n\n    def rerank(\n        self,\n        query: str,\n        candidates: List[Dict[str, Any]],\n        session_id: Optional[str] = None,\n        initial_scores: Optional[List[float]] = None,\n    ) -> List[Dict[str, Any]]:\n        if not candidates:\n            return []\n\n        session_latent = None\n        if session_id:\n            session_latent = self.get_session_latent(session_id)\n\n        query_emb = self.reranker._encode([query])[0]\n        query_emb = self.reranker._project_to_dim(query_emb.reshape(1, -1))[0]\n\n        if session_latent is not None:\n            initial_z = 0.7 * query_emb + 0.3 * session_latent\n            initial_z = initial_z / (np.linalg.norm(initial_z) + 1e-8)\n        else:\n            initial_z = query_emb.copy()\n\n        doc_texts = []\n        for c in candidates:\n            text_parts = []\n            if c.get(\"symbol\"):\n                text_parts.append(str(c[\"symbol\"]))\n            if c.get(\"path\"):\n                text_parts.append(str(c[\"path\"]))\n            code = c.get(\"code\") or c.get(\"snippet\") or c.get(\"text\") or \"\"\n            if code:\n                text_parts.append(str(code)[:500])\n            doc_texts.append(\" \".join(text_parts) if text_parts else \"empty\")\n\n        doc_embs = self.reranker._encode(doc_texts)\n        doc_embs = self.reranker._project_to_dim(doc_embs)\n\n        if initial_scores is None:\n            initial_scores = [c.get(\"score\", 0.0) for c in candidates]\n\n        state = RefinementState(z=initial_z, scores=np.array(initial_scores, dtype=np.float32))\n        state.score_history.append(state.scores.copy())\n\n        confidence = ConfidenceEstimator()\n        for i in range(self.n_iterations):\n            state.iteration = i + 1\n            new_scores = self.reranker.scorer.forward(query_emb, doc_embs, state.z)\n            alpha = 0.5\n            state.scores = alpha * new_scores + (1 - alpha) * state.scores\n            state.score_history.append(state.scores.copy())\n            state.z = self.reranker.refiner.refine(state.z, query_emb, doc_embs, state.scores)\n            if self.reranker.early_stop and confidence.should_stop(state):\n                break\n\n        if session_id:\n            self.update_session_latent(session_id, state.z)\n\n        final_scores = state.scores\n        if self.reranker.blend_with_initial > 0:\n            init_arr = np.array(initial_scores, dtype=np.float32)\n            std = final_scores.std()\n            if std > 1e-6:\n                final_norm = (final_scores - final_scores.mean()) / std\n            else:\n                final_norm = final_scores - final_scores.mean()\n            std = init_arr.std()\n            if std > 1e-6:\n                init_norm = (init_arr - init_arr.mean()) / std\n            else:\n                init_norm = init_arr - init_arr.mean()\n            final_scores = (1 - self.reranker.blend_with_initial) * final_norm + self.reranker.blend_with_initial * init_norm\n\n        ranked_indices = np.argsort(-final_scores)\n        reranked = []\n        for rank, idx in enumerate(ranked_indices):\n            candidate = candidates[idx].copy()\n            candidate[\"recursive_score\"] = float(final_scores[idx])\n            candidate[\"recursive_rank\"] = rank\n            candidate[\"recursive_iterations\"] = state.iteration\n            candidate[\"session_aware\"] = session_id is not None\n            candidate[\"score_trajectory\"] = [float(h[idx]) for h in state.score_history]\n            candidate[\"score\"] = float(final_scores[idx])\n            reranked.append(candidate)\n        return reranked\n\n    def clear_session(self, session_id: str):\n        with self._session_lock:\n            if session_id in self._sessions:\n                del self._sessions[session_id]\n\n    def get_session_count(self) -> int:\n        with self._session_lock:\n            return len(self._sessions)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___init___458": {
      "name": "__init__",
      "type": "method",
      "start_line": 458,
      "end_line": 473,
      "content_hash": "a2f3333b544841352890acd754ed72ec123d93b3",
      "content": "    def __init__(\n        self,\n        n_iterations: int = 3,\n        dim: int = 256,\n        session_decay: float = 0.9,\n        max_session_age: float = 3600.0,\n        max_sessions: int = 1000,\n    ):\n        self.n_iterations = n_iterations\n        self.dim = dim\n        self.session_decay = session_decay\n        self.max_session_age = max_session_age\n        self.max_sessions = max_sessions\n        self.reranker = RecursiveReranker(n_iterations=n_iterations, dim=dim)\n        self._sessions: Dict[str, tuple] = {}\n        self._session_lock = threading.Lock()",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__cleanup_old_sessions_475": {
      "name": "_cleanup_old_sessions",
      "type": "method",
      "start_line": 475,
      "end_line": 484,
      "content_hash": "38bd26b81708fc1e105df594ffb88b64118620dd",
      "content": "    def _cleanup_old_sessions(self):\n        now = time.time()\n        expired = [sid for sid, (_, last_access) in self._sessions.items() if now - last_access > self.max_session_age]\n        for sid in expired:\n            del self._sessions[sid]\n        if len(self._sessions) > self.max_sessions:\n            sorted_sessions = sorted(self._sessions.items(), key=lambda x: x[1][1])\n            to_remove = len(self._sessions) - self.max_sessions\n            for sid, _ in sorted_sessions[:to_remove]:\n                del self._sessions[sid]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_get_session_latent_486": {
      "name": "get_session_latent",
      "type": "method",
      "start_line": 486,
      "end_line": 494,
      "content_hash": "3ab5ee5370fa91eb89539bc0c97a07379faf64e4",
      "content": "    def get_session_latent(self, session_id: str) -> Optional[np.ndarray]:\n        with self._session_lock:\n            if session_id not in self._sessions:\n                return None\n            latent, last_access = self._sessions[session_id]\n            if time.time() - last_access > self.max_session_age:\n                del self._sessions[session_id]\n                return None\n            return latent",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_update_session_latent_496": {
      "name": "update_session_latent",
      "type": "method",
      "start_line": 496,
      "end_line": 505,
      "content_hash": "5c26d514204b41f9fe3f5b98fc388ce64e29274a",
      "content": "    def update_session_latent(self, session_id: str, new_latent: np.ndarray):\n        with self._session_lock:\n            self._cleanup_old_sessions()\n            if session_id in self._sessions:\n                old_latent, _ = self._sessions[session_id]\n                blended = self.session_decay * old_latent + (1 - self.session_decay) * new_latent\n                blended = blended / (np.linalg.norm(blended) + 1e-8)\n                self._sessions[session_id] = (blended, time.time())\n            else:\n                self._sessions[session_id] = (new_latent.copy(), time.time())",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_rerank_507": {
      "name": "rerank",
      "type": "method",
      "start_line": 507,
      "end_line": 591,
      "content_hash": "18deb8b50e23c682954e1145b0f956d34f36eadf",
      "content": "    def rerank(\n        self,\n        query: str,\n        candidates: List[Dict[str, Any]],\n        session_id: Optional[str] = None,\n        initial_scores: Optional[List[float]] = None,\n    ) -> List[Dict[str, Any]]:\n        if not candidates:\n            return []\n\n        session_latent = None\n        if session_id:\n            session_latent = self.get_session_latent(session_id)\n\n        query_emb = self.reranker._encode([query])[0]\n        query_emb = self.reranker._project_to_dim(query_emb.reshape(1, -1))[0]\n\n        if session_latent is not None:\n            initial_z = 0.7 * query_emb + 0.3 * session_latent\n            initial_z = initial_z / (np.linalg.norm(initial_z) + 1e-8)\n        else:\n            initial_z = query_emb.copy()\n\n        doc_texts = []\n        for c in candidates:\n            text_parts = []\n            if c.get(\"symbol\"):\n                text_parts.append(str(c[\"symbol\"]))\n            if c.get(\"path\"):\n                text_parts.append(str(c[\"path\"]))\n            code = c.get(\"code\") or c.get(\"snippet\") or c.get(\"text\") or \"\"\n            if code:\n                text_parts.append(str(code)[:500])\n            doc_texts.append(\" \".join(text_parts) if text_parts else \"empty\")\n\n        doc_embs = self.reranker._encode(doc_texts)\n        doc_embs = self.reranker._project_to_dim(doc_embs)\n\n        if initial_scores is None:\n            initial_scores = [c.get(\"score\", 0.0) for c in candidates]\n\n        state = RefinementState(z=initial_z, scores=np.array(initial_scores, dtype=np.float32))\n        state.score_history.append(state.scores.copy())\n\n        confidence = ConfidenceEstimator()\n        for i in range(self.n_iterations):\n            state.iteration = i + 1\n            new_scores = self.reranker.scorer.forward(query_emb, doc_embs, state.z)\n            alpha = 0.5\n            state.scores = alpha * new_scores + (1 - alpha) * state.scores\n            state.score_history.append(state.scores.copy())\n            state.z = self.reranker.refiner.refine(state.z, query_emb, doc_embs, state.scores)\n            if self.reranker.early_stop and confidence.should_stop(state):\n                break\n\n        if session_id:\n            self.update_session_latent(session_id, state.z)\n\n        final_scores = state.scores\n        if self.reranker.blend_with_initial > 0:\n            init_arr = np.array(initial_scores, dtype=np.float32)\n            std = final_scores.std()\n            if std > 1e-6:\n                final_norm = (final_scores - final_scores.mean()) / std\n            else:\n                final_norm = final_scores - final_scores.mean()\n            std = init_arr.std()\n            if std > 1e-6:\n                init_norm = (init_arr - init_arr.mean()) / std\n            else:\n                init_norm = init_arr - init_arr.mean()\n            final_scores = (1 - self.reranker.blend_with_initial) * final_norm + self.reranker.blend_with_initial * init_norm\n\n        ranked_indices = np.argsort(-final_scores)\n        reranked = []\n        for rank, idx in enumerate(ranked_indices):\n            candidate = candidates[idx].copy()\n            candidate[\"recursive_score\"] = float(final_scores[idx])\n            candidate[\"recursive_rank\"] = rank\n            candidate[\"recursive_iterations\"] = state.iteration\n            candidate[\"session_aware\"] = session_id is not None\n            candidate[\"score_trajectory\"] = [float(h[idx]) for h in state.score_history]\n            candidate[\"score\"] = float(final_scores[idx])\n            reranked.append(candidate)\n        return reranked",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_clear_session_593": {
      "name": "clear_session",
      "type": "method",
      "start_line": 593,
      "end_line": 596,
      "content_hash": "fd4a6239cef1ac7f4bbcfc0c54265eda77675c8a",
      "content": "    def clear_session(self, session_id: str):\n        with self._session_lock:\n            if session_id in self._sessions:\n                del self._sessions[session_id]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_get_session_count_598": {
      "name": "get_session_count",
      "type": "method",
      "start_line": 598,
      "end_line": 600,
      "content_hash": "66fa04b8be5d897ecf0425a7d3377f6e83bd41a7",
      "content": "    def get_session_count(self) -> int:\n        with self._session_lock:\n            return len(self._sessions)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_rerank_recursive_604": {
      "name": "rerank_recursive",
      "type": "function",
      "start_line": 604,
      "end_line": 613,
      "content_hash": "7c847547ffa7fdd7da7a630d82be339bbd70eae3",
      "content": "def rerank_recursive(\n    query: str,\n    candidates: List[Dict[str, Any]],\n    n_iterations: int = 3,\n    blend_with_initial: float = 0.3,\n) -> List[Dict[str, Any]]:\n    \"\"\"Convenience wrapper for recursive reranking.\"\"\"\n    reranker = RecursiveReranker(n_iterations=n_iterations, blend_with_initial=blend_with_initial)\n    initial_scores = [c.get(\"score\", 0.0) for c in candidates]\n    return reranker.rerank(query, candidates, initial_scores)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_rerank_recursive_inprocess_616": {
      "name": "rerank_recursive_inprocess",
      "type": "function",
      "start_line": 616,
      "end_line": 624,
      "content_hash": "5506c948fb61983566059406daac47b201627b26",
      "content": "def rerank_recursive_inprocess(\n    query: str,\n    candidates: List[Dict[str, Any]],\n    limit: int = 12,\n    n_iterations: int = 3,\n) -> List[Dict[str, Any]]:\n    \"\"\"In-process recursive reranking for MCP server integration.\"\"\"\n    reranked = rerank_recursive(query=query, candidates=candidates, n_iterations=n_iterations)\n    return reranked[:limit]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function__get_learning_reranker_632": {
      "name": "_get_learning_reranker",
      "type": "function",
      "start_line": 632,
      "end_line": 645,
      "content_hash": "82e27adbb4ece0e276af6fa0961911b9318d9ae7",
      "content": "def _get_learning_reranker(\n    n_iterations: int = 3,\n    dim: int = 256,\n    collection: str = \"default\",\n) -> RecursiveReranker:\n    \"\"\"Get or create a learning reranker for a specific collection.\"\"\"\n    with _LEARNING_RERANKERS_LOCK:\n        if collection not in _LEARNING_RERANKERS:\n            reranker = RecursiveReranker(n_iterations=n_iterations, dim=dim)\n            reranker.scorer.set_collection(collection)\n            reranker.refiner.set_collection(collection)\n            reranker._learned_projection.set_collection(collection)\n            _LEARNING_RERANKERS[collection] = reranker\n        return _LEARNING_RERANKERS[collection]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_rerank_with_learning_648": {
      "name": "rerank_with_learning",
      "type": "function",
      "start_line": 648,
      "end_line": 703,
      "content_hash": "4ff0ad14006fcc5fffe29dfe58e1e54e35e8daf1",
      "content": "def rerank_with_learning(\n    query: str,\n    candidates: List[Dict[str, Any]],\n    limit: int = 12,\n    n_iterations: int = 3,\n    learn_from_onnx: bool = True,\n    collection: str = \"default\",\n) -> List[Dict[str, Any]]:\n    \"\"\"Learning-enabled reranking for MCP server integration.\"\"\"\n    reranker = _get_learning_reranker(n_iterations=n_iterations, collection=collection)\n    initial_scores = [c.get(\"score\", 0) for c in candidates]\n\n    if learn_from_onnx and candidates:\n        teacher_scores = None\n        if str(os.environ.get(\"RERANK_TEACHER_INLINE\", \"\")).strip().lower() in {\"1\", \"true\", \"yes\", \"on\"}:\n            try:\n                from scripts.rerank_local import rerank_local\n            except ImportError:\n                try:\n                    from rerank_local import rerank_local\n                except ImportError:\n                    rerank_local = None\n            if rerank_local is not None:\n                try:\n                    pairs = []\n                    for c in candidates:\n                        doc = c.get(\"code\") or c.get(\"snippet\") or \"\"\n                        if not doc:\n                            parts = []\n                            if c.get(\"symbol\"):\n                                parts.append(str(c[\"symbol\"]))\n                            if c.get(\"path\"):\n                                parts.append(str(c[\"path\"]))\n                            doc = \" \".join(parts) if parts else \"empty\"\n                        pairs.append((query, doc[:1000]))\n                    teacher_scores = rerank_local(pairs)\n                except Exception:\n                    teacher_scores = None\n        try:\n            try:\n                from rerank_events import log_training_event\n            except ImportError:\n                from scripts.rerank_events import log_training_event\n            log_training_event(\n                query=query,\n                candidates=candidates,\n                initial_scores=initial_scores,\n                teacher_scores=(list(teacher_scores) if teacher_scores is not None else None),\n                collection=collection,\n                metadata={\"teacher_inline\": bool(teacher_scores is not None)},\n            )\n        except Exception:\n            pass\n\n    reranked = reranker.rerank(query, candidates, initial_scores)\n    return reranked[:limit]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_get_recursive_reranker_706": {
      "name": "get_recursive_reranker",
      "type": "function",
      "start_line": 706,
      "end_line": 713,
      "content_hash": "b5544158006834cd6d4a09ab0aa14741b688f97f",
      "content": "def get_recursive_reranker(n_iterations: int = 3, **kwargs) -> RecursiveReranker:\n    \"\"\"Get the best available recursive reranker.\"\"\"\n    onnx_path = os.environ.get(\"RERANKER_ONNX_PATH\", \"\")\n    tokenizer_path = os.environ.get(\"RERANKER_TOKENIZER_PATH\", \"\")\n    if HAS_ONNX and onnx_path and tokenizer_path:\n        return ONNXRecursiveReranker(n_iterations=n_iterations, **kwargs)\n    else:\n        return RecursiveReranker(n_iterations=n_iterations, **kwargs)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_rerank_with_session_716": {
      "name": "rerank_with_session",
      "type": "function",
      "start_line": 716,
      "end_line": 724,
      "content_hash": "94d27a4d4d55de098fd6ead3708ca26a11677e75",
      "content": "def rerank_with_session(\n    query: str,\n    candidates: List[Dict[str, Any]],\n    session_id: str,\n    n_iterations: int = 3,\n) -> List[Dict[str, Any]]:\n    \"\"\"Session-aware reranking (stateless convenience wrapper).\"\"\"\n    reranker = SessionAwareReranker(n_iterations=n_iterations)\n    return reranker.rerank(query, candidates, session_id=session_id)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}