{
  "file_path": "/work/external-deps/helix-db/helix-db/src/helix_gateway/tests/gateway_loom_tests.rs",
  "file_hash": "4302bcefbcc0237efe314c153e899bd392addad5",
  "updated_at": "2025-12-26T17:34:20.765134",
  "symbols": {
    "function_loom_parity_fairness_27": {
      "name": "loom_parity_fairness",
      "type": "function",
      "start_line": 27,
      "end_line": 132,
      "content_hash": "99b4dac30409705aaaf947a34514b70e19cff610",
      "content": "fn loom_parity_fairness() {\n    loom::model(|| {\n        // Model: channels as atomic counters\n        // Request channel has pending items\n        let request_pending = Arc::new(AtomicU64::new(2));\n        // Continuation channel has pending items\n        let cont_pending = Arc::new(AtomicU64::new(2));\n\n        // Track which channel each worker serviced\n        let requests_serviced = Arc::new(AtomicU64::new(0));\n        let conts_serviced = Arc::new(AtomicU64::new(0));\n\n        let mut handles = vec![];\n\n        // Two workers with opposite parity\n        for parity in [true, false] {\n            let req = Arc::clone(&request_pending);\n            let cont = Arc::clone(&cont_pending);\n            let req_srv = Arc::clone(&requests_serviced);\n            let cont_srv = Arc::clone(&conts_serviced);\n\n            handles.push(thread::spawn(move || {\n                // Simulate one iteration of the worker loop\n                if parity {\n                    // Even parity: cont first\n                    let cont_val = cont.load(Ordering::Acquire);\n                    if cont_val > 0\n                        && cont\n                            .compare_exchange(\n                                cont_val,\n                                cont_val - 1,\n                                Ordering::SeqCst,\n                                Ordering::SeqCst,\n                            )\n                            .is_ok()\n                    {\n                        cont_srv.fetch_add(1, Ordering::SeqCst);\n                    } else {\n                        // Fall through to request channel\n                        let req_val = req.load(Ordering::Acquire);\n                        if req_val > 0\n                            && req\n                                .compare_exchange(\n                                    req_val,\n                                    req_val - 1,\n                                    Ordering::SeqCst,\n                                    Ordering::SeqCst,\n                                )\n                                .is_ok()\n                        {\n                            req_srv.fetch_add(1, Ordering::SeqCst);\n                        }\n                    }\n                } else {\n                    // Odd parity: request first\n                    let req_val = req.load(Ordering::Acquire);\n                    if req_val > 0\n                        && req\n                            .compare_exchange(\n                                req_val,\n                                req_val - 1,\n                                Ordering::SeqCst,\n                                Ordering::SeqCst,\n                            )\n                            .is_ok()\n                    {\n                        req_srv.fetch_add(1, Ordering::SeqCst);\n                    } else {\n                        // Fall through to continuation channel\n                        let cont_val = cont.load(Ordering::Acquire);\n                        if cont_val > 0\n                            && cont\n                                .compare_exchange(\n                                    cont_val,\n                                    cont_val - 1,\n                                    Ordering::SeqCst,\n                                    Ordering::SeqCst,\n                                )\n                                .is_ok()\n                        {\n                            cont_srv.fetch_add(1, Ordering::SeqCst);\n                        }\n                    }\n                }\n            }));\n        }\n\n        for handle in handles {\n            handle.join().unwrap();\n        }\n\n        // Total serviced should be 2 (one from each worker)\n        let total_serviced =\n            requests_serviced.load(Ordering::SeqCst) + conts_serviced.load(Ordering::SeqCst);\n        assert!(\n            total_serviced >= 1 && total_serviced <= 2,\n            \"Should service 1-2 items, got {}\",\n            total_serviced\n        );\n    });\n}\n\n/// Models starvation prevention in the parity mechanism\n///\n/// Verifies that with enough workers of both parities, neither channel starves.\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_loom_parity_starvation_prevention_133": {
      "name": "loom_parity_starvation_prevention",
      "type": "function",
      "start_line": 133,
      "end_line": 223,
      "content_hash": "3b09bb20b3ac45391566ea65f566b69558c7f237",
      "content": "fn loom_parity_starvation_prevention() {\n    loom::model(|| {\n        // Model: one item in each channel\n        let request_available = Arc::new(AtomicBool::new(true));\n        let cont_available = Arc::new(AtomicBool::new(true));\n\n        let request_consumed = Arc::new(AtomicBool::new(false));\n        let cont_consumed = Arc::new(AtomicBool::new(false));\n\n        let mut handles = vec![];\n\n        // Even parity worker (tries cont first)\n        {\n            let cont_avail = Arc::clone(&cont_available);\n            let cont_cons = Arc::clone(&cont_consumed);\n            let req_avail = Arc::clone(&request_available);\n            let req_cons = Arc::clone(&request_consumed);\n\n            handles.push(thread::spawn(move || {\n                // Try cont first\n                if cont_avail\n                    .compare_exchange(true, false, Ordering::SeqCst, Ordering::SeqCst)\n                    .is_ok()\n                {\n                    cont_cons.store(true, Ordering::SeqCst);\n                    return \"cont\";\n                }\n                // Then try request\n                if req_avail\n                    .compare_exchange(true, false, Ordering::SeqCst, Ordering::SeqCst)\n                    .is_ok()\n                {\n                    req_cons.store(true, Ordering::SeqCst);\n                    return \"req\";\n                }\n                \"none\"\n            }));\n        }\n\n        // Odd parity worker (tries request first)\n        {\n            let cont_avail = Arc::clone(&cont_available);\n            let cont_cons = Arc::clone(&cont_consumed);\n            let req_avail = Arc::clone(&request_available);\n            let req_cons = Arc::clone(&request_consumed);\n\n            handles.push(thread::spawn(move || {\n                // Try request first\n                if req_avail\n                    .compare_exchange(true, false, Ordering::SeqCst, Ordering::SeqCst)\n                    .is_ok()\n                {\n                    req_cons.store(true, Ordering::SeqCst);\n                    return \"req\";\n                }\n                // Then try cont\n                if cont_avail\n                    .compare_exchange(true, false, Ordering::SeqCst, Ordering::SeqCst)\n                    .is_ok()\n                {\n                    cont_cons.store(true, Ordering::SeqCst);\n                    return \"cont\";\n                }\n                \"none\"\n            }));\n        }\n\n        let results: Vec<_> = handles.into_iter().map(|h| h.join().unwrap()).collect();\n\n        // Both items should be consumed (no starvation)\n        let req_was_consumed = request_consumed.load(Ordering::SeqCst);\n        let cont_was_consumed = cont_consumed.load(Ordering::SeqCst);\n\n        assert!(\n            req_was_consumed && cont_was_consumed,\n            \"Both channels should be serviced: req={}, cont={}\",\n            req_was_consumed,\n            cont_was_consumed\n        );\n\n        // Each worker should have consumed exactly one item\n        let consumed_count = results.iter().filter(|&&r| r != \"none\").count();\n        assert_eq!(consumed_count, 2, \"Both workers should consume one item\");\n    });\n}\n\n/// Models per-request continuation channel for writer\n///\n/// The writer creates a new bounded(1) channel per request, processes\n/// the request, drops its sender, and polls until disconnected.\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_loom_writer_continuation_per_request_224": {
      "name": "loom_writer_continuation_per_request",
      "type": "function",
      "start_line": 224,
      "end_line": 304,
      "content_hash": "f644e6ef4cc65d528de8fb0f3e3b715b6faa5614",
      "content": "fn loom_writer_continuation_per_request() {\n    loom::model(|| {\n        // Model: per-request continuation channel state\n        // sender_alive: true if sender still exists\n        // continuation_pending: true if continuation queued\n        // continuation_completed: true if continuation was executed\n        let sender_alive = Arc::new(AtomicBool::new(true));\n        let continuation_pending = Arc::new(AtomicBool::new(false));\n        let continuation_completed = Arc::new(AtomicBool::new(false));\n\n        let io_pending = Arc::clone(&continuation_pending);\n        let io_completed = Arc::clone(&continuation_completed);\n        let io_sender = Arc::clone(&sender_alive);\n\n        let w_pending = Arc::clone(&continuation_pending);\n        let w_completed = Arc::clone(&continuation_completed);\n        let w_sender = Arc::clone(&sender_alive);\n\n        // IO runtime thread: spawns continuation\n        let io_thread = thread::spawn(move || {\n            // Queue a continuation\n            io_pending.store(true, Ordering::SeqCst);\n\n            // Simulate async work completing\n            loom::thread::yield_now();\n\n            // Execute continuation and signal completion\n            io_completed.store(true, Ordering::SeqCst);\n\n            // Drop our reference to sender (simulates future completing)\n            io_sender.store(false, Ordering::Release);\n        });\n\n        // Writer thread: processes request then polls for continuations\n        let writer_thread = thread::spawn(move || {\n            // Process request (already done in this model)\n\n            // Drop sender (in real code: drop(cont_tx))\n            // Note: We can't actually drop here since io_thread holds reference\n            // This models the race between drop and continuation completion\n\n            // Poll for continuations until sender is dropped\n            let mut poll_count = 0;\n            loop {\n                poll_count += 1;\n                if poll_count > 3 {\n                    break; // Prevent infinite loop in loom\n                }\n\n                let pending = w_pending.load(Ordering::Acquire);\n                let sender_exists = w_sender.load(Ordering::Acquire);\n\n                if pending && w_completed.load(Ordering::Acquire) {\n                    // Continuation completed\n                    break;\n                }\n\n                if !sender_exists {\n                    // Channel disconnected\n                    break;\n                }\n\n                loom::thread::yield_now();\n            }\n\n            poll_count\n        });\n\n        io_thread.join().unwrap();\n        let _polls = writer_thread.join().unwrap();\n\n        // Continuation should have completed\n        let completed = continuation_completed.load(Ordering::SeqCst);\n        assert!(completed, \"Continuation should have completed\");\n    });\n}\n\n/// Models continuation channel ordering\n///\n/// Verifies that continuations are processed in the order they complete.\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_loom_continuation_channel_ordering_305": {
      "name": "loom_continuation_channel_ordering",
      "type": "function",
      "start_line": 305,
      "end_line": 350,
      "content_hash": "9e840d99a5e298c8c96950a78a32ec379ee949ed",
      "content": "fn loom_continuation_channel_ordering() {\n    loom::model(|| {\n        // Model: sequence of continuations\n        let next_to_execute = Arc::new(AtomicU64::new(0));\n        let executed_sequence = Arc::new(Mutex::new(Vec::new()));\n\n        let mut handles = vec![];\n\n        // Two continuations queued\n        for cont_id in 0..2 {\n            let next = Arc::clone(&next_to_execute);\n            let seq = Arc::clone(&executed_sequence);\n\n            handles.push(thread::spawn(move || {\n                // Try to claim execution slot\n                let my_slot = next.fetch_add(1, Ordering::SeqCst);\n\n                // Record execution order\n                let mut guard = seq.lock().unwrap();\n                guard.push((cont_id, my_slot));\n            }));\n        }\n\n        for handle in handles {\n            handle.join().unwrap();\n        }\n\n        let sequence = executed_sequence.lock().unwrap();\n\n        // Both should have executed\n        assert_eq!(sequence.len(), 2, \"Both continuations should execute\");\n\n        // Each got unique slot\n        let slots: Vec<_> = sequence.iter().map(|(_, slot)| slot).collect();\n        assert!(\n            slots.contains(&&0) && slots.contains(&&1),\n            \"Slots should be 0 and 1\"\n        );\n    });\n}\n\n/// Models read/write request routing\n///\n/// Verifies that write requests are serialized (only one writer at a time).\n/// NOTE: Simplified to 2 threads to keep loom state space manageable.\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_loom_read_write_routing_351": {
      "name": "loom_read_write_routing",
      "type": "function",
      "start_line": 351,
      "end_line": 394,
      "content_hash": "7ed4306b477b0f91e395ac84839e8756daad69e4",
      "content": "fn loom_read_write_routing() {\n    loom::model(|| {\n        // Model: write lock (only one writer at a time)\n        let write_in_progress = Arc::new(AtomicBool::new(false));\n        // Track if concurrent write was detected\n        let concurrent_write_detected = Arc::new(AtomicBool::new(false));\n\n        let w1_flag = Arc::clone(&write_in_progress);\n        let w1_violation = Arc::clone(&concurrent_write_detected);\n\n        let w2_flag = Arc::clone(&write_in_progress);\n        let w2_violation = Arc::clone(&concurrent_write_detected);\n\n        // Two writers trying to acquire lock\n        let writer1 = thread::spawn(move || {\n            let was_writing = w1_flag.swap(true, Ordering::SeqCst);\n            if was_writing {\n                w1_violation.store(true, Ordering::SeqCst);\n            }\n            w1_flag.store(false, Ordering::SeqCst);\n        });\n\n        let writer2 = thread::spawn(move || {\n            let was_writing = w2_flag.swap(true, Ordering::SeqCst);\n            if was_writing {\n                w2_violation.store(true, Ordering::SeqCst);\n            }\n            w2_flag.store(false, Ordering::SeqCst);\n        });\n\n        writer1.join().unwrap();\n        writer2.join().unwrap();\n\n        // With swap, concurrent writes CAN be detected (this is expected)\n        // The test verifies the detection mechanism works\n        let final_write = write_in_progress.load(Ordering::SeqCst);\n        assert!(!final_write, \"No writer should be active at end\");\n    });\n}\n\n/// Models multiple concurrent reads with a single write\n///\n/// Verifies readers don't block each other but write is serialized.\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_loom_concurrent_reads_with_write_395": {
      "name": "loom_concurrent_reads_with_write",
      "type": "function",
      "start_line": 395,
      "end_line": 449,
      "content_hash": "35d85bc05d2fc2d0972332251f2d2600829cba32",
      "content": "fn loom_concurrent_reads_with_write() {\n    loom::model(|| {\n        // Model: shared data version\n        let version = Arc::new(AtomicU64::new(1));\n        // Model: read results\n        let read_results = Arc::new(Mutex::new(Vec::new()));\n\n        let mut handles = vec![];\n\n        // Writer updates version\n        {\n            let ver = Arc::clone(&version);\n            handles.push(thread::spawn(move || {\n                ver.store(2, Ordering::SeqCst);\n            }));\n        }\n\n        // Multiple readers\n        for reader_id in 0..2 {\n            let ver = Arc::clone(&version);\n            let results = Arc::clone(&read_results);\n\n            handles.push(thread::spawn(move || {\n                let observed = ver.load(Ordering::SeqCst);\n                let mut guard = results.lock().unwrap();\n                guard.push((reader_id, observed));\n            }));\n        }\n\n        for handle in handles {\n            handle.join().unwrap();\n        }\n\n        let results = read_results.lock().unwrap();\n\n        // All readers should see valid versions (1 or 2)\n        for &(reader_id, version) in results.iter() {\n            assert!(\n                version == 1 || version == 2,\n                \"Reader {} saw invalid version {}\",\n                reader_id,\n                version\n            );\n        }\n\n        // Final version should be 2\n        let final_ver = version.load(Ordering::SeqCst);\n        assert_eq!(final_ver, 2, \"Final version should be 2\");\n    });\n}\n\n/// Models graceful shutdown via channel disconnection\n///\n/// Verifies that workers detect channel disconnection and exit cleanly.\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_loom_graceful_shutdown_channels_450": {
      "name": "loom_graceful_shutdown_channels",
      "type": "function",
      "start_line": 450,
      "end_line": 488,
      "content_hash": "1e1e48ff4ce55e8e08c9b620568444fee1406ece",
      "content": "fn loom_graceful_shutdown_channels() {\n    loom::model(|| {\n        // Model: channel state (starts connected, then disconnects)\n        let channel_connected = Arc::new(AtomicBool::new(true));\n\n        let disc_connected = Arc::clone(&channel_connected);\n        let worker_connected = Arc::clone(&channel_connected);\n\n        // Main thread disconnects channel\n        let disconnector = thread::spawn(move || {\n            disc_connected.store(false, Ordering::Release);\n        });\n\n        // Worker checks channel state\n        let worker = thread::spawn(move || {\n            // Check if channel is still connected\n            let connected = worker_connected.load(Ordering::Acquire);\n            // Return whether we detected disconnection\n            !connected\n        });\n\n        disconnector.join().unwrap();\n        let detected_disconnect = worker.join().unwrap();\n\n        // In some interleavings, worker sees disconnect; in others, it doesn't\n        // This is expected behavior - we just verify no crashes\n        let _ = detected_disconnect;\n\n        // Final state: channel should be disconnected\n        let final_state = channel_connected.load(Ordering::SeqCst);\n        assert!(!final_state, \"Channel should be disconnected\");\n    });\n}\n\n/// Models client disconnect handling\n///\n/// Verifies that when a client disconnects (drops RetChan), the worker\n/// continues processing subsequent requests without issue.\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_loom_client_disconnect_handling_489": {
      "name": "loom_client_disconnect_handling",
      "type": "function",
      "start_line": 489,
      "end_line": 539,
      "content_hash": "92c731a3d5e49725364ca4f41ccb3451bacdecb6",
      "content": "fn loom_client_disconnect_handling() {\n    loom::model(|| {\n        // Model: two requests, first client disconnects\n        let request1_completed = Arc::new(AtomicBool::new(false));\n        let request2_completed = Arc::new(AtomicBool::new(false));\n        let client1_connected = Arc::new(AtomicBool::new(true));\n        let _client2_connected = Arc::new(AtomicBool::new(true));\n\n        let r1_completed = Arc::clone(&request1_completed);\n        let r2_completed = Arc::clone(&request2_completed);\n        let c1_connected = Arc::clone(&client1_connected);\n\n        // Worker processes requests\n        let worker = thread::spawn(move || {\n            // Process request 1\n            r1_completed.store(true, Ordering::SeqCst);\n\n            // Try to send response - client disconnected\n            let send_result = c1_connected.load(Ordering::SeqCst);\n            // (Worker should continue regardless of send result)\n            let _ = send_result;\n\n            // Process request 2\n            r2_completed.store(true, Ordering::SeqCst);\n\n            true // Worker continues normally\n        });\n\n        // Client 1 disconnects\n        let client = thread::spawn(move || {\n            client1_connected.store(false, Ordering::SeqCst);\n        });\n\n        client.join().unwrap();\n        let worker_ok = worker.join().unwrap();\n\n        assert!(worker_ok, \"Worker should complete successfully\");\n\n        // Both requests should be processed\n        let r1 = request1_completed.load(Ordering::SeqCst);\n        let r2 = request2_completed.load(Ordering::SeqCst);\n        assert!(r1, \"Request 1 should be processed\");\n        assert!(r2, \"Request 2 should be processed\");\n    });\n}\n\n/// Models atomic core setter index allocation\n///\n/// In the real CoreSetter, an AtomicUsize is used to assign worker threads\n/// to CPU cores. This tests that the allocation is correct.\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_loom_core_setter_allocation_540": {
      "name": "loom_core_setter_allocation",
      "type": "function",
      "start_line": 540,
      "end_line": 575,
      "content_hash": "6a639186149cf5e4509d6314b39d6656aa60daea",
      "content": "fn loom_core_setter_allocation() {\n    loom::model(|| {\n        // Model: atomic index for core assignment\n        let next_core_index = Arc::new(AtomicUsize::new(0));\n        let num_cores = 4;\n\n        let mut handles = vec![];\n\n        // Multiple threads requesting core assignments\n        for _ in 0..3 {\n            let index = Arc::clone(&next_core_index);\n\n            handles.push(thread::spawn(move || {\n                // Atomically get and increment index\n                let my_index = index.fetch_add(1, Ordering::SeqCst);\n                my_index % num_cores\n            }));\n        }\n\n        let core_assignments: Vec<_> = handles.into_iter().map(|h| h.join().unwrap()).collect();\n\n        // All assignments should be valid core indices\n        for &core in &core_assignments {\n            assert!(core < num_cores, \"Core index {} exceeds num_cores\", core);\n        }\n\n        // Final index should be 3\n        let final_index = next_core_index.load(Ordering::SeqCst);\n        assert_eq!(final_index, 3, \"Should have allocated 3 indices\");\n    });\n}\n\n/// Models request backpressure with bounded channels\n///\n/// When channel is full, senders should block until space is available.\n#[test]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_loom_channel_backpressure_576": {
      "name": "loom_channel_backpressure",
      "type": "function",
      "start_line": 576,
      "end_line": 635,
      "content_hash": "a3fff6fdcca56288b073b10fa579365c0ffccce2",
      "content": "fn loom_channel_backpressure() {\n    loom::model(|| {\n        // Model: bounded channel with capacity 1\n        let channel_slots = Arc::new(AtomicU64::new(1)); // 1 slot available\n        let items_sent = Arc::new(AtomicU64::new(0));\n        let items_received = Arc::new(AtomicU64::new(0));\n\n        let send_slots = Arc::clone(&channel_slots);\n        let send_count = Arc::clone(&items_sent);\n        let recv_slots = Arc::clone(&channel_slots);\n        let recv_count = Arc::clone(&items_sent);\n        let recv_items = Arc::clone(&items_received);\n\n        // Sender tries to send 2 items\n        let sender = thread::spawn(move || {\n            for _ in 0..2 {\n                // Try to claim a slot\n                loop {\n                    let slots = send_slots.load(Ordering::Acquire);\n                    if slots > 0\n                        && send_slots\n                            .compare_exchange(slots, slots - 1, Ordering::SeqCst, Ordering::SeqCst)\n                            .is_ok()\n                    {\n                        send_count.fetch_add(1, Ordering::SeqCst);\n                        break;\n                    }\n                    loom::thread::yield_now();\n                }\n            }\n        });\n\n        // Receiver processes items\n        let receiver = thread::spawn(move || {\n            for _ in 0..2 {\n                // Wait for item\n                loop {\n                    let received = recv_items.load(Ordering::Acquire);\n                    if received < recv_count.load(Ordering::Acquire) {\n                        // Item available, process it\n                        recv_items.fetch_add(1, Ordering::SeqCst);\n                        // Return slot to channel\n                        recv_slots.fetch_add(1, Ordering::SeqCst);\n                        break;\n                    }\n                    loom::thread::yield_now();\n                }\n            }\n        });\n\n        sender.join().unwrap();\n        receiver.join().unwrap();\n\n        // All items should be sent and received\n        let sent = items_sent.load(Ordering::SeqCst);\n        let received = items_received.load(Ordering::SeqCst);\n        assert_eq!(sent, 2, \"Should have sent 2 items\");\n        assert_eq!(received, 2, \"Should have received 2 items\");\n    });\n}",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}