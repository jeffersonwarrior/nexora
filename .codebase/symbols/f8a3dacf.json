{
  "file_path": "/work/context-engine/tests/test_workspace_state.py",
  "file_hash": "59e1330defa8e23243f7c3cbb999dd8947a956fc",
  "updated_at": "2025-12-26T17:34:24.544175",
  "symbols": {
    "function_ws_module_29": {
      "name": "ws_module",
      "type": "function",
      "start_line": 29,
      "end_line": 44,
      "content_hash": "7150e3449a031edbcf0b818576b8d8e6bb0d44bc",
      "content": "def ws_module(monkeypatch, tmp_path):\n    \"\"\"\n    Import workspace_state with isolated environment and temp workspace.\n    Returns the reloaded module.\n    \"\"\"\n    ws_root = tmp_path / \"work\"\n    ws_root.mkdir(parents=True, exist_ok=True)\n\n    monkeypatch.setenv(\"WORKSPACE_PATH\", str(ws_root))\n    monkeypatch.setenv(\"WATCH_ROOT\", str(ws_root))\n    monkeypatch.delenv(\"MULTI_REPO_MODE\", raising=False)\n    monkeypatch.delenv(\"LOGICAL_REPO_REUSE\", raising=False)\n\n    ws = importlib.import_module(\"scripts.workspace_state\")\n    ws = importlib.reload(ws)\n    return ws",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_TestSanitizeName_50": {
      "name": "TestSanitizeName",
      "type": "class",
      "start_line": 50,
      "end_line": 78,
      "content_hash": "3cd75a680cfb500fb19e0cdd313ba5c6da390f29",
      "content": "class TestSanitizeName:\n    \"\"\"Tests for _sanitize_name function.\"\"\"\n\n    def test_sanitize_basic(self, ws_module):\n        \"\"\"Basic name sanitization.\"\"\"\n        assert ws_module._sanitize_name(\"My-Project\") == \"my-project\"\n        assert ws_module._sanitize_name(\"  UPPERCASE  \") == \"uppercase\"\n\n    def test_sanitize_special_chars(self, ws_module):\n        \"\"\"Special characters are converted to hyphens.\"\"\"\n        assert ws_module._sanitize_name(\"foo@bar!baz\") == \"foo-bar-baz\"\n        assert ws_module._sanitize_name(\"a/b\\\\c:d\") == \"a-b-c-d\"\n\n    def test_sanitize_consecutive_hyphens(self, ws_module):\n        \"\"\"Multiple consecutive hyphens are collapsed.\"\"\"\n        assert ws_module._sanitize_name(\"foo---bar\") == \"foo-bar\"\n        assert ws_module._sanitize_name(\"a@@@b\") == \"a-b\"\n\n    def test_sanitize_empty_string(self, ws_module):\n        \"\"\"Empty string falls back to 'workspace'.\"\"\"\n        assert ws_module._sanitize_name(\"\") == \"workspace\"\n        assert ws_module._sanitize_name(\"   \") == \"workspace\"\n        assert ws_module._sanitize_name(\"@#$%\") == \"workspace\"\n\n    def test_sanitize_max_length(self, ws_module):\n        \"\"\"Truncates to max_len.\"\"\"\n        long_name = \"a\" * 100\n        result = ws_module._sanitize_name(long_name, max_len=10)\n        assert len(result) == 10",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_sanitize_basic_53": {
      "name": "test_sanitize_basic",
      "type": "method",
      "start_line": 53,
      "end_line": 56,
      "content_hash": "4e5c09cf2172de2d5636507859cb31d06c881856",
      "content": "    def test_sanitize_basic(self, ws_module):\n        \"\"\"Basic name sanitization.\"\"\"\n        assert ws_module._sanitize_name(\"My-Project\") == \"my-project\"\n        assert ws_module._sanitize_name(\"  UPPERCASE  \") == \"uppercase\"",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_sanitize_special_chars_58": {
      "name": "test_sanitize_special_chars",
      "type": "method",
      "start_line": 58,
      "end_line": 61,
      "content_hash": "5f96c834344bbae91dece20af7edd0d4bf21e256",
      "content": "    def test_sanitize_special_chars(self, ws_module):\n        \"\"\"Special characters are converted to hyphens.\"\"\"\n        assert ws_module._sanitize_name(\"foo@bar!baz\") == \"foo-bar-baz\"\n        assert ws_module._sanitize_name(\"a/b\\\\c:d\") == \"a-b-c-d\"",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_sanitize_consecutive_hyphens_63": {
      "name": "test_sanitize_consecutive_hyphens",
      "type": "method",
      "start_line": 63,
      "end_line": 66,
      "content_hash": "e29901dd1cd42f1b8b192e6e79d803bf9f67bd80",
      "content": "    def test_sanitize_consecutive_hyphens(self, ws_module):\n        \"\"\"Multiple consecutive hyphens are collapsed.\"\"\"\n        assert ws_module._sanitize_name(\"foo---bar\") == \"foo-bar\"\n        assert ws_module._sanitize_name(\"a@@@b\") == \"a-b\"",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_sanitize_empty_string_68": {
      "name": "test_sanitize_empty_string",
      "type": "method",
      "start_line": 68,
      "end_line": 72,
      "content_hash": "51f65fcd97b333fb244b9f8383bbe4672147bef5",
      "content": "    def test_sanitize_empty_string(self, ws_module):\n        \"\"\"Empty string falls back to 'workspace'.\"\"\"\n        assert ws_module._sanitize_name(\"\") == \"workspace\"\n        assert ws_module._sanitize_name(\"   \") == \"workspace\"\n        assert ws_module._sanitize_name(\"@#$%\") == \"workspace\"",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_sanitize_max_length_74": {
      "name": "test_sanitize_max_length",
      "type": "method",
      "start_line": 74,
      "end_line": 78,
      "content_hash": "72519b668c2aac694b174a9159c3e727d1a0fbf5",
      "content": "    def test_sanitize_max_length(self, ws_module):\n        \"\"\"Truncates to max_len.\"\"\"\n        long_name = \"a\" * 100\n        result = ws_module._sanitize_name(long_name, max_len=10)\n        assert len(result) == 10",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_TestCollectionNameGeneration_84": {
      "name": "TestCollectionNameGeneration",
      "type": "class",
      "start_line": 84,
      "end_line": 109,
      "content_hash": "bd67f33174e04dea7f8c61c08249badf1fee2c0d",
      "content": "class TestCollectionNameGeneration:\n    \"\"\"Tests for _generate_collection_name function.\"\"\"\n\n    def test_generates_consistent_hash(self, ws_module, tmp_path):\n        \"\"\"Same path generates same collection name.\"\"\"\n        ws_path = tmp_path / \"my-repo\"\n        ws_path.mkdir()\n\n        name1 = ws_module._generate_collection_name(str(ws_path))\n        name2 = ws_module._generate_collection_name(str(ws_path))\n\n        assert name1 == name2\n        assert \"my-repo-\" in name1  # Contains repo name\n        assert len(name1.split(\"-\")[-1]) == 6  # 6 char hash suffix\n\n    def test_different_paths_different_hashes(self, ws_module, tmp_path):\n        \"\"\"Different paths get different hashes.\"\"\"\n        path1 = tmp_path / \"repo-a\"\n        path2 = tmp_path / \"repo-b\"\n        path1.mkdir()\n        path2.mkdir()\n\n        name1 = ws_module._generate_collection_name(str(path1))\n        name2 = ws_module._generate_collection_name(str(path2))\n\n        assert name1 != name2",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_generates_consistent_hash_87": {
      "name": "test_generates_consistent_hash",
      "type": "method",
      "start_line": 87,
      "end_line": 97,
      "content_hash": "efe9fc1d622a5e511156fbafd2e98b28d4dcb964",
      "content": "    def test_generates_consistent_hash(self, ws_module, tmp_path):\n        \"\"\"Same path generates same collection name.\"\"\"\n        ws_path = tmp_path / \"my-repo\"\n        ws_path.mkdir()\n\n        name1 = ws_module._generate_collection_name(str(ws_path))\n        name2 = ws_module._generate_collection_name(str(ws_path))\n\n        assert name1 == name2\n        assert \"my-repo-\" in name1  # Contains repo name\n        assert len(name1.split(\"-\")[-1]) == 6  # 6 char hash suffix",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_different_paths_different_hashes_99": {
      "name": "test_different_paths_different_hashes",
      "type": "method",
      "start_line": 99,
      "end_line": 109,
      "content_hash": "64269fa32882d2ef43a8d8d70e66c79b66885e9e",
      "content": "    def test_different_paths_different_hashes(self, ws_module, tmp_path):\n        \"\"\"Different paths get different hashes.\"\"\"\n        path1 = tmp_path / \"repo-a\"\n        path2 = tmp_path / \"repo-b\"\n        path1.mkdir()\n        path2.mkdir()\n\n        name1 = ws_module._generate_collection_name(str(path1))\n        name2 = ws_module._generate_collection_name(str(path2))\n\n        assert name1 != name2",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_TestEnvHelpers_115": {
      "name": "TestEnvHelpers",
      "type": "class",
      "start_line": 115,
      "end_line": 147,
      "content_hash": "7e4e1ebb581a7e9f8739f69cd3975b6875680bea",
      "content": "class TestEnvHelpers:\n    \"\"\"Tests for environment-based feature flags.\"\"\"\n\n    def test_is_multi_repo_mode_disabled_by_default(self, ws_module, monkeypatch):\n        \"\"\"Multi-repo mode is disabled by default.\"\"\"\n        monkeypatch.delenv(\"MULTI_REPO_MODE\", raising=False)\n        ws = importlib.reload(ws_module)\n        assert ws.is_multi_repo_mode() is False\n\n    def test_is_multi_repo_mode_enabled(self, ws_module, monkeypatch):\n        \"\"\"Multi-repo mode can be enabled.\"\"\"\n        for val in [\"1\", \"true\", \"yes\", \"on\", \"TRUE\", \"ON\"]:\n            monkeypatch.setenv(\"MULTI_REPO_MODE\", val)\n            ws = importlib.reload(ws_module)\n            assert ws.is_multi_repo_mode() is True, f\"Failed for {val}\"\n\n    def test_logical_repo_reuse_disabled_by_default(self, ws_module, monkeypatch):\n        \"\"\"Logical repo reuse is disabled by default.\"\"\"\n        monkeypatch.delenv(\"LOGICAL_REPO_REUSE\", raising=False)\n        ws = importlib.reload(ws_module)\n        assert ws.logical_repo_reuse_enabled() is False\n\n    def test_logical_repo_reuse_enabled(self, ws_module, monkeypatch):\n        \"\"\"Logical repo reuse can be enabled.\"\"\"\n        monkeypatch.setenv(\"LOGICAL_REPO_REUSE\", \"1\")\n        ws = importlib.reload(ws_module)\n        assert ws.logical_repo_reuse_enabled() is True\n\n    def test_is_staging_enabled_disabled_by_default(self, ws_module, monkeypatch):\n        \"\"\"Staging is disabled by default.\"\"\"\n        monkeypatch.delenv(\"CTXCE_STAGING_ENABLED\", raising=False)\n        ws = importlib.reload(ws_module)\n        assert ws.is_staging_enabled() is False",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_is_multi_repo_mode_disabled_by_default_118": {
      "name": "test_is_multi_repo_mode_disabled_by_default",
      "type": "method",
      "start_line": 118,
      "end_line": 122,
      "content_hash": "ebe964beadd332bb3d1c7793c48c60f64b68c9f0",
      "content": "    def test_is_multi_repo_mode_disabled_by_default(self, ws_module, monkeypatch):\n        \"\"\"Multi-repo mode is disabled by default.\"\"\"\n        monkeypatch.delenv(\"MULTI_REPO_MODE\", raising=False)\n        ws = importlib.reload(ws_module)\n        assert ws.is_multi_repo_mode() is False",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_is_multi_repo_mode_enabled_124": {
      "name": "test_is_multi_repo_mode_enabled",
      "type": "method",
      "start_line": 124,
      "end_line": 129,
      "content_hash": "c972abf7a912d5ad63471c99f99c876a1dae51a9",
      "content": "    def test_is_multi_repo_mode_enabled(self, ws_module, monkeypatch):\n        \"\"\"Multi-repo mode can be enabled.\"\"\"\n        for val in [\"1\", \"true\", \"yes\", \"on\", \"TRUE\", \"ON\"]:\n            monkeypatch.setenv(\"MULTI_REPO_MODE\", val)\n            ws = importlib.reload(ws_module)\n            assert ws.is_multi_repo_mode() is True, f\"Failed for {val}\"",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_logical_repo_reuse_disabled_by_default_131": {
      "name": "test_logical_repo_reuse_disabled_by_default",
      "type": "method",
      "start_line": 131,
      "end_line": 135,
      "content_hash": "b92bdfca1132d0166afc2c62ac67e6584cbdd4d4",
      "content": "    def test_logical_repo_reuse_disabled_by_default(self, ws_module, monkeypatch):\n        \"\"\"Logical repo reuse is disabled by default.\"\"\"\n        monkeypatch.delenv(\"LOGICAL_REPO_REUSE\", raising=False)\n        ws = importlib.reload(ws_module)\n        assert ws.logical_repo_reuse_enabled() is False",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_logical_repo_reuse_enabled_137": {
      "name": "test_logical_repo_reuse_enabled",
      "type": "method",
      "start_line": 137,
      "end_line": 141,
      "content_hash": "f68a21f69a232a330d1dca8f7eedff0a8996e196",
      "content": "    def test_logical_repo_reuse_enabled(self, ws_module, monkeypatch):\n        \"\"\"Logical repo reuse can be enabled.\"\"\"\n        monkeypatch.setenv(\"LOGICAL_REPO_REUSE\", \"1\")\n        ws = importlib.reload(ws_module)\n        assert ws.logical_repo_reuse_enabled() is True",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_is_staging_enabled_disabled_by_default_143": {
      "name": "test_is_staging_enabled_disabled_by_default",
      "type": "method",
      "start_line": 143,
      "end_line": 147,
      "content_hash": "cfce093c16531693593ccb81b10cc1b3d0774912",
      "content": "    def test_is_staging_enabled_disabled_by_default(self, ws_module, monkeypatch):\n        \"\"\"Staging is disabled by default.\"\"\"\n        monkeypatch.delenv(\"CTXCE_STAGING_ENABLED\", raising=False)\n        ws = importlib.reload(ws_module)\n        assert ws.is_staging_enabled() is False",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_TestStatePathHelpers_153": {
      "name": "TestStatePathHelpers",
      "type": "class",
      "start_line": 153,
      "end_line": 193,
      "content_hash": "2f41749a9921192c3874b548dec5a337fe253787",
      "content": "class TestStatePathHelpers:\n    \"\"\"Tests for state path resolution functions.\"\"\"\n\n    def test_resolve_workspace_root_from_env(self, ws_module, monkeypatch, tmp_path):\n        \"\"\"Workspace root is resolved from WORKSPACE_PATH.\"\"\"\n        ws_root = tmp_path / \"custom-root\"\n        ws_root.mkdir()\n        monkeypatch.setenv(\"WORKSPACE_PATH\", str(ws_root))\n        ws = importlib.reload(ws_module)\n\n        assert ws._resolve_workspace_root() == str(ws_root)\n\n    def test_resolve_workspace_root_fallback_watch_root(self, ws_module, monkeypatch, tmp_path):\n        \"\"\"Falls back to WATCH_ROOT when WORKSPACE_PATH not set.\"\"\"\n        ws_root = tmp_path / \"watch-root\"\n        ws_root.mkdir()\n        monkeypatch.delenv(\"WORKSPACE_PATH\", raising=False)\n        monkeypatch.setenv(\"WATCH_ROOT\", str(ws_root))\n        ws = importlib.reload(ws_module)\n\n        assert ws._resolve_workspace_root() == str(ws_root)\n\n    def test_get_state_path(self, ws_module, tmp_path):\n        \"\"\"State path is workspace/.codebase/state.json.\"\"\"\n        ws_path = tmp_path / \"my-workspace\"\n        ws_path.mkdir()\n\n        state_path = ws_module._get_state_path(str(ws_path))\n\n        assert state_path.name == \"state.json\"\n        assert state_path.parent.name == \".codebase\"\n\n    def test_ensure_state_dir_creates_codebase_dir(self, ws_module, tmp_path):\n        \"\"\"_ensure_state_dir creates .codebase directory.\"\"\"\n        ws_path = tmp_path / \"new-workspace\"\n        ws_path.mkdir()\n\n        state_path = ws_module._ensure_state_dir(str(ws_path))\n\n        assert state_path.parent.exists()\n        assert state_path.parent.name == \".codebase\"",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_resolve_workspace_root_from_env_156": {
      "name": "test_resolve_workspace_root_from_env",
      "type": "method",
      "start_line": 156,
      "end_line": 163,
      "content_hash": "c2641cff8b251e4f9679c96577741c7f40242fdb",
      "content": "    def test_resolve_workspace_root_from_env(self, ws_module, monkeypatch, tmp_path):\n        \"\"\"Workspace root is resolved from WORKSPACE_PATH.\"\"\"\n        ws_root = tmp_path / \"custom-root\"\n        ws_root.mkdir()\n        monkeypatch.setenv(\"WORKSPACE_PATH\", str(ws_root))\n        ws = importlib.reload(ws_module)\n\n        assert ws._resolve_workspace_root() == str(ws_root)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_resolve_workspace_root_fallback_watch_root_165": {
      "name": "test_resolve_workspace_root_fallback_watch_root",
      "type": "method",
      "start_line": 165,
      "end_line": 173,
      "content_hash": "ddddbff075b7699f95ec52f42efa4b30d7b94d6d",
      "content": "    def test_resolve_workspace_root_fallback_watch_root(self, ws_module, monkeypatch, tmp_path):\n        \"\"\"Falls back to WATCH_ROOT when WORKSPACE_PATH not set.\"\"\"\n        ws_root = tmp_path / \"watch-root\"\n        ws_root.mkdir()\n        monkeypatch.delenv(\"WORKSPACE_PATH\", raising=False)\n        monkeypatch.setenv(\"WATCH_ROOT\", str(ws_root))\n        ws = importlib.reload(ws_module)\n\n        assert ws._resolve_workspace_root() == str(ws_root)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_get_state_path_175": {
      "name": "test_get_state_path",
      "type": "method",
      "start_line": 175,
      "end_line": 183,
      "content_hash": "8ee935d6a425f52b54dc89613c84f4f22a73682b",
      "content": "    def test_get_state_path(self, ws_module, tmp_path):\n        \"\"\"State path is workspace/.codebase/state.json.\"\"\"\n        ws_path = tmp_path / \"my-workspace\"\n        ws_path.mkdir()\n\n        state_path = ws_module._get_state_path(str(ws_path))\n\n        assert state_path.name == \"state.json\"\n        assert state_path.parent.name == \".codebase\"",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_ensure_state_dir_creates_codebase_dir_185": {
      "name": "test_ensure_state_dir_creates_codebase_dir",
      "type": "method",
      "start_line": 185,
      "end_line": 193,
      "content_hash": "d2870f19a785fe6ba808b8ecd1d46ad5e22edcb8",
      "content": "    def test_ensure_state_dir_creates_codebase_dir(self, ws_module, tmp_path):\n        \"\"\"_ensure_state_dir creates .codebase directory.\"\"\"\n        ws_path = tmp_path / \"new-workspace\"\n        ws_path.mkdir()\n\n        state_path = ws_module._ensure_state_dir(str(ws_path))\n\n        assert state_path.parent.exists()\n        assert state_path.parent.name == \".codebase\"",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_TestStateReadWrite_199": {
      "name": "TestStateReadWrite",
      "type": "class",
      "start_line": 199,
      "end_line": 260,
      "content_hash": "29acadfd406b072bab0b38a356fcaae17f2d18e4",
      "content": "class TestStateReadWrite:\n    \"\"\"Tests for get_workspace_state and update_workspace_state.\"\"\"\n\n    def test_get_workspace_state_creates_new_state(self, ws_module, tmp_path, monkeypatch):\n        \"\"\"get_workspace_state creates state file if it doesn't exist.\"\"\"\n        ws_path = tmp_path / \"fresh-workspace\"\n        ws_path.mkdir()\n        monkeypatch.setenv(\"WORKSPACE_PATH\", str(ws_path))\n        ws = importlib.reload(ws_module)\n\n        state = ws.get_workspace_state(str(ws_path))\n\n        assert \"qdrant_collection\" in state\n        assert \"created_at\" in state\n        assert \"updated_at\" in state\n        assert state[\"indexing_status\"][\"state\"] == \"idle\"\n\n        # Verify file was created\n        state_file = ws_path / \".codebase\" / \"state.json\"\n        assert state_file.exists()\n\n    def test_get_workspace_state_reads_existing_state(self, ws_module, tmp_path, monkeypatch):\n        \"\"\"get_workspace_state reads existing state file.\"\"\"\n        ws_path = tmp_path / \"existing-workspace\"\n        ws_path.mkdir()\n        (ws_path / \".codebase\").mkdir()\n\n        existing_state = {\n            \"created_at\": \"2024-01-01T00:00:00\",\n            \"updated_at\": \"2024-01-01T00:00:00\",\n            \"qdrant_collection\": \"test-collection\",\n            \"indexing_status\": {\"state\": \"watching\"},\n        }\n        state_file = ws_path / \".codebase\" / \"state.json\"\n        state_file.write_text(json.dumps(existing_state))\n\n        monkeypatch.setenv(\"WORKSPACE_PATH\", str(ws_path))\n        ws = importlib.reload(ws_module)\n\n        state = ws.get_workspace_state(str(ws_path))\n\n        assert state[\"qdrant_collection\"] == \"test-collection\"\n        assert state[\"indexing_status\"][\"state\"] == \"watching\"\n\n    def test_update_workspace_state_merges_updates(self, ws_module, tmp_path, monkeypatch):\n        \"\"\"update_workspace_state merges updates into existing state.\"\"\"\n        ws_path = tmp_path / \"update-workspace\"\n        ws_path.mkdir()\n        monkeypatch.setenv(\"WORKSPACE_PATH\", str(ws_path))\n        ws = importlib.reload(ws_module)\n\n        # Create initial state\n        ws.get_workspace_state(str(ws_path))\n\n        # Update state\n        updated = ws.update_workspace_state(\n            str(ws_path),\n            {\"indexing_status\": {\"state\": \"indexing\"}}\n        )\n\n        assert updated[\"indexing_status\"][\"state\"] == \"indexing\"\n        assert \"qdrant_collection\" in updated  # Original field preserved",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_get_workspace_state_creates_new_state_202": {
      "name": "test_get_workspace_state_creates_new_state",
      "type": "method",
      "start_line": 202,
      "end_line": 218,
      "content_hash": "5901b853d53e9d637476f8251ddd5113064b5b3a",
      "content": "    def test_get_workspace_state_creates_new_state(self, ws_module, tmp_path, monkeypatch):\n        \"\"\"get_workspace_state creates state file if it doesn't exist.\"\"\"\n        ws_path = tmp_path / \"fresh-workspace\"\n        ws_path.mkdir()\n        monkeypatch.setenv(\"WORKSPACE_PATH\", str(ws_path))\n        ws = importlib.reload(ws_module)\n\n        state = ws.get_workspace_state(str(ws_path))\n\n        assert \"qdrant_collection\" in state\n        assert \"created_at\" in state\n        assert \"updated_at\" in state\n        assert state[\"indexing_status\"][\"state\"] == \"idle\"\n\n        # Verify file was created\n        state_file = ws_path / \".codebase\" / \"state.json\"\n        assert state_file.exists()",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_get_workspace_state_reads_existing_state_220": {
      "name": "test_get_workspace_state_reads_existing_state",
      "type": "method",
      "start_line": 220,
      "end_line": 241,
      "content_hash": "6bccee588b8f255e50b1ff6bc8c284e759528e2b",
      "content": "    def test_get_workspace_state_reads_existing_state(self, ws_module, tmp_path, monkeypatch):\n        \"\"\"get_workspace_state reads existing state file.\"\"\"\n        ws_path = tmp_path / \"existing-workspace\"\n        ws_path.mkdir()\n        (ws_path / \".codebase\").mkdir()\n\n        existing_state = {\n            \"created_at\": \"2024-01-01T00:00:00\",\n            \"updated_at\": \"2024-01-01T00:00:00\",\n            \"qdrant_collection\": \"test-collection\",\n            \"indexing_status\": {\"state\": \"watching\"},\n        }\n        state_file = ws_path / \".codebase\" / \"state.json\"\n        state_file.write_text(json.dumps(existing_state))\n\n        monkeypatch.setenv(\"WORKSPACE_PATH\", str(ws_path))\n        ws = importlib.reload(ws_module)\n\n        state = ws.get_workspace_state(str(ws_path))\n\n        assert state[\"qdrant_collection\"] == \"test-collection\"\n        assert state[\"indexing_status\"][\"state\"] == \"watching\"",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_update_workspace_state_merges_updates_243": {
      "name": "test_update_workspace_state_merges_updates",
      "type": "method",
      "start_line": 243,
      "end_line": 260,
      "content_hash": "44ad1721d2b828ddd932e926c701bd06107c85dc",
      "content": "    def test_update_workspace_state_merges_updates(self, ws_module, tmp_path, monkeypatch):\n        \"\"\"update_workspace_state merges updates into existing state.\"\"\"\n        ws_path = tmp_path / \"update-workspace\"\n        ws_path.mkdir()\n        monkeypatch.setenv(\"WORKSPACE_PATH\", str(ws_path))\n        ws = importlib.reload(ws_module)\n\n        # Create initial state\n        ws.get_workspace_state(str(ws_path))\n\n        # Update state\n        updated = ws.update_workspace_state(\n            str(ws_path),\n            {\"indexing_status\": {\"state\": \"indexing\"}}\n        )\n\n        assert updated[\"indexing_status\"][\"state\"] == \"indexing\"\n        assert \"qdrant_collection\" in updated  # Original field preserved",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_TestFileLocking_266": {
      "name": "TestFileLocking",
      "type": "class",
      "start_line": 266,
      "end_line": 305,
      "content_hash": "3081653b9fbaff4b87f4d49419f428843046b523",
      "content": "class TestFileLocking:\n    \"\"\"Tests for per-file locking mechanism.\"\"\"\n\n    def test_is_file_locked_returns_false_when_no_lock(self, ws_module, tmp_path):\n        \"\"\"is_file_locked returns False when no lock exists.\"\"\"\n        fake_file = str(tmp_path / \"nonexistent.py\")\n        assert ws_module.is_file_locked(fake_file) is False\n\n    def test_file_indexing_lock_context_manager(self, ws_module, tmp_path, monkeypatch):\n        \"\"\"file_indexing_lock creates and removes lock file.\"\"\"\n        # Use tmp_path for lock files\n        lock_dir = tmp_path / \"locks\"\n        lock_dir.mkdir()\n        monkeypatch.setattr(ws_module, \"_FILE_LOCKS_DIR\", lock_dir)\n\n        test_file = str(tmp_path / \"test.py\")\n\n        # Lock should not exist before\n        assert ws_module.is_file_locked(test_file) is False\n\n        # Lock should exist during context\n        with ws_module.file_indexing_lock(test_file):\n            lock_path = ws_module._get_file_lock_path(test_file)\n            assert lock_path.exists()\n\n        # Lock should be removed after context\n        assert not lock_path.exists()\n\n    def test_file_indexing_lock_prevents_double_lock(self, ws_module, tmp_path, monkeypatch):\n        \"\"\"file_indexing_lock raises FileExistsError if already locked.\"\"\"\n        lock_dir = tmp_path / \"locks\"\n        lock_dir.mkdir()\n        monkeypatch.setattr(ws_module, \"_FILE_LOCKS_DIR\", lock_dir)\n\n        test_file = str(tmp_path / \"test.py\")\n\n        with ws_module.file_indexing_lock(test_file):\n            with pytest.raises(FileExistsError):\n                with ws_module.file_indexing_lock(test_file):\n                    pass  # Should not reach here",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_is_file_locked_returns_false_when_no_lock_269": {
      "name": "test_is_file_locked_returns_false_when_no_lock",
      "type": "method",
      "start_line": 269,
      "end_line": 272,
      "content_hash": "adb03d8cd7b7cbc7581125c0bda1a81f98b3a13b",
      "content": "    def test_is_file_locked_returns_false_when_no_lock(self, ws_module, tmp_path):\n        \"\"\"is_file_locked returns False when no lock exists.\"\"\"\n        fake_file = str(tmp_path / \"nonexistent.py\")\n        assert ws_module.is_file_locked(fake_file) is False",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_file_indexing_lock_context_manager_274": {
      "name": "test_file_indexing_lock_context_manager",
      "type": "method",
      "start_line": 274,
      "end_line": 292,
      "content_hash": "362113921c2efa5962909e0902cbabf2030292ff",
      "content": "    def test_file_indexing_lock_context_manager(self, ws_module, tmp_path, monkeypatch):\n        \"\"\"file_indexing_lock creates and removes lock file.\"\"\"\n        # Use tmp_path for lock files\n        lock_dir = tmp_path / \"locks\"\n        lock_dir.mkdir()\n        monkeypatch.setattr(ws_module, \"_FILE_LOCKS_DIR\", lock_dir)\n\n        test_file = str(tmp_path / \"test.py\")\n\n        # Lock should not exist before\n        assert ws_module.is_file_locked(test_file) is False\n\n        # Lock should exist during context\n        with ws_module.file_indexing_lock(test_file):\n            lock_path = ws_module._get_file_lock_path(test_file)\n            assert lock_path.exists()\n\n        # Lock should be removed after context\n        assert not lock_path.exists()",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_file_indexing_lock_prevents_double_lock_294": {
      "name": "test_file_indexing_lock_prevents_double_lock",
      "type": "method",
      "start_line": 294,
      "end_line": 305,
      "content_hash": "db0c5323a5496bfc09efae3f3675b88b162cbbcd",
      "content": "    def test_file_indexing_lock_prevents_double_lock(self, ws_module, tmp_path, monkeypatch):\n        \"\"\"file_indexing_lock raises FileExistsError if already locked.\"\"\"\n        lock_dir = tmp_path / \"locks\"\n        lock_dir.mkdir()\n        monkeypatch.setattr(ws_module, \"_FILE_LOCKS_DIR\", lock_dir)\n\n        test_file = str(tmp_path / \"test.py\")\n\n        with ws_module.file_indexing_lock(test_file):\n            with pytest.raises(FileExistsError):\n                with ws_module.file_indexing_lock(test_file):\n                    pass  # Should not reach here",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_TestLogicalRepoId_311": {
      "name": "TestLogicalRepoId",
      "type": "class",
      "start_line": 311,
      "end_line": 343,
      "content_hash": "0159a02699834ed3001d321094cdef538878ae1b",
      "content": "class TestLogicalRepoId:\n    \"\"\"Tests for compute_logical_repo_id function.\"\"\"\n\n    def test_compute_logical_repo_id_fs_fallback(self, ws_module, tmp_path, monkeypatch):\n        \"\"\"compute_logical_repo_id uses fs: prefix when not a git repo.\"\"\"\n        # Suppress git detection\n        def _no_git(*args, **kwargs):\n            return None\n\n        monkeypatch.setattr(ws_module, \"_detect_git_common_dir\", _no_git)\n\n        ws_path = tmp_path / \"not-a-repo\"\n        ws_path.mkdir()\n\n        lrid = ws_module.compute_logical_repo_id(str(ws_path))\n\n        assert lrid.startswith(\"fs:\")\n        assert len(lrid) == 3 + 16  # \"fs:\" + 16 char hash\n\n    def test_compute_logical_repo_id_consistent(self, ws_module, tmp_path, monkeypatch):\n        \"\"\"compute_logical_repo_id returns consistent results.\"\"\"\n        def _no_git(*args, **kwargs):\n            return None\n\n        monkeypatch.setattr(ws_module, \"_detect_git_common_dir\", _no_git)\n\n        ws_path = tmp_path / \"consistent-repo\"\n        ws_path.mkdir()\n\n        lrid1 = ws_module.compute_logical_repo_id(str(ws_path))\n        lrid2 = ws_module.compute_logical_repo_id(str(ws_path))\n\n        assert lrid1 == lrid2",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_compute_logical_repo_id_fs_fallback_314": {
      "name": "test_compute_logical_repo_id_fs_fallback",
      "type": "method",
      "start_line": 314,
      "end_line": 328,
      "content_hash": "df07e7414939b9b372fc5c71e33db3ccfbf8fa84",
      "content": "    def test_compute_logical_repo_id_fs_fallback(self, ws_module, tmp_path, monkeypatch):\n        \"\"\"compute_logical_repo_id uses fs: prefix when not a git repo.\"\"\"\n        # Suppress git detection\n        def _no_git(*args, **kwargs):\n            return None\n\n        monkeypatch.setattr(ws_module, \"_detect_git_common_dir\", _no_git)\n\n        ws_path = tmp_path / \"not-a-repo\"\n        ws_path.mkdir()\n\n        lrid = ws_module.compute_logical_repo_id(str(ws_path))\n\n        assert lrid.startswith(\"fs:\")\n        assert len(lrid) == 3 + 16  # \"fs:\" + 16 char hash",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__no_git_317": {
      "name": "_no_git",
      "type": "method",
      "start_line": 317,
      "end_line": 318,
      "content_hash": "c8e3a5a83af35c7dbc404e1b78445927811b04bc",
      "content": "        def _no_git(*args, **kwargs):\n            return None",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_compute_logical_repo_id_consistent_330": {
      "name": "test_compute_logical_repo_id_consistent",
      "type": "method",
      "start_line": 330,
      "end_line": 343,
      "content_hash": "629eac1aa176434125347dd4c98341ec3aa5b9d3",
      "content": "    def test_compute_logical_repo_id_consistent(self, ws_module, tmp_path, monkeypatch):\n        \"\"\"compute_logical_repo_id returns consistent results.\"\"\"\n        def _no_git(*args, **kwargs):\n            return None\n\n        monkeypatch.setattr(ws_module, \"_detect_git_common_dir\", _no_git)\n\n        ws_path = tmp_path / \"consistent-repo\"\n        ws_path.mkdir()\n\n        lrid1 = ws_module.compute_logical_repo_id(str(ws_path))\n        lrid2 = ws_module.compute_logical_repo_id(str(ws_path))\n\n        assert lrid1 == lrid2",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__no_git_332": {
      "name": "_no_git",
      "type": "method",
      "start_line": 332,
      "end_line": 333,
      "content_hash": "c8e3a5a83af35c7dbc404e1b78445927811b04bc",
      "content": "        def _no_git(*args, **kwargs):\n            return None",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_TestAtomicWrite_349": {
      "name": "TestAtomicWrite",
      "type": "class",
      "start_line": 349,
      "end_line": 380,
      "content_hash": "598314e5d7ab5c6e85146b4dcaf8f864a52415ab",
      "content": "class TestAtomicWrite:\n    \"\"\"Tests for _atomic_write_state function.\"\"\"\n\n    def test_atomic_write_creates_valid_json(self, ws_module, tmp_path):\n        \"\"\"_atomic_write_state creates valid JSON file.\"\"\"\n        state_file = tmp_path / \"state.json\"\n        state = {\n            \"created_at\": \"2024-01-01T00:00:00\",\n            \"updated_at\": \"2024-01-01T00:00:00\",\n            \"qdrant_collection\": \"test\",\n        }\n\n        ws_module._atomic_write_state(state_file, state)\n\n        assert state_file.exists()\n        loaded = json.loads(state_file.read_text())\n        assert loaded[\"qdrant_collection\"] == \"test\"\n\n    def test_atomic_write_replaces_existing_file(self, ws_module, tmp_path):\n        \"\"\"_atomic_write_state atomically replaces existing file.\"\"\"\n        state_file = tmp_path / \"state.json\"\n\n        # Write initial state\n        state_file.write_text('{\"old\": \"data\"}')\n\n        # Overwrite with new state\n        new_state = {\"new\": \"state\"}\n        ws_module._atomic_write_state(state_file, new_state)\n\n        loaded = json.loads(state_file.read_text())\n        assert \"new\" in loaded\n        assert \"old\" not in loaded",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_atomic_write_creates_valid_json_352": {
      "name": "test_atomic_write_creates_valid_json",
      "type": "method",
      "start_line": 352,
      "end_line": 365,
      "content_hash": "8a5414d557f6e6a04fa37b38b2f00e76dfec5fbb",
      "content": "    def test_atomic_write_creates_valid_json(self, ws_module, tmp_path):\n        \"\"\"_atomic_write_state creates valid JSON file.\"\"\"\n        state_file = tmp_path / \"state.json\"\n        state = {\n            \"created_at\": \"2024-01-01T00:00:00\",\n            \"updated_at\": \"2024-01-01T00:00:00\",\n            \"qdrant_collection\": \"test\",\n        }\n\n        ws_module._atomic_write_state(state_file, state)\n\n        assert state_file.exists()\n        loaded = json.loads(state_file.read_text())\n        assert loaded[\"qdrant_collection\"] == \"test\"",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_atomic_write_replaces_existing_file_367": {
      "name": "test_atomic_write_replaces_existing_file",
      "type": "method",
      "start_line": 367,
      "end_line": 380,
      "content_hash": "e6f7c86d9fdc090c7e84362d800c275e4de6cc51",
      "content": "    def test_atomic_write_replaces_existing_file(self, ws_module, tmp_path):\n        \"\"\"_atomic_write_state atomically replaces existing file.\"\"\"\n        state_file = tmp_path / \"state.json\"\n\n        # Write initial state\n        state_file.write_text('{\"old\": \"data\"}')\n\n        # Overwrite with new state\n        new_state = {\"new\": \"state\"}\n        ws_module._atomic_write_state(state_file, new_state)\n\n        loaded = json.loads(state_file.read_text())\n        assert \"new\" in loaded\n        assert \"old\" not in loaded",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_TestConstants_386": {
      "name": "TestConstants",
      "type": "class",
      "start_line": 386,
      "end_line": 401,
      "content_hash": "349badba9036a90a056069ba2e9dd9dd846fbb73",
      "content": "class TestConstants:\n    \"\"\"Tests for module constants.\"\"\"\n\n    def test_state_dirname(self, ws_module):\n        \"\"\"STATE_DIRNAME is .codebase.\"\"\"\n        assert ws_module.STATE_DIRNAME == \".codebase\"\n\n    def test_state_filename(self, ws_module):\n        \"\"\"STATE_FILENAME is state.json.\"\"\"\n        assert ws_module.STATE_FILENAME == \"state.json\"\n\n    def test_placeholder_collection_names(self, ws_module):\n        \"\"\"PLACEHOLDER_COLLECTION_NAMES contains expected values.\"\"\"\n        assert \"\" in ws_module.PLACEHOLDER_COLLECTION_NAMES\n        assert \"default-collection\" in ws_module.PLACEHOLDER_COLLECTION_NAMES\n        assert \"my-collection\" in ws_module.PLACEHOLDER_COLLECTION_NAMES",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_state_dirname_389": {
      "name": "test_state_dirname",
      "type": "method",
      "start_line": 389,
      "end_line": 391,
      "content_hash": "7ff05b72342316911970a956ffacb0307f9e3642",
      "content": "    def test_state_dirname(self, ws_module):\n        \"\"\"STATE_DIRNAME is .codebase.\"\"\"\n        assert ws_module.STATE_DIRNAME == \".codebase\"",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_state_filename_393": {
      "name": "test_state_filename",
      "type": "method",
      "start_line": 393,
      "end_line": 395,
      "content_hash": "63103098b377d07003d404a6b4e3cd911bf5d1bc",
      "content": "    def test_state_filename(self, ws_module):\n        \"\"\"STATE_FILENAME is state.json.\"\"\"\n        assert ws_module.STATE_FILENAME == \"state.json\"",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_placeholder_collection_names_397": {
      "name": "test_placeholder_collection_names",
      "type": "method",
      "start_line": 397,
      "end_line": 401,
      "content_hash": "7bd699dad162e12bc3dddb35b95b9b4723902e2b",
      "content": "    def test_placeholder_collection_names(self, ws_module):\n        \"\"\"PLACEHOLDER_COLLECTION_NAMES contains expected values.\"\"\"\n        assert \"\" in ws_module.PLACEHOLDER_COLLECTION_NAMES\n        assert \"default-collection\" in ws_module.PLACEHOLDER_COLLECTION_NAMES\n        assert \"my-collection\" in ws_module.PLACEHOLDER_COLLECTION_NAMES",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}