{
  "file_path": "/work/external-deps/Context-Engine/scripts/cache_manager.py",
  "file_hash": "3f74a261f41cfcf36435b3d2cfbc94cac4c33800",
  "updated_at": "2025-12-26T17:34:21.521006",
  "symbols": {
    "class_EvictionPolicy_22": {
      "name": "EvictionPolicy",
      "type": "class",
      "start_line": 22,
      "end_line": 27,
      "content_hash": "0fe3ff223cad670c52435e328c2541534e572547",
      "content": "class EvictionPolicy(Enum):\n    \"\"\"Cache eviction policies.\"\"\"\n    LRU = \"lru\"  # Least Recently Used\n    LFU = \"lfu\"  # Least Frequently Used\n    TTL = \"ttl\"  # Time To Live\n    FIFO = \"fifo\"  # First In First Out",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_CacheEntry_30": {
      "name": "CacheEntry",
      "type": "class",
      "start_line": 30,
      "end_line": 65,
      "content_hash": "a4b19772818e2d689e0c265d088ad67be1f0597b",
      "content": "class CacheEntry:\n    \"\"\"Individual cache entry with metadata.\"\"\"\n    \n    def __init__(self, value: Any, ttl: Optional[float] = None):\n        self.value = value\n        self.created_at = time.time()\n        self.last_accessed = self.created_at\n        self.access_count = 1\n        self.ttl = ttl  # TTL in seconds\n        self.size = self._calculate_size(value)\n    \n    def _calculate_size(self, value: Any) -> int:\n        \"\"\"Estimate memory size of cached value.\"\"\"\n        try:\n            if isinstance(value, str):\n                return len(value.encode('utf-8'))\n            elif isinstance(value, (list, tuple)):\n                return sum(self._calculate_size(item) for item in value)\n            elif isinstance(value, dict):\n                return sum(self._calculate_size(k) + self._calculate_size(v) for k, v in value.items())\n            else:\n                return len(str(value).encode('utf-8'))\n        except Exception:\n            return 100  # Default size estimation\n    \n    def is_expired(self) -> bool:\n        \"\"\"Check if entry has expired based on TTL.\"\"\"\n        if self.ttl is None:\n            return False\n        return time.time() - self.created_at > self.ttl\n    \n    def access(self) -> Any:\n        \"\"\"Record access and return value.\"\"\"\n        self.last_accessed = time.time()\n        self.access_count += 1\n        return self.value",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___init___33": {
      "name": "__init__",
      "type": "method",
      "start_line": 33,
      "end_line": 39,
      "content_hash": "66a4238c4afed6485d876dd474d860835428cbee",
      "content": "    def __init__(self, value: Any, ttl: Optional[float] = None):\n        self.value = value\n        self.created_at = time.time()\n        self.last_accessed = self.created_at\n        self.access_count = 1\n        self.ttl = ttl  # TTL in seconds\n        self.size = self._calculate_size(value)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__calculate_size_41": {
      "name": "_calculate_size",
      "type": "method",
      "start_line": 41,
      "end_line": 53,
      "content_hash": "2ffa2ee753e7962af14a1a7b06066a79d7f10c1a",
      "content": "    def _calculate_size(self, value: Any) -> int:\n        \"\"\"Estimate memory size of cached value.\"\"\"\n        try:\n            if isinstance(value, str):\n                return len(value.encode('utf-8'))\n            elif isinstance(value, (list, tuple)):\n                return sum(self._calculate_size(item) for item in value)\n            elif isinstance(value, dict):\n                return sum(self._calculate_size(k) + self._calculate_size(v) for k, v in value.items())\n            else:\n                return len(str(value).encode('utf-8'))\n        except Exception:\n            return 100  # Default size estimation",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_is_expired_55": {
      "name": "is_expired",
      "type": "method",
      "start_line": 55,
      "end_line": 59,
      "content_hash": "f1ababa9ab53bd2359a49b29889a064ec416fc0d",
      "content": "    def is_expired(self) -> bool:\n        \"\"\"Check if entry has expired based on TTL.\"\"\"\n        if self.ttl is None:\n            return False\n        return time.time() - self.created_at > self.ttl",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_access_61": {
      "name": "access",
      "type": "method",
      "start_line": 61,
      "end_line": 65,
      "content_hash": "4ab4caaea3c3961e86bd5029064a3c1cf8f40630",
      "content": "    def access(self) -> Any:\n        \"\"\"Record access and return value.\"\"\"\n        self.last_accessed = time.time()\n        self.access_count += 1\n        return self.value",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_UnifiedCache_68": {
      "name": "UnifiedCache",
      "type": "class",
      "start_line": 68,
      "end_line": 410,
      "content_hash": "b0cd35010f55e8464df943bbf8ce9f5ab5adc3a0",
      "content": "class UnifiedCache:\n    \"\"\"\n    Unified cache system with configurable eviction policies and statistics.\n    \n    Features:\n    - Multiple eviction policies (LRU, LFU, TTL, FIFO)\n    - Thread-safe operations\n    - Statistics tracking\n    - Configurable size limits\n    - Automatic cleanup of expired entries\n    \"\"\"\n    \n    def __init__(\n        self,\n        name: str,\n        max_size: int = 1000,\n        max_memory_mb: int = 100,\n        eviction_policy: EvictionPolicy = EvictionPolicy.LRU,\n        default_ttl: Optional[float] = None,\n        cleanup_interval: float = 60.0\n    ):\n        self.name = name\n        self.max_size = max_size\n        self.max_memory_bytes = max_memory_mb * 1024 * 1024\n        self.eviction_policy = eviction_policy\n        self.default_ttl = default_ttl\n        self.cleanup_interval = cleanup_interval\n        \n        # Storage\n        self._cache: Dict[str, CacheEntry] = {}\n        self._access_order = OrderedDict()  # For LRU/FIFO\n        self._frequency = {}  # For LFU\n        \n        # Thread safety\n        self._lock = threading.RLock()\n        \n        # Statistics\n        self._stats = {\n            'hits': 0,\n            'misses': 0,\n            'evictions': 0,\n            'expirations': 0,\n            'current_size': 0,\n            'current_memory_bytes': 0,\n            'total_requests': 0\n        }\n        \n        # Start cleanup thread\n        self._cleanup_thread = threading.Thread(target=self._cleanup_worker, daemon=True)\n        self._cleanup_thread.start()\n        \n        logger.debug(f\"Initialized cache '{name}' with policy {eviction_policy.value}, \"\n                    f\"max_size={max_size}, max_memory={max_memory_mb}MB\")\n    \n    def _generate_key(self, key: Union[str, Tuple, List, Dict]) -> str:\n        \"\"\"Generate consistent cache key from various input types.\"\"\"\n        try:\n            if isinstance(key, str):\n                return key\n            elif isinstance(key, (tuple, list)):\n                key_str = json.dumps(list(key), sort_keys=True)\n            elif isinstance(key, dict):\n                key_str = json.dumps(key, sort_keys=True)\n            else:\n                key_str = str(key)\n            \n            # Hash long keys to avoid memory issues\n            if len(key_str) > 200:\n                return hashlib.md5(key_str.encode()).hexdigest()\n            return key_str\n        except Exception:\n            return str(key)\n    \n    def _should_evict(self) -> bool:\n        \"\"\"Check if cache should trigger eviction.\"\"\"\n        return (\n            len(self._cache) >= self.max_size or\n            self._stats['current_memory_bytes'] >= self.max_memory_bytes\n        )\n    \n    def _select_victim(self) -> Optional[str]:\n        \"\"\"Select entry for eviction based on policy.\"\"\"\n        if not self._cache:\n            return None\n        \n        if self.eviction_policy == EvictionPolicy.LRU:\n            # Least Recently Used\n            return next(iter(self._access_order))\n        \n        elif self.eviction_policy == EvictionPolicy.FIFO:\n            # First In First Out\n            return next(iter(self._access_order))\n        \n        elif self.eviction_policy == EvictionPolicy.LFU:\n            # Least Frequently Used\n            return min(self._frequency.keys(), key=lambda k: self._frequency[k])\n        \n        elif self.eviction_policy == EvictionPolicy.TTL:\n            # Time To Live (expired entries first)\n            for key, entry in self._cache.items():\n                if entry.is_expired():\n                    return key\n            # Fallback to LRU if no expired entries\n            return next(iter(self._access_order))\n        \n        return None\n    \n    def _evict_entry(self, key: str) -> None:\n        \"\"\"Evict a specific entry from cache.\"\"\"\n        if key not in self._cache:\n            return\n        \n        entry = self._cache[key]\n        \n        # Update statistics\n        self._stats['evictions'] += 1\n        self._stats['current_size'] -= 1\n        self._stats['current_memory_bytes'] -= entry.size\n        \n        # Remove from all data structures\n        del self._cache[key]\n        self._access_order.pop(key, None)\n        self._frequency.pop(key, None)\n        \n        logger.debug(f\"Evicted cache entry '{key}' from cache '{self.name}'\")\n    \n    def _cleanup_expired(self) -> int:\n        \"\"\"Clean up expired entries and return count cleaned.\"\"\"\n        if self.eviction_policy != EvictionPolicy.TTL and self.default_ttl is None:\n            return 0\n        \n        expired_keys = []\n        current_time = time.time()\n        \n        for key, entry in self._cache.items():\n            if entry.is_expired():\n                expired_keys.append(key)\n        \n        for key in expired_keys:\n            entry = self._cache[key]\n            del self._cache[key]\n            self._access_order.pop(key, None)\n            self._frequency.pop(key, None)\n            \n            # Update statistics\n            self._stats['expirations'] += 1\n            self._stats['current_size'] -= 1\n            self._stats['current_memory_bytes'] -= entry.size\n        \n        if expired_keys:\n            logger.debug(f\"Cleaned up {len(expired_keys)} expired entries from cache '{self.name}'\")\n        \n        return len(expired_keys)\n    \n    def _cleanup_worker(self) -> None:\n        \"\"\"Background worker for periodic cleanup.\"\"\"\n        while True:\n            try:\n                time.sleep(self.cleanup_interval)\n                with self._lock:\n                    self._cleanup_expired()\n            except Exception as e:\n                logger.error(f\"Cache cleanup error in '{self.name}': {e}\")\n    \n    def get(self, key: Union[str, Tuple, List, Dict]) -> Optional[Any]:\n        \"\"\"Get value from cache.\"\"\"\n        cache_key = self._generate_key(key)\n        \n        with self._lock:\n            self._stats['total_requests'] += 1\n            \n            if cache_key not in self._cache:\n                self._stats['misses'] += 1\n                return None\n            \n            entry = self._cache[cache_key]\n            \n            # Check expiration\n            if entry.is_expired():\n                del self._cache[cache_key]\n                self._access_order.pop(cache_key, None)\n                self._frequency.pop(cache_key, None)\n                \n                self._stats['misses'] += 1\n                self._stats['expirations'] += 1\n                self._stats['current_size'] -= 1\n                self._stats['current_memory_bytes'] -= entry.size\n                return None\n            \n            # Update access tracking\n            value = entry.access()\n            \n            # Update access order for LRU/FIFO\n            if cache_key in self._access_order:\n                self._access_order.move_to_end(cache_key)\n            \n            # Update frequency for LFU\n            self._frequency[cache_key] = self._frequency.get(cache_key, 0) + 1\n            \n            self._stats['hits'] += 1\n            \n            logger.debug(f\"Cache hit for key '{cache_key}' in cache '{self.name}'\")\n            return value\n    \n    def set(\n        self,\n        key: Union[str, Tuple, List, Dict],\n        value: Any,\n        ttl: Optional[float] = None\n    ) -> bool:\n        \"\"\"Set value in cache.\"\"\"\n        cache_key = self._generate_key(key)\n        ttl = ttl or self.default_ttl\n\n        with self._lock:\n            # Track previous entry so we can restore on failure\n            old_entry = self._cache.get(cache_key)\n            prev_freq = self._frequency.get(cache_key, 0)\n\n            entry = CacheEntry(value, ttl)\n\n            if old_entry is not None:\n                # Remove old entry bookkeeping while we attempt to insert the replacement\n                self._cache.pop(cache_key, None)\n                self._access_order.pop(cache_key, None)\n                self._frequency.pop(cache_key, None)\n                self._stats['current_size'] -= 1\n                self._stats['current_memory_bytes'] -= old_entry.size\n\n            def _needs_evict() -> bool:\n                if self.max_size > 0 and (len(self._cache) + 1) > self.max_size:\n                    return True\n                if self.max_memory_bytes > 0 and (self._stats['current_memory_bytes'] + entry.size) > self.max_memory_bytes:\n                    return len(self._cache) > 0\n                return False\n\n            # Evict least valuable entries until the new item fits or we run out of victims\n            while _needs_evict():\n                victim_key = self._select_victim()\n                if not victim_key:\n                    break\n                self._evict_entry(victim_key)\n\n            # If the new entry still does not fit, restore prior state (for updates) and abort\n            if (self.max_size > 0 and (len(self._cache) + 1) > self.max_size) or (\n                self.max_memory_bytes > 0 and (self._stats['current_memory_bytes'] + entry.size) > self.max_memory_bytes\n            ):\n                if old_entry is not None:\n                    self._cache[cache_key] = old_entry\n                    self._access_order[cache_key] = True\n                    self._frequency[cache_key] = max(1, prev_freq)\n                    self._stats['current_size'] += 1\n                    self._stats['current_memory_bytes'] += old_entry.size\n                logger.debug(\n                    f\"Entry '{cache_key}' exceeds cache constraints; not retained in '{self.name}'\"\n                )\n                return False\n\n            # Insert new entry\n            self._cache[cache_key] = entry\n            self._access_order[cache_key] = True\n            self._frequency[cache_key] = (prev_freq + 1) if prev_freq else 1\n            self._stats['current_size'] += 1\n            self._stats['current_memory_bytes'] += entry.size\n\n            logger.debug(f\"Cache set for key '{cache_key}' in cache '{self.name}'\")\n            return True\n\n    def delete(self, key: Union[str, Tuple, List, Dict]) -> bool:\n        \"\"\"Delete value from cache.\"\"\"\n        cache_key = self._generate_key(key)\n        \n        with self._lock:\n            if cache_key not in self._cache:\n                return False\n            \n            entry = self._cache[cache_key]\n            del self._cache[cache_key]\n            self._access_order.pop(cache_key, None)\n            self._frequency.pop(cache_key, None)\n            \n            # Update statistics\n            self._stats['current_size'] -= 1\n            self._stats['current_memory_bytes'] -= entry.size\n            \n            logger.debug(f\"Cache delete for key '{cache_key}' in cache '{self.name}'\")\n            return True\n    \n    def clear(self) -> None:\n        \"\"\"Clear all entries from cache.\"\"\"\n        with self._lock:\n            self._cache.clear()\n            self._access_order.clear()\n            self._frequency.clear()\n            \n            # Reset statistics\n            self._stats['current_size'] = 0\n            self._stats['current_memory_bytes'] = 0\n            \n            logger.debug(f\"Cleared cache '{self.name}'\")\n    \n    def get_stats(self) -> Dict[str, Any]:\n        \"\"\"Get cache statistics.\"\"\"\n        with self._lock:\n            stats = self._stats.copy()\n            stats['hit_rate'] = (\n                stats['hits'] / max(1, stats['total_requests']) * 100\n            )\n            stats['memory_usage_mb'] = stats['current_memory_bytes'] / (1024 * 1024)\n            stats['cache_name'] = self.name\n            stats['eviction_policy'] = self.eviction_policy.value\n            return stats\n    \n    def get_keys(self) -> List[str]:\n        \"\"\"Get all cache keys.\"\"\"\n        with self._lock:\n            return list(self._cache.keys())\n    \n    def size(self) -> int:\n        \"\"\"Get current cache size.\"\"\"\n        with self._lock:\n            return len(self._cache)\n    \n    def __len__(self) -> int:\n        \"\"\"Get current cache size.\"\"\"\n        return self.size()\n    \n    def __contains__(self, key: Union[str, Tuple, List, Dict]) -> bool:\n        \"\"\"Check if key exists in cache.\"\"\"\n        cache_key = self._generate_key(key)\n        with self._lock:\n            return cache_key in self._cache\n    \n    def __enter__(self):\n        \"\"\"Context manager entry.\"\"\"\n        return self\n    \n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Context manager exit with cleanup.\"\"\"\n        try:\n            self.clear()\n        except Exception:\n            pass",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___init___80": {
      "name": "__init__",
      "type": "method",
      "start_line": 80,
      "end_line": 120,
      "content_hash": "443e1ca3acbc55e5c1a1c24fb55a32053cdbf59c",
      "content": "    def __init__(\n        self,\n        name: str,\n        max_size: int = 1000,\n        max_memory_mb: int = 100,\n        eviction_policy: EvictionPolicy = EvictionPolicy.LRU,\n        default_ttl: Optional[float] = None,\n        cleanup_interval: float = 60.0\n    ):\n        self.name = name\n        self.max_size = max_size\n        self.max_memory_bytes = max_memory_mb * 1024 * 1024\n        self.eviction_policy = eviction_policy\n        self.default_ttl = default_ttl\n        self.cleanup_interval = cleanup_interval\n        \n        # Storage\n        self._cache: Dict[str, CacheEntry] = {}\n        self._access_order = OrderedDict()  # For LRU/FIFO\n        self._frequency = {}  # For LFU\n        \n        # Thread safety\n        self._lock = threading.RLock()\n        \n        # Statistics\n        self._stats = {\n            'hits': 0,\n            'misses': 0,\n            'evictions': 0,\n            'expirations': 0,\n            'current_size': 0,\n            'current_memory_bytes': 0,\n            'total_requests': 0\n        }\n        \n        # Start cleanup thread\n        self._cleanup_thread = threading.Thread(target=self._cleanup_worker, daemon=True)\n        self._cleanup_thread.start()\n        \n        logger.debug(f\"Initialized cache '{name}' with policy {eviction_policy.value}, \"\n                    f\"max_size={max_size}, max_memory={max_memory_mb}MB\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__generate_key_122": {
      "name": "_generate_key",
      "type": "method",
      "start_line": 122,
      "end_line": 139,
      "content_hash": "59ae7f288968a26a43d6375d04040fbcd11c81a8",
      "content": "    def _generate_key(self, key: Union[str, Tuple, List, Dict]) -> str:\n        \"\"\"Generate consistent cache key from various input types.\"\"\"\n        try:\n            if isinstance(key, str):\n                return key\n            elif isinstance(key, (tuple, list)):\n                key_str = json.dumps(list(key), sort_keys=True)\n            elif isinstance(key, dict):\n                key_str = json.dumps(key, sort_keys=True)\n            else:\n                key_str = str(key)\n            \n            # Hash long keys to avoid memory issues\n            if len(key_str) > 200:\n                return hashlib.md5(key_str.encode()).hexdigest()\n            return key_str\n        except Exception:\n            return str(key)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__should_evict_141": {
      "name": "_should_evict",
      "type": "method",
      "start_line": 141,
      "end_line": 146,
      "content_hash": "03a0cafcd1712d02d534681b6521ca935052fd82",
      "content": "    def _should_evict(self) -> bool:\n        \"\"\"Check if cache should trigger eviction.\"\"\"\n        return (\n            len(self._cache) >= self.max_size or\n            self._stats['current_memory_bytes'] >= self.max_memory_bytes\n        )",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__select_victim_148": {
      "name": "_select_victim",
      "type": "method",
      "start_line": 148,
      "end_line": 173,
      "content_hash": "49866f253b574f9f85b44d875cae75eac930e36b",
      "content": "    def _select_victim(self) -> Optional[str]:\n        \"\"\"Select entry for eviction based on policy.\"\"\"\n        if not self._cache:\n            return None\n        \n        if self.eviction_policy == EvictionPolicy.LRU:\n            # Least Recently Used\n            return next(iter(self._access_order))\n        \n        elif self.eviction_policy == EvictionPolicy.FIFO:\n            # First In First Out\n            return next(iter(self._access_order))\n        \n        elif self.eviction_policy == EvictionPolicy.LFU:\n            # Least Frequently Used\n            return min(self._frequency.keys(), key=lambda k: self._frequency[k])\n        \n        elif self.eviction_policy == EvictionPolicy.TTL:\n            # Time To Live (expired entries first)\n            for key, entry in self._cache.items():\n                if entry.is_expired():\n                    return key\n            # Fallback to LRU if no expired entries\n            return next(iter(self._access_order))\n        \n        return None",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__evict_entry_175": {
      "name": "_evict_entry",
      "type": "method",
      "start_line": 175,
      "end_line": 192,
      "content_hash": "1231de782c5717a2601817d16a2a81ef72d5fa2f",
      "content": "    def _evict_entry(self, key: str) -> None:\n        \"\"\"Evict a specific entry from cache.\"\"\"\n        if key not in self._cache:\n            return\n        \n        entry = self._cache[key]\n        \n        # Update statistics\n        self._stats['evictions'] += 1\n        self._stats['current_size'] -= 1\n        self._stats['current_memory_bytes'] -= entry.size\n        \n        # Remove from all data structures\n        del self._cache[key]\n        self._access_order.pop(key, None)\n        self._frequency.pop(key, None)\n        \n        logger.debug(f\"Evicted cache entry '{key}' from cache '{self.name}'\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__cleanup_expired_194": {
      "name": "_cleanup_expired",
      "type": "method",
      "start_line": 194,
      "end_line": 220,
      "content_hash": "94584e90e52f340f52234bf4c67f55d16d20f299",
      "content": "    def _cleanup_expired(self) -> int:\n        \"\"\"Clean up expired entries and return count cleaned.\"\"\"\n        if self.eviction_policy != EvictionPolicy.TTL and self.default_ttl is None:\n            return 0\n        \n        expired_keys = []\n        current_time = time.time()\n        \n        for key, entry in self._cache.items():\n            if entry.is_expired():\n                expired_keys.append(key)\n        \n        for key in expired_keys:\n            entry = self._cache[key]\n            del self._cache[key]\n            self._access_order.pop(key, None)\n            self._frequency.pop(key, None)\n            \n            # Update statistics\n            self._stats['expirations'] += 1\n            self._stats['current_size'] -= 1\n            self._stats['current_memory_bytes'] -= entry.size\n        \n        if expired_keys:\n            logger.debug(f\"Cleaned up {len(expired_keys)} expired entries from cache '{self.name}'\")\n        \n        return len(expired_keys)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__cleanup_worker_222": {
      "name": "_cleanup_worker",
      "type": "method",
      "start_line": 222,
      "end_line": 230,
      "content_hash": "a8fdbf09c1115275375321764cba018fa93bd1f2",
      "content": "    def _cleanup_worker(self) -> None:\n        \"\"\"Background worker for periodic cleanup.\"\"\"\n        while True:\n            try:\n                time.sleep(self.cleanup_interval)\n                with self._lock:\n                    self._cleanup_expired()\n            except Exception as e:\n                logger.error(f\"Cache cleanup error in '{self.name}': {e}\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_get_232": {
      "name": "get",
      "type": "method",
      "start_line": 232,
      "end_line": 270,
      "content_hash": "1a0f8075b56ef2c914911c6ec0d7295eb3337fd8",
      "content": "    def get(self, key: Union[str, Tuple, List, Dict]) -> Optional[Any]:\n        \"\"\"Get value from cache.\"\"\"\n        cache_key = self._generate_key(key)\n        \n        with self._lock:\n            self._stats['total_requests'] += 1\n            \n            if cache_key not in self._cache:\n                self._stats['misses'] += 1\n                return None\n            \n            entry = self._cache[cache_key]\n            \n            # Check expiration\n            if entry.is_expired():\n                del self._cache[cache_key]\n                self._access_order.pop(cache_key, None)\n                self._frequency.pop(cache_key, None)\n                \n                self._stats['misses'] += 1\n                self._stats['expirations'] += 1\n                self._stats['current_size'] -= 1\n                self._stats['current_memory_bytes'] -= entry.size\n                return None\n            \n            # Update access tracking\n            value = entry.access()\n            \n            # Update access order for LRU/FIFO\n            if cache_key in self._access_order:\n                self._access_order.move_to_end(cache_key)\n            \n            # Update frequency for LFU\n            self._frequency[cache_key] = self._frequency.get(cache_key, 0) + 1\n            \n            self._stats['hits'] += 1\n            \n            logger.debug(f\"Cache hit for key '{cache_key}' in cache '{self.name}'\")\n            return value",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_set_272": {
      "name": "set",
      "type": "method",
      "start_line": 272,
      "end_line": 334,
      "content_hash": "563a973337c2609db6338c37c6dd7c442b2687d1",
      "content": "    def set(\n        self,\n        key: Union[str, Tuple, List, Dict],\n        value: Any,\n        ttl: Optional[float] = None\n    ) -> bool:\n        \"\"\"Set value in cache.\"\"\"\n        cache_key = self._generate_key(key)\n        ttl = ttl or self.default_ttl\n\n        with self._lock:\n            # Track previous entry so we can restore on failure\n            old_entry = self._cache.get(cache_key)\n            prev_freq = self._frequency.get(cache_key, 0)\n\n            entry = CacheEntry(value, ttl)\n\n            if old_entry is not None:\n                # Remove old entry bookkeeping while we attempt to insert the replacement\n                self._cache.pop(cache_key, None)\n                self._access_order.pop(cache_key, None)\n                self._frequency.pop(cache_key, None)\n                self._stats['current_size'] -= 1\n                self._stats['current_memory_bytes'] -= old_entry.size\n\n            def _needs_evict() -> bool:\n                if self.max_size > 0 and (len(self._cache) + 1) > self.max_size:\n                    return True\n                if self.max_memory_bytes > 0 and (self._stats['current_memory_bytes'] + entry.size) > self.max_memory_bytes:\n                    return len(self._cache) > 0\n                return False\n\n            # Evict least valuable entries until the new item fits or we run out of victims\n            while _needs_evict():\n                victim_key = self._select_victim()\n                if not victim_key:\n                    break\n                self._evict_entry(victim_key)\n\n            # If the new entry still does not fit, restore prior state (for updates) and abort\n            if (self.max_size > 0 and (len(self._cache) + 1) > self.max_size) or (\n                self.max_memory_bytes > 0 and (self._stats['current_memory_bytes'] + entry.size) > self.max_memory_bytes\n            ):\n                if old_entry is not None:\n                    self._cache[cache_key] = old_entry\n                    self._access_order[cache_key] = True\n                    self._frequency[cache_key] = max(1, prev_freq)\n                    self._stats['current_size'] += 1\n                    self._stats['current_memory_bytes'] += old_entry.size\n                logger.debug(\n                    f\"Entry '{cache_key}' exceeds cache constraints; not retained in '{self.name}'\"\n                )\n                return False\n\n            # Insert new entry\n            self._cache[cache_key] = entry\n            self._access_order[cache_key] = True\n            self._frequency[cache_key] = (prev_freq + 1) if prev_freq else 1\n            self._stats['current_size'] += 1\n            self._stats['current_memory_bytes'] += entry.size\n\n            logger.debug(f\"Cache set for key '{cache_key}' in cache '{self.name}'\")\n            return True",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__needs_evict_297": {
      "name": "_needs_evict",
      "type": "method",
      "start_line": 297,
      "end_line": 302,
      "content_hash": "6e5381d41400d42e5d2dbf7e6a318737c8620cde",
      "content": "            def _needs_evict() -> bool:\n                if self.max_size > 0 and (len(self._cache) + 1) > self.max_size:\n                    return True\n                if self.max_memory_bytes > 0 and (self._stats['current_memory_bytes'] + entry.size) > self.max_memory_bytes:\n                    return len(self._cache) > 0\n                return False",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_delete_336": {
      "name": "delete",
      "type": "method",
      "start_line": 336,
      "end_line": 354,
      "content_hash": "6526ad347c838b395290185700f35ab5fdb8b4e3",
      "content": "    def delete(self, key: Union[str, Tuple, List, Dict]) -> bool:\n        \"\"\"Delete value from cache.\"\"\"\n        cache_key = self._generate_key(key)\n        \n        with self._lock:\n            if cache_key not in self._cache:\n                return False\n            \n            entry = self._cache[cache_key]\n            del self._cache[cache_key]\n            self._access_order.pop(cache_key, None)\n            self._frequency.pop(cache_key, None)\n            \n            # Update statistics\n            self._stats['current_size'] -= 1\n            self._stats['current_memory_bytes'] -= entry.size\n            \n            logger.debug(f\"Cache delete for key '{cache_key}' in cache '{self.name}'\")\n            return True",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_clear_356": {
      "name": "clear",
      "type": "method",
      "start_line": 356,
      "end_line": 367,
      "content_hash": "8f76b2b9cf36806441e4e433b1f02ae3e2320022",
      "content": "    def clear(self) -> None:\n        \"\"\"Clear all entries from cache.\"\"\"\n        with self._lock:\n            self._cache.clear()\n            self._access_order.clear()\n            self._frequency.clear()\n            \n            # Reset statistics\n            self._stats['current_size'] = 0\n            self._stats['current_memory_bytes'] = 0\n            \n            logger.debug(f\"Cleared cache '{self.name}'\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_get_stats_369": {
      "name": "get_stats",
      "type": "method",
      "start_line": 369,
      "end_line": 379,
      "content_hash": "4568628632248179417a329ddf5a7ff70af83de3",
      "content": "    def get_stats(self) -> Dict[str, Any]:\n        \"\"\"Get cache statistics.\"\"\"\n        with self._lock:\n            stats = self._stats.copy()\n            stats['hit_rate'] = (\n                stats['hits'] / max(1, stats['total_requests']) * 100\n            )\n            stats['memory_usage_mb'] = stats['current_memory_bytes'] / (1024 * 1024)\n            stats['cache_name'] = self.name\n            stats['eviction_policy'] = self.eviction_policy.value\n            return stats",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_get_keys_381": {
      "name": "get_keys",
      "type": "method",
      "start_line": 381,
      "end_line": 384,
      "content_hash": "ada6ba63d8ed8d56cdebf5e8a39c57cd8eea036e",
      "content": "    def get_keys(self) -> List[str]:\n        \"\"\"Get all cache keys.\"\"\"\n        with self._lock:\n            return list(self._cache.keys())",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_size_386": {
      "name": "size",
      "type": "method",
      "start_line": 386,
      "end_line": 389,
      "content_hash": "f3bdf7217dc9492f7548bdb86667a28720e6dfa6",
      "content": "    def size(self) -> int:\n        \"\"\"Get current cache size.\"\"\"\n        with self._lock:\n            return len(self._cache)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___len___391": {
      "name": "__len__",
      "type": "method",
      "start_line": 391,
      "end_line": 393,
      "content_hash": "d6622228a08004bbdca9a27ebdf767aa2c6c8e61",
      "content": "    def __len__(self) -> int:\n        \"\"\"Get current cache size.\"\"\"\n        return self.size()",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___contains___395": {
      "name": "__contains__",
      "type": "method",
      "start_line": 395,
      "end_line": 399,
      "content_hash": "912274ec9eea45f9fcd1434736859a513f107018",
      "content": "    def __contains__(self, key: Union[str, Tuple, List, Dict]) -> bool:\n        \"\"\"Check if key exists in cache.\"\"\"\n        cache_key = self._generate_key(key)\n        with self._lock:\n            return cache_key in self._cache",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___enter___401": {
      "name": "__enter__",
      "type": "method",
      "start_line": 401,
      "end_line": 403,
      "content_hash": "96b998e00a1972043cbb74bb1fc33857195294eb",
      "content": "    def __enter__(self):\n        \"\"\"Context manager entry.\"\"\"\n        return self",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___exit___405": {
      "name": "__exit__",
      "type": "method",
      "start_line": 405,
      "end_line": 410,
      "content_hash": "a0f986a4b864cd3b6fa92172c7548ae4e72c21a6",
      "content": "    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Context manager exit with cleanup.\"\"\"\n        try:\n            self.clear()\n        except Exception:\n            pass",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_get_cache_418": {
      "name": "get_cache",
      "type": "function",
      "start_line": 418,
      "end_line": 453,
      "content_hash": "ec17af89379a621b85e7e8cdc85b4bfe94dd5ad6",
      "content": "def get_cache(\n    name: str,\n    max_size: Optional[int] = None,\n    max_memory_mb: Optional[int] = None,\n    eviction_policy: Optional[EvictionPolicy] = None,\n    default_ttl: Optional[float] = None\n) -> UnifiedCache:\n    \"\"\"Get or create a cache instance with specified configuration.\"\"\"\n    with _registry_lock:\n        if name not in _cache_registry:\n            # Get configuration from environment or defaults\n            env_prefix = f\"CACHE_{name.upper()}_\"\n            \n            max_size = max_size or int(os.environ.get(f\"{env_prefix}MAX_SIZE\", \"1000\"))\n            max_memory_mb = max_memory_mb or int(os.environ.get(f\"{env_prefix}MAX_MEMORY_MB\", \"100\"))\n            \n            policy_str = os.environ.get(f\"{env_prefix}EVICT_POLICY\", \"lru\").lower()\n            eviction_policy = eviction_policy or EvictionPolicy(policy_str)\n            \n            default_ttl = default_ttl or (\n                float(os.environ.get(f\"{env_prefix}DEFAULT_TTL\")) \n                if os.environ.get(f\"{env_prefix}DEFAULT_TTL\") else None\n            )\n            \n            cleanup_interval = float(os.environ.get(f\"{env_prefix}CLEANUP_INTERVAL\", \"60\"))\n            \n            _cache_registry[name] = UnifiedCache(\n                name=name,\n                max_size=max_size,\n                max_memory_mb=max_memory_mb,\n                eviction_policy=eviction_policy,\n                default_ttl=default_ttl,\n                cleanup_interval=cleanup_interval\n            )\n        \n        return _cache_registry[name]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_clear_all_caches_456": {
      "name": "clear_all_caches",
      "type": "function",
      "start_line": 456,
      "end_line": 463,
      "content_hash": "cb07e02a4dc8699d890980eaab862e5de8d21f19",
      "content": "def clear_all_caches() -> None:\n    \"\"\"Clear all registered caches.\"\"\"\n    with _registry_lock:\n        for cache in _cache_registry.values():\n            try:\n                cache.clear()\n            except Exception as e:\n                logger.error(f\"Error clearing cache '{cache.name}': {e}\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_get_all_cache_stats_466": {
      "name": "get_all_cache_stats",
      "type": "function",
      "start_line": 466,
      "end_line": 479,
      "content_hash": "78ea1de1754c4fbeb84c6c366eecd74a2415541b",
      "content": "def get_all_cache_stats() -> Dict[str, Dict[str, Any]]:\n    \"\"\"Get statistics for all registered caches.\n    Ensures predefined caches are present so callers can rely on standard keys.\n    \"\"\"\n    # Ensure predefined caches are instantiated OUTSIDE the registry lock to avoid deadlocks\n    try:\n        get_embedding_cache()\n        get_search_cache()\n        get_expansion_cache()\n    except Exception:\n        pass\n\n    with _registry_lock:\n        return {name: cache.get_stats() for name, cache in _cache_registry.items()}",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_cached_483": {
      "name": "cached",
      "type": "function",
      "start_line": 483,
      "end_line": 515,
      "content_hash": "9befab0f33a9467e99bab8486355fc1b83646d2f",
      "content": "def cached(\n    cache_name: str = \"default\",\n    ttl: Optional[float] = None,\n    key_func: Optional[Callable] = None\n):\n    \"\"\"Decorator to cache function results.\"\"\"\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            # Generate cache key\n            if key_func:\n                cache_key = key_func(*args, **kwargs)\n            else:\n                cache_key = (args, tuple(sorted(kwargs.items())))\n            \n            # Get cache\n            cache = get_cache(cache_name)\n            \n            # Try to get from cache\n            result = cache.get(cache_key)\n            if result is not None:\n                return result\n            \n            # Compute and cache result\n            result = func(*args, **kwargs)\n            cache.set(cache_key, result, ttl=ttl)\n            \n            return result\n        \n        wrapper._cached = True\n        wrapper._cache_name = cache_name\n        return wrapper\n    \n    return decorator",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_decorator_489": {
      "name": "decorator",
      "type": "function",
      "start_line": 489,
      "end_line": 513,
      "content_hash": "f2aed4a5080f3822f419836317d5479e5469a958",
      "content": "    def decorator(func):\n        def wrapper(*args, **kwargs):\n            # Generate cache key\n            if key_func:\n                cache_key = key_func(*args, **kwargs)\n            else:\n                cache_key = (args, tuple(sorted(kwargs.items())))\n            \n            # Get cache\n            cache = get_cache(cache_name)\n            \n            # Try to get from cache\n            result = cache.get(cache_key)\n            if result is not None:\n                return result\n            \n            # Compute and cache result\n            result = func(*args, **kwargs)\n            cache.set(cache_key, result, ttl=ttl)\n            \n            return result\n        \n        wrapper._cached = True\n        wrapper._cache_name = cache_name\n        return wrapper",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_wrapper_490": {
      "name": "wrapper",
      "type": "function",
      "start_line": 490,
      "end_line": 509,
      "content_hash": "19dbfd91a248681d47db992711d618f26aa6fe71",
      "content": "        def wrapper(*args, **kwargs):\n            # Generate cache key\n            if key_func:\n                cache_key = key_func(*args, **kwargs)\n            else:\n                cache_key = (args, tuple(sorted(kwargs.items())))\n            \n            # Get cache\n            cache = get_cache(cache_name)\n            \n            # Try to get from cache\n            result = cache.get(cache_key)\n            if result is not None:\n                return result\n            \n            # Compute and cache result\n            result = func(*args, **kwargs)\n            cache.set(cache_key, result, ttl=ttl)\n            \n            return result",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_get_embedding_cache_519": {
      "name": "get_embedding_cache",
      "type": "function",
      "start_line": 519,
      "end_line": 527,
      "content_hash": "1a3d4d320ac0c38a82ada8b4d8e3ea6fdc96dd70",
      "content": "def get_embedding_cache() -> UnifiedCache:\n    \"\"\"Get cache for query embeddings.\"\"\"\n    return get_cache(\n        \"embeddings\",\n        max_size=int(os.environ.get(\"EMBED_CACHE_MAX_SIZE\", \"8192\")),\n        max_memory_mb=int(os.environ.get(\"EMBED_CACHE_MAX_MEMORY_MB\", \"50\")),\n        eviction_policy=EvictionPolicy.LRU,\n        default_ttl=None  # Embeddings don't expire\n    )",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_get_search_cache_530": {
      "name": "get_search_cache",
      "type": "function",
      "start_line": 530,
      "end_line": 538,
      "content_hash": "46c6011dd654d5d1485c246950afa9f24f7f676e",
      "content": "def get_search_cache() -> UnifiedCache:\n    \"\"\"Get cache for search results.\"\"\"\n    return get_cache(\n        \"search_results\",\n        max_size=int(os.environ.get(\"SEARCH_CACHE_MAX_SIZE\", \"1000\")),\n        max_memory_mb=int(os.environ.get(\"SEARCH_CACHE_MAX_MEMORY_MB\", \"100\")),\n        eviction_policy=EvictionPolicy.TTL,\n        default_ttl=float(os.environ.get(\"SEARCH_CACHE_TTL\", \"300\"))  # 5 minutes\n    )",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_get_expansion_cache_541": {
      "name": "get_expansion_cache",
      "type": "function",
      "start_line": 541,
      "end_line": 549,
      "content_hash": "bcd9a95a8bd78c240cc89e9623177836613c1b89",
      "content": "def get_expansion_cache() -> UnifiedCache:\n    \"\"\"Get cache for query expansion results.\"\"\"\n    return get_cache(\n        \"expansions\",\n        max_size=int(os.environ.get(\"EXPANSION_CACHE_MAX_SIZE\", \"1000\")),\n        max_memory_mb=int(os.environ.get(\"EXPANSION_CACHE_MAX_MEMORY_MB\", \"20\")),\n        eviction_policy=EvictionPolicy.LRU,\n        default_ttl=float(os.environ.get(\"EXPANSION_CACHE_TTL\", \"1800\"))  # 30 minutes\n    )",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}