{
  "file_path": "/work/context-engine/scripts/mcp_impl/code_signals.py",
  "file_hash": "9ce862a9fcc1e6253047fda9a207d105d4b37b3f",
  "updated_at": "2025-12-26T17:34:22.624109",
  "symbols": {
    "function__init_code_intent_centroids_76": {
      "name": "_init_code_intent_centroids",
      "type": "function",
      "start_line": 76,
      "end_line": 112,
      "content_hash": "6618ad0629944f453ba4042cbb467659f6d1723c",
      "content": "def _init_code_intent_centroids():\n    \"\"\"Initialize embedding centroids for code vs prose query detection.\"\"\"\n    global _CODE_INTENT_CACHE\n    \n    # Import here to avoid circular dependency\n    from scripts.mcp_impl.admin_tools import _get_embedding_model\n    import numpy as np\n    \n    with _CODE_INTENT_LOCK:\n        if _CODE_INTENT_CACHE.get(\"initialized\"):\n            return\n        try:\n            model_name = os.environ.get(\"EMBEDDING_MODEL\", \"BAAI/bge-base-en-v1.5\")\n            model = _get_embedding_model(model_name)\n            if model is None:\n                _CODE_INTENT_CACHE[\"initialized\"] = False\n                return\n\n            # Embed archetypes\n            code_embeddings = list(model.embed(_CODE_QUERY_ARCHETYPES))\n            prose_embeddings = list(model.embed(_PROSE_QUERY_ARCHETYPES))\n\n            # Compute centroids\n            code_centroid = np.mean(code_embeddings, axis=0)\n            prose_centroid = np.mean(prose_embeddings, axis=0)\n\n            # Normalize\n            code_centroid = code_centroid / (np.linalg.norm(code_centroid) + 1e-9)\n            prose_centroid = prose_centroid / (np.linalg.norm(prose_centroid) + 1e-9)\n\n            _CODE_INTENT_CACHE[\"code_centroid\"] = code_centroid\n            _CODE_INTENT_CACHE[\"prose_centroid\"] = prose_centroid\n            _CODE_INTENT_CACHE[\"initialized\"] = True\n        except Exception as e:\n            if os.environ.get(\"DEBUG_CODE_SIGNALS\"):\n                print(f\"[DEBUG] Failed to init code intent centroids: {e}\")\n            _CODE_INTENT_CACHE[\"initialized\"] = False",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function__detect_code_intent_embedding_115": {
      "name": "_detect_code_intent_embedding",
      "type": "function",
      "start_line": 115,
      "end_line": 153,
      "content_hash": "f745dd151112a505852393eff351db1d9f5f36c7",
      "content": "def _detect_code_intent_embedding(query: str) -> float:\n    \"\"\"Detect code intent using embedding similarity to pre-computed centroids.\n\n    Returns:\n        float: 0.0-1.0 indicating code-likeness (1.0 = very code-like)\n    \"\"\"\n    # Import here to avoid circular dependency\n    from scripts.mcp_impl.admin_tools import _get_embedding_model\n    import numpy as np\n    \n    if not _CODE_INTENT_CACHE.get(\"initialized\"):\n        _init_code_intent_centroids()\n\n    if not _CODE_INTENT_CACHE.get(\"initialized\"):\n        return 0.5  # Neutral if init failed\n\n    try:\n        model_name = os.environ.get(\"EMBEDDING_MODEL\", \"BAAI/bge-base-en-v1.5\")\n        model = _get_embedding_model(model_name)\n        if model is None:\n            return 0.5\n\n        query_embedding = next(model.embed([query]))\n        query_embedding = query_embedding / (np.linalg.norm(query_embedding) + 1e-9)\n\n        code_centroid = _CODE_INTENT_CACHE[\"code_centroid\"]\n        prose_centroid = _CODE_INTENT_CACHE[\"prose_centroid\"]\n\n        # Cosine similarity\n        code_sim = float(np.dot(query_embedding, code_centroid))\n        prose_sim = float(np.dot(query_embedding, prose_centroid))\n\n        # Convert to 0-1 score (softmax-ish)\n        diff = code_sim - prose_sim\n        score = 1.0 / (1.0 + np.exp(-diff * 5))  # Sigmoid with scaling\n\n        return float(score)\n    except Exception:\n        return 0.5",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function__detect_code_signals_215": {
      "name": "_detect_code_signals",
      "type": "function",
      "start_line": 215,
      "end_line": 387,
      "content_hash": "1bb59eaadfe51d7631863cfc97c1d0de7c7d1eb2",
      "content": "def _detect_code_signals(query: str) -> dict:\n    \"\"\"Detect code-like patterns in query and extract potential symbols.\n\n    Returns:\n        {\n            \"has_code_signals\": bool,\n            \"signal_strength\": float (0.0-1.0),\n            \"extracted_symbols\": list[str],\n            \"detected_patterns\": list[str],\n            \"suggested_boosts\": dict\n        }\n    \"\"\"\n    if not query or not isinstance(query, str):\n        return {\"has_code_signals\": False, \"signal_strength\": 0.0, \"extracted_symbols\": [], \"detected_patterns\": [], \"suggested_boosts\": {}}\n\n    query_lower = query.lower()\n    detected_patterns = []\n    extracted_symbols = set()\n    signal_score = 0.0\n\n    # Check for backtick-wrapped code (highest signal)\n    backtick_matches = _CODE_SIGNAL_PATTERNS[\"backticks\"].findall(query)\n    if backtick_matches:\n        detected_patterns.append(\"backticks\")\n        signal_score += 0.4\n        for m in backtick_matches:\n            if len(m) > 1:\n                extracted_symbols.add(m.strip())\n\n    # Check CamelCase/PascalCase\n    for name, pattern in [(\"PascalCase\", _CODE_SIGNAL_PATTERNS[\"PascalCase\"]),\n                          (\"camelCase\", _CODE_SIGNAL_PATTERNS[\"camelCase\"])]:\n        matches = pattern.findall(query)\n        if matches:\n            detected_patterns.append(name)\n            signal_score += 0.3\n            for m in matches:\n                if len(m) > 2 and m.lower() not in {\"the\", \"and\", \"for\", \"with\"}:\n                    extracted_symbols.add(m)\n\n    # Check snake_case\n    snake_matches = _CODE_SIGNAL_PATTERNS[\"snake_case\"].findall(query)\n    if snake_matches:\n        detected_patterns.append(\"snake_case\")\n        signal_score += 0.3\n        for m in snake_matches:\n            if len(m) > 3:\n                extracted_symbols.add(m)\n\n    # Check SCREAMING_SNAKE_CASE\n    screaming_matches = _CODE_SIGNAL_PATTERNS[\"SCREAMING_SNAKE\"].findall(query)\n    if screaming_matches:\n        detected_patterns.append(\"SCREAMING_SNAKE\")\n        signal_score += 0.2\n        for m in screaming_matches:\n            if len(m) > 3:\n                extracted_symbols.add(m)\n\n    # Check for function call syntax: name()\n    paren_matches = _CODE_SIGNAL_PATTERNS[\"parentheses\"].findall(query)\n    if paren_matches:\n        detected_patterns.append(\"parentheses\")\n        signal_score += 0.3\n        for m in paren_matches:\n            if len(m) > 1:\n                extracted_symbols.add(m)\n\n    # Check for module.path.syntax\n    dot_matches = _CODE_SIGNAL_PATTERNS[\"dot_path\"].findall(query)\n    if dot_matches:\n        detected_patterns.append(\"dot_path\")\n        signal_score += 0.2\n        for m in dot_matches:\n            parts = m.split(\".\")\n            if parts:\n                extracted_symbols.add(parts[-1])\n                extracted_symbols.add(m)\n\n    # Check for namespace::path syntax\n    namespace_matches = _CODE_SIGNAL_PATTERNS[\"namespace_path\"].findall(query)\n    if namespace_matches:\n        detected_patterns.append(\"namespace_path\")\n        signal_score += 0.3\n        for m in namespace_matches:\n            parts = m.split(\"::\")\n            if parts:\n                extracted_symbols.add(parts[-1])\n                if len(parts) >= 2:\n                    extracted_symbols.add(\"::\".join(parts[-2:]))\n                extracted_symbols.add(m)\n\n    # Check for generic types\n    generic_matches = _CODE_SIGNAL_PATTERNS[\"generic_type\"].findall(query)\n    if generic_matches:\n        detected_patterns.append(\"generic_type\")\n        signal_score += 0.25\n        for m in generic_matches:\n            base = m.split(\"<\")[0]\n            if base and len(base) > 1:\n                extracted_symbols.add(base)\n\n    # Check for file paths/extensions\n    if _CODE_SIGNAL_PATTERNS[\"file_ext\"].search(query):\n        detected_patterns.append(\"file_ext\")\n        signal_score += 0.2\n\n    if _CODE_SIGNAL_PATTERNS[\"path_like\"].search(query):\n        detected_patterns.append(\"path_like\")\n        signal_score += 0.15\n\n    # Check for interface naming (IFoo)\n    interface_matches = _CODE_SIGNAL_PATTERNS[\"interface_I\"].findall(query)\n    if interface_matches:\n        detected_patterns.append(\"interface_I\")\n        signal_score += 0.3\n        for m in interface_matches:\n            if len(m) > 2:\n                extracted_symbols.add(m)\n\n    # Check for type names\n    type_matches = _CODE_SIGNAL_PATTERNS[\"type_name\"].findall(query)\n    if type_matches:\n        for m in type_matches:\n            if m.lower() not in {\"the\", \"and\", \"for\", \"with\", \"from\", \"this\", \"that\", \"have\", \"been\", \"were\", \"they\"}:\n                if len(m) > 2:\n                    extracted_symbols.add(m)\n        if type_matches and not detected_patterns:\n            signal_score += 0.1\n\n    # Check for code keywords\n    words = set(query_lower.split())\n    keyword_matches = words & _CODE_KEYWORDS\n    if keyword_matches:\n        detected_patterns.append(\"code_keywords\")\n        signal_score += 0.1 * min(len(keyword_matches), 3)\n\n    # Embedding-based intent detection (blended with regex)\n    embedding_score = 0.0\n    if 0.1 <= signal_score <= 0.5:\n        try:\n            embedding_score = _detect_code_intent_embedding(query)\n            if embedding_score > 0.6:\n                detected_patterns.append(\"embedding_code_intent\")\n                blend_weight = 0.4 if signal_score < 0.3 else 0.25\n                signal_score = signal_score * (1 - blend_weight) + embedding_score * blend_weight\n        except Exception:\n            pass\n    elif str(os.environ.get(\"CODE_SIGNAL_EMBEDDING\", \"\")).lower() in {\"1\", \"true\", \"yes\"} and signal_score < 0.1:\n        try:\n            embedding_score = _detect_code_intent_embedding(query)\n            if embedding_score > 0.55:\n                detected_patterns.append(\"embedding_code_intent\")\n                signal_score = embedding_score * 0.6\n        except Exception:\n            pass\n\n    # Cap at 1.0\n    signal_score = min(1.0, signal_score)\n\n    # Build suggested boosts\n    suggested_boosts = {}\n    if signal_score >= 0.25:\n        suggested_boosts[\"symbol_boost_multiplier\"] = 1.0 + signal_score\n        suggested_boosts[\"impl_boost_multiplier\"] = 1.0 + (signal_score * 0.5)\n\n    return {\n        \"has_code_signals\": signal_score >= 0.2,\n        \"signal_strength\": round(signal_score, 2),\n        \"embedding_score\": round(embedding_score, 2) if embedding_score else None,\n        \"extracted_symbols\": sorted(extracted_symbols)[:10],\n        \"detected_patterns\": detected_patterns,\n        \"suggested_boosts\": suggested_boosts,\n    }",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}