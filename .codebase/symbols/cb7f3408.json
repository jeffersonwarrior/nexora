{
  "file_path": "/work/external-deps/Context-Engine/scripts/rerank_train.py",
  "file_hash": "ef265b3f2e3c64e1fd3002da6c06602e6a669094",
  "updated_at": "2025-12-26T17:34:21.630768",
  "symbols": {
    "class_TrainingExample_32": {
      "name": "TrainingExample",
      "type": "class",
      "start_line": 32,
      "end_line": 39,
      "content_hash": "94ae6e497a23c0da545e5361b5f02fcf4b56a690",
      "content": "class TrainingExample:\n    \"\"\"A single training example for pairwise ranking.\"\"\"\n    query: str\n    doc_positive: str  # Should rank higher\n    doc_negative: str  # Should rank lower\n    # Optional: relevance scores for regression loss\n    score_positive: float = 1.0\n    score_negative: float = 0.0",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_TrainingConfig_43": {
      "name": "TrainingConfig",
      "type": "class",
      "start_line": 43,
      "end_line": 54,
      "content_hash": "3d7fca17b6360fef6f537fc0493cc72924e37d0f",
      "content": "class TrainingConfig:\n    \"\"\"Configuration for training.\"\"\"\n    learning_rate: float = 0.001\n    batch_size: int = 32\n    epochs: int = 100\n    margin: float = 0.5  # Margin for pairwise loss\n    n_iterations: int = 3  # Refinement iterations\n    deep_supervision_weight: float = 0.5  # Weight for intermediate losses\n    dim: int = 256\n    hidden_dim: int = 512\n    weight_decay: float = 0.01\n    save_every: int = 10  # Save checkpoint every N epochs",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_SimpleGradientDescent_57": {
      "name": "SimpleGradientDescent",
      "type": "class",
      "start_line": 57,
      "end_line": 90,
      "content_hash": "25bb7133176254154728cf91dda587a251062156",
      "content": "class SimpleGradientDescent:\n    \"\"\"\n    Simple gradient descent optimizer with momentum.\n\n    We implement our own to avoid PyTorch/TensorFlow dependency.\n    \"\"\"\n\n    def __init__(self, lr: float = 0.001, momentum: float = 0.9, weight_decay: float = 0.01):\n        self.lr = lr\n        self.momentum = momentum\n        self.weight_decay = weight_decay\n        self.velocities: Dict[str, np.ndarray] = {}\n\n    def step(self, params: Dict[str, np.ndarray], grads: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Update parameters using gradients.\"\"\"\n        updated = {}\n        for name, param in params.items():\n            if name not in grads:\n                updated[name] = param\n                continue\n\n            grad = grads[name]\n\n            # Weight decay (L2 regularization)\n            grad = grad + self.weight_decay * param\n\n            # Momentum\n            if name not in self.velocities:\n                self.velocities[name] = np.zeros_like(param)\n\n            self.velocities[name] = self.momentum * self.velocities[name] - self.lr * grad\n            updated[name] = param + self.velocities[name]\n\n        return updated",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___init___64": {
      "name": "__init__",
      "type": "method",
      "start_line": 64,
      "end_line": 68,
      "content_hash": "bfb0fe182e344e9283d49da15785291f060979d1",
      "content": "    def __init__(self, lr: float = 0.001, momentum: float = 0.9, weight_decay: float = 0.01):\n        self.lr = lr\n        self.momentum = momentum\n        self.weight_decay = weight_decay\n        self.velocities: Dict[str, np.ndarray] = {}",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_step_70": {
      "name": "step",
      "type": "method",
      "start_line": 70,
      "end_line": 90,
      "content_hash": "070a4730353e07c9a186603f4faf1002f7984f54",
      "content": "    def step(self, params: Dict[str, np.ndarray], grads: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Update parameters using gradients.\"\"\"\n        updated = {}\n        for name, param in params.items():\n            if name not in grads:\n                updated[name] = param\n                continue\n\n            grad = grads[name]\n\n            # Weight decay (L2 regularization)\n            grad = grad + self.weight_decay * param\n\n            # Momentum\n            if name not in self.velocities:\n                self.velocities[name] = np.zeros_like(param)\n\n            self.velocities[name] = self.momentum * self.velocities[name] - self.lr * grad\n            updated[name] = param + self.velocities[name]\n\n        return updated",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_TrainableTinyScorer_93": {
      "name": "TrainableTinyScorer",
      "type": "class",
      "start_line": 93,
      "end_line": 174,
      "content_hash": "93ee036cdb8639f38c2cce3eb09632a7cfd8e1c3",
      "content": "class TrainableTinyScorer:\n    \"\"\"\n    Tiny scorer with gradient computation for training.\n\n    Uses numerical gradients for simplicity (analytical gradients would be faster).\n    \"\"\"\n\n    def __init__(self, dim: int = 256, hidden_dim: int = 512, seed: int = 42):\n        self.dim = dim\n        self.hidden_dim = hidden_dim\n\n        # Initialize weights\n        np.random.seed(seed)\n        scale = np.sqrt(2.0 / (dim * 3))  # He initialization\n        self.params = {\n            \"W1\": np.random.randn(dim * 3, hidden_dim).astype(np.float32) * scale,\n            \"b1\": np.zeros(hidden_dim, dtype=np.float32),\n            \"W2\": np.random.randn(hidden_dim, 1).astype(np.float32) * np.sqrt(2.0 / hidden_dim),\n            \"b2\": np.zeros(1, dtype=np.float32),\n        }\n\n    def forward(self, x: np.ndarray) -> Tuple[np.ndarray, Dict[str, np.ndarray]]:\n        \"\"\"\n        Forward pass with cached activations for backprop.\n\n        x: (batch, dim*3) concatenated [query, doc, latent]\n        returns: (batch,) scores, cache dict\n        \"\"\"\n        # Layer 1: Linear + ReLU\n        z1 = x @ self.params[\"W1\"] + self.params[\"b1\"]  # (batch, hidden)\n        h1 = np.maximum(0, z1)  # ReLU\n\n        # Layer 2: Linear\n        z2 = h1 @ self.params[\"W2\"] + self.params[\"b2\"]  # (batch, 1)\n        scores = z2.squeeze(-1)  # (batch,)\n\n        cache = {\"x\": x, \"z1\": z1, \"h1\": h1}\n        return scores, cache\n\n    def backward(self, dscores: np.ndarray, cache: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"\n        Backward pass to compute gradients.\n\n        dscores: (batch,) gradient of loss w.r.t. scores\n        returns: dict of gradients for each parameter\n        \"\"\"\n        batch_size = dscores.shape[0]\n\n        # Reshape for matrix ops\n        dz2 = dscores.reshape(-1, 1)  # (batch, 1)\n\n        # Layer 2 gradients\n        dW2 = cache[\"h1\"].T @ dz2  # (hidden, 1)\n        db2 = dz2.sum(axis=0)  # (1,)\n        dh1 = dz2 @ self.params[\"W2\"].T  # (batch, hidden)\n\n        # ReLU backward\n        dz1 = dh1 * (cache[\"z1\"] > 0).astype(np.float32)  # (batch, hidden)\n\n        # Layer 1 gradients\n        dW1 = cache[\"x\"].T @ dz1  # (dim*3, hidden)\n        db1 = dz1.sum(axis=0)  # (hidden,)\n\n        # Average over batch\n        grads = {\n            \"W1\": dW1 / batch_size,\n            \"b1\": db1 / batch_size,\n            \"W2\": dW2 / batch_size,\n            \"b2\": db2 / batch_size,\n        }\n        return grads\n\n    def save(self, path: str):\n        \"\"\"Save model weights to file.\"\"\"\n        np.savez(path, **self.params)\n\n    def load(self, path: str):\n        \"\"\"Load model weights from file.\"\"\"\n        data = np.load(path)\n        for key in self.params:\n            if key in data:\n                self.params[key] = data[key]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___init___100": {
      "name": "__init__",
      "type": "method",
      "start_line": 100,
      "end_line": 112,
      "content_hash": "169cba12f8d1edc9fe667cb0864b6b7dc204de8a",
      "content": "    def __init__(self, dim: int = 256, hidden_dim: int = 512, seed: int = 42):\n        self.dim = dim\n        self.hidden_dim = hidden_dim\n\n        # Initialize weights\n        np.random.seed(seed)\n        scale = np.sqrt(2.0 / (dim * 3))  # He initialization\n        self.params = {\n            \"W1\": np.random.randn(dim * 3, hidden_dim).astype(np.float32) * scale,\n            \"b1\": np.zeros(hidden_dim, dtype=np.float32),\n            \"W2\": np.random.randn(hidden_dim, 1).astype(np.float32) * np.sqrt(2.0 / hidden_dim),\n            \"b2\": np.zeros(1, dtype=np.float32),\n        }",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_forward_114": {
      "name": "forward",
      "type": "method",
      "start_line": 114,
      "end_line": 130,
      "content_hash": "06b3426985f00a7b7a208938a013f15c52b97a8f",
      "content": "    def forward(self, x: np.ndarray) -> Tuple[np.ndarray, Dict[str, np.ndarray]]:\n        \"\"\"\n        Forward pass with cached activations for backprop.\n\n        x: (batch, dim*3) concatenated [query, doc, latent]\n        returns: (batch,) scores, cache dict\n        \"\"\"\n        # Layer 1: Linear + ReLU\n        z1 = x @ self.params[\"W1\"] + self.params[\"b1\"]  # (batch, hidden)\n        h1 = np.maximum(0, z1)  # ReLU\n\n        # Layer 2: Linear\n        z2 = h1 @ self.params[\"W2\"] + self.params[\"b2\"]  # (batch, 1)\n        scores = z2.squeeze(-1)  # (batch,)\n\n        cache = {\"x\": x, \"z1\": z1, \"h1\": h1}\n        return scores, cache",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_backward_132": {
      "name": "backward",
      "type": "method",
      "start_line": 132,
      "end_line": 163,
      "content_hash": "5c1e93246d8283339551eae14b0094ee70b951f6",
      "content": "    def backward(self, dscores: np.ndarray, cache: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"\n        Backward pass to compute gradients.\n\n        dscores: (batch,) gradient of loss w.r.t. scores\n        returns: dict of gradients for each parameter\n        \"\"\"\n        batch_size = dscores.shape[0]\n\n        # Reshape for matrix ops\n        dz2 = dscores.reshape(-1, 1)  # (batch, 1)\n\n        # Layer 2 gradients\n        dW2 = cache[\"h1\"].T @ dz2  # (hidden, 1)\n        db2 = dz2.sum(axis=0)  # (1,)\n        dh1 = dz2 @ self.params[\"W2\"].T  # (batch, hidden)\n\n        # ReLU backward\n        dz1 = dh1 * (cache[\"z1\"] > 0).astype(np.float32)  # (batch, hidden)\n\n        # Layer 1 gradients\n        dW1 = cache[\"x\"].T @ dz1  # (dim*3, hidden)\n        db1 = dz1.sum(axis=0)  # (hidden,)\n\n        # Average over batch\n        grads = {\n            \"W1\": dW1 / batch_size,\n            \"b1\": db1 / batch_size,\n            \"W2\": dW2 / batch_size,\n            \"b2\": db2 / batch_size,\n        }\n        return grads",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_save_165": {
      "name": "save",
      "type": "method",
      "start_line": 165,
      "end_line": 167,
      "content_hash": "8612a35947a093f56c651ff8b544a9b943ea59be",
      "content": "    def save(self, path: str):\n        \"\"\"Save model weights to file.\"\"\"\n        np.savez(path, **self.params)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_load_169": {
      "name": "load",
      "type": "method",
      "start_line": 169,
      "end_line": 174,
      "content_hash": "afba6a5cb0ce60f288e4f8f5f8f9c965cdfc7904",
      "content": "    def load(self, path: str):\n        \"\"\"Load model weights from file.\"\"\"\n        data = np.load(path)\n        for key in self.params:\n            if key in data:\n                self.params[key] = data[key]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_TrainableLatentRefiner_177": {
      "name": "TrainableLatentRefiner",
      "type": "class",
      "start_line": 177,
      "end_line": 210,
      "content_hash": "1a78443d036b12e5239c521d3ca3970e25a244ef",
      "content": "class TrainableLatentRefiner:\n    \"\"\"Latent refiner with gradient support.\"\"\"\n\n    def __init__(self, dim: int = 256, hidden_dim: int = 256, seed: int = 43):\n        self.dim = dim\n        self.hidden_dim = hidden_dim\n\n        np.random.seed(seed)\n        scale = np.sqrt(2.0 / (dim * 3))\n        self.params = {\n            \"W1\": np.random.randn(dim * 3, hidden_dim).astype(np.float32) * scale,\n            \"b1\": np.zeros(hidden_dim, dtype=np.float32),\n            \"W2\": np.random.randn(hidden_dim, dim).astype(np.float32) * np.sqrt(2.0 / hidden_dim),\n            \"b2\": np.zeros(dim, dtype=np.float32),\n        }\n\n    def forward(self, z: np.ndarray, query: np.ndarray, doc_summary: np.ndarray, alpha: float = 0.5) -> np.ndarray:\n        \"\"\"Refine latent state.\"\"\"\n        x = np.concatenate([z, query, doc_summary], axis=-1)\n        h = np.maximum(0, x @ self.params[\"W1\"] + self.params[\"b1\"])\n        z_new = h @ self.params[\"W2\"] + self.params[\"b2\"]\n        z_refined = alpha * z_new + (1 - alpha) * z\n        # Normalize\n        norm = np.linalg.norm(z_refined, axis=-1, keepdims=True) + 1e-8\n        return z_refined / norm\n\n    def save(self, path: str):\n        np.savez(path, **self.params)\n\n    def load(self, path: str):\n        data = np.load(path)\n        for key in self.params:\n            if key in data:\n                self.params[key] = data[key]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___init___180": {
      "name": "__init__",
      "type": "method",
      "start_line": 180,
      "end_line": 191,
      "content_hash": "e228c8478947ea914d13c5de393e59146abf56df",
      "content": "    def __init__(self, dim: int = 256, hidden_dim: int = 256, seed: int = 43):\n        self.dim = dim\n        self.hidden_dim = hidden_dim\n\n        np.random.seed(seed)\n        scale = np.sqrt(2.0 / (dim * 3))\n        self.params = {\n            \"W1\": np.random.randn(dim * 3, hidden_dim).astype(np.float32) * scale,\n            \"b1\": np.zeros(hidden_dim, dtype=np.float32),\n            \"W2\": np.random.randn(hidden_dim, dim).astype(np.float32) * np.sqrt(2.0 / hidden_dim),\n            \"b2\": np.zeros(dim, dtype=np.float32),\n        }",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_forward_193": {
      "name": "forward",
      "type": "method",
      "start_line": 193,
      "end_line": 201,
      "content_hash": "145bab5a38f5c7d96a7bf4729d8f009ecd74135c",
      "content": "    def forward(self, z: np.ndarray, query: np.ndarray, doc_summary: np.ndarray, alpha: float = 0.5) -> np.ndarray:\n        \"\"\"Refine latent state.\"\"\"\n        x = np.concatenate([z, query, doc_summary], axis=-1)\n        h = np.maximum(0, x @ self.params[\"W1\"] + self.params[\"b1\"])\n        z_new = h @ self.params[\"W2\"] + self.params[\"b2\"]\n        z_refined = alpha * z_new + (1 - alpha) * z\n        # Normalize\n        norm = np.linalg.norm(z_refined, axis=-1, keepdims=True) + 1e-8\n        return z_refined / norm",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_save_203": {
      "name": "save",
      "type": "method",
      "start_line": 203,
      "end_line": 204,
      "content_hash": "17d51fa4cb5f84d6be56c66629ff1db52dd764be",
      "content": "    def save(self, path: str):\n        np.savez(path, **self.params)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_load_206": {
      "name": "load",
      "type": "method",
      "start_line": 206,
      "end_line": 210,
      "content_hash": "c70e9eac3214b9b0af998bedf9d88922af8f316c",
      "content": "    def load(self, path: str):\n        data = np.load(path)\n        for key in self.params:\n            if key in data:\n                self.params[key] = data[key]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_margin_ranking_loss_213": {
      "name": "margin_ranking_loss",
      "type": "function",
      "start_line": 213,
      "end_line": 230,
      "content_hash": "2067b52a66033679540e80e92eea7e830a1ce6b5",
      "content": "def margin_ranking_loss(score_pos: np.ndarray, score_neg: np.ndarray, margin: float = 0.5) -> Tuple[float, np.ndarray, np.ndarray]:\n    \"\"\"\n    Pairwise margin ranking loss.\n\n    Loss = max(0, margin - (score_pos - score_neg))\n\n    Returns: (loss_value, grad_pos, grad_neg)\n    \"\"\"\n    diff = score_pos - score_neg\n    violations = margin - diff\n    loss = np.maximum(0, violations)\n\n    # Gradient: -1 for pos, +1 for neg when violating\n    mask = (violations > 0).astype(np.float32)\n    grad_pos = -mask\n    grad_neg = mask\n\n    return loss.mean(), grad_pos, grad_neg",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_deep_supervision_loss_233": {
      "name": "deep_supervision_loss",
      "type": "function",
      "start_line": 233,
      "end_line": 268,
      "content_hash": "ba3792a3de7875f82a8f02f13e03fd3f8bb299b6",
      "content": "def deep_supervision_loss(\n    scores_per_iter: List[np.ndarray],\n    labels: np.ndarray,\n    weight: float = 0.5\n) -> Tuple[float, List[np.ndarray]]:\n    \"\"\"\n    Deep supervision: compute loss at each iteration.\n\n    From TRM paper: train model to improve answer at each step.\n    Later iterations get higher weight.\n\n    scores_per_iter: List of (batch,) score arrays, one per iteration\n    labels: (batch,) ground truth relevance\n    weight: how much to weight intermediate losses vs final\n\n    Returns: (total_loss, list of gradients per iteration)\n    \"\"\"\n    n_iters = len(scores_per_iter)\n    total_loss = 0.0\n    grads = []\n\n    for i, scores in enumerate(scores_per_iter):\n        # Later iterations get higher weight\n        iter_weight = (i + 1) / n_iters\n        if i < n_iters - 1:\n            iter_weight *= weight\n\n        # MSE loss for simplicity\n        diff = scores - labels\n        loss = (diff ** 2).mean()\n        grad = 2 * diff / len(diff) * iter_weight\n\n        total_loss += loss * iter_weight\n        grads.append(grad)\n\n    return total_loss, grads",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_RecursiveRerankerTrainer_271": {
      "name": "RecursiveRerankerTrainer",
      "type": "class",
      "start_line": 271,
      "end_line": 437,
      "content_hash": "76e77aeb9b71ba9efc77d2d3f7e7fcf5cb36b540",
      "content": "class RecursiveRerankerTrainer:\n    \"\"\"\n    Trainer for the recursive reranker with deep supervision.\n    \"\"\"\n\n    def __init__(self, config: TrainingConfig):\n        self.config = config\n\n        # Initialize models\n        self.scorer = TrainableTinyScorer(dim=config.dim, hidden_dim=config.hidden_dim)\n        self.refiner = TrainableLatentRefiner(dim=config.dim)\n\n        # Optimizers\n        self.scorer_opt = SimpleGradientDescent(\n            lr=config.learning_rate, weight_decay=config.weight_decay\n        )\n        self.refiner_opt = SimpleGradientDescent(\n            lr=config.learning_rate, weight_decay=config.weight_decay\n        )\n\n        # Training state\n        self.epoch = 0\n        self.losses: List[float] = []\n\n    def _encode_text(self, texts: List[str]) -> np.ndarray:\n        \"\"\"Simple bag-of-chars encoding (placeholder for real embeddings).\"\"\"\n        result = []\n        for text in texts:\n            # Hash-based pseudo-embedding\n            np.random.seed(hash(text) % (2**32))\n            vec = np.random.randn(self.config.dim).astype(np.float32)\n            vec = vec / (np.linalg.norm(vec) + 1e-8)\n            result.append(vec)\n        return np.array(result, dtype=np.float32)\n\n    def train_step(self, examples: List[TrainingExample]) -> float:\n        \"\"\"Single training step on a batch of examples.\"\"\"\n        batch_size = len(examples)\n\n        # Encode texts\n        queries = self._encode_text([ex.query for ex in examples])\n        docs_pos = self._encode_text([ex.doc_positive for ex in examples])\n        docs_neg = self._encode_text([ex.doc_negative for ex in examples])\n\n        # Initialize latent states\n        z_pos = queries.copy()\n        z_neg = queries.copy()\n\n        # Collect scores per iteration for deep supervision\n        scores_pos_per_iter = []\n        scores_neg_per_iter = []\n        caches_pos = []\n        caches_neg = []\n\n        # Forward pass through all iterations\n        for i in range(self.config.n_iterations):\n            # Score positive docs\n            x_pos = np.concatenate([queries, docs_pos, z_pos], axis=1)\n            s_pos, cache_pos = self.scorer.forward(x_pos)\n            scores_pos_per_iter.append(s_pos)\n            caches_pos.append(cache_pos)\n\n            # Score negative docs\n            x_neg = np.concatenate([queries, docs_neg, z_neg], axis=1)\n            s_neg, cache_neg = self.scorer.forward(x_neg)\n            scores_neg_per_iter.append(s_neg)\n            caches_neg.append(cache_neg)\n\n            # Refine latent states\n            if i < self.config.n_iterations - 1:\n                z_pos = self.refiner.forward(z_pos, queries, docs_pos)\n                z_neg = self.refiner.forward(z_neg, queries, docs_neg)\n\n        # Compute loss with deep supervision\n        total_loss = 0.0\n        scorer_grads_accumulated = {k: np.zeros_like(v) for k, v in self.scorer.params.items()}\n\n        for i in range(self.config.n_iterations):\n            # Pairwise margin loss at each iteration\n            iter_weight = (i + 1) / self.config.n_iterations\n            if i < self.config.n_iterations - 1:\n                iter_weight *= self.config.deep_supervision_weight\n\n            loss, grad_pos, grad_neg = margin_ranking_loss(\n                scores_pos_per_iter[i],\n                scores_neg_per_iter[i],\n                self.config.margin\n            )\n            total_loss += loss * iter_weight\n\n            # Backprop through scorer\n            grads_pos = self.scorer.backward(grad_pos * iter_weight, caches_pos[i])\n            grads_neg = self.scorer.backward(grad_neg * iter_weight, caches_neg[i])\n\n            for k in scorer_grads_accumulated:\n                scorer_grads_accumulated[k] += grads_pos[k] + grads_neg[k]\n\n        # Update scorer parameters\n        self.scorer.params = self.scorer_opt.step(self.scorer.params, scorer_grads_accumulated)\n\n        return total_loss\n\n    def train(self, examples: List[TrainingExample], val_examples: Optional[List[TrainingExample]] = None):\n        \"\"\"Full training loop.\"\"\"\n        n_batches = (len(examples) + self.config.batch_size - 1) // self.config.batch_size\n\n        for epoch in range(self.config.epochs):\n            self.epoch = epoch\n            epoch_loss = 0.0\n\n            # Shuffle examples\n            indices = np.random.permutation(len(examples))\n\n            for batch_idx in range(n_batches):\n                start = batch_idx * self.config.batch_size\n                end = min(start + self.config.batch_size, len(examples))\n                batch_indices = indices[start:end]\n                batch = [examples[i] for i in batch_indices]\n\n                loss = self.train_step(batch)\n                epoch_loss += loss\n\n            epoch_loss /= n_batches\n            self.losses.append(epoch_loss)\n\n            # Logging\n            if epoch % 10 == 0:\n                print(f\"Epoch {epoch}: loss={epoch_loss:.4f}\")\n\n            # Save checkpoint\n            if (epoch + 1) % self.config.save_every == 0:\n                self.save_checkpoint(f\"checkpoint_epoch_{epoch+1}\")\n\n    def save_checkpoint(self, name: str):\n        \"\"\"Save model checkpoint.\"\"\"\n        save_dir = Path(\"models/rerank_recursive\")\n        save_dir.mkdir(parents=True, exist_ok=True)\n\n        self.scorer.save(str(save_dir / f\"{name}_scorer.npz\"))\n        self.refiner.save(str(save_dir / f\"{name}_refiner.npz\"))\n\n        # Save training state\n        state = {\n            \"epoch\": self.epoch,\n            \"losses\": self.losses,\n            \"config\": {\n                \"dim\": self.config.dim,\n                \"hidden_dim\": self.config.hidden_dim,\n                \"n_iterations\": self.config.n_iterations,\n            }\n        }\n        with open(save_dir / f\"{name}_state.json\", \"w\") as f:\n            json.dump(state, f)\n\n        print(f\"Saved checkpoint: {name}\")\n\n    def load_checkpoint(self, name: str):\n        \"\"\"Load model checkpoint.\"\"\"\n        save_dir = Path(\"models/rerank_recursive\")\n        self.scorer.load(str(save_dir / f\"{name}_scorer.npz\"))\n        self.refiner.load(str(save_dir / f\"{name}_refiner.npz\"))\n\n        with open(save_dir / f\"{name}_state.json\") as f:\n            state = json.load(f)\n        self.epoch = state[\"epoch\"]\n        self.losses = state[\"losses\"]\n        print(f\"Loaded checkpoint: {name}\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___init___276": {
      "name": "__init__",
      "type": "method",
      "start_line": 276,
      "end_line": 293,
      "content_hash": "d8e72653ca994ddf59b2dccc33753436f51ff4a1",
      "content": "    def __init__(self, config: TrainingConfig):\n        self.config = config\n\n        # Initialize models\n        self.scorer = TrainableTinyScorer(dim=config.dim, hidden_dim=config.hidden_dim)\n        self.refiner = TrainableLatentRefiner(dim=config.dim)\n\n        # Optimizers\n        self.scorer_opt = SimpleGradientDescent(\n            lr=config.learning_rate, weight_decay=config.weight_decay\n        )\n        self.refiner_opt = SimpleGradientDescent(\n            lr=config.learning_rate, weight_decay=config.weight_decay\n        )\n\n        # Training state\n        self.epoch = 0\n        self.losses: List[float] = []",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__encode_text_295": {
      "name": "_encode_text",
      "type": "method",
      "start_line": 295,
      "end_line": 304,
      "content_hash": "2dab61ecb60e6098322deb08cfe9c321a90a80c8",
      "content": "    def _encode_text(self, texts: List[str]) -> np.ndarray:\n        \"\"\"Simple bag-of-chars encoding (placeholder for real embeddings).\"\"\"\n        result = []\n        for text in texts:\n            # Hash-based pseudo-embedding\n            np.random.seed(hash(text) % (2**32))\n            vec = np.random.randn(self.config.dim).astype(np.float32)\n            vec = vec / (np.linalg.norm(vec) + 1e-8)\n            result.append(vec)\n        return np.array(result, dtype=np.float32)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_train_step_306": {
      "name": "train_step",
      "type": "method",
      "start_line": 306,
      "end_line": 371,
      "content_hash": "72c54dee7545e3cb7a57b95aadf9ed3aa0f2f649",
      "content": "    def train_step(self, examples: List[TrainingExample]) -> float:\n        \"\"\"Single training step on a batch of examples.\"\"\"\n        batch_size = len(examples)\n\n        # Encode texts\n        queries = self._encode_text([ex.query for ex in examples])\n        docs_pos = self._encode_text([ex.doc_positive for ex in examples])\n        docs_neg = self._encode_text([ex.doc_negative for ex in examples])\n\n        # Initialize latent states\n        z_pos = queries.copy()\n        z_neg = queries.copy()\n\n        # Collect scores per iteration for deep supervision\n        scores_pos_per_iter = []\n        scores_neg_per_iter = []\n        caches_pos = []\n        caches_neg = []\n\n        # Forward pass through all iterations\n        for i in range(self.config.n_iterations):\n            # Score positive docs\n            x_pos = np.concatenate([queries, docs_pos, z_pos], axis=1)\n            s_pos, cache_pos = self.scorer.forward(x_pos)\n            scores_pos_per_iter.append(s_pos)\n            caches_pos.append(cache_pos)\n\n            # Score negative docs\n            x_neg = np.concatenate([queries, docs_neg, z_neg], axis=1)\n            s_neg, cache_neg = self.scorer.forward(x_neg)\n            scores_neg_per_iter.append(s_neg)\n            caches_neg.append(cache_neg)\n\n            # Refine latent states\n            if i < self.config.n_iterations - 1:\n                z_pos = self.refiner.forward(z_pos, queries, docs_pos)\n                z_neg = self.refiner.forward(z_neg, queries, docs_neg)\n\n        # Compute loss with deep supervision\n        total_loss = 0.0\n        scorer_grads_accumulated = {k: np.zeros_like(v) for k, v in self.scorer.params.items()}\n\n        for i in range(self.config.n_iterations):\n            # Pairwise margin loss at each iteration\n            iter_weight = (i + 1) / self.config.n_iterations\n            if i < self.config.n_iterations - 1:\n                iter_weight *= self.config.deep_supervision_weight\n\n            loss, grad_pos, grad_neg = margin_ranking_loss(\n                scores_pos_per_iter[i],\n                scores_neg_per_iter[i],\n                self.config.margin\n            )\n            total_loss += loss * iter_weight\n\n            # Backprop through scorer\n            grads_pos = self.scorer.backward(grad_pos * iter_weight, caches_pos[i])\n            grads_neg = self.scorer.backward(grad_neg * iter_weight, caches_neg[i])\n\n            for k in scorer_grads_accumulated:\n                scorer_grads_accumulated[k] += grads_pos[k] + grads_neg[k]\n\n        # Update scorer parameters\n        self.scorer.params = self.scorer_opt.step(self.scorer.params, scorer_grads_accumulated)\n\n        return total_loss",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_train_373": {
      "name": "train",
      "type": "method",
      "start_line": 373,
      "end_line": 402,
      "content_hash": "2ee3fd1825c7140fd77284433dd4a049e6e2351f",
      "content": "    def train(self, examples: List[TrainingExample], val_examples: Optional[List[TrainingExample]] = None):\n        \"\"\"Full training loop.\"\"\"\n        n_batches = (len(examples) + self.config.batch_size - 1) // self.config.batch_size\n\n        for epoch in range(self.config.epochs):\n            self.epoch = epoch\n            epoch_loss = 0.0\n\n            # Shuffle examples\n            indices = np.random.permutation(len(examples))\n\n            for batch_idx in range(n_batches):\n                start = batch_idx * self.config.batch_size\n                end = min(start + self.config.batch_size, len(examples))\n                batch_indices = indices[start:end]\n                batch = [examples[i] for i in batch_indices]\n\n                loss = self.train_step(batch)\n                epoch_loss += loss\n\n            epoch_loss /= n_batches\n            self.losses.append(epoch_loss)\n\n            # Logging\n            if epoch % 10 == 0:\n                print(f\"Epoch {epoch}: loss={epoch_loss:.4f}\")\n\n            # Save checkpoint\n            if (epoch + 1) % self.config.save_every == 0:\n                self.save_checkpoint(f\"checkpoint_epoch_{epoch+1}\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_save_checkpoint_404": {
      "name": "save_checkpoint",
      "type": "method",
      "start_line": 404,
      "end_line": 425,
      "content_hash": "1bb13fbefa279b39dbd79cebe6f085cdff7df123",
      "content": "    def save_checkpoint(self, name: str):\n        \"\"\"Save model checkpoint.\"\"\"\n        save_dir = Path(\"models/rerank_recursive\")\n        save_dir.mkdir(parents=True, exist_ok=True)\n\n        self.scorer.save(str(save_dir / f\"{name}_scorer.npz\"))\n        self.refiner.save(str(save_dir / f\"{name}_refiner.npz\"))\n\n        # Save training state\n        state = {\n            \"epoch\": self.epoch,\n            \"losses\": self.losses,\n            \"config\": {\n                \"dim\": self.config.dim,\n                \"hidden_dim\": self.config.hidden_dim,\n                \"n_iterations\": self.config.n_iterations,\n            }\n        }\n        with open(save_dir / f\"{name}_state.json\", \"w\") as f:\n            json.dump(state, f)\n\n        print(f\"Saved checkpoint: {name}\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_load_checkpoint_427": {
      "name": "load_checkpoint",
      "type": "method",
      "start_line": 427,
      "end_line": 437,
      "content_hash": "a57da15f8220083bd27ee6a64d2a206d81caed0a",
      "content": "    def load_checkpoint(self, name: str):\n        \"\"\"Load model checkpoint.\"\"\"\n        save_dir = Path(\"models/rerank_recursive\")\n        self.scorer.load(str(save_dir / f\"{name}_scorer.npz\"))\n        self.refiner.load(str(save_dir / f\"{name}_refiner.npz\"))\n\n        with open(save_dir / f\"{name}_state.json\") as f:\n            state = json.load(f)\n        self.epoch = state[\"epoch\"]\n        self.losses = state[\"losses\"]\n        print(f\"Loaded checkpoint: {name}\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_generate_synthetic_data_441": {
      "name": "generate_synthetic_data",
      "type": "function",
      "start_line": 441,
      "end_line": 512,
      "content_hash": "f42e765be34a2006c703daf2e018e85518864314",
      "content": "def generate_synthetic_data(n_examples: int = 1000, output_path: str = \"data/rerank_train.jsonl\"):\n    \"\"\"\n    Generate synthetic training data for the reranker.\n\n    Creates pairwise examples where:\n    - Positive doc contains query terms\n    - Negative doc is unrelated\n    \"\"\"\n    # Code-like queries and documents\n    queries = [\n        \"hybrid search implementation\",\n        \"recursive reranker training\",\n        \"embedding model initialization\",\n        \"cache manager eviction policy\",\n        \"file watcher debounce\",\n        \"MCP server tool registration\",\n        \"vector similarity search\",\n        \"document indexing pipeline\",\n        \"query expansion techniques\",\n        \"relevance scoring function\",\n    ]\n\n    positive_templates = [\n        \"def {keyword}(query): # Implements {keyword} for search\",\n        \"class {Keyword}Manager: # Handles {keyword} operations\",\n        \"async def run_{keyword}(): # Execute {keyword} pipeline\",\n        \"# {keyword} configuration and setup\\nconfig = load_{keyword}_config()\",\n        \"def test_{keyword}(): # Unit tests for {keyword}\",\n    ]\n\n    negative_templates = [\n        \"def unrelated_function(): return 42\",\n        \"class DatabaseConnection: # Connect to database\",\n        \"import os, sys, json  # Standard imports\",\n        \"# Configuration file for logging\\nLOG_LEVEL = 'INFO'\",\n        \"def helper_util(): pass  # Utility function\",\n    ]\n\n    examples = []\n\n    for i in range(n_examples):\n        # Pick a query\n        query = queries[i % len(queries)]\n        keyword = query.split()[0].lower()\n        Keyword = keyword.capitalize()\n\n        # Generate positive doc (contains query terms)\n        pos_template = positive_templates[i % len(positive_templates)]\n        pos_doc = pos_template.format(keyword=keyword, Keyword=Keyword)\n\n        # Generate negative doc (unrelated)\n        neg_doc = negative_templates[i % len(negative_templates)]\n\n        example = {\n            \"query\": query,\n            \"doc_positive\": pos_doc,\n            \"doc_negative\": neg_doc,\n            \"score_positive\": 1.0,\n            \"score_negative\": 0.0,\n        }\n        examples.append(example)\n\n    # Save to file\n    output_path = Path(output_path)\n    output_path.parent.mkdir(parents=True, exist_ok=True)\n\n    with open(output_path, \"w\") as f:\n        for ex in examples:\n            f.write(json.dumps(ex) + \"\\n\")\n\n    print(f\"Generated {n_examples} training examples -> {output_path}\")\n    return examples",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_load_training_data_515": {
      "name": "load_training_data",
      "type": "function",
      "start_line": 515,
      "end_line": 528,
      "content_hash": "712b4d2f789cec28d01542fd474f8ca7b45a7c63",
      "content": "def load_training_data(path: str) -> List[TrainingExample]:\n    \"\"\"Load training examples from JSONL file.\"\"\"\n    examples = []\n    with open(path) as f:\n        for line in f:\n            data = json.loads(line)\n            examples.append(TrainingExample(\n                query=data[\"query\"],\n                doc_positive=data[\"doc_positive\"],\n                doc_negative=data[\"doc_negative\"],\n                score_positive=data.get(\"score_positive\", 1.0),\n                score_negative=data.get(\"score_negative\", 0.0),\n            ))\n    return examples",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_export_trained_weights_531": {
      "name": "export_trained_weights",
      "type": "function",
      "start_line": 531,
      "end_line": 555,
      "content_hash": "5755aa3c6c851703249422c6c3b56d5a36bf25aa",
      "content": "def export_trained_weights(checkpoint_name: str, output_dir: str = \"models/rerank_recursive\"):\n    \"\"\"\n    Export trained weights to the rerank_recursive module.\n\n    Copies the .npz files to where RecursiveReranker can load them.\n    \"\"\"\n    import shutil\n\n    src_dir = Path(\"models/rerank_recursive\")\n    dst_dir = Path(output_dir)\n    dst_dir.mkdir(parents=True, exist_ok=True)\n\n    # Copy scorer weights\n    scorer_src = src_dir / f\"{checkpoint_name}_scorer.npz\"\n    scorer_dst = dst_dir / \"scorer_weights.npz\"\n    if scorer_src.exists():\n        shutil.copy(scorer_src, scorer_dst)\n        print(f\"Exported scorer weights -> {scorer_dst}\")\n\n    # Copy refiner weights\n    refiner_src = src_dir / f\"{checkpoint_name}_refiner.npz\"\n    refiner_dst = dst_dir / \"refiner_weights.npz\"\n    if refiner_src.exists():\n        shutil.copy(refiner_src, refiner_dst)\n        print(f\"Exported refiner weights -> {refiner_dst}\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_main_558": {
      "name": "main",
      "type": "function",
      "start_line": 558,
      "end_line": 656,
      "content_hash": "e03e1cfe2fda468bb7660ba18d6121fe1c87b714",
      "content": "def main():\n    parser = argparse.ArgumentParser(description=\"Train Tiny Recursive Reranker\")\n    parser.add_argument(\"--generate-data\", action=\"store_true\", help=\"Generate synthetic training data\")\n    parser.add_argument(\"--train\", action=\"store_true\", help=\"Train the model\")\n    parser.add_argument(\"--evaluate\", action=\"store_true\", help=\"Evaluate the model\")\n    parser.add_argument(\"--export\", type=str, help=\"Export checkpoint weights\")\n    parser.add_argument(\"--data\", type=str, default=\"data/rerank_train.jsonl\", help=\"Training data path\")\n    parser.add_argument(\"--output\", type=str, default=\"data/rerank_train.jsonl\", help=\"Output path for generated data\")\n    parser.add_argument(\"--n-examples\", type=int, default=1000, help=\"Number of examples to generate\")\n    parser.add_argument(\"--epochs\", type=int, default=100, help=\"Training epochs\")\n    parser.add_argument(\"--lr\", type=float, default=0.001, help=\"Learning rate\")\n    parser.add_argument(\"--batch-size\", type=int, default=32, help=\"Batch size\")\n    parser.add_argument(\"--checkpoint\", type=str, help=\"Checkpoint to load/export\")\n\n    args = parser.parse_args()\n\n    if args.generate_data:\n        generate_synthetic_data(n_examples=args.n_examples, output_path=args.output)\n\n    elif args.train:\n        # Load data\n        if not Path(args.data).exists():\n            print(f\"Training data not found: {args.data}\")\n            print(\"Run with --generate-data first\")\n            return\n\n        examples = load_training_data(args.data)\n        print(f\"Loaded {len(examples)} training examples\")\n\n        # Create trainer\n        config = TrainingConfig(\n            epochs=args.epochs,\n            learning_rate=args.lr,\n            batch_size=args.batch_size,\n        )\n        trainer = RecursiveRerankerTrainer(config)\n\n        # Load checkpoint if specified\n        if args.checkpoint:\n            try:\n                trainer.load_checkpoint(args.checkpoint)\n            except Exception as e:\n                print(f\"Could not load checkpoint: {e}\")\n\n        # Train\n        trainer.train(examples)\n        trainer.save_checkpoint(\"final\")\n        print(\"Training complete!\")\n\n    elif args.export:\n        export_trained_weights(args.export or \"final\")\n\n    elif args.evaluate:\n        if not Path(args.data).exists():\n            print(f\"Evaluation data not found: {args.data}\")\n            return\n\n        examples = load_training_data(args.data)\n\n        # Load trained model\n        config = TrainingConfig()\n        trainer = RecursiveRerankerTrainer(config)\n\n        try:\n            trainer.load_checkpoint(args.checkpoint or \"final\")\n        except Exception as e:\n            print(f\"Could not load checkpoint: {e}\")\n            print(\"Training with random weights...\")\n\n        # Evaluate: compute accuracy (positive > negative)\n        correct = 0\n        total = 0\n\n        for ex in examples[:100]:  # Sample\n            q = trainer._encode_text([ex.query])[0]\n            d_pos = trainer._encode_text([ex.doc_positive])[0]\n            d_neg = trainer._encode_text([ex.doc_negative])[0]\n\n            z = q.copy()\n\n            # Run through iterations\n            for _ in range(config.n_iterations):\n                x_pos = np.concatenate([q, d_pos, z])\n                x_neg = np.concatenate([q, d_neg, z])\n\n                s_pos, _ = trainer.scorer.forward(x_pos.reshape(1, -1))\n                s_neg, _ = trainer.scorer.forward(x_neg.reshape(1, -1))\n\n                z = trainer.refiner.forward(z.reshape(1, -1), q.reshape(1, -1), d_pos.reshape(1, -1))[0]\n\n            if s_pos[0] > s_neg[0]:\n                correct += 1\n            total += 1\n\n        accuracy = correct / total if total > 0 else 0\n        print(f\"Pairwise accuracy: {accuracy:.2%} ({correct}/{total})\")\n\n    else:\n        parser.print_help()",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}