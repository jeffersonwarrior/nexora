{
  "file_path": "/work/internal/mcp/zai/vision.go",
  "file_hash": "0b26a89d4e9669e12ddbc22c064b3ab2718c4265",
  "updated_at": "2025-12-26T17:34:21.816489",
  "symbols": {
    "struct_VisionResponse_12": {
      "name": "VisionResponse",
      "type": "struct",
      "start_line": 12,
      "end_line": 19,
      "content_hash": "0422f2b960fb9a522ec13e507c88a981bbc04a0f",
      "content": "type VisionResponse struct {\n\tContent   string `json:\"content\"`\n\tData      []byte `json:\"data,omitempty\"`\n\tMediaType string `json:\"media_type,omitempty\"`\n\tType      string `json:\"type\"`\n}\n\n// AnalyzeDataVisualization performs data visualization analysis",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_AnalyzeDataVisualization_20": {
      "name": "AnalyzeDataVisualization",
      "type": "method",
      "start_line": 20,
      "end_line": 30,
      "content_hash": "23d7901b7f091e56ddda715ef06ca705baad4378",
      "content": "func (c *Client) AnalyzeDataVisualization(ctx context.Context, imageSource, analysisFocus, prompt string) (*VisionResponse, error) {\n\targuments := map[string]interface{}{\n\t\t\"image_source\":   imageSource,\n\t\t\"analysis_focus\": analysisFocus,\n\t\t\"prompt\":         prompt,\n\t}\n\n\treturn c.executeVisionTool(ctx, \"mcp_vision_analyze_data_visualization\", arguments)\n}\n\n// AnalyzeImage performs general-purpose image analysis",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_AnalyzeImage_31": {
      "name": "AnalyzeImage",
      "type": "method",
      "start_line": 31,
      "end_line": 40,
      "content_hash": "9f3e1f2e08a8046423131ded31dbb3ad5ac9bf15",
      "content": "func (c *Client) AnalyzeImage(ctx context.Context, imageSource, prompt string) (*VisionResponse, error) {\n\targuments := map[string]interface{}{\n\t\t\"image_source\": imageSource,\n\t\t\"prompt\":       prompt,\n\t}\n\n\treturn c.executeVisionTool(ctx, \"mcp_vision_analyze_image\", arguments)\n}\n\n// ExtractTextFromScreenshot performs OCR on screenshots",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_ExtractTextFromScreenshot_41": {
      "name": "ExtractTextFromScreenshot",
      "type": "method",
      "start_line": 41,
      "end_line": 51,
      "content_hash": "4ba4c970e5e28da3bf0a8342455bc598debcb131",
      "content": "func (c *Client) ExtractTextFromScreenshot(ctx context.Context, imageSource, programmingLanguage, prompt string) (*VisionResponse, error) {\n\targuments := map[string]interface{}{\n\t\t\"image_source\":         imageSource,\n\t\t\"programming_language\": programmingLanguage,\n\t\t\"prompt\":               prompt,\n\t}\n\n\treturn c.executeVisionTool(ctx, \"mcp_vision_extract_text_from_screenshot\", arguments)\n}\n\n// UIToArtifact converts UI screenshots to various artifacts",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_UIToArtifact_52": {
      "name": "UIToArtifact",
      "type": "method",
      "start_line": 52,
      "end_line": 62,
      "content_hash": "b4deab4f03105c9305697d01a6a997ae2c309e70",
      "content": "func (c *Client) UIToArtifact(ctx context.Context, imageSource, outputType, prompt string) (*VisionResponse, error) {\n\targuments := map[string]interface{}{\n\t\t\"image_source\": imageSource,\n\t\t\"output_type\":  outputType,\n\t\t\"prompt\":       prompt,\n\t}\n\n\treturn c.executeVisionTool(ctx, \"mcp_vision_ui_to_artifact\", arguments)\n}\n\n// DiagnoseErrorScreenshot analyzes error screenshots",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_DiagnoseErrorScreenshot_63": {
      "name": "DiagnoseErrorScreenshot",
      "type": "method",
      "start_line": 63,
      "end_line": 73,
      "content_hash": "2adbe6b440fc2459055d97c58a82cdab9202d211",
      "content": "func (c *Client) DiagnoseErrorScreenshot(ctx context.Context, imageSource, context, prompt string) (*VisionResponse, error) {\n\targuments := map[string]interface{}{\n\t\t\"image_source\": imageSource,\n\t\t\"context\":      context,\n\t\t\"prompt\":       prompt,\n\t}\n\n\treturn c.executeVisionTool(ctx, \"mcp_vision_diagnose_error_screenshot\", arguments)\n}\n\n// UnderstandTechnicalDiagram analyzes technical diagrams",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_UnderstandTechnicalDiagram_74": {
      "name": "UnderstandTechnicalDiagram",
      "type": "method",
      "start_line": 74,
      "end_line": 84,
      "content_hash": "8f3ac06c84192c41bec0a21af143bc70cb5f157f",
      "content": "func (c *Client) UnderstandTechnicalDiagram(ctx context.Context, imageSource, diagramType, prompt string) (*VisionResponse, error) {\n\targuments := map[string]interface{}{\n\t\t\"image_source\": imageSource,\n\t\t\"diagram_type\": diagramType,\n\t\t\"prompt\":       prompt,\n\t}\n\n\treturn c.executeVisionTool(ctx, \"mcp_vision_understand_technical_diagram\", arguments)\n}\n\n// UIDiffCheck compares two UI screenshots",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_UIDiffCheck_85": {
      "name": "UIDiffCheck",
      "type": "method",
      "start_line": 85,
      "end_line": 95,
      "content_hash": "367b8cb6497815ba30c64ec0401d5135debd1cd3",
      "content": "func (c *Client) UIDiffCheck(ctx context.Context, expectedImageSource, actualImageSource, prompt string) (*VisionResponse, error) {\n\targuments := map[string]interface{}{\n\t\t\"expected_image_source\": expectedImageSource,\n\t\t\"actual_image_source\":   actualImageSource,\n\t\t\"prompt\":                prompt,\n\t}\n\n\treturn c.executeVisionTool(ctx, \"mcp_vision_ui_diff_check\", arguments)\n}\n\n// AnalyzeVideo performs video content analysis",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_AnalyzeVideo_96": {
      "name": "AnalyzeVideo",
      "type": "method",
      "start_line": 96,
      "end_line": 105,
      "content_hash": "c06910ef4ff0c2ea5657a9c2a0cca1304eca0c2f",
      "content": "func (c *Client) AnalyzeVideo(ctx context.Context, videoSource, prompt string) (*VisionResponse, error) {\n\targuments := map[string]interface{}{\n\t\t\"video_source\": videoSource,\n\t\t\"prompt\":       prompt,\n\t}\n\n\treturn c.executeVisionTool(ctx, \"mcp_vision_analyze_video\", arguments)\n}\n\n// executeVisionTool is a helper method to execute vision tools and convert responses",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_executeVisionTool_106": {
      "name": "executeVisionTool",
      "type": "method",
      "start_line": 106,
      "end_line": 120,
      "content_hash": "4c6dddac256d4650dae249ca90fba947c72a068c",
      "content": "func (c *Client) executeVisionTool(ctx context.Context, toolName string, arguments map[string]interface{}) (*VisionResponse, error) {\n\tc.logger.Info(\"executing Z.ai vision tool\", \"tool\", toolName)\n\n\tresult, err := c.CallTool(ctx, &mcp.CallToolParams{\n\t\tName:      toolName,\n\t\tArguments: arguments,\n\t})\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to call vision tool %s: %w\", toolName, err)\n\t}\n\n\treturn c.convertMCPResult(result)\n}\n\n// convertMCPResult converts MCP CallToolResult to VisionResponse",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_convertMCPResult_121": {
      "name": "convertMCPResult",
      "type": "method",
      "start_line": 121,
      "end_line": 167,
      "content_hash": "90eeb547c042e46b6c0382d6a5e32bcc73ff64c2",
      "content": "func (c *Client) convertMCPResult(result *mcp.CallToolResult) (*VisionResponse, error) {\n\tif len(result.Content) == 0 {\n\t\treturn &VisionResponse{\n\t\t\tType:    \"text\",\n\t\t\tContent: \"\",\n\t\t}, nil\n\t}\n\n\tvar textContent string\n\tvar data []byte\n\tvar mediaType string\n\n\tfor _, content := range result.Content {\n\t\tswitch c := content.(type) {\n\t\tcase *mcp.TextContent:\n\t\t\ttextContent += c.Text\n\t\tcase *mcp.ImageContent:\n\t\t\tdata = c.Data\n\t\t\tmediaType = c.MIMEType\n\t\tcase *mcp.AudioContent:\n\t\t\tdata = c.Data\n\t\t\tmediaType = c.MIMEType\n\t\t}\n\t}\n\n\tresponse := &VisionResponse{\n\t\tContent: textContent,\n\t\tData:    data,\n\t}\n\n\tif mediaType != \"\" {\n\t\tresponse.MediaType = mediaType\n\t\tif mediaType == \"image/png\" || mediaType == \"image/jpeg\" || mediaType == \"image/webp\" {\n\t\t\tresponse.Type = \"image\"\n\t\t} else if mediaType == \"audio/mp3\" || mediaType == \"audio/wav\" || mediaType == \"audio/ogg\" {\n\t\t\tresponse.Type = \"audio\"\n\t\t} else {\n\t\t\tresponse.Type = \"media\"\n\t\t}\n\t} else {\n\t\tresponse.Type = \"text\"\n\t}\n\n\treturn response, nil\n}\n\n// VisionInput represents input parameters for vision tools",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "struct_VisionInput_168": {
      "name": "VisionInput",
      "type": "struct",
      "start_line": 168,
      "end_line": 181,
      "content_hash": "325d2bb8e18a11bb44add6e74d500a3fea13ceee",
      "content": "type VisionInput struct {\n\tImageSource         string `json:\"image_source\"`\n\tVideoSource         string `json:\"video_source,omitempty\"`\n\tAnalysisFocus       string `json:\"analysis_focus,omitempty\"`\n\tDiagramType         string `json:\"diagram_type,omitempty\"`\n\tProgrammingLanguage string `json:\"programming_language,omitempty\"`\n\tOutputType          string `json:\"output_type,omitempty\"`\n\tContext             string `json:\"context,omitempty\"`\n\tPrompt              string `json:\"prompt\"`\n\tExpectedImageSource string `json:\"expected_image_source,omitempty\"`\n\tActualImageSource   string `json:\"actual_image_source,omitempty\"`\n}\n\n// ParseVisionInput parses JSON input into VisionInput struct",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_ParseVisionInput_182": {
      "name": "ParseVisionInput",
      "type": "function",
      "start_line": 182,
      "end_line": 190,
      "content_hash": "2be1a21472e5198e8a91f93be3352df6903cffe1",
      "content": "func ParseVisionInput(jsonInput string) (*VisionInput, error) {\n\tvar input VisionInput\n\tif err := json.Unmarshal([]byte(jsonInput), &input); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to parse vision input: %w\", err)\n\t}\n\treturn &input, nil\n}\n\n// ValidateVisionInput validates the input for vision tools",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_ValidateVisionInput_191": {
      "name": "ValidateVisionInput",
      "type": "function",
      "start_line": 191,
      "end_line": 214,
      "content_hash": "8d922d11544fe47bddd0976e7aaf4ccb0431797a",
      "content": "func ValidateVisionInput(input *VisionInput, requiredType string) error {\n\tswitch requiredType {\n\tcase \"image\":\n\t\tif input.ImageSource == \"\" {\n\t\t\treturn fmt.Errorf(\"image_source is required\")\n\t\t}\n\tcase \"video\":\n\t\tif input.VideoSource == \"\" {\n\t\t\treturn fmt.Errorf(\"video_source is required\")\n\t\t}\n\tcase \"diff\":\n\t\tif input.ExpectedImageSource == \"\" || input.ActualImageSource == \"\" {\n\t\t\treturn fmt.Errorf(\"expected_image_source and actual_image_source are required for UI diff comparison\")\n\t\t}\n\t}\n\n\tif input.Prompt == \"\" {\n\t\treturn fmt.Errorf(\"prompt is required\")\n\t}\n\n\treturn nil\n}\n\n// GetRequiredInputType returns the required input type for a given tool",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_GetRequiredInputType_215": {
      "name": "GetRequiredInputType",
      "type": "function",
      "start_line": 215,
      "end_line": 224,
      "content_hash": "03ba1c62eeb0663fd21902f5d81c4e254ea5baf3",
      "content": "func GetRequiredInputType(toolName string) string {\n\tswitch toolName {\n\tcase \"mcp_vision_analyze_video\":\n\t\treturn \"video\"\n\tcase \"mcp_vision_ui_diff_check\":\n\t\treturn \"diff\"\n\tdefault:\n\t\treturn \"image\"\n\t}\n}",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}