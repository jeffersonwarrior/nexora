{
  "file_path": "/work/external-deps/helix-db/helix-db/src/helix_engine/storage_core/storage_migration.rs",
  "file_hash": "385514fe316b0077a12faefc70b71d71794fd83f",
  "updated_at": "2025-12-26T17:34:21.489080",
  "symbols": {
    "function_migrate_16": {
      "name": "migrate",
      "type": "function",
      "start_line": 16,
      "end_line": 310,
      "content_hash": "568b4c7f8296c2fe4255205a4115e6c5022899a9",
      "content": "pub fn migrate(storage: &mut HelixGraphStorage) -> Result<(), GraphError> {\n    let mut metadata = {\n        let txn = storage.graph_env.read_txn()?;\n        StorageMetadata::read(&txn, &storage.metadata_db)?\n    };\n\n    loop {\n        metadata = match metadata {\n            StorageMetadata::PreMetadata => {\n                migrate_pre_metadata_to_native_vector_endianness(storage)?\n            }\n            StorageMetadata::VectorNativeEndianness {\n                vector_endianness: NATIVE_VECTOR_ENDIANNESS,\n            } => {\n                // If the vectors are in the native vector endianness, we're done migrating them\n                break;\n            }\n            StorageMetadata::VectorNativeEndianness {\n                vector_endianness: currently_stored_vector_endianness,\n            } => convert_vectors_to_native_endianness(currently_stored_vector_endianness, storage)?,\n        };\n    }\n\n    verify_vectors_and_repair(storage)?;\n    remove_orphaned_vector_edges(storage)?;\n\n    Ok(())\n}\n\npub(crate) fn migrate_pre_metadata_to_native_vector_endianness(\n    storage: &mut HelixGraphStorage,\n) -> Result<StorageMetadata, GraphError> {\n    // In PreMetadata, all vectors are stored as big endian.\n    // If we are on a big endian machine, all we need to do is store the metadata.\n    // Otherwise, we need to convert all the vectors and then store the metadata.\n\n    let metadata = StorageMetadata::VectorNativeEndianness {\n        vector_endianness: NATIVE_VECTOR_ENDIANNESS,\n    };\n\n    #[cfg(target_endian = \"little\")]\n    {\n        // On little-endian machines, we need to convert from big-endian to little-endian\n        convert_all_vectors(VectorEndianness::BigEndian, storage)?;\n    }\n\n    convert_all_vector_properties(storage)?;\n\n    // Save the metadata\n    let mut txn = storage.graph_env.write_txn()?;\n    metadata.save(&mut txn, &storage.metadata_db)?;\n    txn.commit()?;\n\n    Ok(metadata)\n}\n\npub(crate) fn convert_vectors_to_native_endianness(\n    currently_stored_vector_endianness: VectorEndianness,\n    storage: &mut HelixGraphStorage,\n) -> Result<StorageMetadata, GraphError> {\n    // Convert all vectors from currently_stored_vector_endianness to native endianness\n    convert_all_vectors(currently_stored_vector_endianness, storage)?;\n\n    let metadata = StorageMetadata::VectorNativeEndianness {\n        vector_endianness: NATIVE_VECTOR_ENDIANNESS,\n    };\n\n    // Save the updated metadata\n    let mut txn = storage.graph_env.write_txn()?;\n    metadata.save(&mut txn, &storage.metadata_db)?;\n    txn.commit()?;\n\n    Ok(metadata)\n}\n\npub(crate) fn convert_all_vectors(\n    source_endianness: VectorEndianness,\n    storage: &mut HelixGraphStorage,\n) -> Result<(), GraphError> {\n    const BATCH_SIZE: usize = 1024;\n\n    let key_arena = bumpalo::Bump::new();\n    let batch_bounds = {\n        let mut keys = vec![];\n\n        let txn = storage.graph_env.read_txn()?;\n\n        for (i, kv) in storage\n            .vectors\n            .vectors_db\n            .lazily_decode_data()\n            .iter(&txn)?\n            .enumerate()\n        {\n            let (key, _) = kv?;\n\n            if i % BATCH_SIZE == 0 {\n                let key: &[u8] = key_arena.alloc_slice_copy(key);\n                keys.push(key);\n            }\n        }\n\n        let mut ranges = vec![];\n        for (start, end) in keys.iter().copied().tuple_windows() {\n            ranges.push((Bound::Included(start), Bound::Excluded(end)));\n        }\n        ranges.extend(\n            keys.last()\n                .copied()\n                .map(|last_batch_end| (Bound::Included(last_batch_end), Bound::Unbounded)),\n        );\n\n        ranges\n    };\n\n    for bounds in batch_bounds {\n        let arena = bumpalo::Bump::new();\n\n        let mut txn = storage.graph_env.write_txn()?;\n        let mut cursor = storage.vectors.vectors_db.range_mut(&mut txn, &bounds)?;\n\n        while let Some((key, value)) = cursor.next().transpose()? {\n            if key == vector_core::ENTRY_POINT_KEY {\n                continue;\n            }\n\n            let value = convert_vector_endianness(value, source_endianness, &arena)?;\n\n            let success = unsafe { cursor.put_current(key, value)? };\n            if !success {\n                return Err(GraphError::New(\"failed to update value in LMDB\".into()));\n            }\n        }\n        drop(cursor);\n\n        txn.commit()?;\n    }\n\n    Ok(())\n}\n\n/// Converts a single vector's endianness by reading f64 values in source endianness\n/// and writing them in native endianness. Uses arena for allocations.\npub(crate) fn convert_vector_endianness<'arena>(\n    bytes: &[u8],\n    source_endianness: VectorEndianness,\n    arena: &'arena bumpalo::Bump,\n) -> Result<&'arena [u8], GraphError> {\n    use std::{alloc, mem, ptr, slice};\n\n    if bytes.is_empty() {\n        // We use unsafe stuff below so best not to risk allocating a layout of size zero etc\n        return Ok(&[]);\n    }\n\n    if !bytes.len().is_multiple_of(mem::size_of::<f64>()) {\n        return Err(GraphError::New(\n            \"Vector data length is not a multiple of f64 size\".to_string(),\n        ));\n    }\n\n    let num_floats = bytes.len() / mem::size_of::<f64>();\n\n    // Allocate space for the converted f64 array in the arena\n    let layout = alloc::Layout::array::<f64>(num_floats)\n        .map_err(|_| GraphError::New(\"Failed to create array layout\".to_string()))?;\n\n    let data_ptr: ptr::NonNull<u8> = arena.alloc_layout(layout);\n\n    let converted_floats: &'arena [f64] = unsafe {\n        let float_ptr: ptr::NonNull<f64> = data_ptr.cast();\n        let float_slice = slice::from_raw_parts_mut(float_ptr.as_ptr(), num_floats);\n\n        // Read each f64 in the source endianness and write in native endianness\n        for (i, float) in float_slice.iter_mut().enumerate() {\n            let start = i * mem::size_of::<f64>();\n            let end = start + mem::size_of::<f64>();\n            let float_bytes: [u8; 8] = bytes[start..end]\n                .try_into()\n                .map_err(|_| GraphError::New(\"Failed to extract f64 bytes\".to_string()))?;\n\n            let value = match source_endianness {\n                VectorEndianness::BigEndian => f64::from_be_bytes(float_bytes),\n                VectorEndianness::LittleEndian => f64::from_le_bytes(float_bytes),\n            };\n\n            *float = value;\n        }\n\n        slice::from_raw_parts(float_ptr.as_ptr(), num_floats)\n    };\n\n    // Convert to bytes using bytemuck\n    let result_bytes: &[u8] = bytemuck::cast_slice(converted_floats);\n\n    Ok(result_bytes)\n}\n\npub(crate) fn convert_all_vector_properties(\n    storage: &mut HelixGraphStorage,\n) -> Result<(), GraphError> {\n    const BATCH_SIZE: usize = 1024;\n\n    let batch_bounds = {\n        let txn = storage.graph_env.read_txn()?;\n        let mut keys = vec![];\n\n        for (i, kv) in storage\n            .vectors\n            .vector_properties_db\n            .lazily_decode_data()\n            .iter(&txn)?\n            .enumerate()\n        {\n            let (key, _) = kv?;\n\n            if i % BATCH_SIZE == 0 {\n                keys.push(key);\n            }\n        }\n\n        let mut ranges = vec![];\n        for (start, end) in keys.iter().copied().tuple_windows() {\n            ranges.push((Bound::Included(start), Bound::Excluded(end)));\n        }\n        ranges.extend(\n            keys.last()\n                .copied()\n                .map(|last_batch_end| (Bound::Included(last_batch_end), Bound::Unbounded)),\n        );\n\n        ranges\n    };\n\n    for bounds in batch_bounds {\n        let arena = bumpalo::Bump::new();\n\n        let mut txn = storage.graph_env.write_txn()?;\n        let mut cursor = storage\n            .vectors\n            .vector_properties_db\n            .range_mut(&mut txn, &bounds)?;\n\n        while let Some((key, value)) = cursor.next().transpose()? {\n            let value = convert_old_vector_properties_to_new_format(value, &arena)?;\n\n            let success = unsafe { cursor.put_current(&key, &value)? };\n            if !success {\n                return Err(GraphError::New(\"failed to update value in LMDB\".into()));\n            }\n        }\n        drop(cursor);\n\n        txn.commit()?;\n    }\n\n    Ok(())\n}\n\npub(crate) fn convert_old_vector_properties_to_new_format(\n    property_bytes: &[u8],\n    arena: &bumpalo::Bump,\n) -> Result<Vec<u8>, GraphError> {\n    let mut old_properties: HashMap<String, Value> = bincode::DefaultOptions::new()\n        .with_fixint_encoding()\n        .allow_trailing_bytes()\n        .deserialize(property_bytes)?;\n\n    let label = old_properties\n        .remove(\"label\")\n        .expect(\"all old vectors should have label\");\n    let is_deleted = old_properties\n        .remove(\"is_deleted\")\n        .expect(\"all old vectors should have deleted\");\n\n    let new_properties = ImmutablePropertiesMap::new(\n        old_properties.len(),\n        old_properties.iter().map(|(k, v)| (k.as_str(), v.clone())),\n        arena,\n    );\n\n    let new_vector = HVector {\n        id: 0u128,\n        label: &label.inner_stringify(),\n        version: 0,\n        deleted: is_deleted == true,\n        level: 0,\n        distance: None,\n        data: &[],\n        properties: Some(new_properties),\n    };\n\n    new_vector.to_bincode_bytes().map_err(GraphError::from)\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_verify_vectors_and_repair_311": {
      "name": "verify_vectors_and_repair",
      "type": "function",
      "start_line": 311,
      "end_line": 404,
      "content_hash": "61f946cbd85405bd9ba54e014843252b36642132",
      "content": "fn verify_vectors_and_repair(storage: &HelixGraphStorage) -> Result<(), GraphError> {\n    // Verify that all vectors at level > 0 also exist at level 0 and collect ones that need repair\n    println!(\"\\nVerifying vector integrity after migration...\");\n    let vectors_to_repair: Vec<(u128, usize)> = {\n        let txn = storage.graph_env.read_txn()?;\n        let mut missing = Vec::new();\n\n        for kv in storage.vectors.vectors_db.iter(&txn)? {\n            let (key, _) = kv?;\n            if key.starts_with(b\"v:\") && key.len() >= 26 {\n                let id = u128::from_be_bytes(key[2..18].try_into().unwrap());\n                let level = usize::from_be_bytes(key[18..26].try_into().unwrap());\n\n                if level > 0 {\n                    // Check if level 0 exists\n                    let level_0_key = vector_core::VectorCore::vector_key(id, 0);\n                    if storage\n                        .vectors\n                        .vectors_db\n                        .get(&txn, &level_0_key)?\n                        .is_none()\n                    {\n                        println!(\n                            \"ERROR: Vector {} exists at level {} but NOT at level 0!\",\n                            uuid::Uuid::from_u128(id),\n                            level\n                        );\n                        missing.push((id, level));\n                    }\n                }\n            }\n        }\n        missing\n    };\n\n    if !vectors_to_repair.is_empty() {\n        println!(\n            \"Found {} vectors at level > 0 missing their level 0 counterparts!\",\n            vectors_to_repair.len()\n        );\n        println!(\"Repairing missing level 0 vectors...\");\n\n        const REPAIR_BATCH_SIZE: usize = 128;\n\n        // Process repairs in batches\n        for batch in vectors_to_repair.chunks(REPAIR_BATCH_SIZE) {\n            let mut txn = storage.graph_env.write_txn()?;\n\n            let key_arena = bumpalo::Bump::new();\n\n            for &(id, source_level) in batch {\n                // Read vector data from source level\n                let source_key = vector_core::VectorCore::vector_key(id, source_level);\n                let vector_data: &[u8] = {\n                    let key = storage\n                        .vectors\n                        .vectors_db\n                        .get(&txn, &source_key)?\n                        .ok_or_else(|| {\n                            GraphError::New(format!(\n                                \"Could not read vector {} at level {source_level} for repair\",\n                                uuid::Uuid::from_u128(id)\n                            ))\n                        })?;\n                    key_arena.alloc_slice_copy(key)\n                };\n\n                // Write to level 0\n                let level_0_key = vector_core::VectorCore::vector_key(id, 0);\n                storage\n                    .vectors\n                    .vectors_db\n                    .put(&mut txn, &level_0_key, vector_data)?;\n                println!(\n                    \"  Repaired: Copied vector {} from level {} to level 0\",\n                    uuid::Uuid::from_u128(id),\n                    source_level\n                );\n            }\n\n            txn.commit()?;\n        }\n\n        println!(\n            \"Repair complete! Repaired {} vectors.\",\n            vectors_to_repair.len()\n        );\n    } else {\n        println!(\"All vectors verified successfully!\");\n    }\n\n    Ok(())\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_remove_orphaned_vector_edges_405": {
      "name": "remove_orphaned_vector_edges",
      "type": "function",
      "start_line": 405,
      "end_line": 473,
      "content_hash": "666316be8ad59432969772fa5ce3249b289f9da9",
      "content": "fn remove_orphaned_vector_edges(storage: &HelixGraphStorage) -> Result<(), GraphError> {\n    let txn = storage.graph_env.read_txn()?;\n    let mut orphaned_edges = Vec::new();\n\n    for kv in storage.vectors.edges_db.iter(&txn)? {\n        let (key, _) = kv?;\n\n        // Edge key format: [source_id (16 bytes), level (8 bytes), sink_id (16 bytes)]\n        // Total: 40 bytes\n        if key.len() != 40 {\n            println!(\n                \"WARNING: Vector edge key has unexpected length: {} bytes\",\n                key.len()\n            );\n            continue;\n        }\n\n        // Extract source_id\n        let source_id = u128::from_be_bytes(key[0..16].try_into().unwrap());\n\n        // Extract level\n        let level = usize::from_be_bytes(key[16..24].try_into().unwrap());\n\n        // Extract sink_id\n        let sink_id = u128::from_be_bytes(key[24..40].try_into().unwrap());\n\n        // Check if source vector exists at level 0\n        let source_key = vector_core::VectorCore::vector_key(source_id, 0);\n        let source_exists = storage.vectors.vectors_db.get(&txn, &source_key)?.is_some();\n\n        // Check if sink vector exists at level 0\n        let sink_key = vector_core::VectorCore::vector_key(sink_id, 0);\n        let sink_exists = storage.vectors.vectors_db.get(&txn, &sink_key)?.is_some();\n\n        if !source_exists || !sink_exists {\n            orphaned_edges.push((\n                uuid::Uuid::from_u128(source_id),\n                level,\n                uuid::Uuid::from_u128(sink_id),\n            ));\n        }\n    }\n\n    for chunk in orphaned_edges.into_iter().chunks(64).into_iter() {\n        let mut txn = storage.graph_env.write_txn()?;\n\n        for (source_id, level, sink_id) in chunk {\n            let edge_key = vector_core::VectorCore::out_edges_key(\n                source_id.as_u128(),\n                level,\n                Some(sink_id.as_u128()),\n            );\n\n            storage\n                .vectors\n                .edges_db\n                .get(&txn, &edge_key)?\n                .ok_or_else(|| {\n                    GraphError::New(\"edge key doesnt exist when removing orphan\".into())\n                })?;\n\n            storage.vectors.edges_db.delete(&mut txn, &edge_key)?;\n        }\n\n        txn.commit()?;\n    }\n\n    Ok(())\n}",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}