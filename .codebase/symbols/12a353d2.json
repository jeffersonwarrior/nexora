{
  "file_path": "/work/external-deps/helix-db/helix-db/src/helix_engine/storage_core/storage_concurrent_tests.rs",
  "file_hash": "5b21a4f07d2c472ad6d8b833e41ff3c218bb29e0",
  "updated_at": "2025-12-26T17:34:19.611167",
  "symbols": {
    "function_setup_concurrent_storage_28": {
      "name": "setup_concurrent_storage",
      "type": "function",
      "start_line": 28,
      "end_line": 42,
      "content_hash": "1680db21f4406b2fce2aaa3ba38655dac3230b7d",
      "content": "fn setup_concurrent_storage() -> (Arc<HelixGraphStorage>, TempDir) {\n    let temp_dir = tempfile::tempdir().unwrap();\n    let path = temp_dir.path().to_str().unwrap();\n\n    let mut config = Config::default();\n    config.db_max_size_gb = Some(10); // 10GB for concurrent testing\n\n    let version_info = VersionInfo::default();\n\n    let storage = HelixGraphStorage::new(path, config, version_info).unwrap();\n    (Arc::new(storage), temp_dir)\n}\n\n#[test]\n#[serial(lmdb_stress)]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_concurrent_node_creation_43": {
      "name": "test_concurrent_node_creation",
      "type": "function",
      "start_line": 43,
      "end_line": 99,
      "content_hash": "67f54842d450745f3937e2a763966cf3b7e66f8d",
      "content": "fn test_concurrent_node_creation() {\n    // Tests concurrent node creation from multiple threads\n    //\n    // EXPECTED: All nodes created successfully, no ID collisions\n\n    let (storage, _temp_dir) = setup_concurrent_storage();\n\n    let num_threads = 4;\n    let nodes_per_thread = 25;\n    let barrier = Arc::new(Barrier::new(num_threads));\n\n    let handles: Vec<_> = (0..num_threads)\n        .map(|thread_id| {\n            let storage = Arc::clone(&storage);\n            let barrier = Arc::clone(&barrier);\n\n            thread::spawn(move || {\n                barrier.wait();\n\n                for i in 0..nodes_per_thread {\n                    let mut wtxn = storage.graph_env.write_txn().unwrap();\n                    let arena = Bump::new();\n\n                    // Create node with struct literal\n                    let label = arena.alloc_str(&format!(\"node_t{}_i{}\", thread_id, i));\n                    let node = Node {\n                        id: Uuid::new_v4().as_u128(),\n                        label,\n                        version: 1,\n                        properties: None,\n                    };\n\n                    storage.nodes_db.put(&mut wtxn, &node.id, &node.to_bincode_bytes().unwrap()).unwrap();\n                    wtxn.commit().unwrap();\n                }\n            })\n        })\n        .collect();\n\n    for handle in handles {\n        handle.join().unwrap();\n    }\n\n    // Verify: All nodes created\n    let rtxn = storage.graph_env.read_txn().unwrap();\n    let count = storage.nodes_db.len(&rtxn).unwrap();\n    assert_eq!(\n        count,\n        (num_threads * nodes_per_thread) as u64,\n        \"Expected {} nodes, found {}\",\n        num_threads * nodes_per_thread,\n        count\n    );\n}\n\n#[test]\n#[serial(lmdb_stress)]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_concurrent_edge_creation_100": {
      "name": "test_concurrent_edge_creation",
      "type": "function",
      "start_line": 100,
      "end_line": 194,
      "content_hash": "4a4193fd2da6cfbdef7b6d6c4a1c328c23170761",
      "content": "fn test_concurrent_edge_creation() {\n    // Tests concurrent edge creation between nodes\n    //\n    // EXPECTED: All edges created, proper serialization\n\n    let (storage, _temp_dir) = setup_concurrent_storage();\n\n    // Create source and sink nodes first\n    {\n        let mut wtxn = storage.graph_env.write_txn().unwrap();\n        let arena = Bump::new();\n\n        for i in 0..10 {\n            let label = arena.alloc_str(&format!(\"node_{}\", i));\n            let node = Node {\n                id: Uuid::new_v4().as_u128(),\n                label,\n                version: 1,\n                properties: None,\n            };\n            storage.nodes_db.put(&mut wtxn, &node.id, &node.to_bincode_bytes().unwrap()).unwrap();\n        }\n        wtxn.commit().unwrap();\n    }\n\n    // Get node IDs\n    let node_ids: Vec<u128> = {\n        let rtxn = storage.graph_env.read_txn().unwrap();\n        storage.nodes_db\n            .iter(&rtxn)\n            .unwrap()\n            .map(|result| {\n                let (id, _) = result.unwrap();\n                id\n            })\n            .collect()\n    };\n\n    let num_threads = 4;\n    let edges_per_thread = 10;\n    let barrier = Arc::new(Barrier::new(num_threads));\n    let node_ids = Arc::new(node_ids);\n\n    let handles: Vec<_> = (0..num_threads)\n        .map(|thread_id| {\n            let storage = Arc::clone(&storage);\n            let barrier = Arc::clone(&barrier);\n            let node_ids = Arc::clone(&node_ids);\n\n            thread::spawn(move || {\n                barrier.wait();\n\n                for i in 0..edges_per_thread {\n                    let mut wtxn = storage.graph_env.write_txn().unwrap();\n                    let arena = Bump::new();\n\n                    // Create edge between nodes\n                    let source_idx = (thread_id * 2) % node_ids.len();\n                    let sink_idx = (thread_id * 2 + 1) % node_ids.len();\n\n                    let label = arena.alloc_str(&format!(\"edge_t{}_i{}\", thread_id, i));\n                    let edge = Edge {\n                        id: Uuid::new_v4().as_u128(),\n                        from_node: node_ids[source_idx],\n                        to_node: node_ids[sink_idx],\n                        label,\n                        version: 1,\n                        properties: None,\n                    };\n\n                    storage.edges_db.put(&mut wtxn, &edge.id, &edge.to_bincode_bytes().unwrap()).unwrap();\n                    wtxn.commit().unwrap();\n                }\n            })\n        })\n        .collect();\n\n    for handle in handles {\n        handle.join().unwrap();\n    }\n\n    // Verify: All edges created\n    let rtxn = storage.graph_env.read_txn().unwrap();\n    let count = storage.edges_db.len(&rtxn).unwrap();\n    assert_eq!(\n        count,\n        (num_threads * edges_per_thread) as u64,\n        \"Expected {} edges, found {}\",\n        num_threads * edges_per_thread,\n        count\n    );\n}\n\n#[test]\n#[serial(lmdb_stress)]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_concurrent_node_reads_195": {
      "name": "test_concurrent_node_reads",
      "type": "function",
      "start_line": 195,
      "end_line": 300,
      "content_hash": "a9fa89b682b1f42d4ca5df43953ba1631b20543d",
      "content": "fn test_concurrent_node_reads() {\n    // Tests concurrent reads while writes are happening\n    //\n    // EXPECTED: Readers see consistent snapshots (MVCC)\n\n    let (storage, _temp_dir) = setup_concurrent_storage();\n\n    // Create initial nodes\n    let initial_count = 20u64;\n    {\n        let mut wtxn = storage.graph_env.write_txn().unwrap();\n        let arena = Bump::new();\n\n        for i in 0..initial_count {\n            let label = arena.alloc_str(&format!(\"initial_{}\", i));\n            let node = Node {\n                id: Uuid::new_v4().as_u128(),\n                label,\n                version: 1,\n                properties: None,\n            };\n            storage.nodes_db.put(&mut wtxn, &node.id, &node.to_bincode_bytes().unwrap()).unwrap();\n        }\n        wtxn.commit().unwrap();\n    }\n\n    let num_readers = 4;\n    let num_writers = 2;\n    let barrier = Arc::new(Barrier::new(num_readers + num_writers));\n\n    let mut handles = vec![];\n\n    // Spawn readers\n    for reader_id in 0..num_readers {\n        let storage = Arc::clone(&storage);\n        let barrier = Arc::clone(&barrier);\n\n        handles.push(thread::spawn(move || {\n            barrier.wait();\n\n            let mut total_reads = 0;\n\n            for _ in 0..20 {\n                let rtxn = storage.graph_env.read_txn().unwrap();\n                let count = storage.nodes_db.len(&rtxn).unwrap();\n                total_reads += 1;\n\n                // Count should be at least initial_count\n                assert!(\n                    count >= initial_count,\n                    \"Reader {} saw only {} nodes\",\n                    reader_id,\n                    count\n                );\n\n                thread::sleep(std::time::Duration::from_millis(1));\n            }\n\n            total_reads\n        }));\n    }\n\n    // Spawn writers\n    for writer_id in 0..num_writers {\n        let storage = Arc::clone(&storage);\n        let barrier = Arc::clone(&barrier);\n\n        handles.push(thread::spawn(move || {\n            barrier.wait();\n\n            for i in 0..10 {\n                let mut wtxn = storage.graph_env.write_txn().unwrap();\n                let arena = Bump::new();\n\n                let label = arena.alloc_str(&format!(\"writer_{}_node_{}\", writer_id, i));\n                let node = Node {\n                    id: Uuid::new_v4().as_u128(),\n                    label,\n                    version: 1,\n                    properties: None,\n                };\n                storage.nodes_db.put(&mut wtxn, &node.id, &node.to_bincode_bytes().unwrap()).unwrap();\n                wtxn.commit().unwrap();\n\n                thread::sleep(std::time::Duration::from_millis(2));\n            }\n            0 // Return value to match reader threads\n        }));\n    }\n\n    for handle in handles {\n        handle.join().unwrap();\n    }\n\n    // Final verification\n    let rtxn = storage.graph_env.read_txn().unwrap();\n    let final_count = storage.nodes_db.len(&rtxn).unwrap();\n    assert_eq!(\n        final_count,\n        initial_count + (num_writers * 10) as u64,\n        \"Final count mismatch\"\n    );\n}\n\n#[test]\n#[serial(lmdb_stress)]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_transaction_isolation_storage_301": {
      "name": "test_transaction_isolation_storage",
      "type": "function",
      "start_line": 301,
      "end_line": 370,
      "content_hash": "26c3826333fc8d2ae106667886f7b468ef7e3b07",
      "content": "fn test_transaction_isolation_storage() {\n    // Tests MVCC snapshot isolation at storage layer\n    //\n    // EXPECTED: Long-lived read transactions see consistent snapshot\n\n    let (storage, _temp_dir) = setup_concurrent_storage();\n\n    // Create initial nodes\n    let initial_count = 10u64;\n    {\n        let mut wtxn = storage.graph_env.write_txn().unwrap();\n        let arena = Bump::new();\n\n        for i in 0..initial_count {\n            let label = arena.alloc_str(&format!(\"node_{}\", i));\n            let node = Node {\n                id: Uuid::new_v4().as_u128(),\n                label,\n                version: 1,\n                properties: None,\n            };\n            storage.nodes_db.put(&mut wtxn, &node.id, &node.to_bincode_bytes().unwrap()).unwrap();\n        }\n        wtxn.commit().unwrap();\n    }\n\n    // Start long-lived read transaction\n    let rtxn = storage.graph_env.read_txn().unwrap();\n    let count_before = storage.nodes_db.len(&rtxn).unwrap();\n    assert_eq!(count_before, initial_count);\n\n    // In another thread, add more nodes\n    let storage_clone = Arc::clone(&storage);\n    let handle = thread::spawn(move || {\n        for i in 0..15 {\n            let mut wtxn = storage_clone.graph_env.write_txn().unwrap();\n            let arena = Bump::new();\n\n            let label = arena.alloc_str(&format!(\"new_node_{}\", i));\n            let node = Node {\n                id: Uuid::new_v4().as_u128(),\n                label,\n                version: 1,\n                properties: None,\n            };\n            storage_clone.nodes_db.put(&mut wtxn, &node.id, &node.to_bincode_bytes().unwrap()).unwrap();\n            wtxn.commit().unwrap();\n        }\n    });\n\n    handle.join().unwrap();\n\n    // Original transaction should still see same count (snapshot isolation)\n    let count_after = storage.nodes_db.len(&rtxn).unwrap();\n    assert_eq!(\n        count_after, count_before,\n        \"Transaction isolation violated: count changed from {} to {}\",\n        count_before, count_after\n    );\n\n    drop(rtxn);\n\n    // New transaction should see all nodes\n    let rtxn_new = storage.graph_env.read_txn().unwrap();\n    let count_new = storage.nodes_db.len(&rtxn_new).unwrap();\n    assert_eq!(count_new, initial_count + 15);\n}\n\n#[test]\n#[serial(lmdb_stress)]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_test_write_transaction_serialization_371": {
      "name": "test_write_transaction_serialization",
      "type": "function",
      "start_line": 371,
      "end_line": 428,
      "content_hash": "6fae944d633ce74120f0456e1f9cd70530cfbc4d",
      "content": "fn test_write_transaction_serialization() {\n    // Tests that write transactions are properly serialized\n    //\n    // EXPECTED: Only one write transaction at a time (enforced by LMDB)\n\n    let (storage, _temp_dir) = setup_concurrent_storage();\n\n    let num_threads = 4;\n    let writes_per_thread = 25;\n    let barrier = Arc::new(Barrier::new(num_threads));\n\n    let handles: Vec<_> = (0..num_threads)\n        .map(|thread_id| {\n            let storage = Arc::clone(&storage);\n            let barrier = Arc::clone(&barrier);\n\n            thread::spawn(move || {\n                barrier.wait();\n\n                for i in 0..writes_per_thread {\n                    // Each write transaction should be serialized\n                    let mut wtxn = storage.graph_env.write_txn().unwrap();\n                    let arena = Bump::new();\n\n                    let label = arena.alloc_str(&format!(\"serial_t{}_i{}\", thread_id, i));\n                    let node = Node {\n                        id: Uuid::new_v4().as_u128(),\n                        label,\n                        version: 1,\n                        properties: None,\n                    };\n\n                    storage.nodes_db.put(&mut wtxn, &node.id, &node.to_bincode_bytes().unwrap()).unwrap();\n\n                    // Simulate some work during transaction\n                    thread::sleep(std::time::Duration::from_micros(100));\n\n                    wtxn.commit().unwrap();\n                }\n            })\n        })\n        .collect();\n\n    for handle in handles {\n        handle.join().unwrap();\n    }\n\n    // Verify all writes completed\n    let rtxn = storage.graph_env.read_txn().unwrap();\n    let count = storage.nodes_db.len(&rtxn).unwrap();\n    assert_eq!(\n        count,\n        (num_threads * writes_per_thread) as u64,\n        \"Write serialization failed: expected {} nodes, found {}\",\n        num_threads * writes_per_thread,\n        count\n    );\n}",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}