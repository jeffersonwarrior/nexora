{
  "file_path": "/work/context-engine/scripts/mcp_router/cli.py",
  "file_hash": "3b0e375444f67e139d834dfdbe75bd1eabf1a8ec",
  "updated_at": "2025-12-26T17:34:21.441779",
  "symbols": {
    "function_main_36": {
      "name": "main",
      "type": "function",
      "start_line": 36,
      "end_line": 301,
      "content_hash": "e3c2ab5f9565b796ac9ebc116fff19c51f22ec07",
      "content": "def main(argv: List[str] | None = None) -> int:\n    \"\"\"Main CLI entrypoint.\"\"\"\n    if argv is None:\n        argv = sys.argv[1:]\n    \n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"query\", help=\"User query to route\")\n    ap.add_argument(\"--plan\", action=\"store_true\", help=\"Only print routing plan (no execution)\")\n    ap.add_argument(\"--run\", action=\"store_true\", help=\"Execute the routed tool(s) over HTTP\")\n    ap.add_argument(\"--timeout\", type=float, default=180.0, help=\"HTTP timeout for tool calls\")\n    args = ap.parse_args(argv)\n\n    plan = build_plan(args.query)\n    print(json.dumps({\"router\": {\"url\": HTTP_URL_INDEXER, \"plan\": plan}}, indent=2))\n\n    if args.plan and not args.run:\n        return 0\n\n    # Load scratchpad for prior context\n    sp = {}\n    fresh = False\n    prior_answer = None\n    prior_citations = None\n    prior_paths = None\n    try:\n        sp = load_scratchpad()\n        ts = float(sp.get(\"timestamp\") or 0.0)\n        fresh = bool(ts and (time.time() - ts) <= scratchpad_ttl_sec())\n        if fresh:\n            prior_answer = sp.get(\"last_answer\")\n            prior_citations = sp.get(\"last_citations\")\n            prior_paths = sp.get(\"last_paths\")\n    except Exception:\n        pass\n\n    # Execute sequentially until one succeeds\n    last_err = None\n    last = None\n    tool_servers = discover_tool_endpoints()\n    mem_snippets: list[str] = list(sp.get(\"mem_snippets\") or []) if fresh else []\n    batch_client = get_batch_client()\n\n    for idx, (tool, targs) in enumerate(plan):\n        base_url = tool_servers.get(tool, HTTP_URL_INDEXER)\n        \n        # Skip memory.find if we already have fresh snippets and this is a repeat/expand\n        if (tool.lower().endswith(\"find\") or tool.lower() in {\"find\", \"memory.find\"}) and mem_snippets and fresh and (looks_like_repeat(args.query) or looks_like_expand(args.query)):\n            try:\n                print(json.dumps({\"tool\": tool, \"skipped\": \"scratchpad_fresh\"}))\n            except Exception:\n                pass\n            continue\n\n        # Augment answer queries with context\n        if tool in {\"context_answer\", \"context_answer_compat\"} and (mem_snippets or (fresh and (prior_answer or prior_citations or prior_paths))):\n            try:\n                tq = str((targs or {}).get(\"query\") or args.query)\n                sections = [tq]\n                if mem_snippets:\n                    bullets = []\n                    for s in mem_snippets[:3]:\n                        ss = re.sub(r\"\\s+\", \" \", str(s)).strip()\n                        if len(ss) > 200:\n                            ss = ss[:197] + \"...\"\n                        bullets.append(f\"- {ss}\")\n                    sections.append(\"Memory context:\\n\" + \"\\n\".join(bullets))\n                if fresh and (looks_like_expand(args.query) or looks_like_repeat(args.query)):\n                    if isinstance(prior_answer, str) and prior_answer.strip():\n                        pa = re.sub(r\"\\s+\", \" \", prior_answer).strip()\n                        if len(pa) > 400:\n                            pa = pa[:397] + \"...\"\n                        sections.append(\"Prior summary:\\n\" + pa)\n                    paths_list = []\n                    if isinstance(prior_paths, list) and prior_paths:\n                        paths_list = [str(p) for p in prior_paths[:5]]\n                    elif isinstance(prior_citations, list) and prior_citations:\n                        uniq = []\n                        for c in prior_citations:\n                            if isinstance(c, dict) and c.get(\"path\") and c[\"path\"] not in uniq:\n                                uniq.append(c[\"path\"])\n                        paths_list = uniq[:5]\n                    if paths_list:\n                        sections.append(\"Citations context:\\n\" + \"\\n\".join(f\"- {p}\" for p in paths_list))\n                aug = \"\\n\\n\".join(sections)\n                targs = {**(targs or {}), \"query\": aug}\n            except Exception:\n                pass\n\n        try:\n            if tool in {\"context_answer\", \"context_answer_compat\"}:\n                res = batch_client.call_or_enqueue(base_url, tool, targs, timeout=args.timeout)\n            else:\n                res = call_tool_http(base_url, tool, targs, timeout=args.timeout)\n            print(json.dumps({\"tool\": tool, \"result\": res}, indent=2))\n            last = res\n\n            # Capture memory snippets\n            try:\n                if tool.lower().endswith(\"find\") or tool.lower() in {\"find\", \"memory.find\"}:\n                    r = res.get(\"result\") or {}\n                    items = []\n                    sc = r.get(\"structuredContent\")\n                    if isinstance(sc, dict):\n                        rs0 = sc.get(\"result\") or sc\n                        if isinstance(rs0, dict):\n                            items = rs0.get(\"results\") or rs0.get(\"hits\") or []\n                    if not items:\n                        content = r.get(\"content\")\n                        if isinstance(content, list):\n                            for c in content:\n                                if not isinstance(c, dict):\n                                    continue\n                                if \"json\" in c:\n                                    j = c.get(\"json\")\n                                    if isinstance(j, (dict, list)):\n                                        container = j.get(\"result\") if isinstance(j, dict) and \"result\" in j else j\n                                        if isinstance(container, dict):\n                                            items = container.get(\"results\") or container.get(\"hits\") or []\n                                            if items:\n                                                break\n                                if c.get(\"type\") == \"text\":\n                                    ttxt = c.get(\"text\")\n                                    if isinstance(ttxt, str) and ttxt.strip():\n                                        try:\n                                            j = json.loads(ttxt)\n                                        except Exception:\n                                            continue\n                                        container = j.get(\"result\") if isinstance(j, dict) and \"result\" in j else j\n                                        if isinstance(container, dict):\n                                            items = container.get(\"results\") or container.get(\"hits\") or []\n                                            if items:\n                                                break\n                    for it in items:\n                        if isinstance(it, dict):\n                            txt = it.get(\"information\") or it.get(\"content\") or it.get(\"text\")\n                            if isinstance(txt, str) and txt.strip():\n                                mem_snippets.append(txt.strip())\n            except Exception:\n                pass\n\n            # Determine if we should treat this step as terminal\n            has_future_answer = any(tn in {\"context_answer\", \"context_answer_compat\"} for (tn, _) in plan[idx + 1:])\n            if (not is_failure_response(res)) and is_result_good(tool, res):\n                if tool.lower() in {\"find\", \"memory.find\"} and has_future_answer:\n                    continue\n\n                # Persist scratchpad\n                try:\n                    last_filters: Dict[str, Any] = {}\n                    for (tn, ta) in plan:\n                        if tn == \"repo_search\" or tn.startswith(\"search_\"):\n                            if isinstance(ta, dict):\n                                for k in (\"language\", \"under\", \"symbol\", \"ext\", \"path_glob\", \"not_glob\"):\n                                    if ta.get(k) not in (None, \"\"):\n                                        last_filters[k] = ta.get(k)\n                            break\n                    \n                    last_answer_text = None\n                    last_citations_list = None\n                    last_paths_list: list[str] | None = None\n                    if tool in {\"context_answer\", \"context_answer_compat\"}:\n                        try:\n                            r0 = res.get(\"result\") or {}\n                            sc0 = r0.get(\"structuredContent\") or {}\n                            rs0 = sc0.get(\"result\") or sc0\n                            if isinstance(rs0, dict):\n                                ans0 = rs0.get(\"answer\")\n                                if isinstance(ans0, str):\n                                    last_answer_text = ans0\n                                cites0 = rs0.get(\"citations\")\n                                if isinstance(cites0, list):\n                                    last_citations_list = cites0\n                                    uniqp: list[str] = []\n                                    for c in cites0:\n                                        if isinstance(c, dict) and c.get(\"path\") and c[\"path\"] not in uniqp:\n                                            uniqp.append(c[\"path\"])\n                                    last_paths_list = uniqp\n                        except Exception:\n                            pass\n\n                    # Divergence detection\n                    divergence_should_abort = False\n                    last_metrics_prev = {}\n                    try:\n                        last_metrics_prev = sp.get(\"last_metrics\") or {}\n                        if not isinstance(last_metrics_prev, dict):\n                            last_metrics_prev = {}\n                    except Exception:\n                        last_metrics_prev = {}\n                    metric = extract_metric_from_resp(tool, res)\n                    last_metrics_map = dict(last_metrics_prev)\n                    if metric is not None:\n                        mname, mval = metric\n                        prev_val = None\n                        try:\n                            prev_val = last_metrics_prev.get(tool, {}).get(mname)\n                            if prev_val is not None:\n                                prev_val = float(prev_val)\n                        except Exception:\n                            prev_val = None\n                        drop_frac, min_base = divergence_thresholds()\n                        if material_drop(prev_val, float(mval), drop_frac, min_base):\n                            fatal = divergence_is_fatal_for(tool)\n                            try:\n                                print(json.dumps({\n                                    \"divergence\": {\n                                        \"tool\": tool,\n                                        \"metric\": mname,\n                                        \"previous\": prev_val,\n                                        \"current\": float(mval),\n                                        \"drop_frac\": drop_frac,\n                                        \"fatal\": fatal,\n                                    }\n                                }))\n                            except Exception:\n                                pass\n                            if fatal:\n                                divergence_should_abort = True\n                        try:\n                            last_metrics_map.setdefault(tool, {})[mname] = float(mval)\n                        except Exception:\n                            pass\n                    else:\n                        last_metrics_map = last_metrics_prev\n\n                    success_criteria = {\n                        \"context_answer\": {\"expected_fields\": [\"answer\"], \"min_citations\": 0},\n                        \"context_answer_compat\": {\"expected_fields\": [\"answer\"], \"min_citations\": 0},\n                        \"repo_search\": {\"min_results\": 1},\n                        \"search_config_for\": {\"min_results\": 1},\n                        \"search_tests_for\": {\"min_results\": 1},\n                        \"search_callers_for\": {\"min_results\": 1},\n                        \"search_importers_for\": {\"min_results\": 1},\n                        \"find\": {\"min_results\": 1},\n                    }\n                    sp = {\n                        \"last_query\": args.query,\n                        \"last_plan\": plan,\n                        \"last_filters\": last_filters or None,\n                        \"mem_snippets\": mem_snippets[:5],\n                        \"last_answer\": last_answer_text,\n                        \"last_citations\": last_citations_list,\n                        \"last_paths\": last_paths_list,\n                        \"success_criteria\": success_criteria,\n                        \"last_metrics\": last_metrics_map,\n                        \"timestamp\": time.time(),\n                    }\n                    save_scratchpad(sp)\n                except Exception:\n                    pass\n\n                if divergence_should_abort:\n                    continue\n\n                return 0\n        except Exception as e:\n            last_err = e\n            try:\n                print(json.dumps({\"tool\": tool, \"server\": base_url, \"error\": str(e)}), file=sys.stderr)\n            except Exception:\n                pass\n            continue\n\n    if last_err:\n        print(f\"Router: all attempts failed: {last_err}\", file=sys.stderr)\n    return 1 if last is not None else 2",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}