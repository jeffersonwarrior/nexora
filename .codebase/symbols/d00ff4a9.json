{
  "file_path": "/work/external-deps/Context-Engine/scripts/rerank_recursive.py",
  "file_hash": "b87a2a8dfdb20800123771c19182bf7c4d17e836",
  "updated_at": "2025-12-26T17:34:22.328370",
  "symbols": {
    "function__split_identifier_41": {
      "name": "_split_identifier",
      "type": "function",
      "start_line": 41,
      "end_line": 89,
      "content_hash": "effd436c31201a42a6cc60f04e22511b6a447414",
      "content": "def _split_identifier(s: str) -> List[str]:\n    \"\"\"Split any identifier into tokens, handling all common conventions.\n\n    Handles: snake_case, kebab-case, camelCase, PascalCase, SCREAMING_CASE,\n    numbers, acronyms (XMLParser -> xml, parser), dot.notation, and mixed styles.\n\n    Special handling:\n    - Preserves meaningful acronyms (API, HTTP, JSON, XML, URL, etc.)\n    - Strips common prefixes (I for interface, _ for private)\n    - Handles version suffixes (v2, 2.0)\n    \"\"\"\n    if not s:\n        return []\n\n    # Strip common prefixes that don't add meaning\n    if len(s) > 1:\n        # Interface prefix (IUserService -> UserService)\n        if s[0] == 'I' and s[1].isupper():\n            s = s[1:]\n        # Private prefix (_private -> private)\n        elif s[0] == '_':\n            s = s.lstrip('_')\n        # Dollar prefix ($scope -> scope)\n        elif s[0] == '$':\n            s = s[1:]\n\n    # Insert space before uppercase letters that follow lowercase (camelCase)\n    s = re.sub(r\"([a-z])([A-Z])\", r\"\\1 \\2\", s)\n    # Insert space before uppercase letters followed by lowercase (acronyms: XMLParser -> XML Parser)\n    s = re.sub(r\"([A-Z]+)([A-Z][a-z])\", r\"\\1 \\2\", s)\n    # Insert space around digit sequences (handler2 -> handler 2, v2 -> v 2)\n    s = re.sub(r\"([a-zA-Z])(\\d)\", r\"\\1 \\2\", s)\n    s = re.sub(r\"(\\d)([a-zA-Z])\", r\"\\1 \\2\", s)\n\n    # Split on separators: underscore, hyphen, dot, space\n    parts = re.split(r\"[_\\-.\\s]+\", s)\n    tokens = []\n    for part in parts:\n        part = part.strip().lower()\n        # Skip pure numbers and single chars (except meaningful ones)\n        if not part:\n            continue\n        if part.isdigit():\n            continue  # Skip version numbers like \"2\", \"18\"\n        if len(part) < 2:\n            continue\n        tokens.append(part)\n\n    return tokens",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function__normalize_token_92": {
      "name": "_normalize_token",
      "type": "function",
      "start_line": 92,
      "end_line": 105,
      "content_hash": "d4bbc73684194550db45337dfc06afa54228f221",
      "content": "def _normalize_token(tok: str) -> set[str]:\n    \"\"\"Return the token plus simple morphological variants.\"\"\"\n    forms = {tok}\n    # Simple plural/singular normalization\n    if tok.endswith('s') and len(tok) > 3:\n        forms.add(tok[:-1])  # services -> service\n    elif tok.endswith('es') and len(tok) > 4:\n        forms.add(tok[:-2])  # processes -> process\n    elif tok.endswith('ies') and len(tok) > 4:\n        forms.add(tok[:-3] + 'y')  # utilities -> utility\n    # Add singular -> plural\n    if not tok.endswith('s') and len(tok) > 2:\n        forms.add(tok + 's')\n    return forms",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function__tokenize_for_fname_boost_108": {
      "name": "_tokenize_for_fname_boost",
      "type": "function",
      "start_line": 108,
      "end_line": 128,
      "content_hash": "c059422dcff137083642db6f2928859bc9a04ac1",
      "content": "def _tokenize_for_fname_boost(text: Any) -> set[str]:\n    \"\"\"Robust tokenization for filename boosts.\n\n    Some MCP/IDE clients pass query strings that include quotes/brackets\n    or list-like wrappers. Regex tokenization is resilient to that.\n    \"\"\"\n    if not text:\n        return set()\n    try:\n        s = str(text)\n    except Exception:\n        return set()\n\n    # Split on any non-alphanumeric\n    raw_parts = re.split(r\"[^a-zA-Z0-9]+\", s)\n    tokens = set()\n    for part in raw_parts:\n        for tok in _split_identifier(part):\n            if len(tok) >= 3:  # Query tokens need 3+ chars\n                tokens.add(tok)\n    return tokens",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function__candidate_path_for_fname_boost_131": {
      "name": "_candidate_path_for_fname_boost",
      "type": "function",
      "start_line": 131,
      "end_line": 151,
      "content_hash": "fada8795a42d9c813be9a529e239d9cbaadbfc22",
      "content": "def _candidate_path_for_fname_boost(candidate: Dict[str, Any]) -> str:\n    \"\"\"Best-effort extraction of a path/filename from candidate objects.\"\"\"\n    for key in (\"path\", \"rel_path\", \"host_path\", \"container_path\", \"client_path\"):\n        try:\n            val = candidate.get(key)\n        except Exception:\n            val = None\n        if isinstance(val, str) and val.strip():\n            return val\n\n    try:\n        md = candidate.get(\"metadata\") or {}\n        if isinstance(md, dict):\n            for key in (\"path\", \"rel_path\", \"host_path\", \"container_path\", \"client_path\"):\n                val = md.get(key)\n                if isinstance(val, str) and val.strip():\n                    return val\n    except Exception:\n        pass\n\n    return \"\"",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function__compute_fname_boost_154": {
      "name": "_compute_fname_boost",
      "type": "function",
      "start_line": 154,
      "end_line": 303,
      "content_hash": "7066e1cca1f3309fc4bef93b8b19e51c6d2157ab",
      "content": "def _compute_fname_boost(query: Any, candidate: Dict[str, Any], factor: float) -> float:\n    \"\"\"Compute filename/query correlation boost for a candidate.\n\n    Production-grade matching for real-world codebases at scale:\n\n    **Naming convention support:**\n    - snake_case, camelCase, PascalCase, kebab-case, SCREAMING_CASE\n    - Dot notation (com.company.auth.service)\n    - Mixed styles (legacy codebases)\n\n    **Smart tokenization:**\n    - Acronyms: XMLParser -> xml, parser; HTTPClient -> http, client\n    - Prefixes stripped: IService -> service, _private -> private\n    - Numbers separated: handler2 -> handler, React18 -> react\n\n    **Normalization:**\n    - Simple plural/singular normalization (services <-> service)\n\n    **Position-aware scoring:**\n    - Filename matches weighted higher than directory matches\n    - Deeper directories weighted less (noise reduction)\n\n    **Specificity weighting:**\n    - Common tokens (index, main, utils) weighted less\n    - Rare/specific tokens weighted more\n\n    **Scoring tiers:**\n    - Exact match: 1.0 \u00d7 factor\n    - Normalized match (morphology): 0.8 \u00d7 factor\n    - Substring containment: 0.4 \u00d7 factor\n    - Common token penalty: 0.5\u00d7 multiplier\n    - Filename bonus: 1.5\u00d7 multiplier for filename matches\n\n    Requires 2+ quality matches to trigger (prevents noise).\n    \"\"\"\n    if not factor or factor <= 0:\n        return 0.0\n\n    query_tokens = _tokenize_for_fname_boost(query)\n    if not query_tokens:\n        return 0.0\n\n    path = _candidate_path_for_fname_boost(candidate)\n    path = str(path or \"\")\n    if not path:\n        return 0.0\n\n    # Strip common prefixes that add noise (preserve case for splitting)\n    path_clean = path\n    path_lower = path.lower()\n    for prefix in (\"/work/\", \"/app/\", \"/src/\", \"/home/\", \"/var/\", \"/opt/\", \"/usr/\"):\n        if path_lower.startswith(prefix):\n            path_clean = path[len(prefix):]\n            break\n\n    # Split path into segments, track position for weighting\n    path_segments = re.split(r\"[/\\\\]\", path_clean)\n    path_segments = [s for s in path_segments if s]  # Remove empty\n\n    if not path_segments:\n        return 0.0\n\n    # Tokenize with position info: (token, is_filename, depth)\n    # Filename = last segment, depth = 0 for filename, 1 for parent, etc.\n    path_token_info: Dict[str, Dict[str, Any]] = {}  # token -> {is_filename, min_depth}\n\n    for i, segment in enumerate(reversed(path_segments)):\n        is_filename = (i == 0)\n        depth = i\n\n        # Strip extension from filename\n        if is_filename and \".\" in segment:\n            segment = segment.rsplit(\".\", 1)[0]\n\n        for tok in _split_identifier(segment):\n            if len(tok) >= 2:\n                if tok not in path_token_info:\n                    path_token_info[tok] = {\"is_filename\": is_filename, \"depth\": depth}\n                # Keep the most important occurrence (filename > dir, shallow > deep)\n                elif is_filename and not path_token_info[tok][\"is_filename\"]:\n                    path_token_info[tok] = {\"is_filename\": True, \"depth\": depth}\n\n    if not path_token_info:\n        return 0.0\n\n    path_tokens = set(path_token_info.keys())\n\n    # Build normalized lookup for path tokens\n    path_normalized: Dict[str, str] = {}  # normalized_form -> original_token\n    for ptok in path_tokens:\n        for form in _normalize_token(ptok):\n            if form not in path_normalized:\n                path_normalized[form] = ptok\n\n    # Score matches with quality tiers\n    score = 0.0\n    matched_query_tokens = set()\n\n    for qtok in query_tokens:\n        qtok_forms = _normalize_token(qtok)\n        match_score = 0.0\n        matched_ptok = None\n\n        # Tier 1: Exact match\n        if qtok in path_tokens:\n            match_score = 1.0\n            matched_ptok = qtok\n        else:\n            # Tier 2: Normalized match (plural/singular)\n            for qform in qtok_forms:\n                if qform in path_normalized:\n                    match_score = 0.8\n                    matched_ptok = path_normalized[qform]\n                    break\n\n            # Tier 3: Substring containment (if no normalized match)\n            if match_score == 0.0:\n                for ptok in path_tokens:\n                    if len(qtok) >= 4 and len(ptok) >= 4:\n                        if qtok in ptok or ptok in qtok:\n                            overlap = min(len(qtok), len(ptok))\n                            if overlap >= 4:\n                                match_score = 0.4\n                                matched_ptok = ptok\n                                break\n\n        if match_score > 0 and matched_ptok:\n            matched_query_tokens.add(qtok)\n\n            # Apply position bonus (filename matches worth more)\n            info = path_token_info.get(matched_ptok, {})\n            if info.get(\"is_filename\"):\n                match_score *= 1.5  # 50% bonus for filename match\n            else:\n                # Depth penalty for deep directories\n                depth = info.get(\"depth\", 0)\n                if depth > 2:\n                    match_score *= 0.8  # Slight penalty for deep paths\n\n            # Common token penalty\n            if qtok in _COMMON_TOKENS or matched_ptok in _COMMON_TOKENS:\n                match_score *= 0.5\n\n            score += match_score\n\n    # Require 2+ quality matches to trigger (prevents noise from single common word)\n    if len(matched_query_tokens) < 2:\n        return 0.0\n\n    return float(score * factor)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_RefinementState_317": {
      "name": "RefinementState",
      "type": "class",
      "start_line": 317,
      "end_line": 325,
      "content_hash": "80af980e80fb3a050d99b634cb55a2e2a2c091b8",
      "content": "class RefinementState:\n    \"\"\"Carries latent state between refinement iterations.\"\"\"\n    z: np.ndarray  # Latent representation (query understanding)\n    scores: np.ndarray  # Current score estimates\n    iteration: int = 0\n    confidence: float = 0.0  # For early stopping\n\n    # Track per-iteration improvements for analysis\n    score_history: List[np.ndarray] = field(default_factory=list)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function__cache_key_335": {
      "name": "_cache_key",
      "type": "function",
      "start_line": 335,
      "end_line": 338,
      "content_hash": "c22cba8685e29d877299d7ec302db6fb313af155",
      "content": "def _cache_key(text: str) -> str:\n    \"\"\"Generate deterministic cache key from text (process-stable, collision-resistant).\"\"\"\n    import hashlib\n    return hashlib.sha256(text.encode(\"utf-8\", errors=\"replace\")).hexdigest()",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function__get_cached_embedding_341": {
      "name": "_get_cached_embedding",
      "type": "function",
      "start_line": 341,
      "end_line": 345,
      "content_hash": "d691150c6222becf5e0bfa22c4e8d1fd650c8105",
      "content": "def _get_cached_embedding(text: str) -> Optional[np.ndarray]:\n    \"\"\"Get embedding from cache if exists.\"\"\"\n    key = _cache_key(text)\n    with _EMBEDDING_CACHE_LOCK:\n        return _EMBEDDING_CACHE.get(key)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function__cache_embedding_348": {
      "name": "_cache_embedding",
      "type": "function",
      "start_line": 348,
      "end_line": 357,
      "content_hash": "8f2a2316b7e786d9fb3888650e8d8975df521e5c",
      "content": "def _cache_embedding(text: str, embedding: np.ndarray):\n    \"\"\"Cache embedding for text.\"\"\"\n    key = _cache_key(text)\n    with _EMBEDDING_CACHE_LOCK:\n        if len(_EMBEDDING_CACHE) >= _EMBEDDING_CACHE_MAX_SIZE:\n            # Evict oldest 10%\n            keys_to_remove = list(_EMBEDDING_CACHE.keys())[:_EMBEDDING_CACHE_MAX_SIZE // 10]\n            for k in keys_to_remove:\n                del _EMBEDDING_CACHE[k]\n        _EMBEDDING_CACHE[key] = embedding",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_TinyScorer_360": {
      "name": "TinyScorer",
      "type": "class",
      "start_line": 360,
      "end_line": 808,
      "content_hash": "a9da6a09ae975bbf7ec548f20d50deb74bed25e0",
      "content": "class TinyScorer:\n    \"\"\"\n    Tiny 2-layer MLP for scoring query-document pairs.\n\n    Inspired by TRM: minimal parameters, maximum iterations.\n    Production-ready with:\n    - Collection-aware weights with atomic loading\n    - Checkpoint versioning (keep last N versions)\n    - Training metrics (loss, sample count, convergence)\n    - Learning rate decay\n    - Hot reload from background worker updates\n    \"\"\"\n\n    # Class-level configuration\n    WEIGHTS_DIR = os.environ.get(\"RERANKER_WEIGHTS_DIR\", \"/tmp/rerank_weights\")\n    WEIGHTS_RELOAD_INTERVAL = float(os.environ.get(\"RERANKER_WEIGHTS_RELOAD_INTERVAL\", \"60\"))\n    MAX_CHECKPOINTS = int(os.environ.get(\"RERANKER_MAX_CHECKPOINTS\", \"5\"))\n    LR_DECAY_STEPS = int(os.environ.get(\"RERANKER_LR_DECAY_STEPS\", \"1000\"))\n    LR_DECAY_RATE = float(os.environ.get(\"RERANKER_LR_DECAY_RATE\", \"0.95\"))\n    MIN_LR = float(os.environ.get(\"RERANKER_MIN_LR\", \"0.0001\"))\n\n    def __init__(self, dim: int = 256, hidden_dim: int = 512, lr: float = 0.001):\n        self.dim = dim\n        self.hidden_dim = hidden_dim\n        self.base_lr = lr\n        self.lr = lr\n        self._collection = \"default\"\n        self._weights_path = self._get_weights_path(\"default\")\n        self._weights_mtime = 0.0\n        self._last_reload_check = 0.0\n\n        # Training metrics\n        self._update_count = 0\n        self._total_samples = 0\n        self._cumulative_loss = 0.0\n        self._recent_losses: List[float] = []  # Rolling window for convergence detection\n        self._version = 0\n\n        # Try to load saved weights, otherwise init random\n        if os.path.exists(self._weights_path):\n            try:\n                self._load_weights()\n                return\n            except Exception as e:\n                from scripts.logger import get_logger\n                get_logger(__name__).warning(f\"TinyScorer: failed to load {self._weights_path}: {e}, using random init\")\n\n        self._init_random_weights()\n\n    def _init_random_weights(self):\n        \"\"\"Initialize weights randomly using He initialization (local RNG, deterministic).\"\"\"\n        # Use local RandomState to avoid polluting global RNG\n        rng = np.random.RandomState(42)\n        scale = np.float32(np.sqrt(2.0 / (self.dim * 3)))\n        self.W1 = rng.randn(self.dim * 3, self.hidden_dim).astype(np.float32) * scale\n        self.b1 = np.zeros(self.hidden_dim, dtype=np.float32)\n        w2_scale = np.float32(np.sqrt(2.0 / self.hidden_dim))\n        self.W2 = rng.randn(self.hidden_dim, 1).astype(np.float32) * w2_scale\n        self.b2 = np.zeros(1, dtype=np.float32)\n\n        # Momentum for SGD\n        self._momentum_W1 = np.zeros_like(self.W1)\n        self._momentum_b1 = np.zeros_like(self.b1)\n        self._momentum_W2 = np.zeros_like(self.W2)\n        self._momentum_b2 = np.zeros_like(self.b2)\n\n    def _update_learning_rate(self):\n        \"\"\"Decay learning rate based on update count.\"\"\"\n        if self._update_count > 0 and self._update_count % self.LR_DECAY_STEPS == 0:\n            self.lr = max(self.MIN_LR, self.lr * self.LR_DECAY_RATE)\n\n    def get_metrics(self) -> Dict[str, Any]:\n        \"\"\"Get current training metrics.\"\"\"\n        avg_loss = self._cumulative_loss / max(1, self._update_count)\n        recent_avg = np.mean(self._recent_losses) if self._recent_losses else 0.0\n        return {\n            \"collection\": self._collection,\n            \"version\": self._version,\n            \"update_count\": self._update_count,\n            \"total_samples\": self._total_samples,\n            \"cumulative_loss\": self._cumulative_loss,\n            \"avg_loss\": avg_loss,\n            \"recent_avg_loss\": float(recent_avg),\n            \"learning_rate\": self.lr,\n            \"converged\": self._is_converged(),\n        }\n\n    def _is_converged(self, window: int = 100, threshold: float = 0.01) -> bool:\n        \"\"\"Check if training has converged (loss not improving).\"\"\"\n        if len(self._recent_losses) < window:\n            return False\n        recent = self._recent_losses[-window:]\n        first_half = np.mean(recent[:window // 2])\n        second_half = np.mean(recent[window // 2:])\n        # Converged if improvement is less than threshold\n        return abs(first_half - second_half) < threshold * first_half\n\n    def _get_weights_path(self, collection: str) -> str:\n        \"\"\"Get weights file path for a collection.\"\"\"\n        os.makedirs(self.WEIGHTS_DIR, exist_ok=True)\n        safe_name = \"\".join(c if c.isalnum() or c in \"-_\" else \"_\" for c in collection)\n        return os.path.join(self.WEIGHTS_DIR, f\"weights_{safe_name}.npz\")\n\n    def set_collection(self, collection: str):\n        \"\"\"Set collection and load corresponding weights.\"\"\"\n        self._collection = collection\n        self._weights_path = self._get_weights_path(collection)\n        if os.path.exists(self._weights_path):\n            try:\n                self._load_weights()\n            except Exception:\n                pass\n\n    def maybe_reload_weights(self):\n        \"\"\"Check if weights file changed and reload if needed (hot reload).\"\"\"\n        now = time.time()\n        if now - self._last_reload_check < self.WEIGHTS_RELOAD_INTERVAL:\n            return\n        self._last_reload_check = now\n\n        try:\n            if os.path.exists(self._weights_path):\n                mtime = os.path.getmtime(self._weights_path)\n                if mtime > self._weights_mtime:\n                    self._load_weights_safe()\n        except Exception:\n            pass\n\n    def _load_weights_safe(self):\n        \"\"\"Load weights with advisory file locking (prevents partial reads during writes).\"\"\"\n        import fcntl\n        lock_path = self._weights_path + \".lock\"\n        try:\n            # Use same lock file as writer for coordination\n            os.makedirs(os.path.dirname(lock_path) or \".\", exist_ok=True)\n            with open(lock_path, \"w\") as lock_file:\n                # Shared lock for reading (blocks if exclusive lock held by writer)\n                fcntl.flock(lock_file.fileno(), fcntl.LOCK_SH)\n                try:\n                    self._load_weights()\n                finally:\n                    fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)\n        except Exception:\n            # Fallback to direct load if locking fails\n            self._load_weights()\n\n    def forward(self, query_emb: np.ndarray, doc_emb: np.ndarray, z: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Score documents given query and latent state.\n\n        Input shapes:\n            query_emb: (dim,) - query embedding\n            doc_emb: (n_docs, dim) - document embeddings\n            z: (dim,) - latent state from previous iteration\n\n        Returns:\n            scores: (n_docs,) - relevance scores\n        \"\"\"\n        # Check for hot-reloaded weights\n        self.maybe_reload_weights()\n\n        n_docs = doc_emb.shape[0]\n        # Broadcast query and z across docs\n        q_broadcast = np.tile(query_emb, (n_docs, 1))  # (n_docs, dim)\n        z_broadcast = np.tile(z, (n_docs, 1))  # (n_docs, dim)\n\n        # Concatenate [query, doc, latent] for each document\n        x = np.concatenate([q_broadcast, doc_emb, z_broadcast], axis=1)  # (n_docs, dim*3)\n\n        # 2-layer MLP with ReLU\n        h = np.maximum(0, x @ self.W1 + self.b1)  # (n_docs, hidden_dim)\n        scores = (h @ self.W2 + self.b2).squeeze(-1)  # (n_docs,)\n\n        return scores\n\n    def forward_with_cache(self, x: np.ndarray) -> Tuple[np.ndarray, Dict[str, np.ndarray]]:\n        \"\"\"Forward pass with cached activations for backprop.\"\"\"\n        z1 = x @ self.W1 + self.b1  # (batch, hidden)\n        h1 = np.maximum(0, z1)  # ReLU\n        z2 = h1 @ self.W2 + self.b2  # (batch, 1)\n        scores = z2.squeeze(-1)  # (batch,)\n        cache = {\"x\": x, \"z1\": z1, \"h1\": h1}\n        return scores, cache\n\n    def backward(self, dscores: np.ndarray, cache: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Backward pass to compute gradients.\"\"\"\n        batch_size = dscores.shape[0]\n        dz2 = dscores.reshape(-1, 1)  # (batch, 1)\n\n        # Layer 2 gradients\n        dW2 = cache[\"h1\"].T @ dz2\n        db2 = dz2.sum(axis=0)\n        dh1 = dz2 @ self.W2.T  # (batch, hidden)\n\n        # ReLU backward\n        dz1 = dh1 * (cache[\"z1\"] > 0).astype(np.float32)\n\n        # Layer 1 gradients\n        dW1 = cache[\"x\"].T @ dz1\n        db1 = dz1.sum(axis=0)\n\n        return {\n            \"W1\": dW1 / batch_size,\n            \"b1\": db1 / batch_size,\n            \"W2\": dW2 / batch_size,\n            \"b2\": db2 / batch_size,\n        }\n\n    def learn_from_teacher(\n        self,\n        query_emb: np.ndarray,\n        doc_embs: np.ndarray,\n        z: np.ndarray,\n        teacher_scores: np.ndarray,\n        margin: float = 0.5,\n    ) -> float:\n        \"\"\"\n        Online learning: update weights to match ONNX teacher ranking.\n\n        Uses pairwise margin ranking loss:\n        L = max(0, margin - (s_pos - s_neg))\n        where s_pos > s_neg in teacher ranking.\n\n        Returns:\n            Loss value (0.0 if no update needed)\n        \"\"\"\n        n_docs = doc_embs.shape[0]\n        if n_docs < 2:\n            return 0.0\n\n        # Build input matrix\n        q_broadcast = np.tile(query_emb, (n_docs, 1))\n        z_broadcast = np.tile(z, (n_docs, 1))\n        x = np.concatenate([q_broadcast, doc_embs, z_broadcast], axis=1)\n\n        # Forward pass with cache\n        our_scores, cache = self.forward_with_cache(x)\n\n        # Get teacher ranking\n        teacher_order = np.argsort(-teacher_scores)\n\n        # Sample pairs from teacher ranking (top vs bottom)\n        n_pairs = min(5, n_docs // 2)\n        total_loss = 0.0\n        dscores = np.zeros(n_docs, dtype=np.float32)\n\n        for i in range(n_pairs):\n            pos_idx = teacher_order[i]  # Should rank high\n            neg_idx = teacher_order[-(i + 1)]  # Should rank low\n\n            # Margin loss\n            diff = our_scores[pos_idx] - our_scores[neg_idx]\n            if diff < margin:\n                # Violation - need to update\n                loss = margin - diff\n                total_loss += loss\n\n                # Gradient: increase pos score, decrease neg score\n                dscores[pos_idx] -= 1.0\n                dscores[neg_idx] += 1.0\n\n        # Track metrics\n        self._total_samples += n_docs\n        self._cumulative_loss += total_loss\n        self._recent_losses.append(total_loss)\n        if len(self._recent_losses) > 200:  # Keep last 200 for convergence check\n            self._recent_losses = self._recent_losses[-200:]\n\n        if total_loss > 0:\n            # Backward pass\n            grads = self.backward(dscores, cache)\n\n            # SGD with momentum update\n            momentum = 0.9\n            self._momentum_W1 = momentum * self._momentum_W1 - self.lr * grads[\"W1\"]\n            self._momentum_b1 = momentum * self._momentum_b1 - self.lr * grads[\"b1\"]\n            self._momentum_W2 = momentum * self._momentum_W2 - self.lr * grads[\"W2\"]\n            self._momentum_b2 = momentum * self._momentum_b2 - self.lr * grads[\"b2\"]\n\n            self.W1 += self._momentum_W1\n            self.b1 += self._momentum_b1\n            self.W2 += self._momentum_W2\n            self.b2 += self._momentum_b2\n\n            self._update_count += 1\n            self._update_learning_rate()\n\n        return total_loss\n\n    def _save_weights(self, checkpoint: bool = False):\n        \"\"\"\n        Save weights to disk atomically (write to .tmp, then rename).\n\n        Uses advisory file locking to coordinate with readers during hot reload.\n\n        Args:\n            checkpoint: If True, also save a versioned checkpoint\n        \"\"\"\n        import fcntl\n        try:\n            self._version += 1\n            # np.savez automatically adds .npz extension, so use a base path\n            # that when .npz is added becomes our tmp file\n            tmp_base = self._weights_path.replace(\".npz\", \".tmp\")\n            np.savez(\n                tmp_base,\n                W1=self.W1, b1=self.b1, W2=self.W2, b2=self.b2,\n                momentum_W1=self._momentum_W1, momentum_b1=self._momentum_b1,\n                momentum_W2=self._momentum_W2, momentum_b2=self._momentum_b2,\n                update_count=self._update_count,\n                total_samples=self._total_samples,\n                cumulative_loss=self._cumulative_loss,\n                learning_rate=self.lr,\n                version=self._version,\n                collection=self._collection,\n            )\n            # np.savez writes to tmp_base + \".npz\"\n            tmp_path = tmp_base + \".npz\"\n\n            # Acquire exclusive lock on target before atomic rename\n            # This blocks any readers currently holding shared locks\n            lock_path = self._weights_path + \".lock\"\n            os.makedirs(os.path.dirname(lock_path) or \".\", exist_ok=True)\n            with open(lock_path, \"w\") as lock_file:\n                fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX)\n                try:\n                    # Atomic rename to final path\n                    os.replace(tmp_path, self._weights_path)\n                finally:\n                    fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)\n\n            # Save versioned checkpoint\n            if checkpoint or self._version % 100 == 0:\n                self._save_checkpoint()\n\n        except Exception:\n            pass\n\n    def _save_checkpoint(self):\n        \"\"\"Save a versioned checkpoint and prune old ones.\"\"\"\n        try:\n            checkpoint_path = self._weights_path.replace(\".npz\", f\"_v{self._version}.npz\")\n            # Copy current weights to checkpoint\n            import shutil\n            shutil.copy2(self._weights_path, checkpoint_path)\n\n            # Prune old checkpoints (keep last MAX_CHECKPOINTS)\n            self._prune_old_checkpoints()\n        except Exception:\n            pass\n\n    def _prune_old_checkpoints(self):\n        \"\"\"Remove old checkpoints keeping only the most recent MAX_CHECKPOINTS.\"\"\"\n        try:\n            import glob\n            pattern = self._weights_path.replace(\".npz\", \"_v*.npz\")\n            checkpoints = sorted(glob.glob(pattern))\n            if len(checkpoints) > self.MAX_CHECKPOINTS:\n                for old_cp in checkpoints[:-self.MAX_CHECKPOINTS]:\n                    try:\n                        os.remove(old_cp)\n                    except Exception:\n                        pass\n        except Exception:\n            pass\n\n    def _load_weights(self):\n        \"\"\"Load weights from disk with dimension validation.\"\"\"\n        from scripts.logger import get_logger\n        logger = get_logger(__name__)\n\n        data = np.load(self._weights_path, allow_pickle=True)\n\n        # Helper to safely get from NpzFile (doesn't have .get())\n        def _get(key: str, default):\n            return data[key] if key in data.files else default\n\n        # Validate all dimensions before loading to prevent shape mismatch crashes\n        w1_loaded = data[\"W1\"]\n        w2_loaded = data[\"W2\"]\n        b1_loaded = data[\"b1\"]\n        b2_loaded = data[\"b2\"]\n\n        expected_w1 = (self.dim * 3, self.hidden_dim)\n        expected_w2 = (self.hidden_dim, 1)\n        expected_b1 = (self.hidden_dim,)\n        expected_b2 = (1,)\n\n        shape_ok = (\n            w1_loaded.shape == expected_w1 and\n            w2_loaded.shape == expected_w2 and\n            b1_loaded.shape == expected_b1 and\n            b2_loaded.shape == expected_b2\n        )\n\n        if not shape_ok:\n            logger.warning(\n                f\"TinyScorer: shape mismatch in {self._weights_path}, \"\n                f\"W1={w1_loaded.shape} (expected {expected_w1}), \"\n                f\"W2={w2_loaded.shape} (expected {expected_w2}), \"\n                f\"b1={b1_loaded.shape} (expected {expected_b1}), \"\n                f\"b2={b2_loaded.shape} (expected {expected_b2}). \"\n                f\"Falling back to random init.\"\n            )\n            data.close()\n            self._init_random_weights()\n            return\n\n        # Cast to float32 to keep inference dtype stable\n        self.W1 = w1_loaded.astype(np.float32, copy=False)\n        self.b1 = b1_loaded.astype(np.float32, copy=False)\n        self.W2 = w2_loaded.astype(np.float32, copy=False)\n        self.b2 = b2_loaded.astype(np.float32, copy=False)\n        self._update_count = int(_get(\"update_count\", 0))\n        self._total_samples = int(_get(\"total_samples\", 0))\n        self._cumulative_loss = float(_get(\"cumulative_loss\", 0.0))\n        self._version = int(_get(\"version\", 0))\n\n        # Restore learning rate if saved\n        if \"learning_rate\" in data.files:\n            self.lr = float(data[\"learning_rate\"])\n\n        # Restore momentum if saved\n        if \"momentum_W1\" in data.files:\n            self._momentum_W1 = data[\"momentum_W1\"].astype(np.float32, copy=False)\n            self._momentum_b1 = data[\"momentum_b1\"].astype(np.float32, copy=False)\n            self._momentum_W2 = data[\"momentum_W2\"].astype(np.float32, copy=False)\n            self._momentum_b2 = data[\"momentum_b2\"].astype(np.float32, copy=False)\n        else:\n            self._momentum_W1 = np.zeros_like(self.W1)\n            self._momentum_b1 = np.zeros_like(self.b1)\n            self._momentum_W2 = np.zeros_like(self.W2)\n            self._momentum_b2 = np.zeros_like(self.b2)\n\n        self._weights_mtime = os.path.getmtime(self._weights_path)\n        data.close()\n\n    def rollback_to_checkpoint(self, version: int) -> bool:\n        \"\"\"Rollback to a specific checkpoint version.\"\"\"\n        try:\n            checkpoint_path = self._weights_path.replace(\".npz\", f\"_v{version}.npz\")\n            if os.path.exists(checkpoint_path):\n                import shutil\n                shutil.copy2(checkpoint_path, self._weights_path)\n                self._load_weights()\n                return True\n        except Exception:\n            pass\n        return False",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___init___381": {
      "name": "__init__",
      "type": "method",
      "start_line": 381,
      "end_line": 407,
      "content_hash": "ee5cf407cae1ba10659aa6c19c14f58d13cdf37f",
      "content": "    def __init__(self, dim: int = 256, hidden_dim: int = 512, lr: float = 0.001):\n        self.dim = dim\n        self.hidden_dim = hidden_dim\n        self.base_lr = lr\n        self.lr = lr\n        self._collection = \"default\"\n        self._weights_path = self._get_weights_path(\"default\")\n        self._weights_mtime = 0.0\n        self._last_reload_check = 0.0\n\n        # Training metrics\n        self._update_count = 0\n        self._total_samples = 0\n        self._cumulative_loss = 0.0\n        self._recent_losses: List[float] = []  # Rolling window for convergence detection\n        self._version = 0\n\n        # Try to load saved weights, otherwise init random\n        if os.path.exists(self._weights_path):\n            try:\n                self._load_weights()\n                return\n            except Exception as e:\n                from scripts.logger import get_logger\n                get_logger(__name__).warning(f\"TinyScorer: failed to load {self._weights_path}: {e}, using random init\")\n\n        self._init_random_weights()",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__init_random_weights_409": {
      "name": "_init_random_weights",
      "type": "method",
      "start_line": 409,
      "end_line": 424,
      "content_hash": "c0b19d36aa7b442b4865aed4d633e80cfad1ba7e",
      "content": "    def _init_random_weights(self):\n        \"\"\"Initialize weights randomly using He initialization (local RNG, deterministic).\"\"\"\n        # Use local RandomState to avoid polluting global RNG\n        rng = np.random.RandomState(42)\n        scale = np.float32(np.sqrt(2.0 / (self.dim * 3)))\n        self.W1 = rng.randn(self.dim * 3, self.hidden_dim).astype(np.float32) * scale\n        self.b1 = np.zeros(self.hidden_dim, dtype=np.float32)\n        w2_scale = np.float32(np.sqrt(2.0 / self.hidden_dim))\n        self.W2 = rng.randn(self.hidden_dim, 1).astype(np.float32) * w2_scale\n        self.b2 = np.zeros(1, dtype=np.float32)\n\n        # Momentum for SGD\n        self._momentum_W1 = np.zeros_like(self.W1)\n        self._momentum_b1 = np.zeros_like(self.b1)\n        self._momentum_W2 = np.zeros_like(self.W2)\n        self._momentum_b2 = np.zeros_like(self.b2)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__update_learning_rate_426": {
      "name": "_update_learning_rate",
      "type": "method",
      "start_line": 426,
      "end_line": 429,
      "content_hash": "100d7dcc50a41d4de8a27517f69fae791f714d4e",
      "content": "    def _update_learning_rate(self):\n        \"\"\"Decay learning rate based on update count.\"\"\"\n        if self._update_count > 0 and self._update_count % self.LR_DECAY_STEPS == 0:\n            self.lr = max(self.MIN_LR, self.lr * self.LR_DECAY_RATE)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_get_metrics_431": {
      "name": "get_metrics",
      "type": "method",
      "start_line": 431,
      "end_line": 445,
      "content_hash": "8f428d8ca69d941e9346d837d03707c3d68ac865",
      "content": "    def get_metrics(self) -> Dict[str, Any]:\n        \"\"\"Get current training metrics.\"\"\"\n        avg_loss = self._cumulative_loss / max(1, self._update_count)\n        recent_avg = np.mean(self._recent_losses) if self._recent_losses else 0.0\n        return {\n            \"collection\": self._collection,\n            \"version\": self._version,\n            \"update_count\": self._update_count,\n            \"total_samples\": self._total_samples,\n            \"cumulative_loss\": self._cumulative_loss,\n            \"avg_loss\": avg_loss,\n            \"recent_avg_loss\": float(recent_avg),\n            \"learning_rate\": self.lr,\n            \"converged\": self._is_converged(),\n        }",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__is_converged_447": {
      "name": "_is_converged",
      "type": "method",
      "start_line": 447,
      "end_line": 455,
      "content_hash": "bf04756cea69bb171b7a9edabad30d977ff100a5",
      "content": "    def _is_converged(self, window: int = 100, threshold: float = 0.01) -> bool:\n        \"\"\"Check if training has converged (loss not improving).\"\"\"\n        if len(self._recent_losses) < window:\n            return False\n        recent = self._recent_losses[-window:]\n        first_half = np.mean(recent[:window // 2])\n        second_half = np.mean(recent[window // 2:])\n        # Converged if improvement is less than threshold\n        return abs(first_half - second_half) < threshold * first_half",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__get_weights_path_457": {
      "name": "_get_weights_path",
      "type": "method",
      "start_line": 457,
      "end_line": 461,
      "content_hash": "4cd5bf21e6f665bda9b57137d7721003629bf36d",
      "content": "    def _get_weights_path(self, collection: str) -> str:\n        \"\"\"Get weights file path for a collection.\"\"\"\n        os.makedirs(self.WEIGHTS_DIR, exist_ok=True)\n        safe_name = \"\".join(c if c.isalnum() or c in \"-_\" else \"_\" for c in collection)\n        return os.path.join(self.WEIGHTS_DIR, f\"weights_{safe_name}.npz\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_set_collection_463": {
      "name": "set_collection",
      "type": "method",
      "start_line": 463,
      "end_line": 471,
      "content_hash": "4dae7da98f3091db4d26c907c21a25aa337d6f9d",
      "content": "    def set_collection(self, collection: str):\n        \"\"\"Set collection and load corresponding weights.\"\"\"\n        self._collection = collection\n        self._weights_path = self._get_weights_path(collection)\n        if os.path.exists(self._weights_path):\n            try:\n                self._load_weights()\n            except Exception:\n                pass",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_maybe_reload_weights_473": {
      "name": "maybe_reload_weights",
      "type": "method",
      "start_line": 473,
      "end_line": 486,
      "content_hash": "03da8dbd8e230701333223b3c451ce4c35c6cbce",
      "content": "    def maybe_reload_weights(self):\n        \"\"\"Check if weights file changed and reload if needed (hot reload).\"\"\"\n        now = time.time()\n        if now - self._last_reload_check < self.WEIGHTS_RELOAD_INTERVAL:\n            return\n        self._last_reload_check = now\n\n        try:\n            if os.path.exists(self._weights_path):\n                mtime = os.path.getmtime(self._weights_path)\n                if mtime > self._weights_mtime:\n                    self._load_weights_safe()\n        except Exception:\n            pass",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__load_weights_safe_488": {
      "name": "_load_weights_safe",
      "type": "method",
      "start_line": 488,
      "end_line": 504,
      "content_hash": "d75ac170d0b94a610206fe51bc9976daf4997fc0",
      "content": "    def _load_weights_safe(self):\n        \"\"\"Load weights with advisory file locking (prevents partial reads during writes).\"\"\"\n        import fcntl\n        lock_path = self._weights_path + \".lock\"\n        try:\n            # Use same lock file as writer for coordination\n            os.makedirs(os.path.dirname(lock_path) or \".\", exist_ok=True)\n            with open(lock_path, \"w\") as lock_file:\n                # Shared lock for reading (blocks if exclusive lock held by writer)\n                fcntl.flock(lock_file.fileno(), fcntl.LOCK_SH)\n                try:\n                    self._load_weights()\n                finally:\n                    fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)\n        except Exception:\n            # Fallback to direct load if locking fails\n            self._load_weights()",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_forward_506": {
      "name": "forward",
      "type": "method",
      "start_line": 506,
      "end_line": 533,
      "content_hash": "7ef28e6c59b0d6f1751584a7a026deb9c4318d98",
      "content": "    def forward(self, query_emb: np.ndarray, doc_emb: np.ndarray, z: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Score documents given query and latent state.\n\n        Input shapes:\n            query_emb: (dim,) - query embedding\n            doc_emb: (n_docs, dim) - document embeddings\n            z: (dim,) - latent state from previous iteration\n\n        Returns:\n            scores: (n_docs,) - relevance scores\n        \"\"\"\n        # Check for hot-reloaded weights\n        self.maybe_reload_weights()\n\n        n_docs = doc_emb.shape[0]\n        # Broadcast query and z across docs\n        q_broadcast = np.tile(query_emb, (n_docs, 1))  # (n_docs, dim)\n        z_broadcast = np.tile(z, (n_docs, 1))  # (n_docs, dim)\n\n        # Concatenate [query, doc, latent] for each document\n        x = np.concatenate([q_broadcast, doc_emb, z_broadcast], axis=1)  # (n_docs, dim*3)\n\n        # 2-layer MLP with ReLU\n        h = np.maximum(0, x @ self.W1 + self.b1)  # (n_docs, hidden_dim)\n        scores = (h @ self.W2 + self.b2).squeeze(-1)  # (n_docs,)\n\n        return scores",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_forward_with_cache_535": {
      "name": "forward_with_cache",
      "type": "method",
      "start_line": 535,
      "end_line": 542,
      "content_hash": "17ceb9c0b3aaeb6945796ea58f09f02db5e6665b",
      "content": "    def forward_with_cache(self, x: np.ndarray) -> Tuple[np.ndarray, Dict[str, np.ndarray]]:\n        \"\"\"Forward pass with cached activations for backprop.\"\"\"\n        z1 = x @ self.W1 + self.b1  # (batch, hidden)\n        h1 = np.maximum(0, z1)  # ReLU\n        z2 = h1 @ self.W2 + self.b2  # (batch, 1)\n        scores = z2.squeeze(-1)  # (batch,)\n        cache = {\"x\": x, \"z1\": z1, \"h1\": h1}\n        return scores, cache",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_backward_544": {
      "name": "backward",
      "type": "method",
      "start_line": 544,
      "end_line": 566,
      "content_hash": "d440635f1cb91b174e428fe7ef496acaf22ddea1",
      "content": "    def backward(self, dscores: np.ndarray, cache: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n        \"\"\"Backward pass to compute gradients.\"\"\"\n        batch_size = dscores.shape[0]\n        dz2 = dscores.reshape(-1, 1)  # (batch, 1)\n\n        # Layer 2 gradients\n        dW2 = cache[\"h1\"].T @ dz2\n        db2 = dz2.sum(axis=0)\n        dh1 = dz2 @ self.W2.T  # (batch, hidden)\n\n        # ReLU backward\n        dz1 = dh1 * (cache[\"z1\"] > 0).astype(np.float32)\n\n        # Layer 1 gradients\n        dW1 = cache[\"x\"].T @ dz1\n        db1 = dz1.sum(axis=0)\n\n        return {\n            \"W1\": dW1 / batch_size,\n            \"b1\": db1 / batch_size,\n            \"W2\": dW2 / batch_size,\n            \"b2\": db2 / batch_size,\n        }",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_learn_from_teacher_568": {
      "name": "learn_from_teacher",
      "type": "method",
      "start_line": 568,
      "end_line": 647,
      "content_hash": "a1a867813ece5327b717d0ecec9286cedfe6848a",
      "content": "    def learn_from_teacher(\n        self,\n        query_emb: np.ndarray,\n        doc_embs: np.ndarray,\n        z: np.ndarray,\n        teacher_scores: np.ndarray,\n        margin: float = 0.5,\n    ) -> float:\n        \"\"\"\n        Online learning: update weights to match ONNX teacher ranking.\n\n        Uses pairwise margin ranking loss:\n        L = max(0, margin - (s_pos - s_neg))\n        where s_pos > s_neg in teacher ranking.\n\n        Returns:\n            Loss value (0.0 if no update needed)\n        \"\"\"\n        n_docs = doc_embs.shape[0]\n        if n_docs < 2:\n            return 0.0\n\n        # Build input matrix\n        q_broadcast = np.tile(query_emb, (n_docs, 1))\n        z_broadcast = np.tile(z, (n_docs, 1))\n        x = np.concatenate([q_broadcast, doc_embs, z_broadcast], axis=1)\n\n        # Forward pass with cache\n        our_scores, cache = self.forward_with_cache(x)\n\n        # Get teacher ranking\n        teacher_order = np.argsort(-teacher_scores)\n\n        # Sample pairs from teacher ranking (top vs bottom)\n        n_pairs = min(5, n_docs // 2)\n        total_loss = 0.0\n        dscores = np.zeros(n_docs, dtype=np.float32)\n\n        for i in range(n_pairs):\n            pos_idx = teacher_order[i]  # Should rank high\n            neg_idx = teacher_order[-(i + 1)]  # Should rank low\n\n            # Margin loss\n            diff = our_scores[pos_idx] - our_scores[neg_idx]\n            if diff < margin:\n                # Violation - need to update\n                loss = margin - diff\n                total_loss += loss\n\n                # Gradient: increase pos score, decrease neg score\n                dscores[pos_idx] -= 1.0\n                dscores[neg_idx] += 1.0\n\n        # Track metrics\n        self._total_samples += n_docs\n        self._cumulative_loss += total_loss\n        self._recent_losses.append(total_loss)\n        if len(self._recent_losses) > 200:  # Keep last 200 for convergence check\n            self._recent_losses = self._recent_losses[-200:]\n\n        if total_loss > 0:\n            # Backward pass\n            grads = self.backward(dscores, cache)\n\n            # SGD with momentum update\n            momentum = 0.9\n            self._momentum_W1 = momentum * self._momentum_W1 - self.lr * grads[\"W1\"]\n            self._momentum_b1 = momentum * self._momentum_b1 - self.lr * grads[\"b1\"]\n            self._momentum_W2 = momentum * self._momentum_W2 - self.lr * grads[\"W2\"]\n            self._momentum_b2 = momentum * self._momentum_b2 - self.lr * grads[\"b2\"]\n\n            self.W1 += self._momentum_W1\n            self.b1 += self._momentum_b1\n            self.W2 += self._momentum_W2\n            self.b2 += self._momentum_b2\n\n            self._update_count += 1\n            self._update_learning_rate()\n\n        return total_loss",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__save_weights_649": {
      "name": "_save_weights",
      "type": "method",
      "start_line": 649,
      "end_line": 696,
      "content_hash": "cb8391daa3430140530c8e143f07d909c5298a1c",
      "content": "    def _save_weights(self, checkpoint: bool = False):\n        \"\"\"\n        Save weights to disk atomically (write to .tmp, then rename).\n\n        Uses advisory file locking to coordinate with readers during hot reload.\n\n        Args:\n            checkpoint: If True, also save a versioned checkpoint\n        \"\"\"\n        import fcntl\n        try:\n            self._version += 1\n            # np.savez automatically adds .npz extension, so use a base path\n            # that when .npz is added becomes our tmp file\n            tmp_base = self._weights_path.replace(\".npz\", \".tmp\")\n            np.savez(\n                tmp_base,\n                W1=self.W1, b1=self.b1, W2=self.W2, b2=self.b2,\n                momentum_W1=self._momentum_W1, momentum_b1=self._momentum_b1,\n                momentum_W2=self._momentum_W2, momentum_b2=self._momentum_b2,\n                update_count=self._update_count,\n                total_samples=self._total_samples,\n                cumulative_loss=self._cumulative_loss,\n                learning_rate=self.lr,\n                version=self._version,\n                collection=self._collection,\n            )\n            # np.savez writes to tmp_base + \".npz\"\n            tmp_path = tmp_base + \".npz\"\n\n            # Acquire exclusive lock on target before atomic rename\n            # This blocks any readers currently holding shared locks\n            lock_path = self._weights_path + \".lock\"\n            os.makedirs(os.path.dirname(lock_path) or \".\", exist_ok=True)\n            with open(lock_path, \"w\") as lock_file:\n                fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX)\n                try:\n                    # Atomic rename to final path\n                    os.replace(tmp_path, self._weights_path)\n                finally:\n                    fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)\n\n            # Save versioned checkpoint\n            if checkpoint or self._version % 100 == 0:\n                self._save_checkpoint()\n\n        except Exception:\n            pass",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__save_checkpoint_698": {
      "name": "_save_checkpoint",
      "type": "method",
      "start_line": 698,
      "end_line": 709,
      "content_hash": "fb9f8c15e2420b7ecada014f52ca9b8573f821ae",
      "content": "    def _save_checkpoint(self):\n        \"\"\"Save a versioned checkpoint and prune old ones.\"\"\"\n        try:\n            checkpoint_path = self._weights_path.replace(\".npz\", f\"_v{self._version}.npz\")\n            # Copy current weights to checkpoint\n            import shutil\n            shutil.copy2(self._weights_path, checkpoint_path)\n\n            # Prune old checkpoints (keep last MAX_CHECKPOINTS)\n            self._prune_old_checkpoints()\n        except Exception:\n            pass",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__prune_old_checkpoints_711": {
      "name": "_prune_old_checkpoints",
      "type": "method",
      "start_line": 711,
      "end_line": 724,
      "content_hash": "efba76751de0ca88414e12280ceb01b7682d2cc3",
      "content": "    def _prune_old_checkpoints(self):\n        \"\"\"Remove old checkpoints keeping only the most recent MAX_CHECKPOINTS.\"\"\"\n        try:\n            import glob\n            pattern = self._weights_path.replace(\".npz\", \"_v*.npz\")\n            checkpoints = sorted(glob.glob(pattern))\n            if len(checkpoints) > self.MAX_CHECKPOINTS:\n                for old_cp in checkpoints[:-self.MAX_CHECKPOINTS]:\n                    try:\n                        os.remove(old_cp)\n                    except Exception:\n                        pass\n        except Exception:\n            pass",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__load_weights_726": {
      "name": "_load_weights",
      "type": "method",
      "start_line": 726,
      "end_line": 795,
      "content_hash": "9e8743ff7d1c11230d691fc41b72808bda852371",
      "content": "    def _load_weights(self):\n        \"\"\"Load weights from disk with dimension validation.\"\"\"\n        from scripts.logger import get_logger\n        logger = get_logger(__name__)\n\n        data = np.load(self._weights_path, allow_pickle=True)\n\n        # Helper to safely get from NpzFile (doesn't have .get())\n        def _get(key: str, default):\n            return data[key] if key in data.files else default\n\n        # Validate all dimensions before loading to prevent shape mismatch crashes\n        w1_loaded = data[\"W1\"]\n        w2_loaded = data[\"W2\"]\n        b1_loaded = data[\"b1\"]\n        b2_loaded = data[\"b2\"]\n\n        expected_w1 = (self.dim * 3, self.hidden_dim)\n        expected_w2 = (self.hidden_dim, 1)\n        expected_b1 = (self.hidden_dim,)\n        expected_b2 = (1,)\n\n        shape_ok = (\n            w1_loaded.shape == expected_w1 and\n            w2_loaded.shape == expected_w2 and\n            b1_loaded.shape == expected_b1 and\n            b2_loaded.shape == expected_b2\n        )\n\n        if not shape_ok:\n            logger.warning(\n                f\"TinyScorer: shape mismatch in {self._weights_path}, \"\n                f\"W1={w1_loaded.shape} (expected {expected_w1}), \"\n                f\"W2={w2_loaded.shape} (expected {expected_w2}), \"\n                f\"b1={b1_loaded.shape} (expected {expected_b1}), \"\n                f\"b2={b2_loaded.shape} (expected {expected_b2}). \"\n                f\"Falling back to random init.\"\n            )\n            data.close()\n            self._init_random_weights()\n            return\n\n        # Cast to float32 to keep inference dtype stable\n        self.W1 = w1_loaded.astype(np.float32, copy=False)\n        self.b1 = b1_loaded.astype(np.float32, copy=False)\n        self.W2 = w2_loaded.astype(np.float32, copy=False)\n        self.b2 = b2_loaded.astype(np.float32, copy=False)\n        self._update_count = int(_get(\"update_count\", 0))\n        self._total_samples = int(_get(\"total_samples\", 0))\n        self._cumulative_loss = float(_get(\"cumulative_loss\", 0.0))\n        self._version = int(_get(\"version\", 0))\n\n        # Restore learning rate if saved\n        if \"learning_rate\" in data.files:\n            self.lr = float(data[\"learning_rate\"])\n\n        # Restore momentum if saved\n        if \"momentum_W1\" in data.files:\n            self._momentum_W1 = data[\"momentum_W1\"].astype(np.float32, copy=False)\n            self._momentum_b1 = data[\"momentum_b1\"].astype(np.float32, copy=False)\n            self._momentum_W2 = data[\"momentum_W2\"].astype(np.float32, copy=False)\n            self._momentum_b2 = data[\"momentum_b2\"].astype(np.float32, copy=False)\n        else:\n            self._momentum_W1 = np.zeros_like(self.W1)\n            self._momentum_b1 = np.zeros_like(self.b1)\n            self._momentum_W2 = np.zeros_like(self.W2)\n            self._momentum_b2 = np.zeros_like(self.b2)\n\n        self._weights_mtime = os.path.getmtime(self._weights_path)\n        data.close()",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__get_734": {
      "name": "_get",
      "type": "method",
      "start_line": 734,
      "end_line": 735,
      "content_hash": "71a38e2665639cb4b3907a021806f5ff6f53b7ac",
      "content": "        def _get(key: str, default):\n            return data[key] if key in data.files else default",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_rollback_to_checkpoint_797": {
      "name": "rollback_to_checkpoint",
      "type": "method",
      "start_line": 797,
      "end_line": 808,
      "content_hash": "982b48283a8f0584d412a9acd7d3a57767126f0f",
      "content": "    def rollback_to_checkpoint(self, version: int) -> bool:\n        \"\"\"Rollback to a specific checkpoint version.\"\"\"\n        try:\n            checkpoint_path = self._weights_path.replace(\".npz\", f\"_v{version}.npz\")\n            if os.path.exists(checkpoint_path):\n                import shutil\n                shutil.copy2(checkpoint_path, self._weights_path)\n                self._load_weights()\n                return True\n        except Exception:\n            pass\n        return False",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_LatentRefiner_811": {
      "name": "LatentRefiner",
      "type": "class",
      "start_line": 811,
      "end_line": 1246,
      "content_hash": "d8f2da79840eae748f62bcc0c95f32441639291b",
      "content": "class LatentRefiner:\n    \"\"\"\n    Refines the latent state z based on current results.\n\n    From TRM paper: z encodes \"what we've learned about the query so far\"\n    and gets updated based on the current answer (scores).\n\n    Supports:\n    - Per-collection weight persistence (like TinyScorer)\n    - Hot-reload from background worker updates\n    - Online learning via learn_from_teacher()\n    \"\"\"\n\n    # Class-level configuration (mirrors TinyScorer)\n    WEIGHTS_DIR = os.environ.get(\"RERANKER_WEIGHTS_DIR\", \"/tmp/rerank_weights\")\n    WEIGHTS_RELOAD_INTERVAL = float(os.environ.get(\"RERANKER_WEIGHTS_RELOAD_INTERVAL\", \"60\"))\n\n    def __init__(self, dim: int = 256, hidden_dim: int = 256, lr: float = 0.001):\n        self.dim = dim\n        self.hidden_dim = hidden_dim\n        self.base_lr = lr\n        self.lr = lr\n        self._collection = \"default\"\n        self._weights_path = self._get_weights_path(\"default\")\n        self._weights_mtime = 0.0\n        self._last_reload_check = 0.0\n        self._weights_loaded = False\n\n        # Training metrics\n        self._update_count = 0\n        self._version = 0\n\n        # Momentum for SGD\n        self._momentum_W1: Optional[np.ndarray] = None\n        self._momentum_b1: Optional[np.ndarray] = None\n        self._momentum_W2: Optional[np.ndarray] = None\n        self._momentum_b2: Optional[np.ndarray] = None\n\n        # Try to load saved weights, otherwise init random\n        if os.path.exists(self._weights_path):\n            try:\n                self._load_weights()\n                return\n            except Exception as e:\n                from scripts.logger import get_logger\n                get_logger(__name__).warning(f\"LatentRefiner: failed to load {self._weights_path}: {e}, using random init\")\n\n        self._init_random_weights()\n\n    @staticmethod\n    def _sanitize_collection(collection: str) -> str:\n        \"\"\"Sanitize collection name to prevent path traversal.\"\"\"\n        return \"\".join(c if c.isalnum() or c in \"-_\" else \"_\" for c in collection)\n\n    def _get_weights_path(self, collection: str) -> str:\n        \"\"\"Get weights file path for a collection.\"\"\"\n        safe_name = self._sanitize_collection(collection)\n        return os.path.join(self.WEIGHTS_DIR, f\"refiner_{safe_name}.npz\")\n\n    def set_collection(self, collection: str):\n        \"\"\"Set collection and load corresponding weights.\"\"\"\n        self._collection = collection\n        self._weights_path = self._get_weights_path(collection)\n        if os.path.exists(self._weights_path):\n            try:\n                self._load_weights()\n            except Exception:\n                pass\n\n    def maybe_reload_weights(self):\n        \"\"\"Check if weights file changed and reload if needed (hot reload).\"\"\"\n        now = time.time()\n        if now - self._last_reload_check < self.WEIGHTS_RELOAD_INTERVAL:\n            return\n        self._last_reload_check = now\n\n        try:\n            if os.path.exists(self._weights_path):\n                mtime = os.path.getmtime(self._weights_path)\n                if mtime > self._weights_mtime:\n                    self._load_weights_safe()\n        except Exception:\n            pass\n\n    def _load_weights_safe(self):\n        \"\"\"Load weights with advisory file locking (prevents partial reads during writes).\"\"\"\n        import fcntl\n        lock_path = self._weights_path + \".lock\"\n        try:\n            os.makedirs(os.path.dirname(lock_path) or \".\", exist_ok=True)\n            with open(lock_path, \"w\") as lock_file:\n                fcntl.flock(lock_file.fileno(), fcntl.LOCK_SH)\n                try:\n                    self._load_weights()\n                finally:\n                    fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)\n        except Exception:\n            self._load_weights()\n\n    def _init_random_weights(self):\n        \"\"\"Initialize with random weights using He initialization.\"\"\"\n        rng = np.random.RandomState(43)\n        scale = np.float32(np.sqrt(2.0 / (self.dim * 3)))\n        self.W1 = rng.randn(self.dim * 3, self.hidden_dim).astype(np.float32) * scale\n        self.b1 = np.zeros(self.hidden_dim, dtype=np.float32)\n        w2_scale = np.float32(np.sqrt(2.0 / self.hidden_dim))\n        self.W2 = rng.randn(self.hidden_dim, self.dim).astype(np.float32) * w2_scale\n        self.b2 = np.zeros(self.dim, dtype=np.float32)\n\n        # Initialize momentum\n        self._momentum_W1 = np.zeros_like(self.W1)\n        self._momentum_b1 = np.zeros_like(self.b1)\n        self._momentum_W2 = np.zeros_like(self.W2)\n        self._momentum_b2 = np.zeros_like(self.b2)\n\n    def _load_weights(self) -> bool:\n        \"\"\"Load trained weights from disk. Returns True on success.\"\"\"\n        from scripts.logger import get_logger\n        logger = get_logger(__name__)\n        try:\n            data = np.load(self._weights_path, allow_pickle=True)\n\n            # Helper to safely get from NpzFile\n            def _get(key: str, default):\n                return data[key] if key in data.files else default\n\n            # Validate shapes\n            w1 = _get(\"W1\", None)\n            w2 = _get(\"W2\", None)\n            b1 = _get(\"b1\", None)\n            b2 = _get(\"b2\", None)\n\n            if w1 is None or w2 is None:\n                data.close()\n                return False\n\n            expected_w1 = (self.dim * 3, self.hidden_dim)\n            expected_w2 = (self.hidden_dim, self.dim)\n\n            if w1.shape != expected_w1 or w2.shape != expected_w2:\n                logger.warning(f\"LatentRefiner: shape mismatch W1={w1.shape} W2={w2.shape}\")\n                data.close()\n                return False\n\n            self.W1 = w1.astype(np.float32, copy=False)\n            self.b1 = b1.astype(np.float32, copy=False) if b1 is not None else np.zeros(self.hidden_dim, dtype=np.float32)\n            self.W2 = w2.astype(np.float32, copy=False)\n            self.b2 = b2.astype(np.float32, copy=False) if b2 is not None else np.zeros(self.dim, dtype=np.float32)\n\n            # Load training state\n            self._update_count = int(_get(\"update_count\", 0))\n            self._version = int(_get(\"version\", 0))\n\n            # Initialize momentum if not loaded\n            if self._momentum_W1 is None or self._momentum_W1.shape != self.W1.shape:\n                self._momentum_W1 = np.zeros_like(self.W1)\n                self._momentum_b1 = np.zeros_like(self.b1)\n                self._momentum_W2 = np.zeros_like(self.W2)\n                self._momentum_b2 = np.zeros_like(self.b2)\n\n            self._weights_loaded = True\n            self._weights_mtime = os.path.getmtime(self._weights_path)\n            data.close()\n            logger.debug(f\"LatentRefiner: loaded weights v{self._version} from {self._weights_path}\")\n            return True\n        except Exception as e:\n            logger.warning(f\"LatentRefiner: failed to load weights: {e}\")\n            return False\n\n    def refine(\n        self,\n        z: np.ndarray,\n        query_emb: np.ndarray,\n        doc_embs: np.ndarray,\n        scores: np.ndarray,\n        alpha: float = 0.5  # EMA smoothing factor\n    ) -> np.ndarray:\n        \"\"\"\n        Refine latent state based on current ranking.\n\n        Uses attention-weighted sum of top documents as \"answer summary\".\n        \"\"\"\n        # Check for hot-reloaded weights\n        self.maybe_reload_weights()\n\n        # Softmax attention over scores to get weighted doc representation\n        weights = np.exp(scores - scores.max())\n        weights = weights / (weights.sum() + 1e-8)\n        doc_summary = (weights[:, None] * doc_embs).sum(axis=0)  # (dim,)\n\n        # Concatenate [z, query, doc_summary]\n        x = np.concatenate([z, query_emb, doc_summary])  # (dim*3,)\n\n        # 2-layer refinement\n        h = np.maximum(0, x @ self.W1 + self.b1)\n        z_new = h @ self.W2 + self.b2\n\n        # EMA update (from TRM: stabilizes training)\n        z_refined = alpha * z_new + (1 - alpha) * z\n\n        # Normalize to unit sphere\n        z_refined = z_refined / (np.linalg.norm(z_refined) + 1e-8)\n\n        return z_refined\n\n    def refine_with_cache(\n        self,\n        z: np.ndarray,\n        query_emb: np.ndarray,\n        doc_embs: np.ndarray,\n        scores: np.ndarray,\n        alpha: float = 0.5\n    ) -> tuple:\n        \"\"\"Refine with cache for backprop. Returns (z_refined, cache).\"\"\"\n        weights = np.exp(scores - scores.max())\n        weights = weights / (weights.sum() + 1e-8)\n        doc_summary = (weights[:, None] * doc_embs).sum(axis=0)\n\n        x = np.concatenate([z, query_emb, doc_summary])\n        h = np.maximum(0, x @ self.W1 + self.b1)\n        z_new = h @ self.W2 + self.b2\n        z_refined = alpha * z_new + (1 - alpha) * z\n        z_refined = z_refined / (np.linalg.norm(z_refined) + 1e-8)\n\n        cache = {\"x\": x, \"h\": h, \"z\": z, \"z_new\": z_new, \"alpha\": alpha, \"weights\": weights}\n        return z_refined, cache\n\n    def learn_from_teacher(\n        self,\n        z: np.ndarray,\n        query_emb: np.ndarray,\n        doc_embs: np.ndarray,\n        scores: np.ndarray,\n        teacher_z: np.ndarray,\n    ) -> float:\n        \"\"\"\n        Online learning: update weights so refined z moves toward teacher_z.\n\n        Uses MSE loss between our z_refined and teacher_z (normalized).\n\n        Returns:\n            Loss value\n        \"\"\"\n        # Forward pass with cache\n        z_refined, cache = self.refine_with_cache(z, query_emb, doc_embs, scores)\n\n        # MSE loss: ||z_refined - teacher_z||^2\n        diff = z_refined - teacher_z\n        loss = float(np.sum(diff ** 2))\n\n        if loss < 1e-8:\n            return 0.0\n\n        # Backward pass (gradient of MSE)\n        dz_refined = 2.0 * diff  # (dim,)\n\n        # Through normalization (approx - assume near unit norm)\n        dz_new = cache[\"alpha\"] * dz_refined\n\n        # Through W2, b2\n        dW2 = np.outer(cache[\"h\"], dz_new)\n        db2 = dz_new\n\n        # Through ReLU and W1, b1\n        dh = dz_new @ self.W2.T\n        dh = dh * (cache[\"h\"] > 0).astype(np.float32)\n        dW1 = np.outer(cache[\"x\"], dh)\n        db1 = dh\n\n        # SGD with momentum\n        momentum = 0.9\n        if self._momentum_W1 is None:\n            self._momentum_W1 = np.zeros_like(self.W1)\n            self._momentum_b1 = np.zeros_like(self.b1)\n            self._momentum_W2 = np.zeros_like(self.W2)\n            self._momentum_b2 = np.zeros_like(self.b2)\n\n        self._momentum_W1 = momentum * self._momentum_W1 - self.lr * dW1\n        self._momentum_b1 = momentum * self._momentum_b1 - self.lr * db1\n        self._momentum_W2 = momentum * self._momentum_W2 - self.lr * dW2\n        self._momentum_b2 = momentum * self._momentum_b2 - self.lr * db2\n\n        self.W1 += self._momentum_W1\n        self.b1 += self._momentum_b1\n        self.W2 += self._momentum_W2\n        self.b2 += self._momentum_b2\n\n        self._update_count += 1\n        return loss\n\n    def learn_from_teacher_with_cache(\n        self,\n        z: np.ndarray,\n        query_emb: np.ndarray,\n        doc_embs: np.ndarray,\n        scores: np.ndarray,\n        teacher_z: np.ndarray,\n    ) -> Tuple[float, np.ndarray, np.ndarray, Dict[str, Any]]:\n        \"\"\"\n        Online learning with cache for VICReg backprop.\n\n        Like learn_from_teacher(), but returns (z, z_refined, cache) for\n        batch-level VICReg regularization.\n\n        Returns:\n            (loss, z, z_refined, cache)\n        \"\"\"\n        # Forward pass with cache\n        z_refined, cache = self.refine_with_cache(z, query_emb, doc_embs, scores)\n\n        # MSE loss: ||z_refined - teacher_z||^2\n        diff = z_refined - teacher_z\n        loss = float(np.sum(diff ** 2))\n\n        if loss >= 1e-8:\n            # Backward pass (gradient of MSE)\n            dz_refined = 2.0 * diff\n\n            # Through normalization (approx - assume near unit norm)\n            dz_new = cache[\"alpha\"] * dz_refined\n\n            # Through W2, b2\n            dW2 = np.outer(cache[\"h\"], dz_new)\n            db2 = dz_new\n\n            # Through ReLU and W1, b1\n            dh = dz_new @ self.W2.T\n            dh = dh * (cache[\"h\"] > 0).astype(np.float32)\n            dW1 = np.outer(cache[\"x\"], dh)\n            db1 = dh\n\n            # SGD with momentum\n            momentum = 0.9\n            if self._momentum_W1 is None:\n                self._momentum_W1 = np.zeros_like(self.W1)\n                self._momentum_b1 = np.zeros_like(self.b1)\n                self._momentum_W2 = np.zeros_like(self.W2)\n                self._momentum_b2 = np.zeros_like(self.b2)\n\n            self._momentum_W1 = momentum * self._momentum_W1 - self.lr * dW1\n            self._momentum_b1 = momentum * self._momentum_b1 - self.lr * db1\n            self._momentum_W2 = momentum * self._momentum_W2 - self.lr * dW2\n            self._momentum_b2 = momentum * self._momentum_b2 - self.lr * db2\n\n            self.W1 += self._momentum_W1\n            self.b1 += self._momentum_b1\n            self.W2 += self._momentum_W2\n            self.b2 += self._momentum_b2\n\n            self._update_count += 1\n\n        return loss, z, z_refined, cache\n\n    def apply_vicreg_gradient(\n        self,\n        grad_z_refined: np.ndarray,\n        cache: Dict[str, Any],\n        weight: float = 0.1,\n    ):\n        \"\"\"\n        Apply VICReg gradient to refiner weights.\n\n        Called after VICReg.forward() computes gradient w.r.t. z_refined.\n        Backprops through the refiner network to update W1, b1, W2, b2.\n\n        Args:\n            grad_z_refined: (dim,) gradient from VICReg\n            cache: Cache from refine_with_cache() or learn_from_teacher_with_cache()\n            weight: Scaling factor for the regularization gradient\n        \"\"\"\n        # Backprop through z_refined = alpha * z_new + (1-alpha) * z\n        # d/dz_new = alpha * grad_z_refined\n        dz_new = cache[\"alpha\"] * grad_z_refined * weight\n\n        # Through W2, b2: z_new = h @ W2 + b2\n        dW2 = np.outer(cache[\"h\"], dz_new)\n        db2 = dz_new\n\n        # Through ReLU: h = max(0, pre_h)\n        dh = dz_new @ self.W2.T\n        dh = dh * (cache[\"h\"] > 0).astype(np.float32)\n\n        # Through W1, b1: pre_h = x @ W1 + b1\n        dW1 = np.outer(cache[\"x\"], dh)\n        db1 = dh\n\n        # Apply gradients directly (VICReg uses same LR as main training)\n        self.W1 -= self.lr * dW1\n        self.b1 -= self.lr * db1\n        self.W2 -= self.lr * dW2\n        self.b2 -= self.lr * db2\n\n    def _save_weights(self, checkpoint: bool = False):\n        \"\"\"Save weights to disk atomically with file locking.\n\n        Mirrors TinyScorer._save_weights: use a base path without the .npz\n        extension for np.savez (which appends .npz automatically), then\n        atomically rename the resulting file into place.\n        \"\"\"\n        import fcntl\n\n        os.makedirs(self.WEIGHTS_DIR, exist_ok=True)\n        self._version += 1\n\n        # np.savez automatically adds .npz, so follow the same pattern as\n        # TinyScorer: derive a temporary base path and then construct the\n        # actual temp file path that np.savez will create.\n        tmp_base = self._weights_path.replace(\".npz\", \".tmp\")\n        tmp_path = tmp_base + \".npz\"\n        lock_path = self._weights_path + \".lock\"\n\n        try:\n            with open(lock_path, \"w\") as lock_file:\n                fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX)\n                try:\n                    np.savez(\n                        tmp_base,\n                        W1=self.W1,\n                        b1=self.b1,\n                        W2=self.W2,\n                        b2=self.b2,\n                        update_count=self._update_count,\n                        version=self._version,\n                        dim=self.dim,\n                        hidden_dim=self.hidden_dim,\n                    )\n                    os.replace(tmp_path, self._weights_path)\n                finally:\n                    fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)\n        except Exception:\n            if os.path.exists(tmp_path):\n                try:\n                    os.remove(tmp_path)\n                except Exception:\n                    pass\n            raise",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___init___828": {
      "name": "__init__",
      "type": "method",
      "start_line": 828,
      "end_line": 858,
      "content_hash": "85643c76868505981cd993a9cacb7ec523c50f60",
      "content": "    def __init__(self, dim: int = 256, hidden_dim: int = 256, lr: float = 0.001):\n        self.dim = dim\n        self.hidden_dim = hidden_dim\n        self.base_lr = lr\n        self.lr = lr\n        self._collection = \"default\"\n        self._weights_path = self._get_weights_path(\"default\")\n        self._weights_mtime = 0.0\n        self._last_reload_check = 0.0\n        self._weights_loaded = False\n\n        # Training metrics\n        self._update_count = 0\n        self._version = 0\n\n        # Momentum for SGD\n        self._momentum_W1: Optional[np.ndarray] = None\n        self._momentum_b1: Optional[np.ndarray] = None\n        self._momentum_W2: Optional[np.ndarray] = None\n        self._momentum_b2: Optional[np.ndarray] = None\n\n        # Try to load saved weights, otherwise init random\n        if os.path.exists(self._weights_path):\n            try:\n                self._load_weights()\n                return\n            except Exception as e:\n                from scripts.logger import get_logger\n                get_logger(__name__).warning(f\"LatentRefiner: failed to load {self._weights_path}: {e}, using random init\")\n\n        self._init_random_weights()",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__sanitize_collection_861": {
      "name": "_sanitize_collection",
      "type": "method",
      "start_line": 861,
      "end_line": 863,
      "content_hash": "e359c3b5022e7b75309996e45f7d7fa4e7a96710",
      "content": "    def _sanitize_collection(collection: str) -> str:\n        \"\"\"Sanitize collection name to prevent path traversal.\"\"\"\n        return \"\".join(c if c.isalnum() or c in \"-_\" else \"_\" for c in collection)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__get_weights_path_865": {
      "name": "_get_weights_path",
      "type": "method",
      "start_line": 865,
      "end_line": 868,
      "content_hash": "3b7f71aba7ca983a2300356c1762725812b16a31",
      "content": "    def _get_weights_path(self, collection: str) -> str:\n        \"\"\"Get weights file path for a collection.\"\"\"\n        safe_name = self._sanitize_collection(collection)\n        return os.path.join(self.WEIGHTS_DIR, f\"refiner_{safe_name}.npz\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_set_collection_870": {
      "name": "set_collection",
      "type": "method",
      "start_line": 870,
      "end_line": 878,
      "content_hash": "4dae7da98f3091db4d26c907c21a25aa337d6f9d",
      "content": "    def set_collection(self, collection: str):\n        \"\"\"Set collection and load corresponding weights.\"\"\"\n        self._collection = collection\n        self._weights_path = self._get_weights_path(collection)\n        if os.path.exists(self._weights_path):\n            try:\n                self._load_weights()\n            except Exception:\n                pass",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_maybe_reload_weights_880": {
      "name": "maybe_reload_weights",
      "type": "method",
      "start_line": 880,
      "end_line": 893,
      "content_hash": "03da8dbd8e230701333223b3c451ce4c35c6cbce",
      "content": "    def maybe_reload_weights(self):\n        \"\"\"Check if weights file changed and reload if needed (hot reload).\"\"\"\n        now = time.time()\n        if now - self._last_reload_check < self.WEIGHTS_RELOAD_INTERVAL:\n            return\n        self._last_reload_check = now\n\n        try:\n            if os.path.exists(self._weights_path):\n                mtime = os.path.getmtime(self._weights_path)\n                if mtime > self._weights_mtime:\n                    self._load_weights_safe()\n        except Exception:\n            pass",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__load_weights_safe_895": {
      "name": "_load_weights_safe",
      "type": "method",
      "start_line": 895,
      "end_line": 908,
      "content_hash": "49a12dc93634c2afad1167c4d76d915122c247a9",
      "content": "    def _load_weights_safe(self):\n        \"\"\"Load weights with advisory file locking (prevents partial reads during writes).\"\"\"\n        import fcntl\n        lock_path = self._weights_path + \".lock\"\n        try:\n            os.makedirs(os.path.dirname(lock_path) or \".\", exist_ok=True)\n            with open(lock_path, \"w\") as lock_file:\n                fcntl.flock(lock_file.fileno(), fcntl.LOCK_SH)\n                try:\n                    self._load_weights()\n                finally:\n                    fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)\n        except Exception:\n            self._load_weights()",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__init_random_weights_910": {
      "name": "_init_random_weights",
      "type": "method",
      "start_line": 910,
      "end_line": 924,
      "content_hash": "f666574c1e6fd15e424ac9057f4373da089764b6",
      "content": "    def _init_random_weights(self):\n        \"\"\"Initialize with random weights using He initialization.\"\"\"\n        rng = np.random.RandomState(43)\n        scale = np.float32(np.sqrt(2.0 / (self.dim * 3)))\n        self.W1 = rng.randn(self.dim * 3, self.hidden_dim).astype(np.float32) * scale\n        self.b1 = np.zeros(self.hidden_dim, dtype=np.float32)\n        w2_scale = np.float32(np.sqrt(2.0 / self.hidden_dim))\n        self.W2 = rng.randn(self.hidden_dim, self.dim).astype(np.float32) * w2_scale\n        self.b2 = np.zeros(self.dim, dtype=np.float32)\n\n        # Initialize momentum\n        self._momentum_W1 = np.zeros_like(self.W1)\n        self._momentum_b1 = np.zeros_like(self.b1)\n        self._momentum_W2 = np.zeros_like(self.W2)\n        self._momentum_b2 = np.zeros_like(self.b2)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__load_weights_926": {
      "name": "_load_weights",
      "type": "method",
      "start_line": 926,
      "end_line": 978,
      "content_hash": "6d69946fbf26cc6b273b3942bba241cfdb10e638",
      "content": "    def _load_weights(self) -> bool:\n        \"\"\"Load trained weights from disk. Returns True on success.\"\"\"\n        from scripts.logger import get_logger\n        logger = get_logger(__name__)\n        try:\n            data = np.load(self._weights_path, allow_pickle=True)\n\n            # Helper to safely get from NpzFile\n            def _get(key: str, default):\n                return data[key] if key in data.files else default\n\n            # Validate shapes\n            w1 = _get(\"W1\", None)\n            w2 = _get(\"W2\", None)\n            b1 = _get(\"b1\", None)\n            b2 = _get(\"b2\", None)\n\n            if w1 is None or w2 is None:\n                data.close()\n                return False\n\n            expected_w1 = (self.dim * 3, self.hidden_dim)\n            expected_w2 = (self.hidden_dim, self.dim)\n\n            if w1.shape != expected_w1 or w2.shape != expected_w2:\n                logger.warning(f\"LatentRefiner: shape mismatch W1={w1.shape} W2={w2.shape}\")\n                data.close()\n                return False\n\n            self.W1 = w1.astype(np.float32, copy=False)\n            self.b1 = b1.astype(np.float32, copy=False) if b1 is not None else np.zeros(self.hidden_dim, dtype=np.float32)\n            self.W2 = w2.astype(np.float32, copy=False)\n            self.b2 = b2.astype(np.float32, copy=False) if b2 is not None else np.zeros(self.dim, dtype=np.float32)\n\n            # Load training state\n            self._update_count = int(_get(\"update_count\", 0))\n            self._version = int(_get(\"version\", 0))\n\n            # Initialize momentum if not loaded\n            if self._momentum_W1 is None or self._momentum_W1.shape != self.W1.shape:\n                self._momentum_W1 = np.zeros_like(self.W1)\n                self._momentum_b1 = np.zeros_like(self.b1)\n                self._momentum_W2 = np.zeros_like(self.W2)\n                self._momentum_b2 = np.zeros_like(self.b2)\n\n            self._weights_loaded = True\n            self._weights_mtime = os.path.getmtime(self._weights_path)\n            data.close()\n            logger.debug(f\"LatentRefiner: loaded weights v{self._version} from {self._weights_path}\")\n            return True\n        except Exception as e:\n            logger.warning(f\"LatentRefiner: failed to load weights: {e}\")\n            return False",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__get_934": {
      "name": "_get",
      "type": "method",
      "start_line": 934,
      "end_line": 935,
      "content_hash": "4fff3505da9167a31a9ea4b26b1edd806f258c7d",
      "content": "            def _get(key: str, default):\n                return data[key] if key in data.files else default",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_refine_980": {
      "name": "refine",
      "type": "method",
      "start_line": 980,
      "end_line": 1014,
      "content_hash": "a48bcee7bfb312868a8dcc362cf4c197c45c961a",
      "content": "    def refine(\n        self,\n        z: np.ndarray,\n        query_emb: np.ndarray,\n        doc_embs: np.ndarray,\n        scores: np.ndarray,\n        alpha: float = 0.5  # EMA smoothing factor\n    ) -> np.ndarray:\n        \"\"\"\n        Refine latent state based on current ranking.\n\n        Uses attention-weighted sum of top documents as \"answer summary\".\n        \"\"\"\n        # Check for hot-reloaded weights\n        self.maybe_reload_weights()\n\n        # Softmax attention over scores to get weighted doc representation\n        weights = np.exp(scores - scores.max())\n        weights = weights / (weights.sum() + 1e-8)\n        doc_summary = (weights[:, None] * doc_embs).sum(axis=0)  # (dim,)\n\n        # Concatenate [z, query, doc_summary]\n        x = np.concatenate([z, query_emb, doc_summary])  # (dim*3,)\n\n        # 2-layer refinement\n        h = np.maximum(0, x @ self.W1 + self.b1)\n        z_new = h @ self.W2 + self.b2\n\n        # EMA update (from TRM: stabilizes training)\n        z_refined = alpha * z_new + (1 - alpha) * z\n\n        # Normalize to unit sphere\n        z_refined = z_refined / (np.linalg.norm(z_refined) + 1e-8)\n\n        return z_refined",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_refine_with_cache_1016": {
      "name": "refine_with_cache",
      "type": "method",
      "start_line": 1016,
      "end_line": 1036,
      "content_hash": "5208c69fb5d55590fd781f367aa02246ed902987",
      "content": "    def refine_with_cache(\n        self,\n        z: np.ndarray,\n        query_emb: np.ndarray,\n        doc_embs: np.ndarray,\n        scores: np.ndarray,\n        alpha: float = 0.5\n    ) -> tuple:\n        \"\"\"Refine with cache for backprop. Returns (z_refined, cache).\"\"\"\n        weights = np.exp(scores - scores.max())\n        weights = weights / (weights.sum() + 1e-8)\n        doc_summary = (weights[:, None] * doc_embs).sum(axis=0)\n\n        x = np.concatenate([z, query_emb, doc_summary])\n        h = np.maximum(0, x @ self.W1 + self.b1)\n        z_new = h @ self.W2 + self.b2\n        z_refined = alpha * z_new + (1 - alpha) * z\n        z_refined = z_refined / (np.linalg.norm(z_refined) + 1e-8)\n\n        cache = {\"x\": x, \"h\": h, \"z\": z, \"z_new\": z_new, \"alpha\": alpha, \"weights\": weights}\n        return z_refined, cache",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_learn_from_teacher_1038": {
      "name": "learn_from_teacher",
      "type": "method",
      "start_line": 1038,
      "end_line": 1099,
      "content_hash": "c2fc4c4bb7bf8df5a0641d02138a455c876f158e",
      "content": "    def learn_from_teacher(\n        self,\n        z: np.ndarray,\n        query_emb: np.ndarray,\n        doc_embs: np.ndarray,\n        scores: np.ndarray,\n        teacher_z: np.ndarray,\n    ) -> float:\n        \"\"\"\n        Online learning: update weights so refined z moves toward teacher_z.\n\n        Uses MSE loss between our z_refined and teacher_z (normalized).\n\n        Returns:\n            Loss value\n        \"\"\"\n        # Forward pass with cache\n        z_refined, cache = self.refine_with_cache(z, query_emb, doc_embs, scores)\n\n        # MSE loss: ||z_refined - teacher_z||^2\n        diff = z_refined - teacher_z\n        loss = float(np.sum(diff ** 2))\n\n        if loss < 1e-8:\n            return 0.0\n\n        # Backward pass (gradient of MSE)\n        dz_refined = 2.0 * diff  # (dim,)\n\n        # Through normalization (approx - assume near unit norm)\n        dz_new = cache[\"alpha\"] * dz_refined\n\n        # Through W2, b2\n        dW2 = np.outer(cache[\"h\"], dz_new)\n        db2 = dz_new\n\n        # Through ReLU and W1, b1\n        dh = dz_new @ self.W2.T\n        dh = dh * (cache[\"h\"] > 0).astype(np.float32)\n        dW1 = np.outer(cache[\"x\"], dh)\n        db1 = dh\n\n        # SGD with momentum\n        momentum = 0.9\n        if self._momentum_W1 is None:\n            self._momentum_W1 = np.zeros_like(self.W1)\n            self._momentum_b1 = np.zeros_like(self.b1)\n            self._momentum_W2 = np.zeros_like(self.W2)\n            self._momentum_b2 = np.zeros_like(self.b2)\n\n        self._momentum_W1 = momentum * self._momentum_W1 - self.lr * dW1\n        self._momentum_b1 = momentum * self._momentum_b1 - self.lr * db1\n        self._momentum_W2 = momentum * self._momentum_W2 - self.lr * dW2\n        self._momentum_b2 = momentum * self._momentum_b2 - self.lr * db2\n\n        self.W1 += self._momentum_W1\n        self.b1 += self._momentum_b1\n        self.W2 += self._momentum_W2\n        self.b2 += self._momentum_b2\n\n        self._update_count += 1\n        return loss",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_learn_from_teacher_with_cache_1101": {
      "name": "learn_from_teacher_with_cache",
      "type": "method",
      "start_line": 1101,
      "end_line": 1162,
      "content_hash": "e2903f1d15be430d3c09f7e405897f281b046da8",
      "content": "    def learn_from_teacher_with_cache(\n        self,\n        z: np.ndarray,\n        query_emb: np.ndarray,\n        doc_embs: np.ndarray,\n        scores: np.ndarray,\n        teacher_z: np.ndarray,\n    ) -> Tuple[float, np.ndarray, np.ndarray, Dict[str, Any]]:\n        \"\"\"\n        Online learning with cache for VICReg backprop.\n\n        Like learn_from_teacher(), but returns (z, z_refined, cache) for\n        batch-level VICReg regularization.\n\n        Returns:\n            (loss, z, z_refined, cache)\n        \"\"\"\n        # Forward pass with cache\n        z_refined, cache = self.refine_with_cache(z, query_emb, doc_embs, scores)\n\n        # MSE loss: ||z_refined - teacher_z||^2\n        diff = z_refined - teacher_z\n        loss = float(np.sum(diff ** 2))\n\n        if loss >= 1e-8:\n            # Backward pass (gradient of MSE)\n            dz_refined = 2.0 * diff\n\n            # Through normalization (approx - assume near unit norm)\n            dz_new = cache[\"alpha\"] * dz_refined\n\n            # Through W2, b2\n            dW2 = np.outer(cache[\"h\"], dz_new)\n            db2 = dz_new\n\n            # Through ReLU and W1, b1\n            dh = dz_new @ self.W2.T\n            dh = dh * (cache[\"h\"] > 0).astype(np.float32)\n            dW1 = np.outer(cache[\"x\"], dh)\n            db1 = dh\n\n            # SGD with momentum\n            momentum = 0.9\n            if self._momentum_W1 is None:\n                self._momentum_W1 = np.zeros_like(self.W1)\n                self._momentum_b1 = np.zeros_like(self.b1)\n                self._momentum_W2 = np.zeros_like(self.W2)\n                self._momentum_b2 = np.zeros_like(self.b2)\n\n            self._momentum_W1 = momentum * self._momentum_W1 - self.lr * dW1\n            self._momentum_b1 = momentum * self._momentum_b1 - self.lr * db1\n            self._momentum_W2 = momentum * self._momentum_W2 - self.lr * dW2\n            self._momentum_b2 = momentum * self._momentum_b2 - self.lr * db2\n\n            self.W1 += self._momentum_W1\n            self.b1 += self._momentum_b1\n            self.W2 += self._momentum_W2\n            self.b2 += self._momentum_b2\n\n            self._update_count += 1\n\n        return loss, z, z_refined, cache",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_apply_vicreg_gradient_1164": {
      "name": "apply_vicreg_gradient",
      "type": "method",
      "start_line": 1164,
      "end_line": 1201,
      "content_hash": "1f62fff509e88a7830e95ed59823656ae46aaf0a",
      "content": "    def apply_vicreg_gradient(\n        self,\n        grad_z_refined: np.ndarray,\n        cache: Dict[str, Any],\n        weight: float = 0.1,\n    ):\n        \"\"\"\n        Apply VICReg gradient to refiner weights.\n\n        Called after VICReg.forward() computes gradient w.r.t. z_refined.\n        Backprops through the refiner network to update W1, b1, W2, b2.\n\n        Args:\n            grad_z_refined: (dim,) gradient from VICReg\n            cache: Cache from refine_with_cache() or learn_from_teacher_with_cache()\n            weight: Scaling factor for the regularization gradient\n        \"\"\"\n        # Backprop through z_refined = alpha * z_new + (1-alpha) * z\n        # d/dz_new = alpha * grad_z_refined\n        dz_new = cache[\"alpha\"] * grad_z_refined * weight\n\n        # Through W2, b2: z_new = h @ W2 + b2\n        dW2 = np.outer(cache[\"h\"], dz_new)\n        db2 = dz_new\n\n        # Through ReLU: h = max(0, pre_h)\n        dh = dz_new @ self.W2.T\n        dh = dh * (cache[\"h\"] > 0).astype(np.float32)\n\n        # Through W1, b1: pre_h = x @ W1 + b1\n        dW1 = np.outer(cache[\"x\"], dh)\n        db1 = dh\n\n        # Apply gradients directly (VICReg uses same LR as main training)\n        self.W1 -= self.lr * dW1\n        self.b1 -= self.lr * db1\n        self.W2 -= self.lr * dW2\n        self.b2 -= self.lr * db2",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__save_weights_1203": {
      "name": "_save_weights",
      "type": "method",
      "start_line": 1203,
      "end_line": 1246,
      "content_hash": "765398d169027c9c0d8eb1fe94f844343e5c1c45",
      "content": "    def _save_weights(self, checkpoint: bool = False):\n        \"\"\"Save weights to disk atomically with file locking.\n\n        Mirrors TinyScorer._save_weights: use a base path without the .npz\n        extension for np.savez (which appends .npz automatically), then\n        atomically rename the resulting file into place.\n        \"\"\"\n        import fcntl\n\n        os.makedirs(self.WEIGHTS_DIR, exist_ok=True)\n        self._version += 1\n\n        # np.savez automatically adds .npz, so follow the same pattern as\n        # TinyScorer: derive a temporary base path and then construct the\n        # actual temp file path that np.savez will create.\n        tmp_base = self._weights_path.replace(\".npz\", \".tmp\")\n        tmp_path = tmp_base + \".npz\"\n        lock_path = self._weights_path + \".lock\"\n\n        try:\n            with open(lock_path, \"w\") as lock_file:\n                fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX)\n                try:\n                    np.savez(\n                        tmp_base,\n                        W1=self.W1,\n                        b1=self.b1,\n                        W2=self.W2,\n                        b2=self.b2,\n                        update_count=self._update_count,\n                        version=self._version,\n                        dim=self.dim,\n                        hidden_dim=self.hidden_dim,\n                    )\n                    os.replace(tmp_path, self._weights_path)\n                finally:\n                    fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)\n        except Exception:\n            if os.path.exists(tmp_path):\n                try:\n                    os.remove(tmp_path)\n                except Exception:\n                    pass\n            raise",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_VICReg_1270": {
      "name": "VICReg",
      "type": "class",
      "start_line": 1270,
      "end_line": 1377,
      "content_hash": "5f43b7df0c51e67a2d0b61e3803710c274805295",
      "content": "class VICReg:\n    \"\"\"\n    VICReg regularization for refinement residuals.\n\n    Regularizes the refiner's residual (z_refined - z) to have:\n    - Unit variance per dimension (prevents collapse)\n    - Decorrelated dimensions (prevents redundancy)\n    - Bounded magnitude (stable updates)\n\n    Designed for online learning: accumulate residuals across a batch,\n    then call forward() once at batch end.\n\n    Reference: VICReg (Bardes et al., 2021)\n    \"\"\"\n\n    def __init__(\n        self,\n        lambda_var: float = 1.0,\n        lambda_cov: float = 0.04,\n        lambda_inv: float = 0.1,\n        var_target: float = 1.0,\n    ):\n        \"\"\"\n        Args:\n            lambda_var: Weight for variance loss (prevent collapse)\n            lambda_cov: Weight for covariance loss (decorrelation)\n            lambda_inv: Weight for invariance loss (bounded updates)\n            var_target: Target std deviation per dimension (default 1.0)\n        \"\"\"\n        self.lambda_var = lambda_var\n        self.lambda_cov = lambda_cov\n        self.lambda_inv = lambda_inv\n        self.var_target = var_target\n\n    def forward(\n        self, z_batch: np.ndarray, z_refined_batch: np.ndarray\n    ) -> Tuple[float, np.ndarray, Dict[str, float]]:\n        \"\"\"\n        Compute VICReg loss and gradient w.r.t. z_refined.\n\n        Args:\n            z_batch: (N, dim) original latent states\n            z_refined_batch: (N, dim) refined latent states\n\n        Returns:\n            (total_loss, grad_z_refined, loss_components)\n            - grad_z_refined: gradient w.r.t. z_refined_batch (N, dim)\n            - loss_components: dict with var_loss, cov_loss, inv_loss\n        \"\"\"\n        N, dim = z_batch.shape\n        eps = 1e-8\n\n        # Residual = what the refiner added\n        residual = z_refined_batch - z_batch  # (N, dim)\n        mean_res = residual.mean(axis=0, keepdims=True)  # (1, dim)\n        residual_centered = residual - mean_res  # (N, dim)\n\n        # ===== 1. VARIANCE LOSS =====\n        # Goal: std(residual) \u2248 var_target per dimension\n        # Loss: mean(max(0, var_target - std))  [hinge loss]\n        std = residual.std(axis=0) + eps  # (dim,)\n        var_diff = self.var_target - std  # positive when std too small\n        var_loss = float(np.maximum(0, var_diff).mean())\n\n        # Gradient: d(hinge)/d(residual)\n        hinge_mask = (var_diff > 0).astype(np.float32)  # (dim,)\n        d_var = -hinge_mask[None, :] * residual_centered / (N * std[None, :] * dim)\n\n        # ===== 2. COVARIANCE LOSS =====\n        # Goal: off-diagonal covariance \u2248 0\n        # Loss: sum(cov_ij^2) / dim for i \u2260 j\n        cov = (residual_centered.T @ residual_centered) / (N - 1 + eps)  # (dim, dim)\n        off_diag_mask = 1.0 - np.eye(dim, dtype=np.float32)\n        off_diag = cov * off_diag_mask\n        cov_loss = float((off_diag ** 2).sum() / dim)\n\n        # Gradient: d(L)/d(residual)\n        d_cov = 4 * residual_centered @ (off_diag * off_diag_mask) / ((N - 1 + eps) * dim)\n\n        # ===== 3. INVARIANCE LOSS =====\n        # Goal: residual magnitude bounded\n        # Loss: mean(||residual||\u00b2)\n        inv_loss = float((residual ** 2).mean())\n\n        # Gradient: d(mean(x\u00b2))/d(x) = 2x / (N * dim)\n        d_inv = 2 * residual / (N * dim)\n\n        # ===== TOTAL =====\n        total_loss = (\n            self.lambda_var * var_loss\n            + self.lambda_cov * cov_loss\n            + self.lambda_inv * inv_loss\n        )\n\n        # Gradient w.r.t. z_refined (residual = z_refined - z, so d/dz_refined = d/dresidual)\n        grad = (\n            self.lambda_var * d_var\n            + self.lambda_cov * d_cov\n            + self.lambda_inv * d_inv\n        ).astype(np.float32)\n\n        components = {\n            \"var_loss\": var_loss,\n            \"cov_loss\": cov_loss,\n            \"inv_loss\": inv_loss,\n        }\n\n        return total_loss, grad, components",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___init___1285": {
      "name": "__init__",
      "type": "method",
      "start_line": 1285,
      "end_line": 1302,
      "content_hash": "94b5f35ca7d1b247efbc96d95925fcd1b750d6d6",
      "content": "    def __init__(\n        self,\n        lambda_var: float = 1.0,\n        lambda_cov: float = 0.04,\n        lambda_inv: float = 0.1,\n        var_target: float = 1.0,\n    ):\n        \"\"\"\n        Args:\n            lambda_var: Weight for variance loss (prevent collapse)\n            lambda_cov: Weight for covariance loss (decorrelation)\n            lambda_inv: Weight for invariance loss (bounded updates)\n            var_target: Target std deviation per dimension (default 1.0)\n        \"\"\"\n        self.lambda_var = lambda_var\n        self.lambda_cov = lambda_cov\n        self.lambda_inv = lambda_inv\n        self.var_target = var_target",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_forward_1304": {
      "name": "forward",
      "type": "method",
      "start_line": 1304,
      "end_line": 1377,
      "content_hash": "bb8b006db187a366f48e812e9b7db4e0d2bceeac",
      "content": "    def forward(\n        self, z_batch: np.ndarray, z_refined_batch: np.ndarray\n    ) -> Tuple[float, np.ndarray, Dict[str, float]]:\n        \"\"\"\n        Compute VICReg loss and gradient w.r.t. z_refined.\n\n        Args:\n            z_batch: (N, dim) original latent states\n            z_refined_batch: (N, dim) refined latent states\n\n        Returns:\n            (total_loss, grad_z_refined, loss_components)\n            - grad_z_refined: gradient w.r.t. z_refined_batch (N, dim)\n            - loss_components: dict with var_loss, cov_loss, inv_loss\n        \"\"\"\n        N, dim = z_batch.shape\n        eps = 1e-8\n\n        # Residual = what the refiner added\n        residual = z_refined_batch - z_batch  # (N, dim)\n        mean_res = residual.mean(axis=0, keepdims=True)  # (1, dim)\n        residual_centered = residual - mean_res  # (N, dim)\n\n        # ===== 1. VARIANCE LOSS =====\n        # Goal: std(residual) \u2248 var_target per dimension\n        # Loss: mean(max(0, var_target - std))  [hinge loss]\n        std = residual.std(axis=0) + eps  # (dim,)\n        var_diff = self.var_target - std  # positive when std too small\n        var_loss = float(np.maximum(0, var_diff).mean())\n\n        # Gradient: d(hinge)/d(residual)\n        hinge_mask = (var_diff > 0).astype(np.float32)  # (dim,)\n        d_var = -hinge_mask[None, :] * residual_centered / (N * std[None, :] * dim)\n\n        # ===== 2. COVARIANCE LOSS =====\n        # Goal: off-diagonal covariance \u2248 0\n        # Loss: sum(cov_ij^2) / dim for i \u2260 j\n        cov = (residual_centered.T @ residual_centered) / (N - 1 + eps)  # (dim, dim)\n        off_diag_mask = 1.0 - np.eye(dim, dtype=np.float32)\n        off_diag = cov * off_diag_mask\n        cov_loss = float((off_diag ** 2).sum() / dim)\n\n        # Gradient: d(L)/d(residual)\n        d_cov = 4 * residual_centered @ (off_diag * off_diag_mask) / ((N - 1 + eps) * dim)\n\n        # ===== 3. INVARIANCE LOSS =====\n        # Goal: residual magnitude bounded\n        # Loss: mean(||residual||\u00b2)\n        inv_loss = float((residual ** 2).mean())\n\n        # Gradient: d(mean(x\u00b2))/d(x) = 2x / (N * dim)\n        d_inv = 2 * residual / (N * dim)\n\n        # ===== TOTAL =====\n        total_loss = (\n            self.lambda_var * var_loss\n            + self.lambda_cov * cov_loss\n            + self.lambda_inv * inv_loss\n        )\n\n        # Gradient w.r.t. z_refined (residual = z_refined - z, so d/dz_refined = d/dresidual)\n        grad = (\n            self.lambda_var * d_var\n            + self.lambda_cov * d_cov\n            + self.lambda_inv * d_inv\n        ).astype(np.float32)\n\n        components = {\n            \"var_loss\": var_loss,\n            \"cov_loss\": cov_loss,\n            \"inv_loss\": inv_loss,\n        }\n\n        return total_loss, grad, components",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_LearnedProjection_1380": {
      "name": "LearnedProjection",
      "type": "class",
      "start_line": 1380,
      "end_line": 1611,
      "content_hash": "135342fe28e83e7755eb024ac84d2fb5ec29d2a2",
      "content": "class LearnedProjection:\n    \"\"\"\n    Learnable linear projection from embedding dim to working dim.\n\n    Replaces fixed random projection with a learnable layer that adapts\n    to domain-specific semantics. Key for true \"self-learning search\".\n\n    Features:\n    - Per-collection weights (like TinyScorer/LatentRefiner)\n    - Gradient from downstream scorer/refiner backprops through\n    - VICReg-compatible: can receive regularization gradients\n    - Hot-reload from background worker updates\n\n    Architecture:\n        input (768) \u2192 linear \u2192 normalize \u2192 output (256)\n\n    The projection learns which subspace of BGE is most useful for code search.\n    \"\"\"\n\n    WEIGHTS_DIR = os.environ.get(\"RERANKER_WEIGHTS_DIR\", \"/tmp/rerank_weights\")\n    WEIGHTS_RELOAD_INTERVAL = float(os.environ.get(\"RERANKER_WEIGHTS_RELOAD_INTERVAL\", \"60\"))\n\n    def __init__(\n        self,\n        input_dim: int = 768,\n        output_dim: int = 256,\n        lr: float = 0.0005,  # Lower LR than scorer - projection is more sensitive\n    ):\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.base_lr = lr\n        self.lr = lr\n        self._collection = \"default\"\n        self._weights_path = self._get_weights_path(\"default\")\n        self._weights_mtime = 0.0\n        self._last_reload_check = 0.0\n        self._weights_loaded = False\n\n        # Training metrics\n        self._update_count = 0\n        self._version = 0\n\n        # Momentum for SGD\n        self._momentum_W: Optional[np.ndarray] = None\n        self._momentum = 0.9\n\n        # Try to load saved weights, otherwise init random\n        if os.path.exists(self._weights_path):\n            try:\n                self._load_weights()\n                return\n            except Exception as e:\n                from scripts.logger import get_logger\n                get_logger(__name__).warning(f\"LearnedProjection: failed to load {self._weights_path}: {e}\")\n\n        self._init_random_weights()\n\n    @staticmethod\n    def _sanitize_collection(collection: str) -> str:\n        return \"\".join(c if c.isalnum() or c in \"-_\" else \"_\" for c in collection)\n\n    def _get_weights_path(self, collection: str) -> str:\n        safe_name = self._sanitize_collection(collection)\n        return os.path.join(self.WEIGHTS_DIR, f\"projection_{safe_name}.npz\")\n\n    def _init_random_weights(self):\n        \"\"\"Initialize with scaled random weights (Xavier-style).\"\"\"\n        scale = np.sqrt(2.0 / (self.input_dim + self.output_dim))\n        rng = np.random.RandomState(44)  # Deterministic init\n        self.W = (rng.randn(self.input_dim, self.output_dim) * scale).astype(np.float32)\n        self._momentum_W = np.zeros_like(self.W)\n\n    def set_collection(self, collection: str):\n        \"\"\"Set collection and load corresponding weights.\"\"\"\n        self._collection = collection\n        self._weights_path = self._get_weights_path(collection)\n        if os.path.exists(self._weights_path):\n            try:\n                self._load_weights()\n            except Exception:\n                pass\n\n    def maybe_reload_weights(self):\n        \"\"\"Check if weights file changed and reload if needed.\"\"\"\n        now = time.time()\n        if now - self._last_reload_check < self.WEIGHTS_RELOAD_INTERVAL:\n            return\n        self._last_reload_check = now\n\n        try:\n            if os.path.exists(self._weights_path):\n                mtime = os.path.getmtime(self._weights_path)\n                if mtime > self._weights_mtime:\n                    self._load_weights()\n        except Exception:\n            pass\n\n    def _load_weights(self):\n        \"\"\"Load weights from disk.\"\"\"\n        import fcntl\n        lock_path = self._weights_path + \".lock\"\n        try:\n            os.makedirs(os.path.dirname(lock_path) or \".\", exist_ok=True)\n            with open(lock_path, \"w\") as lock_file:\n                fcntl.flock(lock_file.fileno(), fcntl.LOCK_SH)\n                data = np.load(self._weights_path)\n                self.W = data[\"W\"].astype(np.float32)\n                self._version = int(data.get(\"version\", 0))\n                fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)\n            self._weights_mtime = os.path.getmtime(self._weights_path)\n            self._weights_loaded = True\n            self._momentum_W = np.zeros_like(self.W)\n        except Exception as e:\n            from scripts.logger import get_logger\n            get_logger(__name__).warning(f\"LearnedProjection: load failed: {e}\")\n\n    def _save_weights(self):\n        \"\"\"Save weights to disk atomically.\"\"\"\n        import fcntl\n        os.makedirs(os.path.dirname(self._weights_path) or \".\", exist_ok=True)\n        lock_path = self._weights_path + \".lock\"\n        # np.savez adds .npz extension, so use base path without extension for tmp\n        base_path = self._weights_path.rsplit(\".npz\", 1)[0]\n        tmp_path = base_path + \".tmp.npz\"\n\n        try:\n            with open(lock_path, \"w\") as lock_file:\n                fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX)\n                np.savez(tmp_path, W=self.W, version=self._version)\n                os.replace(tmp_path, self._weights_path)\n                fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)\n            self._weights_mtime = os.path.getmtime(self._weights_path)\n        except Exception as e:\n            from scripts.logger import get_logger\n            get_logger(__name__).warning(f\"LearnedProjection: save failed: {e}\")\n\n    def forward(self, embeddings: np.ndarray) -> np.ndarray:\n        \"\"\"Project embeddings to output dim (normalized).\n\n        Args:\n            embeddings: (batch, input_dim) or (input_dim,)\n\n        Returns:\n            projected: (batch, output_dim) or (output_dim,), L2-normalized\n        \"\"\"\n        squeeze = embeddings.ndim == 1\n        if squeeze:\n            embeddings = embeddings.reshape(1, -1)\n\n        # Linear projection\n        projected = embeddings @ self.W  # (batch, output_dim)\n\n        # L2 normalize\n        norms = np.linalg.norm(projected, axis=-1, keepdims=True) + 1e-8\n        projected = projected / norms\n\n        if squeeze:\n            projected = projected[0]\n\n        return projected\n\n    def forward_with_cache(\n        self, embeddings: np.ndarray\n    ) -> Tuple[np.ndarray, Dict[str, Any]]:\n        \"\"\"Forward pass with cache for backprop.\n\n        Returns:\n            projected: (batch, output_dim), L2-normalized\n            cache: dict with inputs for backward pass\n        \"\"\"\n        squeeze = embeddings.ndim == 1\n        if squeeze:\n            embeddings = embeddings.reshape(1, -1)\n\n        # Linear projection\n        pre_norm = embeddings @ self.W  # (batch, output_dim)\n\n        # L2 normalize\n        norms = np.linalg.norm(pre_norm, axis=-1, keepdims=True) + 1e-8\n        projected = pre_norm / norms\n\n        cache = {\n            \"input\": embeddings,\n            \"pre_norm\": pre_norm,\n            \"norms\": norms,\n            \"projected\": projected,\n        }\n\n        if squeeze:\n            projected = projected[0]\n\n        return projected, cache\n\n    def backward(\n        self, grad_output: np.ndarray, cache: Dict[str, Any], weight: float = 1.0\n    ):\n        \"\"\"Backprop gradient through projection and update weights.\n\n        Args:\n            grad_output: gradient w.r.t. projected output (batch, output_dim) or (output_dim,)\n            cache: from forward_with_cache\n            weight: gradient scaling factor\n        \"\"\"\n        if grad_output.ndim == 1:\n            grad_output = grad_output.reshape(1, -1)\n\n        embeddings = cache[\"input\"]\n        norms = cache[\"norms\"]\n\n        batch_size = embeddings.shape[0]\n\n        # Backprop through L2 normalization\n        # d/dx (x/||x||) = (I - x*x^T/||x||^2) / ||x||\n        # Simplified: grad_pre_norm = (grad_output - projected * (grad_output \u00b7 projected)) / norms\n        projected = cache[\"projected\"]\n        dot = np.sum(grad_output * projected, axis=-1, keepdims=True)\n        grad_pre_norm = (grad_output - projected * dot) / norms\n\n        # Gradient w.r.t. W: dL/dW = input^T @ grad_pre_norm\n        dW = embeddings.T @ grad_pre_norm / batch_size\n\n        # Apply weight and update with momentum SGD\n        dW = dW * weight\n        self._momentum_W = self._momentum * self._momentum_W + dW\n        self.W -= self.lr * self._momentum_W\n\n        self._update_count += 1\n\n        # Periodic save\n        if self._update_count % 100 == 0:\n            self._version += 1\n            self._save_weights()",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___init___1402": {
      "name": "__init__",
      "type": "method",
      "start_line": 1402,
      "end_line": 1435,
      "content_hash": "45df2f512702e6488166a9946f36d7d86aae03e9",
      "content": "    def __init__(\n        self,\n        input_dim: int = 768,\n        output_dim: int = 256,\n        lr: float = 0.0005,  # Lower LR than scorer - projection is more sensitive\n    ):\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.base_lr = lr\n        self.lr = lr\n        self._collection = \"default\"\n        self._weights_path = self._get_weights_path(\"default\")\n        self._weights_mtime = 0.0\n        self._last_reload_check = 0.0\n        self._weights_loaded = False\n\n        # Training metrics\n        self._update_count = 0\n        self._version = 0\n\n        # Momentum for SGD\n        self._momentum_W: Optional[np.ndarray] = None\n        self._momentum = 0.9\n\n        # Try to load saved weights, otherwise init random\n        if os.path.exists(self._weights_path):\n            try:\n                self._load_weights()\n                return\n            except Exception as e:\n                from scripts.logger import get_logger\n                get_logger(__name__).warning(f\"LearnedProjection: failed to load {self._weights_path}: {e}\")\n\n        self._init_random_weights()",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__sanitize_collection_1438": {
      "name": "_sanitize_collection",
      "type": "method",
      "start_line": 1438,
      "end_line": 1439,
      "content_hash": "cdbd85077085baad363b24f06dafd0ea2c67f8d3",
      "content": "    def _sanitize_collection(collection: str) -> str:\n        return \"\".join(c if c.isalnum() or c in \"-_\" else \"_\" for c in collection)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__get_weights_path_1441": {
      "name": "_get_weights_path",
      "type": "method",
      "start_line": 1441,
      "end_line": 1443,
      "content_hash": "755dee6696c6d5d9b92b323238c7551e386fa1fc",
      "content": "    def _get_weights_path(self, collection: str) -> str:\n        safe_name = self._sanitize_collection(collection)\n        return os.path.join(self.WEIGHTS_DIR, f\"projection_{safe_name}.npz\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__init_random_weights_1445": {
      "name": "_init_random_weights",
      "type": "method",
      "start_line": 1445,
      "end_line": 1450,
      "content_hash": "53ce326bd55e36c2e23485870d12925805cec504",
      "content": "    def _init_random_weights(self):\n        \"\"\"Initialize with scaled random weights (Xavier-style).\"\"\"\n        scale = np.sqrt(2.0 / (self.input_dim + self.output_dim))\n        rng = np.random.RandomState(44)  # Deterministic init\n        self.W = (rng.randn(self.input_dim, self.output_dim) * scale).astype(np.float32)\n        self._momentum_W = np.zeros_like(self.W)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_set_collection_1452": {
      "name": "set_collection",
      "type": "method",
      "start_line": 1452,
      "end_line": 1460,
      "content_hash": "4dae7da98f3091db4d26c907c21a25aa337d6f9d",
      "content": "    def set_collection(self, collection: str):\n        \"\"\"Set collection and load corresponding weights.\"\"\"\n        self._collection = collection\n        self._weights_path = self._get_weights_path(collection)\n        if os.path.exists(self._weights_path):\n            try:\n                self._load_weights()\n            except Exception:\n                pass",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_maybe_reload_weights_1462": {
      "name": "maybe_reload_weights",
      "type": "method",
      "start_line": 1462,
      "end_line": 1475,
      "content_hash": "ac18116ef9e63162d3e2d717f6bf5d09dfa12eef",
      "content": "    def maybe_reload_weights(self):\n        \"\"\"Check if weights file changed and reload if needed.\"\"\"\n        now = time.time()\n        if now - self._last_reload_check < self.WEIGHTS_RELOAD_INTERVAL:\n            return\n        self._last_reload_check = now\n\n        try:\n            if os.path.exists(self._weights_path):\n                mtime = os.path.getmtime(self._weights_path)\n                if mtime > self._weights_mtime:\n                    self._load_weights()\n        except Exception:\n            pass",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__load_weights_1477": {
      "name": "_load_weights",
      "type": "method",
      "start_line": 1477,
      "end_line": 1494,
      "content_hash": "e975eeee08f73922c6726f98c8607899ee0eb289",
      "content": "    def _load_weights(self):\n        \"\"\"Load weights from disk.\"\"\"\n        import fcntl\n        lock_path = self._weights_path + \".lock\"\n        try:\n            os.makedirs(os.path.dirname(lock_path) or \".\", exist_ok=True)\n            with open(lock_path, \"w\") as lock_file:\n                fcntl.flock(lock_file.fileno(), fcntl.LOCK_SH)\n                data = np.load(self._weights_path)\n                self.W = data[\"W\"].astype(np.float32)\n                self._version = int(data.get(\"version\", 0))\n                fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)\n            self._weights_mtime = os.path.getmtime(self._weights_path)\n            self._weights_loaded = True\n            self._momentum_W = np.zeros_like(self.W)\n        except Exception as e:\n            from scripts.logger import get_logger\n            get_logger(__name__).warning(f\"LearnedProjection: load failed: {e}\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__save_weights_1496": {
      "name": "_save_weights",
      "type": "method",
      "start_line": 1496,
      "end_line": 1514,
      "content_hash": "c57e43f2068a6ad4c6d73cd9f108988b4f51695b",
      "content": "    def _save_weights(self):\n        \"\"\"Save weights to disk atomically.\"\"\"\n        import fcntl\n        os.makedirs(os.path.dirname(self._weights_path) or \".\", exist_ok=True)\n        lock_path = self._weights_path + \".lock\"\n        # np.savez adds .npz extension, so use base path without extension for tmp\n        base_path = self._weights_path.rsplit(\".npz\", 1)[0]\n        tmp_path = base_path + \".tmp.npz\"\n\n        try:\n            with open(lock_path, \"w\") as lock_file:\n                fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX)\n                np.savez(tmp_path, W=self.W, version=self._version)\n                os.replace(tmp_path, self._weights_path)\n                fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)\n            self._weights_mtime = os.path.getmtime(self._weights_path)\n        except Exception as e:\n            from scripts.logger import get_logger\n            get_logger(__name__).warning(f\"LearnedProjection: save failed: {e}\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_forward_1516": {
      "name": "forward",
      "type": "method",
      "start_line": 1516,
      "end_line": 1539,
      "content_hash": "f9810c78c7bb2cdd185ec55e4ac41a399cbc7464",
      "content": "    def forward(self, embeddings: np.ndarray) -> np.ndarray:\n        \"\"\"Project embeddings to output dim (normalized).\n\n        Args:\n            embeddings: (batch, input_dim) or (input_dim,)\n\n        Returns:\n            projected: (batch, output_dim) or (output_dim,), L2-normalized\n        \"\"\"\n        squeeze = embeddings.ndim == 1\n        if squeeze:\n            embeddings = embeddings.reshape(1, -1)\n\n        # Linear projection\n        projected = embeddings @ self.W  # (batch, output_dim)\n\n        # L2 normalize\n        norms = np.linalg.norm(projected, axis=-1, keepdims=True) + 1e-8\n        projected = projected / norms\n\n        if squeeze:\n            projected = projected[0]\n\n        return projected",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_forward_with_cache_1541": {
      "name": "forward_with_cache",
      "type": "method",
      "start_line": 1541,
      "end_line": 1571,
      "content_hash": "08aede5a7578ff745c8896b80dbb19e3a2caa64e",
      "content": "    def forward_with_cache(\n        self, embeddings: np.ndarray\n    ) -> Tuple[np.ndarray, Dict[str, Any]]:\n        \"\"\"Forward pass with cache for backprop.\n\n        Returns:\n            projected: (batch, output_dim), L2-normalized\n            cache: dict with inputs for backward pass\n        \"\"\"\n        squeeze = embeddings.ndim == 1\n        if squeeze:\n            embeddings = embeddings.reshape(1, -1)\n\n        # Linear projection\n        pre_norm = embeddings @ self.W  # (batch, output_dim)\n\n        # L2 normalize\n        norms = np.linalg.norm(pre_norm, axis=-1, keepdims=True) + 1e-8\n        projected = pre_norm / norms\n\n        cache = {\n            \"input\": embeddings,\n            \"pre_norm\": pre_norm,\n            \"norms\": norms,\n            \"projected\": projected,\n        }\n\n        if squeeze:\n            projected = projected[0]\n\n        return projected, cache",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_backward_1573": {
      "name": "backward",
      "type": "method",
      "start_line": 1573,
      "end_line": 1611,
      "content_hash": "20a88f3db11fb579df5edf7dc31f029ebb7f643c",
      "content": "    def backward(\n        self, grad_output: np.ndarray, cache: Dict[str, Any], weight: float = 1.0\n    ):\n        \"\"\"Backprop gradient through projection and update weights.\n\n        Args:\n            grad_output: gradient w.r.t. projected output (batch, output_dim) or (output_dim,)\n            cache: from forward_with_cache\n            weight: gradient scaling factor\n        \"\"\"\n        if grad_output.ndim == 1:\n            grad_output = grad_output.reshape(1, -1)\n\n        embeddings = cache[\"input\"]\n        norms = cache[\"norms\"]\n\n        batch_size = embeddings.shape[0]\n\n        # Backprop through L2 normalization\n        # d/dx (x/||x||) = (I - x*x^T/||x||^2) / ||x||\n        # Simplified: grad_pre_norm = (grad_output - projected * (grad_output \u00b7 projected)) / norms\n        projected = cache[\"projected\"]\n        dot = np.sum(grad_output * projected, axis=-1, keepdims=True)\n        grad_pre_norm = (grad_output - projected * dot) / norms\n\n        # Gradient w.r.t. W: dL/dW = input^T @ grad_pre_norm\n        dW = embeddings.T @ grad_pre_norm / batch_size\n\n        # Apply weight and update with momentum SGD\n        dW = dW * weight\n        self._momentum_W = self._momentum * self._momentum_W + dW\n        self.W -= self.lr * self._momentum_W\n\n        self._update_count += 1\n\n        # Periodic save\n        if self._update_count % 100 == 0:\n            self._version += 1\n            self._save_weights()",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_LearnedHybridWeights_1614": {
      "name": "LearnedHybridWeights",
      "type": "class",
      "start_line": 1614,
      "end_line": 1756,
      "content_hash": "b178487a6ae38fb30ec8e549b5cdf65209de5e9c",
      "content": "class LearnedHybridWeights:\n    \"\"\"\n    Learns optimal dense vs. lexical balance per-collection.\n\n    The hybrid score is: score = sigmoid(alpha) * dense + (1 - sigmoid(alpha)) * lexical\n\n    Where alpha is learned from teacher feedback:\n    - If teacher prefers results that dense ranked higher \u2192 increase alpha\n    - If teacher prefers results that lexical ranked higher \u2192 decrease alpha\n\n    Features:\n    - Per-collection weights\n    - Online gradient updates from teacher signal\n    - Bounded between 0 and 1 via sigmoid\n    \"\"\"\n\n    WEIGHTS_DIR = os.environ.get(\"RERANKER_WEIGHTS_DIR\", \"/tmp/rerank_weights\")\n\n    def __init__(self, lr: float = 0.01):\n        self.lr = lr\n        self._collection = \"default\"\n        self._weights_path = self._get_weights_path(\"default\")\n\n        # Alpha controls dense weight: dense_w = sigmoid(alpha)\n        # Initialize at 0 \u2192 sigmoid(0) = 0.5 (equal weighting)\n        self.alpha = 0.0\n\n        # Momentum\n        self._momentum_alpha = 0.0\n        self._momentum = 0.9\n\n        # Metrics\n        self._update_count = 0\n        self._version = 0\n\n        # Try to load saved weights\n        if os.path.exists(self._weights_path):\n            try:\n                self._load_weights()\n            except Exception:\n                pass\n\n    @staticmethod\n    def _sanitize_collection(collection: str) -> str:\n        return \"\".join(c if c.isalnum() or c in \"-_\" else \"_\" for c in collection)\n\n    def _get_weights_path(self, collection: str) -> str:\n        safe_name = self._sanitize_collection(collection)\n        return os.path.join(self.WEIGHTS_DIR, f\"hybrid_{safe_name}.npz\")\n\n    def set_collection(self, collection: str):\n        self._collection = collection\n        self._weights_path = self._get_weights_path(collection)\n        if os.path.exists(self._weights_path):\n            try:\n                self._load_weights()\n            except Exception:\n                pass\n\n    def _load_weights(self):\n        import fcntl\n        lock_path = self._weights_path + \".lock\"\n        os.makedirs(os.path.dirname(lock_path) or \".\", exist_ok=True)\n        with open(lock_path, \"w\") as lock_file:\n            fcntl.flock(lock_file.fileno(), fcntl.LOCK_SH)\n            data = np.load(self._weights_path)\n            self.alpha = float(data[\"alpha\"])\n            self._version = int(data.get(\"version\", 0))\n            fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)\n\n    def _save_weights(self):\n        import fcntl\n        os.makedirs(os.path.dirname(self._weights_path) or \".\", exist_ok=True)\n        lock_path = self._weights_path + \".lock\"\n        # np.savez adds .npz extension, so use base path for tmp\n        base_path = self._weights_path.rsplit(\".npz\", 1)[0]\n        tmp_base = base_path + \".tmp\"\n        tmp_path = tmp_base + \".npz\"  # What np.savez actually writes\n        with open(lock_path, \"w\") as lock_file:\n            fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX)\n            np.savez(tmp_base, alpha=self.alpha, version=self._version)\n            os.replace(tmp_path, self._weights_path)\n            fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)\n\n    @property\n    def dense_weight(self) -> float:\n        \"\"\"Current dense weight (0-1).\"\"\"\n        return 1.0 / (1.0 + np.exp(-self.alpha))\n\n    @property\n    def lexical_weight(self) -> float:\n        \"\"\"Current lexical weight (0-1).\"\"\"\n        return 1.0 - self.dense_weight\n\n    def blend(\n        self, dense_scores: np.ndarray, lexical_scores: np.ndarray\n    ) -> np.ndarray:\n        \"\"\"Blend dense and lexical scores with learned weights.\"\"\"\n        w = self.dense_weight\n        return w * dense_scores + (1 - w) * lexical_scores\n\n    def learn_from_teacher(\n        self,\n        dense_scores: np.ndarray,\n        lexical_scores: np.ndarray,\n        teacher_scores: np.ndarray,\n    ):\n        \"\"\"Update alpha based on which modality better matches teacher.\n\n        Gradient: d_loss/d_alpha = (teacher - blended) * (dense - lexical) * sigmoid'(alpha)\n        If teacher prefers dense-high docs more than blended \u2192 increase alpha\n        \"\"\"\n        w = self.dense_weight\n        blended = self.blend(dense_scores, lexical_scores)\n\n        # Normalize scores for comparison\n        teacher_norm = (teacher_scores - teacher_scores.mean()) / (teacher_scores.std() + 1e-8)\n        blended_norm = (blended - blended.mean()) / (blended.std() + 1e-8)\n        dense_norm = (dense_scores - dense_scores.mean()) / (dense_scores.std() + 1e-8)\n        lexical_norm = (lexical_scores - lexical_scores.mean()) / (lexical_scores.std() + 1e-8)\n\n        # Error: how much blended differs from teacher ranking\n        error = teacher_norm - blended_norm  # (n_docs,)\n\n        # Modality difference: positive where dense > lexical\n        modality_diff = dense_norm - lexical_norm  # (n_docs,)\n\n        # Gradient: push alpha toward modality that matches teacher better\n        # sigmoid'(alpha) = w * (1 - w)\n        sigmoid_grad = w * (1 - w)\n        grad = (error * modality_diff).mean() * sigmoid_grad\n\n        # Momentum SGD\n        self._momentum_alpha = self._momentum * self._momentum_alpha + grad\n        self.alpha += self.lr * self._momentum_alpha\n\n        # Clamp to prevent extreme values\n        self.alpha = np.clip(self.alpha, -5.0, 5.0)\n\n        self._update_count += 1\n        if self._update_count % 50 == 0:\n            self._version += 1\n            self._save_weights()",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___init___1632": {
      "name": "__init__",
      "type": "method",
      "start_line": 1632,
      "end_line": 1654,
      "content_hash": "543b90f47bfb057e56ed5888d63035dcb57c9598",
      "content": "    def __init__(self, lr: float = 0.01):\n        self.lr = lr\n        self._collection = \"default\"\n        self._weights_path = self._get_weights_path(\"default\")\n\n        # Alpha controls dense weight: dense_w = sigmoid(alpha)\n        # Initialize at 0 \u2192 sigmoid(0) = 0.5 (equal weighting)\n        self.alpha = 0.0\n\n        # Momentum\n        self._momentum_alpha = 0.0\n        self._momentum = 0.9\n\n        # Metrics\n        self._update_count = 0\n        self._version = 0\n\n        # Try to load saved weights\n        if os.path.exists(self._weights_path):\n            try:\n                self._load_weights()\n            except Exception:\n                pass",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__sanitize_collection_1657": {
      "name": "_sanitize_collection",
      "type": "method",
      "start_line": 1657,
      "end_line": 1658,
      "content_hash": "cdbd85077085baad363b24f06dafd0ea2c67f8d3",
      "content": "    def _sanitize_collection(collection: str) -> str:\n        return \"\".join(c if c.isalnum() or c in \"-_\" else \"_\" for c in collection)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__get_weights_path_1660": {
      "name": "_get_weights_path",
      "type": "method",
      "start_line": 1660,
      "end_line": 1662,
      "content_hash": "fcf1b6cd4ad60badbc2b2ebe33a1277fca0342e6",
      "content": "    def _get_weights_path(self, collection: str) -> str:\n        safe_name = self._sanitize_collection(collection)\n        return os.path.join(self.WEIGHTS_DIR, f\"hybrid_{safe_name}.npz\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_set_collection_1664": {
      "name": "set_collection",
      "type": "method",
      "start_line": 1664,
      "end_line": 1671,
      "content_hash": "5d86e95df72e0d5a0b102dca9bbef687d38ca49a",
      "content": "    def set_collection(self, collection: str):\n        self._collection = collection\n        self._weights_path = self._get_weights_path(collection)\n        if os.path.exists(self._weights_path):\n            try:\n                self._load_weights()\n            except Exception:\n                pass",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__load_weights_1673": {
      "name": "_load_weights",
      "type": "method",
      "start_line": 1673,
      "end_line": 1682,
      "content_hash": "2ac89254c5e63d781e54511f9297b2d3bcdb4443",
      "content": "    def _load_weights(self):\n        import fcntl\n        lock_path = self._weights_path + \".lock\"\n        os.makedirs(os.path.dirname(lock_path) or \".\", exist_ok=True)\n        with open(lock_path, \"w\") as lock_file:\n            fcntl.flock(lock_file.fileno(), fcntl.LOCK_SH)\n            data = np.load(self._weights_path)\n            self.alpha = float(data[\"alpha\"])\n            self._version = int(data.get(\"version\", 0))\n            fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__save_weights_1684": {
      "name": "_save_weights",
      "type": "method",
      "start_line": 1684,
      "end_line": 1696,
      "content_hash": "cbad26621a12e1d16e27eb7b514bfa379039a568",
      "content": "    def _save_weights(self):\n        import fcntl\n        os.makedirs(os.path.dirname(self._weights_path) or \".\", exist_ok=True)\n        lock_path = self._weights_path + \".lock\"\n        # np.savez adds .npz extension, so use base path for tmp\n        base_path = self._weights_path.rsplit(\".npz\", 1)[0]\n        tmp_base = base_path + \".tmp\"\n        tmp_path = tmp_base + \".npz\"  # What np.savez actually writes\n        with open(lock_path, \"w\") as lock_file:\n            fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX)\n            np.savez(tmp_base, alpha=self.alpha, version=self._version)\n            os.replace(tmp_path, self._weights_path)\n            fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_dense_weight_1699": {
      "name": "dense_weight",
      "type": "method",
      "start_line": 1699,
      "end_line": 1701,
      "content_hash": "fb10f2089d6e6f4bb1725dc02a6f4cb784d2f313",
      "content": "    def dense_weight(self) -> float:\n        \"\"\"Current dense weight (0-1).\"\"\"\n        return 1.0 / (1.0 + np.exp(-self.alpha))",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_lexical_weight_1704": {
      "name": "lexical_weight",
      "type": "method",
      "start_line": 1704,
      "end_line": 1706,
      "content_hash": "45b4fd148fe150affe130f8856ada6272cd1bef1",
      "content": "    def lexical_weight(self) -> float:\n        \"\"\"Current lexical weight (0-1).\"\"\"\n        return 1.0 - self.dense_weight",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_blend_1708": {
      "name": "blend",
      "type": "method",
      "start_line": 1708,
      "end_line": 1713,
      "content_hash": "2d702edb09d5bea6c9ad03e8dec326daa82946aa",
      "content": "    def blend(\n        self, dense_scores: np.ndarray, lexical_scores: np.ndarray\n    ) -> np.ndarray:\n        \"\"\"Blend dense and lexical scores with learned weights.\"\"\"\n        w = self.dense_weight\n        return w * dense_scores + (1 - w) * lexical_scores",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_learn_from_teacher_1715": {
      "name": "learn_from_teacher",
      "type": "method",
      "start_line": 1715,
      "end_line": 1756,
      "content_hash": "4d63066284b5afcead5bbf28b2f91522d252acb0",
      "content": "    def learn_from_teacher(\n        self,\n        dense_scores: np.ndarray,\n        lexical_scores: np.ndarray,\n        teacher_scores: np.ndarray,\n    ):\n        \"\"\"Update alpha based on which modality better matches teacher.\n\n        Gradient: d_loss/d_alpha = (teacher - blended) * (dense - lexical) * sigmoid'(alpha)\n        If teacher prefers dense-high docs more than blended \u2192 increase alpha\n        \"\"\"\n        w = self.dense_weight\n        blended = self.blend(dense_scores, lexical_scores)\n\n        # Normalize scores for comparison\n        teacher_norm = (teacher_scores - teacher_scores.mean()) / (teacher_scores.std() + 1e-8)\n        blended_norm = (blended - blended.mean()) / (blended.std() + 1e-8)\n        dense_norm = (dense_scores - dense_scores.mean()) / (dense_scores.std() + 1e-8)\n        lexical_norm = (lexical_scores - lexical_scores.mean()) / (lexical_scores.std() + 1e-8)\n\n        # Error: how much blended differs from teacher ranking\n        error = teacher_norm - blended_norm  # (n_docs,)\n\n        # Modality difference: positive where dense > lexical\n        modality_diff = dense_norm - lexical_norm  # (n_docs,)\n\n        # Gradient: push alpha toward modality that matches teacher better\n        # sigmoid'(alpha) = w * (1 - w)\n        sigmoid_grad = w * (1 - w)\n        grad = (error * modality_diff).mean() * sigmoid_grad\n\n        # Momentum SGD\n        self._momentum_alpha = self._momentum * self._momentum_alpha + grad\n        self.alpha += self.lr * self._momentum_alpha\n\n        # Clamp to prevent extreme values\n        self.alpha = np.clip(self.alpha, -5.0, 5.0)\n\n        self._update_count += 1\n        if self._update_count % 50 == 0:\n            self._version += 1\n            self._save_weights()",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_QueryExpander_1759": {
      "name": "QueryExpander",
      "type": "class",
      "start_line": 1759,
      "end_line": 1936,
      "content_hash": "df8ac05e37c2f8d40597da03e5e6af5388378793",
      "content": "class QueryExpander:\n    \"\"\"\n    Learns query expansions (synonyms/related terms) from usage patterns.\n\n    Observes which terms co-occur with successful retrievals and builds\n    a lightweight term\u2192expansion mapping per-collection.\n\n    Features:\n    - Learns from teacher feedback: which doc terms appear in high-scoring results\n    - Per-collection expansion vocabulary\n    - Confidence-weighted: only expands with high-confidence associations\n    - Decay: old associations fade without reinforcement\n    \"\"\"\n\n    WEIGHTS_DIR = os.environ.get(\"RERANKER_WEIGHTS_DIR\", \"/tmp/rerank_weights\")\n    MAX_EXPANSIONS_PER_TERM = 5\n    MIN_CONFIDENCE = 0.3\n    DECAY_RATE = 0.995  # Per-update decay for old associations\n\n    def __init__(self, lr: float = 0.1):\n        self.lr = lr\n        self._collection = \"default\"\n        self._weights_path = self._get_weights_path(\"default\")\n\n        # term \u2192 {expansion_term: confidence}\n        # confidence in [0, 1], higher = stronger association\n        self.expansions: Dict[str, Dict[str, float]] = {}\n\n        self._update_count = 0\n        self._version = 0\n\n        if os.path.exists(self._weights_path):\n            try:\n                self._load_weights()\n            except Exception:\n                pass\n\n    @staticmethod\n    def _sanitize_collection(collection: str) -> str:\n        return \"\".join(c if c.isalnum() or c in \"-_\" else \"_\" for c in collection)\n\n    def _get_weights_path(self, collection: str) -> str:\n        safe_name = self._sanitize_collection(collection)\n        return os.path.join(self.WEIGHTS_DIR, f\"expander_{safe_name}.json\")\n\n    def set_collection(self, collection: str):\n        self._collection = collection\n        self._weights_path = self._get_weights_path(collection)\n        if os.path.exists(self._weights_path):\n            try:\n                self._load_weights()\n            except Exception:\n                pass\n\n    def _load_weights(self):\n        import json\n        import fcntl\n        lock_path = self._weights_path + \".lock\"\n        os.makedirs(os.path.dirname(lock_path) or \".\", exist_ok=True)\n        with open(lock_path, \"w\") as lock_file:\n            fcntl.flock(lock_file.fileno(), fcntl.LOCK_SH)\n            with open(self._weights_path, \"r\") as f:\n                data = json.load(f)\n            self.expansions = data.get(\"expansions\", {})\n            self._version = data.get(\"version\", 0)\n            fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)\n\n    def _save_weights(self):\n        import json\n        import fcntl\n        os.makedirs(os.path.dirname(self._weights_path) or \".\", exist_ok=True)\n        lock_path = self._weights_path + \".lock\"\n        tmp_path = self._weights_path + \".tmp\"\n        with open(lock_path, \"w\") as lock_file:\n            fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX)\n            with open(tmp_path, \"w\") as f:\n                json.dump({\"expansions\": self.expansions, \"version\": self._version}, f)\n            os.replace(tmp_path, self._weights_path)\n            fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)\n\n    def _tokenize(self, text: str) -> List[str]:\n        \"\"\"Simple tokenization for expansion learning.\"\"\"\n        # Use the same tokenizer as the rest of the system\n        tokens = re.findall(r'[a-zA-Z_][a-zA-Z0-9_]*', text.lower())\n        # Filter common tokens\n        return [t for t in tokens if len(t) > 2 and t not in _COMMON_TOKENS]\n\n    def expand(self, query: str, max_expansions: int = 3) -> List[str]:\n        \"\"\"Return expansion terms for the query.\n\n        Args:\n            query: Original query string\n            max_expansions: Max terms to add\n\n        Returns:\n            List of expansion terms (may be empty)\n        \"\"\"\n        query_tokens = set(self._tokenize(query))\n        candidates: List[Tuple[str, float]] = []\n\n        for token in query_tokens:\n            if token in self.expansions:\n                for exp_term, conf in self.expansions[token].items():\n                    if exp_term not in query_tokens and conf >= self.MIN_CONFIDENCE:\n                        candidates.append((exp_term, conf))\n\n        # Sort by confidence, take top\n        candidates.sort(key=lambda x: -x[1])\n        return [term for term, _ in candidates[:max_expansions]]\n\n    def learn_from_teacher(\n        self,\n        query: str,\n        doc_texts: List[str],\n        teacher_scores: np.ndarray,\n    ):\n        \"\"\"Learn term associations from teacher-scored documents.\n\n        High-scoring docs contribute their terms as expansions for query terms.\n        \"\"\"\n        query_tokens = set(self._tokenize(query))\n        if not query_tokens:\n            return\n\n        # Normalize teacher scores to weights\n        weights = np.exp(teacher_scores - teacher_scores.max())\n        weights = weights / (weights.sum() + 1e-8)\n\n        # Collect doc terms weighted by teacher score\n        doc_term_weights: Dict[str, float] = {}\n        for doc_text, weight in zip(doc_texts, weights):\n            for token in self._tokenize(doc_text):\n                if token not in query_tokens:  # Only non-query terms\n                    doc_term_weights[token] = doc_term_weights.get(token, 0.0) + weight\n\n        # Update expansion associations\n        for query_term in query_tokens:\n            if query_term not in self.expansions:\n                self.expansions[query_term] = {}\n\n            term_expansions = self.expansions[query_term]\n\n            # Decay existing associations\n            for exp in list(term_expansions.keys()):\n                term_expansions[exp] = float(term_expansions[exp] * self.DECAY_RATE)\n                if term_expansions[exp] < 0.01:\n                    del term_expansions[exp]\n\n            # Reinforce associations from high-scoring docs\n            for doc_term, weight in doc_term_weights.items():\n                if weight > 0.1:  # Only significant weights\n                    old_conf = term_expansions.get(doc_term, 0.0)\n                    # EMA update\n                    new_conf = old_conf + self.lr * (weight - old_conf)\n                    # Convert to native float for JSON serialization\n                    term_expansions[doc_term] = float(min(new_conf, 1.0))\n\n            # Prune to max expansions per term\n            if len(term_expansions) > self.MAX_EXPANSIONS_PER_TERM * 2:\n                sorted_exp = sorted(term_expansions.items(), key=lambda x: -x[1])\n                self.expansions[query_term] = dict(sorted_exp[:self.MAX_EXPANSIONS_PER_TERM])\n\n        self._update_count += 1\n        if self._update_count % 20 == 0:\n            self._version += 1\n            self._save_weights()\n\n    def get_stats(self) -> Dict[str, Any]:\n        \"\"\"Return stats about learned expansions.\"\"\"\n        total_terms = len(self.expansions)\n        total_expansions = sum(len(v) for v in self.expansions.values())\n        avg_expansions = total_expansions / max(total_terms, 1)\n        return {\n            \"terms\": total_terms,\n            \"expansions\": total_expansions,\n            \"avg_per_term\": avg_expansions,\n            \"version\": self._version,\n        }",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___init___1778": {
      "name": "__init__",
      "type": "method",
      "start_line": 1778,
      "end_line": 1794,
      "content_hash": "fb73c6812afa0ed72efdcb7c268de347305b78bc",
      "content": "    def __init__(self, lr: float = 0.1):\n        self.lr = lr\n        self._collection = \"default\"\n        self._weights_path = self._get_weights_path(\"default\")\n\n        # term \u2192 {expansion_term: confidence}\n        # confidence in [0, 1], higher = stronger association\n        self.expansions: Dict[str, Dict[str, float]] = {}\n\n        self._update_count = 0\n        self._version = 0\n\n        if os.path.exists(self._weights_path):\n            try:\n                self._load_weights()\n            except Exception:\n                pass",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__sanitize_collection_1797": {
      "name": "_sanitize_collection",
      "type": "method",
      "start_line": 1797,
      "end_line": 1798,
      "content_hash": "cdbd85077085baad363b24f06dafd0ea2c67f8d3",
      "content": "    def _sanitize_collection(collection: str) -> str:\n        return \"\".join(c if c.isalnum() or c in \"-_\" else \"_\" for c in collection)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__get_weights_path_1800": {
      "name": "_get_weights_path",
      "type": "method",
      "start_line": 1800,
      "end_line": 1802,
      "content_hash": "f6ee3062effd8eef764fbd5035a90c7ae077dc5f",
      "content": "    def _get_weights_path(self, collection: str) -> str:\n        safe_name = self._sanitize_collection(collection)\n        return os.path.join(self.WEIGHTS_DIR, f\"expander_{safe_name}.json\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_set_collection_1804": {
      "name": "set_collection",
      "type": "method",
      "start_line": 1804,
      "end_line": 1811,
      "content_hash": "5d86e95df72e0d5a0b102dca9bbef687d38ca49a",
      "content": "    def set_collection(self, collection: str):\n        self._collection = collection\n        self._weights_path = self._get_weights_path(collection)\n        if os.path.exists(self._weights_path):\n            try:\n                self._load_weights()\n            except Exception:\n                pass",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__load_weights_1813": {
      "name": "_load_weights",
      "type": "method",
      "start_line": 1813,
      "end_line": 1824,
      "content_hash": "6c98454b8f12f8932b93cb0f4279af46520a3dbd",
      "content": "    def _load_weights(self):\n        import json\n        import fcntl\n        lock_path = self._weights_path + \".lock\"\n        os.makedirs(os.path.dirname(lock_path) or \".\", exist_ok=True)\n        with open(lock_path, \"w\") as lock_file:\n            fcntl.flock(lock_file.fileno(), fcntl.LOCK_SH)\n            with open(self._weights_path, \"r\") as f:\n                data = json.load(f)\n            self.expansions = data.get(\"expansions\", {})\n            self._version = data.get(\"version\", 0)\n            fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__save_weights_1826": {
      "name": "_save_weights",
      "type": "method",
      "start_line": 1826,
      "end_line": 1837,
      "content_hash": "9506a5fa3ec7f71cbf8fbd9506e26162a110c6a8",
      "content": "    def _save_weights(self):\n        import json\n        import fcntl\n        os.makedirs(os.path.dirname(self._weights_path) or \".\", exist_ok=True)\n        lock_path = self._weights_path + \".lock\"\n        tmp_path = self._weights_path + \".tmp\"\n        with open(lock_path, \"w\") as lock_file:\n            fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX)\n            with open(tmp_path, \"w\") as f:\n                json.dump({\"expansions\": self.expansions, \"version\": self._version}, f)\n            os.replace(tmp_path, self._weights_path)\n            fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__tokenize_1839": {
      "name": "_tokenize",
      "type": "method",
      "start_line": 1839,
      "end_line": 1844,
      "content_hash": "ae0a563fbdb5d17ea49abd18bae346329a9f3755",
      "content": "    def _tokenize(self, text: str) -> List[str]:\n        \"\"\"Simple tokenization for expansion learning.\"\"\"\n        # Use the same tokenizer as the rest of the system\n        tokens = re.findall(r'[a-zA-Z_][a-zA-Z0-9_]*', text.lower())\n        # Filter common tokens\n        return [t for t in tokens if len(t) > 2 and t not in _COMMON_TOKENS]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_expand_1846": {
      "name": "expand",
      "type": "method",
      "start_line": 1846,
      "end_line": 1867,
      "content_hash": "fc8a763ed37794c38e6ae97ad300e063580ffb12",
      "content": "    def expand(self, query: str, max_expansions: int = 3) -> List[str]:\n        \"\"\"Return expansion terms for the query.\n\n        Args:\n            query: Original query string\n            max_expansions: Max terms to add\n\n        Returns:\n            List of expansion terms (may be empty)\n        \"\"\"\n        query_tokens = set(self._tokenize(query))\n        candidates: List[Tuple[str, float]] = []\n\n        for token in query_tokens:\n            if token in self.expansions:\n                for exp_term, conf in self.expansions[token].items():\n                    if exp_term not in query_tokens and conf >= self.MIN_CONFIDENCE:\n                        candidates.append((exp_term, conf))\n\n        # Sort by confidence, take top\n        candidates.sort(key=lambda x: -x[1])\n        return [term for term, _ in candidates[:max_expansions]]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_learn_from_teacher_1869": {
      "name": "learn_from_teacher",
      "type": "method",
      "start_line": 1869,
      "end_line": 1924,
      "content_hash": "a10cf16e9cfaca227266c46e980532c7a7ae0e5a",
      "content": "    def learn_from_teacher(\n        self,\n        query: str,\n        doc_texts: List[str],\n        teacher_scores: np.ndarray,\n    ):\n        \"\"\"Learn term associations from teacher-scored documents.\n\n        High-scoring docs contribute their terms as expansions for query terms.\n        \"\"\"\n        query_tokens = set(self._tokenize(query))\n        if not query_tokens:\n            return\n\n        # Normalize teacher scores to weights\n        weights = np.exp(teacher_scores - teacher_scores.max())\n        weights = weights / (weights.sum() + 1e-8)\n\n        # Collect doc terms weighted by teacher score\n        doc_term_weights: Dict[str, float] = {}\n        for doc_text, weight in zip(doc_texts, weights):\n            for token in self._tokenize(doc_text):\n                if token not in query_tokens:  # Only non-query terms\n                    doc_term_weights[token] = doc_term_weights.get(token, 0.0) + weight\n\n        # Update expansion associations\n        for query_term in query_tokens:\n            if query_term not in self.expansions:\n                self.expansions[query_term] = {}\n\n            term_expansions = self.expansions[query_term]\n\n            # Decay existing associations\n            for exp in list(term_expansions.keys()):\n                term_expansions[exp] = float(term_expansions[exp] * self.DECAY_RATE)\n                if term_expansions[exp] < 0.01:\n                    del term_expansions[exp]\n\n            # Reinforce associations from high-scoring docs\n            for doc_term, weight in doc_term_weights.items():\n                if weight > 0.1:  # Only significant weights\n                    old_conf = term_expansions.get(doc_term, 0.0)\n                    # EMA update\n                    new_conf = old_conf + self.lr * (weight - old_conf)\n                    # Convert to native float for JSON serialization\n                    term_expansions[doc_term] = float(min(new_conf, 1.0))\n\n            # Prune to max expansions per term\n            if len(term_expansions) > self.MAX_EXPANSIONS_PER_TERM * 2:\n                sorted_exp = sorted(term_expansions.items(), key=lambda x: -x[1])\n                self.expansions[query_term] = dict(sorted_exp[:self.MAX_EXPANSIONS_PER_TERM])\n\n        self._update_count += 1\n        if self._update_count % 20 == 0:\n            self._version += 1\n            self._save_weights()",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_get_stats_1926": {
      "name": "get_stats",
      "type": "method",
      "start_line": 1926,
      "end_line": 1936,
      "content_hash": "f03e86b339a435740b4dc7bf2f632612932dfdef",
      "content": "    def get_stats(self) -> Dict[str, Any]:\n        \"\"\"Return stats about learned expansions.\"\"\"\n        total_terms = len(self.expansions)\n        total_expansions = sum(len(v) for v in self.expansions.values())\n        avg_expansions = total_expansions / max(total_terms, 1)\n        return {\n            \"terms\": total_terms,\n            \"expansions\": total_expansions,\n            \"avg_per_term\": avg_expansions,\n            \"version\": self._version,\n        }",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_ConfidenceEstimator_1939": {
      "name": "ConfidenceEstimator",
      "type": "class",
      "start_line": 1939,
      "end_line": 1990,
      "content_hash": "951a08c6f9ea7274bef02ad1d016ae9217d0434e",
      "content": "class ConfidenceEstimator:\n    \"\"\"\n    Estimates confidence to enable early stopping.\n\n    From TRM: Q-learning inspired halting - stop when improvement is minimal.\n    Uses patience to avoid stopping on noisy single-step improvements.\n    \"\"\"\n\n    def __init__(self, patience: int = 1, min_improvement: float = 0.01):\n        self.patience = patience\n        self.min_improvement = min_improvement\n        self._stable_count = 0  # Track consecutive stable iterations\n\n    def reset(self):\n        \"\"\"Reset state for a new query.\"\"\"\n        self._stable_count = 0\n\n    def should_stop(self, state: RefinementState) -> bool:\n        \"\"\"Check if we should stop refining based on score stability.\"\"\"\n        if len(state.score_history) < 2:\n            return False\n\n        # Compare current ranking to previous\n        prev_scores = state.score_history[-2]\n        curr_scores = state.scores\n\n        # Measure ranking correlation (Kendall's tau approximation)\n        prev_order = np.argsort(-prev_scores)\n        curr_order = np.argsort(-curr_scores)\n\n        # Check if this iteration is \"stable\" (minimal change)\n        is_stable = False\n\n        # If top-k rankings are identical, consider stable\n        k = min(5, len(prev_order))\n        if np.array_equal(prev_order[:k], curr_order[:k]):\n            is_stable = True\n\n        # Check score improvement\n        improvement = np.abs(curr_scores - prev_scores).mean()\n        if improvement < self.min_improvement:\n            is_stable = True\n\n        # Update stable count and check patience\n        if is_stable:\n            self._stable_count += 1\n            if self._stable_count >= self.patience:\n                return True\n        else:\n            self._stable_count = 0  # Reset on meaningful change\n\n        return False",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___init___1947": {
      "name": "__init__",
      "type": "method",
      "start_line": 1947,
      "end_line": 1950,
      "content_hash": "14b586649c90de996592a593e7b1928bf47b3816",
      "content": "    def __init__(self, patience: int = 1, min_improvement: float = 0.01):\n        self.patience = patience\n        self.min_improvement = min_improvement\n        self._stable_count = 0  # Track consecutive stable iterations",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_reset_1952": {
      "name": "reset",
      "type": "method",
      "start_line": 1952,
      "end_line": 1954,
      "content_hash": "d6dbc39db48b89ec2d4197acf59577b61c0431d4",
      "content": "    def reset(self):\n        \"\"\"Reset state for a new query.\"\"\"\n        self._stable_count = 0",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_should_stop_1956": {
      "name": "should_stop",
      "type": "method",
      "start_line": 1956,
      "end_line": 1990,
      "content_hash": "68a56b553169007c35b9a575f7a5578952ce4161",
      "content": "    def should_stop(self, state: RefinementState) -> bool:\n        \"\"\"Check if we should stop refining based on score stability.\"\"\"\n        if len(state.score_history) < 2:\n            return False\n\n        # Compare current ranking to previous\n        prev_scores = state.score_history[-2]\n        curr_scores = state.scores\n\n        # Measure ranking correlation (Kendall's tau approximation)\n        prev_order = np.argsort(-prev_scores)\n        curr_order = np.argsort(-curr_scores)\n\n        # Check if this iteration is \"stable\" (minimal change)\n        is_stable = False\n\n        # If top-k rankings are identical, consider stable\n        k = min(5, len(prev_order))\n        if np.array_equal(prev_order[:k], curr_order[:k]):\n            is_stable = True\n\n        # Check score improvement\n        improvement = np.abs(curr_scores - prev_scores).mean()\n        if improvement < self.min_improvement:\n            is_stable = True\n\n        # Update stable count and check patience\n        if is_stable:\n            self._stable_count += 1\n            if self._stable_count >= self.patience:\n                return True\n        else:\n            self._stable_count = 0  # Reset on meaningful change\n\n        return False",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_RecursiveReranker_1993": {
      "name": "RecursiveReranker",
      "type": "class",
      "start_line": 1993,
      "end_line": 2328,
      "content_hash": "c620cdfddcafa3dd513b67b3b84ec41e20e9ed7e",
      "content": "class RecursiveReranker:\n    \"\"\"\n    Main recursive reranking pipeline.\n\n    Implements TRM-style iterative refinement:\n    1. Initialize latent state z from query\n    2. For each iteration:\n       a. Score all candidates using [query, doc, z]\n       b. Refine z based on current scores\n       c. Check for early stopping\n    3. Return final ranking\n\n    Key insight: Multiple passes through tiny networks > one pass through large network\n    \"\"\"\n\n    def __init__(\n        self,\n        n_iterations: int = 3,\n        dim: int = 256,\n        hidden_dim: int = 512,\n        early_stop: bool = True,\n        blend_with_initial: float = 0.3,  # Blend with initial scores\n    ):\n        self.n_iterations = n_iterations\n        self.dim = dim\n        self.early_stop = early_stop\n        self.blend_with_initial = blend_with_initial\n\n        # Initialize components\n        self.scorer = TinyScorer(dim=dim, hidden_dim=hidden_dim)\n        self.refiner = LatentRefiner(dim=dim)\n        # Note: ConfidenceEstimator created per-rerank call for thread safety\n\n        # Learned projection (uses same weights as training worker)\n        from scripts.embedder import get_model_dimension\n        embed_dim = get_model_dimension()\n        self._learned_projection = LearnedProjection(\n            input_dim=embed_dim,\n            output_dim=dim,\n            lr=0.0,  # No learning in serving path\n        )\n\n        # Try to use ONNX embedder for document encoding\n        self._embedder = None\n        self._embedder_lock = threading.Lock()\n\n        # Cached projection matrices: input_dim -> projection_matrix (fallback)\n        self._proj_cache: Dict[int, np.ndarray] = {}\n        self._proj_cache_lock = threading.Lock()\n\n    def _get_embedder(self):\n        \"\"\"Lazy load embedder for encoding queries and documents.\"\"\"\n        if self._embedder is not None:\n            return self._embedder\n\n        with self._embedder_lock:\n            if self._embedder is not None:\n                return self._embedder\n\n            try:\n                from scripts.embedder import get_embedding_model\n                model_name = os.environ.get(\"EMBEDDING_MODEL\", \"BAAI/bge-base-en-v1.5\")\n                self._embedder = get_embedding_model(model_name)\n            except Exception:\n                self._embedder = None\n            return self._embedder\n\n    def _encode(self, texts: List[str]) -> np.ndarray:\n        \"\"\"Encode texts to embeddings with caching and batch optimization.\"\"\"\n        # Check cache first\n        cached_results = []\n        texts_to_encode = []\n        text_indices = []\n\n        for i, text in enumerate(texts):\n            cached = _get_cached_embedding(text)\n            if cached is not None:\n                cached_results.append((i, cached))\n            else:\n                texts_to_encode.append(text)\n                text_indices.append(i)\n\n        # Encode uncached texts in batch\n        new_embeddings = []\n        if texts_to_encode:\n            embedder = self._get_embedder()\n            if embedder is not None:\n                try:\n                    # Batch encode all uncached texts at once\n                    embeddings = list(embedder.embed(texts_to_encode))\n                    # Validate count matches to avoid IndexError in reconstruction\n                    if len(embeddings) != len(texts_to_encode):\n                        raise ValueError(f\"Embedder returned {len(embeddings)} embeddings for {len(texts_to_encode)} texts\")\n                    for text, emb in zip(texts_to_encode, embeddings):\n                        emb_arr = np.array(emb, dtype=np.float32)\n                        # Project to target dim before caching for consistency\n                        if emb_arr.shape[0] != self.dim:\n                            emb_arr = self._project_to_dim(emb_arr.reshape(1, -1))[0]\n                        _cache_embedding(text, emb_arr)\n                        new_embeddings.append(emb_arr)\n                except Exception:\n                    new_embeddings = []\n\n            # Fallback for any that failed - use sha256-derived seed for determinism\n            if not new_embeddings:\n                import hashlib\n                # Determine target dimension: use cached embedding dim if available, else self.dim\n                fallback_dim = self.dim\n                if cached_results:\n                    fallback_dim = cached_results[0][1].shape[0]\n                for text in texts_to_encode:\n                    # Derive deterministic seed from sha256 (process-stable)\n                    text_hash = hashlib.sha256(text.encode(\"utf-8\", errors=\"replace\")).digest()\n                    seed = int.from_bytes(text_hash[:4], \"big\")\n                    rng = np.random.RandomState(seed)\n                    vec = rng.randn(fallback_dim).astype(np.float32)\n                    vec = vec / (np.linalg.norm(vec) + 1e-8)\n                    _cache_embedding(text, vec)\n                    new_embeddings.append(vec)\n\n        # Reconstruct results in original order\n        result = [None] * len(texts)\n        for i, emb in cached_results:\n            result[i] = emb\n        for i, idx in enumerate(text_indices):\n            result[idx] = new_embeddings[i]\n\n        return np.array(result, dtype=np.float32)\n\n    def _encode_raw(self, texts: List[str]) -> np.ndarray:\n        \"\"\"Encode texts to raw embeddings WITHOUT projection (for learner).\n\n        Returns embeddings in the model's native dimension (e.g., 768 for BGE).\n        Used by CollectionLearner to learn the projection matrix.\n        \"\"\"\n        from scripts.embedder import get_model_dimension\n        fallback_dim = get_model_dimension()\n\n        embedder = self._get_embedder()\n        if embedder is None:\n            # Fallback to random embeddings\n            import hashlib\n            result = []\n            for text in texts:\n                text_hash = hashlib.sha256(text.encode(\"utf-8\", errors=\"replace\")).digest()\n                seed = int.from_bytes(text_hash[:4], \"big\")\n                rng = np.random.RandomState(seed)\n                vec = rng.randn(fallback_dim).astype(np.float32)\n                vec = vec / (np.linalg.norm(vec) + 1e-8)\n                result.append(vec)\n            return np.array(result, dtype=np.float32)\n\n        try:\n            embeddings = list(embedder.embed(texts))\n            result = []\n            for emb in embeddings:\n                emb_arr = np.array(emb, dtype=np.float32)\n                result.append(emb_arr)\n            return np.array(result, dtype=np.float32)\n        except Exception:\n            # Fallback\n            import hashlib\n            result = []\n            for text in texts:\n                text_hash = hashlib.sha256(text.encode(\"utf-8\", errors=\"replace\")).digest()\n                seed = int.from_bytes(text_hash[:4], \"big\")\n                rng = np.random.RandomState(seed)\n                vec = rng.randn(fallback_dim).astype(np.float32)\n                vec = vec / (np.linalg.norm(vec) + 1e-8)\n                result.append(vec)\n            return np.array(result, dtype=np.float32)\n\n    def _project_to_dim(self, embeddings: np.ndarray) -> np.ndarray:\n        \"\"\"Project embeddings to target dimension using learned projection.\n\n        Uses LearnedProjection when weights are available (trained by worker),\n        falls back to deterministic random projection otherwise.\n        \"\"\"\n        if embeddings.shape[-1] == self.dim:\n            return embeddings\n\n        input_dim = embeddings.shape[-1]\n\n        # Use learned projection if available and dimension matches\n        if (hasattr(self, '_learned_projection') and\n            self._learned_projection._weights_loaded and\n            self._learned_projection.input_dim == input_dim):\n            return self._learned_projection.forward(embeddings)\n\n        # Fallback: deterministic random projection (for cold start)\n        with self._proj_cache_lock:\n            if input_dim not in self._proj_cache:\n                # Use local RNG for deterministic, process-stable projection\n                rng = np.random.RandomState(44)\n                proj_matrix = rng.randn(input_dim, self.dim).astype(np.float32) * np.float32(0.01)\n                self._proj_cache[input_dim] = proj_matrix\n\n            proj_matrix = self._proj_cache[input_dim]\n\n        projected = embeddings @ proj_matrix\n        # Normalize\n        norms = np.linalg.norm(projected, axis=-1, keepdims=True) + 1e-8\n        return projected / norms\n\n    def rerank(\n        self,\n        query: str,\n        candidates: List[Dict[str, Any]],\n        initial_scores: Optional[List[float]] = None,\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Recursively rerank candidates.\n\n        Args:\n            query: Search query string\n            candidates: List of candidate dicts with 'code', 'path', 'symbol', etc.\n            initial_scores: Optional initial scores from hybrid search\n\n        Returns:\n            Reranked candidates with updated scores and refinement metadata\n        \"\"\"\n        if not candidates:\n            return []\n\n        # Create per-call confidence estimator for thread safety\n        confidence = ConfidenceEstimator()\n\n        n_docs = len(candidates)\n\n        # Extract document text for encoding\n        doc_texts = []\n        for c in candidates:\n            text_parts = []\n            if c.get(\"symbol\"):\n                text_parts.append(str(c[\"symbol\"]))\n            if c.get(\"path\"):\n                text_parts.append(str(c[\"path\"]))\n            code = c.get(\"code\") or c.get(\"snippet\") or c.get(\"text\") or \"\"\n            if code:\n                text_parts.append(str(code)[:500])  # Truncate for efficiency\n            doc_texts.append(\" \".join(text_parts) if text_parts else \"empty\")\n\n        # Encode query and documents\n        query_emb = self._encode([query])[0]  # (emb_dim,)\n        doc_embs = self._encode(doc_texts)  # (n_docs, emb_dim)\n\n        # Project to working dimension\n        query_emb = self._project_to_dim(query_emb.reshape(1, -1))[0]\n        doc_embs = self._project_to_dim(doc_embs)\n\n        # Initialize latent state from query\n        z = query_emb.copy()\n\n        # Initialize scores from initial_scores or zeros\n        if initial_scores is not None:\n            scores = np.array(initial_scores, dtype=np.float32)\n        else:\n            scores = np.zeros(n_docs, dtype=np.float32)\n\n        # Create refinement state\n        state = RefinementState(z=z, scores=scores, iteration=0)\n        state.score_history.append(scores.copy())\n\n        # Iterative refinement loop\n        for i in range(self.n_iterations):\n            state.iteration = i + 1\n\n            # Score using current latent state\n            new_scores = self.scorer.forward(query_emb, doc_embs, state.z)\n\n            # Blend with previous scores (residual connection from TRM)\n            alpha = 0.5  # Weight for new scores\n            state.scores = alpha * new_scores + (1 - alpha) * state.scores\n            state.score_history.append(state.scores.copy())\n\n            # Refine latent state based on current ranking\n            state.z = self.refiner.refine(\n                state.z, query_emb, doc_embs, state.scores\n            )\n\n            # Check for early stopping\n            if self.early_stop and confidence.should_stop(state):\n                break\n\n        # Blend with initial scores if provided\n        final_scores = state.scores\n        if initial_scores is not None and self.blend_with_initial > 0:\n            init_arr = np.array(initial_scores, dtype=np.float32)\n            # Normalize both to similar scale (clamp std for numerical stability)\n            std = final_scores.std()\n            if std > 1e-6:\n                final_norm = (final_scores - final_scores.mean()) / std\n            else:\n                final_norm = final_scores - final_scores.mean()\n            std = init_arr.std()\n            if std > 1e-6:\n                init_norm = (init_arr - init_arr.mean()) / std\n            else:\n                init_norm = init_arr - init_arr.mean()\n\n            final_scores = (1 - self.blend_with_initial) * final_norm + self.blend_with_initial * init_norm\n\n        # Build reranked results\n        ranked_indices = np.argsort(-final_scores)\n        reranked = []\n\n        # Filename-query correlation boost\n        # Boosts results when 2+ query tokens match filename tokens\n        # e.g., \"hybrid search\" matches \"hybrid_search.py\"\n        fname_boost_factor = float(os.environ.get(\"FNAME_BOOST\", \"0.15\") or 0.15)\n\n        for rank, idx in enumerate(ranked_indices):\n            candidate = candidates[idx].copy()\n            candidate[\"recursive_score\"] = float(final_scores[idx])\n            candidate[\"recursive_rank\"] = rank\n            candidate[\"recursive_iterations\"] = state.iteration\n\n            # Add score trajectory for analysis\n            trajectory = [float(h[idx]) for h in state.score_history]\n            candidate[\"score_trajectory\"] = trajectory\n\n            # Filename boost\n            fname_boost = _compute_fname_boost(query, candidate, fname_boost_factor)\n\n            # Update main score\n            candidate[\"score\"] = float(final_scores[idx]) + fname_boost\n            if fname_boost > 0:\n                candidate[\"fname_boost\"] = fname_boost\n\n            reranked.append(candidate)\n\n        # Re-sort if any boosts were applied\n        if fname_boost_factor > 0 and any(c.get(\"fname_boost\", 0) > 0 for c in reranked):\n            reranked.sort(key=lambda x: -x[\"score\"])\n\n        return reranked",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___init___2008": {
      "name": "__init__",
      "type": "method",
      "start_line": 2008,
      "end_line": 2041,
      "content_hash": "9f08caf48f0ce42c967d9377ecb918da1e14cb86",
      "content": "    def __init__(\n        self,\n        n_iterations: int = 3,\n        dim: int = 256,\n        hidden_dim: int = 512,\n        early_stop: bool = True,\n        blend_with_initial: float = 0.3,  # Blend with initial scores\n    ):\n        self.n_iterations = n_iterations\n        self.dim = dim\n        self.early_stop = early_stop\n        self.blend_with_initial = blend_with_initial\n\n        # Initialize components\n        self.scorer = TinyScorer(dim=dim, hidden_dim=hidden_dim)\n        self.refiner = LatentRefiner(dim=dim)\n        # Note: ConfidenceEstimator created per-rerank call for thread safety\n\n        # Learned projection (uses same weights as training worker)\n        from scripts.embedder import get_model_dimension\n        embed_dim = get_model_dimension()\n        self._learned_projection = LearnedProjection(\n            input_dim=embed_dim,\n            output_dim=dim,\n            lr=0.0,  # No learning in serving path\n        )\n\n        # Try to use ONNX embedder for document encoding\n        self._embedder = None\n        self._embedder_lock = threading.Lock()\n\n        # Cached projection matrices: input_dim -> projection_matrix (fallback)\n        self._proj_cache: Dict[int, np.ndarray] = {}\n        self._proj_cache_lock = threading.Lock()",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__get_embedder_2043": {
      "name": "_get_embedder",
      "type": "method",
      "start_line": 2043,
      "end_line": 2058,
      "content_hash": "8e4d5801dba8b133725abf9053bf5e913e8bcf56",
      "content": "    def _get_embedder(self):\n        \"\"\"Lazy load embedder for encoding queries and documents.\"\"\"\n        if self._embedder is not None:\n            return self._embedder\n\n        with self._embedder_lock:\n            if self._embedder is not None:\n                return self._embedder\n\n            try:\n                from scripts.embedder import get_embedding_model\n                model_name = os.environ.get(\"EMBEDDING_MODEL\", \"BAAI/bge-base-en-v1.5\")\n                self._embedder = get_embedding_model(model_name)\n            except Exception:\n                self._embedder = None\n            return self._embedder",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__encode_2060": {
      "name": "_encode",
      "type": "method",
      "start_line": 2060,
      "end_line": 2120,
      "content_hash": "58708cedf18f740487f7287f662e7bece78854d6",
      "content": "    def _encode(self, texts: List[str]) -> np.ndarray:\n        \"\"\"Encode texts to embeddings with caching and batch optimization.\"\"\"\n        # Check cache first\n        cached_results = []\n        texts_to_encode = []\n        text_indices = []\n\n        for i, text in enumerate(texts):\n            cached = _get_cached_embedding(text)\n            if cached is not None:\n                cached_results.append((i, cached))\n            else:\n                texts_to_encode.append(text)\n                text_indices.append(i)\n\n        # Encode uncached texts in batch\n        new_embeddings = []\n        if texts_to_encode:\n            embedder = self._get_embedder()\n            if embedder is not None:\n                try:\n                    # Batch encode all uncached texts at once\n                    embeddings = list(embedder.embed(texts_to_encode))\n                    # Validate count matches to avoid IndexError in reconstruction\n                    if len(embeddings) != len(texts_to_encode):\n                        raise ValueError(f\"Embedder returned {len(embeddings)} embeddings for {len(texts_to_encode)} texts\")\n                    for text, emb in zip(texts_to_encode, embeddings):\n                        emb_arr = np.array(emb, dtype=np.float32)\n                        # Project to target dim before caching for consistency\n                        if emb_arr.shape[0] != self.dim:\n                            emb_arr = self._project_to_dim(emb_arr.reshape(1, -1))[0]\n                        _cache_embedding(text, emb_arr)\n                        new_embeddings.append(emb_arr)\n                except Exception:\n                    new_embeddings = []\n\n            # Fallback for any that failed - use sha256-derived seed for determinism\n            if not new_embeddings:\n                import hashlib\n                # Determine target dimension: use cached embedding dim if available, else self.dim\n                fallback_dim = self.dim\n                if cached_results:\n                    fallback_dim = cached_results[0][1].shape[0]\n                for text in texts_to_encode:\n                    # Derive deterministic seed from sha256 (process-stable)\n                    text_hash = hashlib.sha256(text.encode(\"utf-8\", errors=\"replace\")).digest()\n                    seed = int.from_bytes(text_hash[:4], \"big\")\n                    rng = np.random.RandomState(seed)\n                    vec = rng.randn(fallback_dim).astype(np.float32)\n                    vec = vec / (np.linalg.norm(vec) + 1e-8)\n                    _cache_embedding(text, vec)\n                    new_embeddings.append(vec)\n\n        # Reconstruct results in original order\n        result = [None] * len(texts)\n        for i, emb in cached_results:\n            result[i] = emb\n        for i, idx in enumerate(text_indices):\n            result[idx] = new_embeddings[i]\n\n        return np.array(result, dtype=np.float32)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__encode_raw_2122": {
      "name": "_encode_raw",
      "type": "method",
      "start_line": 2122,
      "end_line": 2163,
      "content_hash": "1c4bf6770903445f00be9a82b654c6411b2ccdc9",
      "content": "    def _encode_raw(self, texts: List[str]) -> np.ndarray:\n        \"\"\"Encode texts to raw embeddings WITHOUT projection (for learner).\n\n        Returns embeddings in the model's native dimension (e.g., 768 for BGE).\n        Used by CollectionLearner to learn the projection matrix.\n        \"\"\"\n        from scripts.embedder import get_model_dimension\n        fallback_dim = get_model_dimension()\n\n        embedder = self._get_embedder()\n        if embedder is None:\n            # Fallback to random embeddings\n            import hashlib\n            result = []\n            for text in texts:\n                text_hash = hashlib.sha256(text.encode(\"utf-8\", errors=\"replace\")).digest()\n                seed = int.from_bytes(text_hash[:4], \"big\")\n                rng = np.random.RandomState(seed)\n                vec = rng.randn(fallback_dim).astype(np.float32)\n                vec = vec / (np.linalg.norm(vec) + 1e-8)\n                result.append(vec)\n            return np.array(result, dtype=np.float32)\n\n        try:\n            embeddings = list(embedder.embed(texts))\n            result = []\n            for emb in embeddings:\n                emb_arr = np.array(emb, dtype=np.float32)\n                result.append(emb_arr)\n            return np.array(result, dtype=np.float32)\n        except Exception:\n            # Fallback\n            import hashlib\n            result = []\n            for text in texts:\n                text_hash = hashlib.sha256(text.encode(\"utf-8\", errors=\"replace\")).digest()\n                seed = int.from_bytes(text_hash[:4], \"big\")\n                rng = np.random.RandomState(seed)\n                vec = rng.randn(fallback_dim).astype(np.float32)\n                vec = vec / (np.linalg.norm(vec) + 1e-8)\n                result.append(vec)\n            return np.array(result, dtype=np.float32)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__project_to_dim_2165": {
      "name": "_project_to_dim",
      "type": "method",
      "start_line": 2165,
      "end_line": 2195,
      "content_hash": "7f3675f04c80c2a39aef27b6fa64dc493509972b",
      "content": "    def _project_to_dim(self, embeddings: np.ndarray) -> np.ndarray:\n        \"\"\"Project embeddings to target dimension using learned projection.\n\n        Uses LearnedProjection when weights are available (trained by worker),\n        falls back to deterministic random projection otherwise.\n        \"\"\"\n        if embeddings.shape[-1] == self.dim:\n            return embeddings\n\n        input_dim = embeddings.shape[-1]\n\n        # Use learned projection if available and dimension matches\n        if (hasattr(self, '_learned_projection') and\n            self._learned_projection._weights_loaded and\n            self._learned_projection.input_dim == input_dim):\n            return self._learned_projection.forward(embeddings)\n\n        # Fallback: deterministic random projection (for cold start)\n        with self._proj_cache_lock:\n            if input_dim not in self._proj_cache:\n                # Use local RNG for deterministic, process-stable projection\n                rng = np.random.RandomState(44)\n                proj_matrix = rng.randn(input_dim, self.dim).astype(np.float32) * np.float32(0.01)\n                self._proj_cache[input_dim] = proj_matrix\n\n            proj_matrix = self._proj_cache[input_dim]\n\n        projected = embeddings @ proj_matrix\n        # Normalize\n        norms = np.linalg.norm(projected, axis=-1, keepdims=True) + 1e-8\n        return projected / norms",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_rerank_2197": {
      "name": "rerank",
      "type": "method",
      "start_line": 2197,
      "end_line": 2328,
      "content_hash": "967e89986acb99909a97b9aceff5d8a7d548fe66",
      "content": "    def rerank(\n        self,\n        query: str,\n        candidates: List[Dict[str, Any]],\n        initial_scores: Optional[List[float]] = None,\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Recursively rerank candidates.\n\n        Args:\n            query: Search query string\n            candidates: List of candidate dicts with 'code', 'path', 'symbol', etc.\n            initial_scores: Optional initial scores from hybrid search\n\n        Returns:\n            Reranked candidates with updated scores and refinement metadata\n        \"\"\"\n        if not candidates:\n            return []\n\n        # Create per-call confidence estimator for thread safety\n        confidence = ConfidenceEstimator()\n\n        n_docs = len(candidates)\n\n        # Extract document text for encoding\n        doc_texts = []\n        for c in candidates:\n            text_parts = []\n            if c.get(\"symbol\"):\n                text_parts.append(str(c[\"symbol\"]))\n            if c.get(\"path\"):\n                text_parts.append(str(c[\"path\"]))\n            code = c.get(\"code\") or c.get(\"snippet\") or c.get(\"text\") or \"\"\n            if code:\n                text_parts.append(str(code)[:500])  # Truncate for efficiency\n            doc_texts.append(\" \".join(text_parts) if text_parts else \"empty\")\n\n        # Encode query and documents\n        query_emb = self._encode([query])[0]  # (emb_dim,)\n        doc_embs = self._encode(doc_texts)  # (n_docs, emb_dim)\n\n        # Project to working dimension\n        query_emb = self._project_to_dim(query_emb.reshape(1, -1))[0]\n        doc_embs = self._project_to_dim(doc_embs)\n\n        # Initialize latent state from query\n        z = query_emb.copy()\n\n        # Initialize scores from initial_scores or zeros\n        if initial_scores is not None:\n            scores = np.array(initial_scores, dtype=np.float32)\n        else:\n            scores = np.zeros(n_docs, dtype=np.float32)\n\n        # Create refinement state\n        state = RefinementState(z=z, scores=scores, iteration=0)\n        state.score_history.append(scores.copy())\n\n        # Iterative refinement loop\n        for i in range(self.n_iterations):\n            state.iteration = i + 1\n\n            # Score using current latent state\n            new_scores = self.scorer.forward(query_emb, doc_embs, state.z)\n\n            # Blend with previous scores (residual connection from TRM)\n            alpha = 0.5  # Weight for new scores\n            state.scores = alpha * new_scores + (1 - alpha) * state.scores\n            state.score_history.append(state.scores.copy())\n\n            # Refine latent state based on current ranking\n            state.z = self.refiner.refine(\n                state.z, query_emb, doc_embs, state.scores\n            )\n\n            # Check for early stopping\n            if self.early_stop and confidence.should_stop(state):\n                break\n\n        # Blend with initial scores if provided\n        final_scores = state.scores\n        if initial_scores is not None and self.blend_with_initial > 0:\n            init_arr = np.array(initial_scores, dtype=np.float32)\n            # Normalize both to similar scale (clamp std for numerical stability)\n            std = final_scores.std()\n            if std > 1e-6:\n                final_norm = (final_scores - final_scores.mean()) / std\n            else:\n                final_norm = final_scores - final_scores.mean()\n            std = init_arr.std()\n            if std > 1e-6:\n                init_norm = (init_arr - init_arr.mean()) / std\n            else:\n                init_norm = init_arr - init_arr.mean()\n\n            final_scores = (1 - self.blend_with_initial) * final_norm + self.blend_with_initial * init_norm\n\n        # Build reranked results\n        ranked_indices = np.argsort(-final_scores)\n        reranked = []\n\n        # Filename-query correlation boost\n        # Boosts results when 2+ query tokens match filename tokens\n        # e.g., \"hybrid search\" matches \"hybrid_search.py\"\n        fname_boost_factor = float(os.environ.get(\"FNAME_BOOST\", \"0.15\") or 0.15)\n\n        for rank, idx in enumerate(ranked_indices):\n            candidate = candidates[idx].copy()\n            candidate[\"recursive_score\"] = float(final_scores[idx])\n            candidate[\"recursive_rank\"] = rank\n            candidate[\"recursive_iterations\"] = state.iteration\n\n            # Add score trajectory for analysis\n            trajectory = [float(h[idx]) for h in state.score_history]\n            candidate[\"score_trajectory\"] = trajectory\n\n            # Filename boost\n            fname_boost = _compute_fname_boost(query, candidate, fname_boost_factor)\n\n            # Update main score\n            candidate[\"score\"] = float(final_scores[idx]) + fname_boost\n            if fname_boost > 0:\n                candidate[\"fname_boost\"] = fname_boost\n\n            reranked.append(candidate)\n\n        # Re-sort if any boosts were applied\n        if fname_boost_factor > 0 and any(c.get(\"fname_boost\", 0) > 0 for c in reranked):\n            reranked.sort(key=lambda x: -x[\"score\"])\n\n        return reranked",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_rerank_recursive_2332": {
      "name": "rerank_recursive",
      "type": "function",
      "start_line": 2332,
      "end_line": 2358,
      "content_hash": "ba48a673cbbfa2af1c0790c493d5b8414796c628",
      "content": "def rerank_recursive(\n    query: str,\n    candidates: List[Dict[str, Any]],\n    n_iterations: int = 3,\n    blend_with_initial: float = 0.3,\n) -> List[Dict[str, Any]]:\n    \"\"\"\n    Convenience wrapper for recursive reranking.\n\n    Args:\n        query: Search query\n        candidates: Candidate results from hybrid search\n        n_iterations: Number of refinement passes\n        blend_with_initial: How much to blend with initial scores (0-1)\n\n    Returns:\n        Reranked candidates\n    \"\"\"\n    reranker = RecursiveReranker(\n        n_iterations=n_iterations,\n        blend_with_initial=blend_with_initial,\n    )\n\n    # Extract initial scores\n    initial_scores = [c.get(\"score\", 0.0) for c in candidates]\n\n    return reranker.rerank(query, candidates, initial_scores)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_rerank_recursive_inprocess_2362": {
      "name": "rerank_recursive_inprocess",
      "type": "function",
      "start_line": 2362,
      "end_line": 2380,
      "content_hash": "8a3d14925304e7bf4238230ed45034d586f35de2",
      "content": "def rerank_recursive_inprocess(\n    query: str,\n    candidates: List[Dict[str, Any]],\n    limit: int = 12,\n    n_iterations: int = 3,\n) -> List[Dict[str, Any]]:\n    \"\"\"\n    In-process recursive reranking for MCP server integration.\n\n    Compatible with existing rerank_in_process signature.\n    \"\"\"\n    reranked = rerank_recursive(\n        query=query,\n        candidates=candidates,\n        n_iterations=n_iterations,\n        blend_with_initial=0.3,\n    )\n\n    return reranked[:limit]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function__get_learning_reranker_2388": {
      "name": "_get_learning_reranker",
      "type": "function",
      "start_line": 2388,
      "end_line": 2402,
      "content_hash": "6ef1aa9358ba1041ca8e60e28c5353f5f9bfe6c0",
      "content": "def _get_learning_reranker(\n    n_iterations: int = 3,\n    dim: int = 256,\n    collection: str = \"default\",\n) -> \"RecursiveReranker\":\n    \"\"\"Get or create a learning reranker for a specific collection.\"\"\"\n    with _LEARNING_RERANKERS_LOCK:\n        if collection not in _LEARNING_RERANKERS:\n            reranker = RecursiveReranker(n_iterations=n_iterations, dim=dim)\n            # Set collection-specific weights path for scorer, refiner, and projection\n            reranker.scorer.set_collection(collection)\n            reranker.refiner.set_collection(collection)\n            reranker._learned_projection.set_collection(collection)\n            _LEARNING_RERANKERS[collection] = reranker\n        return _LEARNING_RERANKERS[collection]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_rerank_with_learning_2405": {
      "name": "rerank_with_learning",
      "type": "function",
      "start_line": 2405,
      "end_line": 2483,
      "content_hash": "8e1550abbb03ef9c85442d9a26c43e3551b21184",
      "content": "def rerank_with_learning(\n    query: str,\n    candidates: List[Dict[str, Any]],\n    limit: int = 12,\n    n_iterations: int = 3,\n    learn_from_onnx: bool = True,\n    collection: str = \"default\",\n) -> List[Dict[str, Any]]:\n    \"\"\"\n    Learning-enabled reranking for MCP server integration.\n\n    Uses a persistent reranker with weights loaded per-collection.\n    Training events are logged for background processing rather than\n    inline learning (keeps hot path fast and deterministic).\n\n    Args:\n        query: Search query\n        candidates: List of candidate documents with scores\n        limit: Maximum results to return\n        n_iterations: Number of refinement iterations\n        learn_from_onnx: Whether to log events for learning (default True)\n        collection: Collection name for weight isolation\n\n    Returns:\n        Reranked candidates with scores\n    \"\"\"\n    reranker = _get_learning_reranker(n_iterations=n_iterations, collection=collection)\n    initial_scores = [c.get(\"score\", 0) for c in candidates]\n\n    # Log training event for background processing (no inline teacher scoring by default)\n    # If you really want inline teacher scoring, set RERANK_TEACHER_INLINE=1.\n    if learn_from_onnx and candidates:\n        teacher_scores = None\n        if str(os.environ.get(\"RERANK_TEACHER_INLINE\", \"\")).strip().lower() in {\"1\", \"true\", \"yes\", \"on\"}:\n            try:\n                from scripts.rerank_local import rerank_local\n            except ImportError:\n                try:\n                    from rerank_local import rerank_local\n                except ImportError:\n                    rerank_local = None\n\n            if rerank_local is not None:\n                try:\n                    pairs = []\n                    for c in candidates:\n                        doc = c.get(\"code\") or c.get(\"snippet\") or \"\"\n                        if not doc:\n                            parts = []\n                            if c.get(\"symbol\"):\n                                parts.append(str(c[\"symbol\"]))\n                            if c.get(\"path\"):\n                                parts.append(str(c[\"path\"]))\n                            doc = \" \".join(parts) if parts else \"empty\"\n                        pairs.append((query, doc[:1000]))\n                    teacher_scores = rerank_local(pairs)\n                except Exception:\n                    teacher_scores = None\n\n        try:\n            # Try both import paths for Docker (/app/scripts) and local (scripts/)\n            try:\n                from rerank_events import log_training_event\n            except ImportError:\n                from scripts.rerank_events import log_training_event\n            log_training_event(\n                query=query,\n                candidates=candidates,\n                initial_scores=initial_scores,\n                teacher_scores=(list(teacher_scores) if teacher_scores is not None else None),\n                collection=collection,\n                metadata={\"teacher_inline\": bool(teacher_scores is not None)},\n            )\n        except Exception:\n            pass  # Best effort - don't fail the request\n\n    # Inference only (no inline learning)\n    reranked = reranker.rerank(query, candidates, initial_scores)\n    return reranked[:limit]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_ONNXRecursiveReranker_2486": {
      "name": "ONNXRecursiveReranker",
      "type": "class",
      "start_line": 2486,
      "end_line": 2721,
      "content_hash": "3464c5aebe6af17ce2670f68951a210a1475d8e3",
      "content": "class ONNXRecursiveReranker(RecursiveReranker):\n    \"\"\"\n    Recursive reranker using ONNX cross-encoder for scoring.\n\n    Combines the power of pre-trained cross-encoders with\n    iterative refinement from TRM paper.\n    \"\"\"\n\n    def __init__(\n        self,\n        n_iterations: int = 3,\n        onnx_path: Optional[str] = None,\n        tokenizer_path: Optional[str] = None,\n        **kwargs\n    ):\n        super().__init__(n_iterations=n_iterations, **kwargs)\n\n        self.onnx_path = onnx_path or os.environ.get(\"RERANKER_ONNX_PATH\", \"\")\n        self.tokenizer_path = tokenizer_path or os.environ.get(\"RERANKER_TOKENIZER_PATH\", \"\")\n\n        self._session = None\n        self._tokenizer = None\n        self._onnx_lock = threading.Lock()\n\n    def _get_onnx_session(self):\n        \"\"\"Load ONNX session and tokenizer.\"\"\"\n        if self._session is not None:\n            return self._session, self._tokenizer\n\n        if not HAS_ONNX or not self.onnx_path or not self.tokenizer_path:\n            return None, None\n\n        with self._onnx_lock:\n            if self._session is not None:\n                return self._session, self._tokenizer\n\n            try:\n                tok = Tokenizer.from_file(self.tokenizer_path)\n                try:\n                    tok.enable_truncation(max_length=512)\n                except Exception:\n                    pass\n\n                sess = ort.InferenceSession(\n                    self.onnx_path,\n                    providers=[\"CPUExecutionProvider\"]\n                )\n\n                self._session, self._tokenizer = sess, tok\n            except Exception:\n                self._session, self._tokenizer = None, None\n\n            return self._session, self._tokenizer\n\n    def _onnx_score(self, query: str, docs: List[str]) -> Optional[np.ndarray]:\n        \"\"\"Score query-document pairs using ONNX cross-encoder.\"\"\"\n        sess, tok = self._get_onnx_session()\n\n        if sess is None or tok is None:\n            # Fall back to parent's tiny scorer\n            return None\n\n        try:\n            pairs = [(query, doc) for doc in docs]\n            enc = tok.encode_batch(pairs)\n\n            input_ids = [e.ids for e in enc]\n            attn = [e.attention_mask for e in enc]\n            max_len = max((len(ids) for ids in input_ids), default=0)\n\n            if max_len == 0:\n                return None\n\n            # Get pad token id from tokenizer if available, else use 0\n            pad_id = 0\n            try:\n                pad_token_id = tok.token_to_id(\"[PAD]\")\n                if pad_token_id is not None:\n                    pad_id = int(pad_token_id)\n            except Exception:\n                pad_id = 0\n\n            def pad(seq, pad_val):\n                return seq + [pad_val] * (max_len - len(seq))\n\n            input_ids_padded = [pad(s, pad_id) for s in input_ids]\n            attn_padded = [pad(s, 0) for s in attn]\n\n            # Convert to numpy arrays with proper dtype (required by many ONNX models)\n            input_ids_arr = np.array(input_ids_padded, dtype=np.int64)\n            attn_arr = np.array(attn_padded, dtype=np.int64)\n\n            input_names = [i.name for i in sess.get_inputs()]\n            feeds = {}\n            if \"input_ids\" in input_names:\n                feeds[\"input_ids\"] = input_ids_arr\n            if \"attention_mask\" in input_names:\n                feeds[\"attention_mask\"] = attn_arr\n            if \"token_type_ids\" in input_names:\n                token_type_arr = np.zeros((len(input_ids_padded), max_len), dtype=np.int64)\n                feeds[\"token_type_ids\"] = token_type_arr\n\n            out = sess.run(None, feeds)\n            logits = out[0]\n\n            scores = []\n            for row in logits:\n                try:\n                    if hasattr(row, \"__len__\") and len(row) >= 2:\n                        scores.append(float(row[1]))\n                    elif hasattr(row, \"__len__\") and len(row) == 1:\n                        scores.append(float(row[0]))\n                    else:\n                        scores.append(float(row))\n                except Exception:\n                    scores.append(0.0)\n\n            return np.array(scores, dtype=np.float32)\n\n        except Exception:\n            return None\n\n    def rerank(\n        self,\n        query: str,\n        candidates: List[Dict[str, Any]],\n        initial_scores: Optional[List[float]] = None,\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Recursive reranking with ONNX cross-encoder.\n\n        Uses ONNX for scoring, but applies iterative refinement\n        through the latent state to capture cross-document relationships.\n        \"\"\"\n        if not candidates:\n            return []\n\n        # Create per-call confidence estimator for thread safety\n        confidence = ConfidenceEstimator()\n\n        # Build document texts\n        doc_texts = []\n        for c in candidates:\n            parts = []\n            if c.get(\"symbol\"):\n                parts.append(str(c[\"symbol\"]))\n            if c.get(\"path\"):\n                parts.append(str(c[\"path\"]))\n            code = c.get(\"code\") or c.get(\"snippet\") or c.get(\"text\") or \"\"\n            if code:\n                parts.append(str(code)[:400])\n            doc_texts.append(\" \".join(parts) if parts else \"empty\")\n\n        # Try ONNX scoring\n        onnx_scores = self._onnx_score(query, doc_texts)\n\n        if onnx_scores is None:\n            # Fall back to parent implementation\n            return super().rerank(query, candidates, initial_scores)\n\n        # Initialize with ONNX scores\n        scores = onnx_scores.copy()\n\n        # Encode for latent refinement\n        query_emb = self._encode([query])[0]\n        doc_embs = self._encode(doc_texts)\n        query_emb = self._project_to_dim(query_emb.reshape(1, -1))[0]\n        doc_embs = self._project_to_dim(doc_embs)\n\n        # Initialize latent state\n        z = query_emb.copy()\n\n        state = RefinementState(z=z, scores=scores, iteration=0)\n        state.score_history.append(scores.copy())\n\n        # Iterative refinement (refine latent, re-score with ONNX is too expensive)\n        # Instead, we use the latent to re-weight the ONNX scores\n        for i in range(self.n_iterations - 1):  # Already did one pass with ONNX\n            state.iteration = i + 1\n\n            # Refine latent based on current ranking\n            state.z = self.refiner.refine(\n                state.z, query_emb, doc_embs, state.scores\n            )\n\n            # Use tiny scorer with refined latent to get adjustment\n            adjustment = self.scorer.forward(query_emb, doc_embs, state.z)\n\n            # Blend ONNX scores with adjustment (adaptive alpha based on convergence)\n            try:\n                metrics = self.scorer.get_metrics()\n                if metrics.get(\"converged\", False) and metrics.get(\"avg_loss\", 1.0) < 0.3:\n                    alpha = 0.5  # Higher weight for well-trained scorer\n                elif metrics.get(\"update_count\", 0) > 100:\n                    alpha = 0.35  # Moderate weight after some training\n                else:\n                    alpha = 0.2  # Conservative weight for untrained scorer\n            except Exception:\n                alpha = 0.2  # Fallback to conservative\n            state.scores = (1 - alpha) * state.scores + alpha * adjustment\n            state.score_history.append(state.scores.copy())\n\n            if self.early_stop and confidence.should_stop(state):\n                break\n\n        # Build results\n        final_scores = state.scores\n        if initial_scores is not None and self.blend_with_initial > 0:\n            init_arr = np.array(initial_scores, dtype=np.float32)\n            # Clamp std for numerical stability\n            std = final_scores.std()\n            if std > 1e-6:\n                final_norm = (final_scores - final_scores.mean()) / std\n            else:\n                final_norm = final_scores - final_scores.mean()\n            std = init_arr.std()\n            if std > 1e-6:\n                init_norm = (init_arr - init_arr.mean()) / std\n            else:\n                init_norm = init_arr - init_arr.mean()\n            final_scores = (1 - self.blend_with_initial) * final_norm + self.blend_with_initial * init_norm\n\n        ranked_indices = np.argsort(-final_scores)\n        reranked = []\n\n        for rank, idx in enumerate(ranked_indices):\n            candidate = candidates[idx].copy()\n            candidate[\"recursive_score\"] = float(final_scores[idx])\n            candidate[\"onnx_score\"] = float(onnx_scores[idx])\n            candidate[\"recursive_rank\"] = rank\n            candidate[\"recursive_iterations\"] = state.iteration + 1\n            candidate[\"score_trajectory\"] = [float(h[idx]) for h in state.score_history]\n            candidate[\"score\"] = float(final_scores[idx])\n            reranked.append(candidate)\n\n        return reranked",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___init___2494": {
      "name": "__init__",
      "type": "method",
      "start_line": 2494,
      "end_line": 2508,
      "content_hash": "a8fbc9a342a4ab92736d79cbe8e31249846e20f7",
      "content": "    def __init__(\n        self,\n        n_iterations: int = 3,\n        onnx_path: Optional[str] = None,\n        tokenizer_path: Optional[str] = None,\n        **kwargs\n    ):\n        super().__init__(n_iterations=n_iterations, **kwargs)\n\n        self.onnx_path = onnx_path or os.environ.get(\"RERANKER_ONNX_PATH\", \"\")\n        self.tokenizer_path = tokenizer_path or os.environ.get(\"RERANKER_TOKENIZER_PATH\", \"\")\n\n        self._session = None\n        self._tokenizer = None\n        self._onnx_lock = threading.Lock()",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__get_onnx_session_2510": {
      "name": "_get_onnx_session",
      "type": "method",
      "start_line": 2510,
      "end_line": 2538,
      "content_hash": "e7490676c799917215198edc120d1a08a3322950",
      "content": "    def _get_onnx_session(self):\n        \"\"\"Load ONNX session and tokenizer.\"\"\"\n        if self._session is not None:\n            return self._session, self._tokenizer\n\n        if not HAS_ONNX or not self.onnx_path or not self.tokenizer_path:\n            return None, None\n\n        with self._onnx_lock:\n            if self._session is not None:\n                return self._session, self._tokenizer\n\n            try:\n                tok = Tokenizer.from_file(self.tokenizer_path)\n                try:\n                    tok.enable_truncation(max_length=512)\n                except Exception:\n                    pass\n\n                sess = ort.InferenceSession(\n                    self.onnx_path,\n                    providers=[\"CPUExecutionProvider\"]\n                )\n\n                self._session, self._tokenizer = sess, tok\n            except Exception:\n                self._session, self._tokenizer = None, None\n\n            return self._session, self._tokenizer",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__onnx_score_2540": {
      "name": "_onnx_score",
      "type": "method",
      "start_line": 2540,
      "end_line": 2606,
      "content_hash": "31a92f1c3bf135f23de135a58884757e7b473f2e",
      "content": "    def _onnx_score(self, query: str, docs: List[str]) -> Optional[np.ndarray]:\n        \"\"\"Score query-document pairs using ONNX cross-encoder.\"\"\"\n        sess, tok = self._get_onnx_session()\n\n        if sess is None or tok is None:\n            # Fall back to parent's tiny scorer\n            return None\n\n        try:\n            pairs = [(query, doc) for doc in docs]\n            enc = tok.encode_batch(pairs)\n\n            input_ids = [e.ids for e in enc]\n            attn = [e.attention_mask for e in enc]\n            max_len = max((len(ids) for ids in input_ids), default=0)\n\n            if max_len == 0:\n                return None\n\n            # Get pad token id from tokenizer if available, else use 0\n            pad_id = 0\n            try:\n                pad_token_id = tok.token_to_id(\"[PAD]\")\n                if pad_token_id is not None:\n                    pad_id = int(pad_token_id)\n            except Exception:\n                pad_id = 0\n\n            def pad(seq, pad_val):\n                return seq + [pad_val] * (max_len - len(seq))\n\n            input_ids_padded = [pad(s, pad_id) for s in input_ids]\n            attn_padded = [pad(s, 0) for s in attn]\n\n            # Convert to numpy arrays with proper dtype (required by many ONNX models)\n            input_ids_arr = np.array(input_ids_padded, dtype=np.int64)\n            attn_arr = np.array(attn_padded, dtype=np.int64)\n\n            input_names = [i.name for i in sess.get_inputs()]\n            feeds = {}\n            if \"input_ids\" in input_names:\n                feeds[\"input_ids\"] = input_ids_arr\n            if \"attention_mask\" in input_names:\n                feeds[\"attention_mask\"] = attn_arr\n            if \"token_type_ids\" in input_names:\n                token_type_arr = np.zeros((len(input_ids_padded), max_len), dtype=np.int64)\n                feeds[\"token_type_ids\"] = token_type_arr\n\n            out = sess.run(None, feeds)\n            logits = out[0]\n\n            scores = []\n            for row in logits:\n                try:\n                    if hasattr(row, \"__len__\") and len(row) >= 2:\n                        scores.append(float(row[1]))\n                    elif hasattr(row, \"__len__\") and len(row) == 1:\n                        scores.append(float(row[0]))\n                    else:\n                        scores.append(float(row))\n                except Exception:\n                    scores.append(0.0)\n\n            return np.array(scores, dtype=np.float32)\n\n        except Exception:\n            return None",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_pad_2568": {
      "name": "pad",
      "type": "method",
      "start_line": 2568,
      "end_line": 2569,
      "content_hash": "d22793858162f0eca252a14c6ac715eb22ccf468",
      "content": "            def pad(seq, pad_val):\n                return seq + [pad_val] * (max_len - len(seq))",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_rerank_2608": {
      "name": "rerank",
      "type": "method",
      "start_line": 2608,
      "end_line": 2721,
      "content_hash": "b685c46d274286e789eddd9bea26328869f8550d",
      "content": "    def rerank(\n        self,\n        query: str,\n        candidates: List[Dict[str, Any]],\n        initial_scores: Optional[List[float]] = None,\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Recursive reranking with ONNX cross-encoder.\n\n        Uses ONNX for scoring, but applies iterative refinement\n        through the latent state to capture cross-document relationships.\n        \"\"\"\n        if not candidates:\n            return []\n\n        # Create per-call confidence estimator for thread safety\n        confidence = ConfidenceEstimator()\n\n        # Build document texts\n        doc_texts = []\n        for c in candidates:\n            parts = []\n            if c.get(\"symbol\"):\n                parts.append(str(c[\"symbol\"]))\n            if c.get(\"path\"):\n                parts.append(str(c[\"path\"]))\n            code = c.get(\"code\") or c.get(\"snippet\") or c.get(\"text\") or \"\"\n            if code:\n                parts.append(str(code)[:400])\n            doc_texts.append(\" \".join(parts) if parts else \"empty\")\n\n        # Try ONNX scoring\n        onnx_scores = self._onnx_score(query, doc_texts)\n\n        if onnx_scores is None:\n            # Fall back to parent implementation\n            return super().rerank(query, candidates, initial_scores)\n\n        # Initialize with ONNX scores\n        scores = onnx_scores.copy()\n\n        # Encode for latent refinement\n        query_emb = self._encode([query])[0]\n        doc_embs = self._encode(doc_texts)\n        query_emb = self._project_to_dim(query_emb.reshape(1, -1))[0]\n        doc_embs = self._project_to_dim(doc_embs)\n\n        # Initialize latent state\n        z = query_emb.copy()\n\n        state = RefinementState(z=z, scores=scores, iteration=0)\n        state.score_history.append(scores.copy())\n\n        # Iterative refinement (refine latent, re-score with ONNX is too expensive)\n        # Instead, we use the latent to re-weight the ONNX scores\n        for i in range(self.n_iterations - 1):  # Already did one pass with ONNX\n            state.iteration = i + 1\n\n            # Refine latent based on current ranking\n            state.z = self.refiner.refine(\n                state.z, query_emb, doc_embs, state.scores\n            )\n\n            # Use tiny scorer with refined latent to get adjustment\n            adjustment = self.scorer.forward(query_emb, doc_embs, state.z)\n\n            # Blend ONNX scores with adjustment (adaptive alpha based on convergence)\n            try:\n                metrics = self.scorer.get_metrics()\n                if metrics.get(\"converged\", False) and metrics.get(\"avg_loss\", 1.0) < 0.3:\n                    alpha = 0.5  # Higher weight for well-trained scorer\n                elif metrics.get(\"update_count\", 0) > 100:\n                    alpha = 0.35  # Moderate weight after some training\n                else:\n                    alpha = 0.2  # Conservative weight for untrained scorer\n            except Exception:\n                alpha = 0.2  # Fallback to conservative\n            state.scores = (1 - alpha) * state.scores + alpha * adjustment\n            state.score_history.append(state.scores.copy())\n\n            if self.early_stop and confidence.should_stop(state):\n                break\n\n        # Build results\n        final_scores = state.scores\n        if initial_scores is not None and self.blend_with_initial > 0:\n            init_arr = np.array(initial_scores, dtype=np.float32)\n            # Clamp std for numerical stability\n            std = final_scores.std()\n            if std > 1e-6:\n                final_norm = (final_scores - final_scores.mean()) / std\n            else:\n                final_norm = final_scores - final_scores.mean()\n            std = init_arr.std()\n            if std > 1e-6:\n                init_norm = (init_arr - init_arr.mean()) / std\n            else:\n                init_norm = init_arr - init_arr.mean()\n            final_scores = (1 - self.blend_with_initial) * final_norm + self.blend_with_initial * init_norm\n\n        ranked_indices = np.argsort(-final_scores)\n        reranked = []\n\n        for rank, idx in enumerate(ranked_indices):\n            candidate = candidates[idx].copy()\n            candidate[\"recursive_score\"] = float(final_scores[idx])\n            candidate[\"onnx_score\"] = float(onnx_scores[idx])\n            candidate[\"recursive_rank\"] = rank\n            candidate[\"recursive_iterations\"] = state.iteration + 1\n            candidate[\"score_trajectory\"] = [float(h[idx]) for h in state.score_history]\n            candidate[\"score\"] = float(final_scores[idx])\n            reranked.append(candidate)\n\n        return reranked",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_get_recursive_reranker_2725": {
      "name": "get_recursive_reranker",
      "type": "function",
      "start_line": 2725,
      "end_line": 2738,
      "content_hash": "caf2edb1efb1e173000383ef74c807b99782f096",
      "content": "def get_recursive_reranker(n_iterations: int = 3, **kwargs) -> RecursiveReranker:\n    \"\"\"\n    Get the best available recursive reranker.\n\n    Returns ONNXRecursiveReranker if ONNX model is available,\n    otherwise falls back to TinyScorer-based reranker.\n    \"\"\"\n    onnx_path = os.environ.get(\"RERANKER_ONNX_PATH\", \"\")\n    tokenizer_path = os.environ.get(\"RERANKER_TOKENIZER_PATH\", \"\")\n\n    if HAS_ONNX and onnx_path and tokenizer_path:\n        return ONNXRecursiveReranker(n_iterations=n_iterations, **kwargs)\n    else:\n        return RecursiveReranker(n_iterations=n_iterations, **kwargs)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_SessionAwareReranker_2741": {
      "name": "SessionAwareReranker",
      "type": "class",
      "start_line": 2741,
      "end_line": 2957,
      "content_hash": "c70dcb5f0d98124978d1b2f2c0b8d373154e0cf6",
      "content": "class SessionAwareReranker:\n    \"\"\"\n    Session-aware recursive reranker with latent state carryover.\n\n    From TRM paper: carry forward latent z across queries in a session\n    to accumulate understanding of what the user is looking for.\n\n    Features:\n    - Maintains per-session latent state\n    - EMA blending with new query embeddings\n    - Automatic decay for stale sessions\n    - Thread-safe session management\n\n    Usage:\n        reranker = SessionAwareReranker()\n\n        # First query in session\n        results1 = reranker.rerank(\"search function\", candidates1, session_id=\"user_123\")\n\n        # Second query - latent carries forward\n        results2 = reranker.rerank(\"search implementation\", candidates2, session_id=\"user_123\")\n    \"\"\"\n\n    def __init__(\n        self,\n        n_iterations: int = 3,\n        dim: int = 256,\n        session_decay: float = 0.9,  # EMA decay for session latent\n        max_session_age: float = 3600.0,  # Seconds before session expires\n        max_sessions: int = 1000,  # Max sessions to keep in memory\n    ):\n        self.n_iterations = n_iterations\n        self.dim = dim\n        self.session_decay = session_decay\n        self.max_session_age = max_session_age\n        self.max_sessions = max_sessions\n\n        # Core reranker\n        self.reranker = RecursiveReranker(n_iterations=n_iterations, dim=dim)\n\n        # Session state: {session_id: (latent_z, last_access_time)}\n        self._sessions: Dict[str, tuple] = {}\n        self._session_lock = threading.Lock()\n\n    def _cleanup_old_sessions(self):\n        \"\"\"Remove expired sessions.\"\"\"\n        now = time.time()\n        expired = [\n            sid for sid, (_, last_access) in self._sessions.items()\n            if now - last_access > self.max_session_age\n        ]\n        for sid in expired:\n            del self._sessions[sid]\n\n        # If still too many, remove oldest\n        if len(self._sessions) > self.max_sessions:\n            sorted_sessions = sorted(\n                self._sessions.items(),\n                key=lambda x: x[1][1]  # Sort by last_access\n            )\n            to_remove = len(self._sessions) - self.max_sessions\n            for sid, _ in sorted_sessions[:to_remove]:\n                del self._sessions[sid]\n\n    def get_session_latent(self, session_id: str) -> Optional[np.ndarray]:\n        \"\"\"Get latent state for a session, if exists and not expired.\"\"\"\n        with self._session_lock:\n            if session_id not in self._sessions:\n                return None\n\n            latent, last_access = self._sessions[session_id]\n            if time.time() - last_access > self.max_session_age:\n                del self._sessions[session_id]\n                return None\n\n            return latent\n\n    def update_session_latent(self, session_id: str, new_latent: np.ndarray):\n        \"\"\"Update latent state for a session with EMA blending.\"\"\"\n        with self._session_lock:\n            self._cleanup_old_sessions()\n\n            if session_id in self._sessions:\n                old_latent, _ = self._sessions[session_id]\n                # EMA blend: decay * old + (1-decay) * new\n                blended = self.session_decay * old_latent + (1 - self.session_decay) * new_latent\n                # Normalize\n                blended = blended / (np.linalg.norm(blended) + 1e-8)\n                self._sessions[session_id] = (blended, time.time())\n            else:\n                self._sessions[session_id] = (new_latent.copy(), time.time())\n\n    def rerank(\n        self,\n        query: str,\n        candidates: List[Dict[str, Any]],\n        session_id: Optional[str] = None,\n        initial_scores: Optional[List[float]] = None,\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Rerank with session-aware latent carryover.\n\n        If session_id is provided:\n        1. Initialize latent from session state (if exists) blended with query\n        2. Run recursive refinement\n        3. Update session state with final latent\n\n        If no session_id, behaves like standard RecursiveReranker.\n        \"\"\"\n        if not candidates:\n            return []\n\n        # Get session latent if available\n        session_latent = None\n        if session_id:\n            session_latent = self.get_session_latent(session_id)\n\n        # Encode query\n        query_emb = self.reranker._encode([query])[0]\n        query_emb = self.reranker._project_to_dim(query_emb.reshape(1, -1))[0]\n\n        # Initialize latent: blend session state with query\n        if session_latent is not None:\n            initial_z = 0.7 * query_emb + 0.3 * session_latent\n            initial_z = initial_z / (np.linalg.norm(initial_z) + 1e-8)\n        else:\n            initial_z = query_emb.copy()\n\n        # Extract document text and encode\n        doc_texts = []\n        for c in candidates:\n            text_parts = []\n            if c.get(\"symbol\"):\n                text_parts.append(str(c[\"symbol\"]))\n            if c.get(\"path\"):\n                text_parts.append(str(c[\"path\"]))\n            code = c.get(\"code\") or c.get(\"snippet\") or c.get(\"text\") or \"\"\n            if code:\n                text_parts.append(str(code)[:500])\n            doc_texts.append(\" \".join(text_parts) if text_parts else \"empty\")\n\n        doc_embs = self.reranker._encode(doc_texts)\n        doc_embs = self.reranker._project_to_dim(doc_embs)\n\n        # Get initial scores\n        if initial_scores is None:\n            initial_scores = [c.get(\"score\", 0.0) for c in candidates]\n\n        # Create refinement state with session-initialized latent\n        state = RefinementState(z=initial_z, scores=np.array(initial_scores, dtype=np.float32))\n        state.score_history.append(state.scores.copy())\n\n        # Iterative refinement loop\n        for i in range(self.n_iterations):\n            state.iteration = i + 1\n\n            # Score using current latent state\n            new_scores = self.reranker.scorer.forward(query_emb, doc_embs, state.z)\n\n            # Blend with previous scores\n            alpha = 0.5\n            state.scores = alpha * new_scores + (1 - alpha) * state.scores\n            state.score_history.append(state.scores.copy())\n\n            # Refine latent state\n            state.z = self.reranker.refiner.refine(state.z, query_emb, doc_embs, state.scores)\n\n            # Check for early stopping\n            if self.reranker.early_stop and self.reranker.confidence.should_stop(state):\n                break\n\n        # Update session state with final latent\n        if session_id:\n            self.update_session_latent(session_id, state.z)\n\n        # Build reranked results\n        final_scores = state.scores\n        if self.reranker.blend_with_initial > 0:\n            init_arr = np.array(initial_scores, dtype=np.float32)\n            # Clamp std for numerical stability\n            std = final_scores.std()\n            if std > 1e-6:\n                final_norm = (final_scores - final_scores.mean()) / std\n            else:\n                final_norm = final_scores - final_scores.mean()\n            std = init_arr.std()\n            if std > 1e-6:\n                init_norm = (init_arr - init_arr.mean()) / std\n            else:\n                init_norm = init_arr - init_arr.mean()\n            final_scores = (1 - self.reranker.blend_with_initial) * final_norm + self.reranker.blend_with_initial * init_norm\n\n        ranked_indices = np.argsort(-final_scores)\n        reranked = []\n\n        for rank, idx in enumerate(ranked_indices):\n            candidate = candidates[idx].copy()\n            candidate[\"recursive_score\"] = float(final_scores[idx])\n            candidate[\"recursive_rank\"] = rank\n            candidate[\"recursive_iterations\"] = state.iteration\n            candidate[\"session_aware\"] = session_id is not None\n            candidate[\"score_trajectory\"] = [float(h[idx]) for h in state.score_history]\n            candidate[\"score\"] = float(final_scores[idx])\n            reranked.append(candidate)\n\n        return reranked\n\n    def clear_session(self, session_id: str):\n        \"\"\"Clear latent state for a session.\"\"\"\n        with self._session_lock:\n            if session_id in self._sessions:\n                del self._sessions[session_id]\n\n    def get_session_count(self) -> int:\n        \"\"\"Get number of active sessions.\"\"\"\n        with self._session_lock:\n            return len(self._sessions)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___init___2764": {
      "name": "__init__",
      "type": "method",
      "start_line": 2764,
      "end_line": 2783,
      "content_hash": "9123d20c6e67e9089c277b86d29af535ded17375",
      "content": "    def __init__(\n        self,\n        n_iterations: int = 3,\n        dim: int = 256,\n        session_decay: float = 0.9,  # EMA decay for session latent\n        max_session_age: float = 3600.0,  # Seconds before session expires\n        max_sessions: int = 1000,  # Max sessions to keep in memory\n    ):\n        self.n_iterations = n_iterations\n        self.dim = dim\n        self.session_decay = session_decay\n        self.max_session_age = max_session_age\n        self.max_sessions = max_sessions\n\n        # Core reranker\n        self.reranker = RecursiveReranker(n_iterations=n_iterations, dim=dim)\n\n        # Session state: {session_id: (latent_z, last_access_time)}\n        self._sessions: Dict[str, tuple] = {}\n        self._session_lock = threading.Lock()",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__cleanup_old_sessions_2785": {
      "name": "_cleanup_old_sessions",
      "type": "method",
      "start_line": 2785,
      "end_line": 2803,
      "content_hash": "6b337fd0fd4c4870b728fddd112149a42ff6cbe8",
      "content": "    def _cleanup_old_sessions(self):\n        \"\"\"Remove expired sessions.\"\"\"\n        now = time.time()\n        expired = [\n            sid for sid, (_, last_access) in self._sessions.items()\n            if now - last_access > self.max_session_age\n        ]\n        for sid in expired:\n            del self._sessions[sid]\n\n        # If still too many, remove oldest\n        if len(self._sessions) > self.max_sessions:\n            sorted_sessions = sorted(\n                self._sessions.items(),\n                key=lambda x: x[1][1]  # Sort by last_access\n            )\n            to_remove = len(self._sessions) - self.max_sessions\n            for sid, _ in sorted_sessions[:to_remove]:\n                del self._sessions[sid]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_get_session_latent_2805": {
      "name": "get_session_latent",
      "type": "method",
      "start_line": 2805,
      "end_line": 2816,
      "content_hash": "75d8780188328cc48ae57a888bc60906fb23d5b1",
      "content": "    def get_session_latent(self, session_id: str) -> Optional[np.ndarray]:\n        \"\"\"Get latent state for a session, if exists and not expired.\"\"\"\n        with self._session_lock:\n            if session_id not in self._sessions:\n                return None\n\n            latent, last_access = self._sessions[session_id]\n            if time.time() - last_access > self.max_session_age:\n                del self._sessions[session_id]\n                return None\n\n            return latent",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_update_session_latent_2818": {
      "name": "update_session_latent",
      "type": "method",
      "start_line": 2818,
      "end_line": 2831,
      "content_hash": "980ac1734e9aaa785d12668587919d27ff2dbb7e",
      "content": "    def update_session_latent(self, session_id: str, new_latent: np.ndarray):\n        \"\"\"Update latent state for a session with EMA blending.\"\"\"\n        with self._session_lock:\n            self._cleanup_old_sessions()\n\n            if session_id in self._sessions:\n                old_latent, _ = self._sessions[session_id]\n                # EMA blend: decay * old + (1-decay) * new\n                blended = self.session_decay * old_latent + (1 - self.session_decay) * new_latent\n                # Normalize\n                blended = blended / (np.linalg.norm(blended) + 1e-8)\n                self._sessions[session_id] = (blended, time.time())\n            else:\n                self._sessions[session_id] = (new_latent.copy(), time.time())",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_rerank_2833": {
      "name": "rerank",
      "type": "method",
      "start_line": 2833,
      "end_line": 2946,
      "content_hash": "a434b63a180057eda6b216f19aab0905522b87df",
      "content": "    def rerank(\n        self,\n        query: str,\n        candidates: List[Dict[str, Any]],\n        session_id: Optional[str] = None,\n        initial_scores: Optional[List[float]] = None,\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Rerank with session-aware latent carryover.\n\n        If session_id is provided:\n        1. Initialize latent from session state (if exists) blended with query\n        2. Run recursive refinement\n        3. Update session state with final latent\n\n        If no session_id, behaves like standard RecursiveReranker.\n        \"\"\"\n        if not candidates:\n            return []\n\n        # Get session latent if available\n        session_latent = None\n        if session_id:\n            session_latent = self.get_session_latent(session_id)\n\n        # Encode query\n        query_emb = self.reranker._encode([query])[0]\n        query_emb = self.reranker._project_to_dim(query_emb.reshape(1, -1))[0]\n\n        # Initialize latent: blend session state with query\n        if session_latent is not None:\n            initial_z = 0.7 * query_emb + 0.3 * session_latent\n            initial_z = initial_z / (np.linalg.norm(initial_z) + 1e-8)\n        else:\n            initial_z = query_emb.copy()\n\n        # Extract document text and encode\n        doc_texts = []\n        for c in candidates:\n            text_parts = []\n            if c.get(\"symbol\"):\n                text_parts.append(str(c[\"symbol\"]))\n            if c.get(\"path\"):\n                text_parts.append(str(c[\"path\"]))\n            code = c.get(\"code\") or c.get(\"snippet\") or c.get(\"text\") or \"\"\n            if code:\n                text_parts.append(str(code)[:500])\n            doc_texts.append(\" \".join(text_parts) if text_parts else \"empty\")\n\n        doc_embs = self.reranker._encode(doc_texts)\n        doc_embs = self.reranker._project_to_dim(doc_embs)\n\n        # Get initial scores\n        if initial_scores is None:\n            initial_scores = [c.get(\"score\", 0.0) for c in candidates]\n\n        # Create refinement state with session-initialized latent\n        state = RefinementState(z=initial_z, scores=np.array(initial_scores, dtype=np.float32))\n        state.score_history.append(state.scores.copy())\n\n        # Iterative refinement loop\n        for i in range(self.n_iterations):\n            state.iteration = i + 1\n\n            # Score using current latent state\n            new_scores = self.reranker.scorer.forward(query_emb, doc_embs, state.z)\n\n            # Blend with previous scores\n            alpha = 0.5\n            state.scores = alpha * new_scores + (1 - alpha) * state.scores\n            state.score_history.append(state.scores.copy())\n\n            # Refine latent state\n            state.z = self.reranker.refiner.refine(state.z, query_emb, doc_embs, state.scores)\n\n            # Check for early stopping\n            if self.reranker.early_stop and self.reranker.confidence.should_stop(state):\n                break\n\n        # Update session state with final latent\n        if session_id:\n            self.update_session_latent(session_id, state.z)\n\n        # Build reranked results\n        final_scores = state.scores\n        if self.reranker.blend_with_initial > 0:\n            init_arr = np.array(initial_scores, dtype=np.float32)\n            # Clamp std for numerical stability\n            std = final_scores.std()\n            if std > 1e-6:\n                final_norm = (final_scores - final_scores.mean()) / std\n            else:\n                final_norm = final_scores - final_scores.mean()\n            std = init_arr.std()\n            if std > 1e-6:\n                init_norm = (init_arr - init_arr.mean()) / std\n            else:\n                init_norm = init_arr - init_arr.mean()\n            final_scores = (1 - self.reranker.blend_with_initial) * final_norm + self.reranker.blend_with_initial * init_norm\n\n        ranked_indices = np.argsort(-final_scores)\n        reranked = []\n\n        for rank, idx in enumerate(ranked_indices):\n            candidate = candidates[idx].copy()\n            candidate[\"recursive_score\"] = float(final_scores[idx])\n            candidate[\"recursive_rank\"] = rank\n            candidate[\"recursive_iterations\"] = state.iteration\n            candidate[\"session_aware\"] = session_id is not None\n            candidate[\"score_trajectory\"] = [float(h[idx]) for h in state.score_history]\n            candidate[\"score\"] = float(final_scores[idx])\n            reranked.append(candidate)\n\n        return reranked",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_clear_session_2948": {
      "name": "clear_session",
      "type": "method",
      "start_line": 2948,
      "end_line": 2952,
      "content_hash": "d57445e4c918f5db14885807acccfdf001224ec0",
      "content": "    def clear_session(self, session_id: str):\n        \"\"\"Clear latent state for a session.\"\"\"\n        with self._session_lock:\n            if session_id in self._sessions:\n                del self._sessions[session_id]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_get_session_count_2954": {
      "name": "get_session_count",
      "type": "method",
      "start_line": 2954,
      "end_line": 2957,
      "content_hash": "f8a70fa3fa9f13a9f5a1eab4b08647b8243e0948",
      "content": "    def get_session_count(self) -> int:\n        \"\"\"Get number of active sessions.\"\"\"\n        with self._session_lock:\n            return len(self._sessions)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_rerank_with_session_2961": {
      "name": "rerank_with_session",
      "type": "function",
      "start_line": 2961,
      "end_line": 2974,
      "content_hash": "1dd71ca9d4fbe60354609dec99106e30b9f399ce",
      "content": "def rerank_with_session(\n    query: str,\n    candidates: List[Dict[str, Any]],\n    session_id: str,\n    n_iterations: int = 3,\n) -> List[Dict[str, Any]]:\n    \"\"\"\n    Session-aware reranking (stateless convenience wrapper).\n\n    Note: For efficiency, use SessionAwareReranker directly to maintain\n    a single instance across requests.\n    \"\"\"\n    reranker = SessionAwareReranker(n_iterations=n_iterations)\n    return reranker.rerank(query, candidates, session_id=session_id)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}