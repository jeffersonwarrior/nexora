{
  "file_path": "/work/context-engine/scripts/mcp_router/batching.py",
  "file_hash": "1f7166c4800d52704ca13ec997e04b1523ccd48b",
  "updated_at": "2025-12-26T17:34:20.439143",
  "symbols": {
    "class_BatchingContextAnswerClient_18": {
      "name": "BatchingContextAnswerClient",
      "type": "class",
      "start_line": 18,
      "end_line": 319,
      "content_hash": "1933d92483bed24a879d1289ca48834523f299b9",
      "content": "class BatchingContextAnswerClient:\n    \"\"\"Lightweight in-memory batching for context_answer calls.\n\n    - Queues short-lived requests keyed by (base_url, collection, filters_fingerprint)\n    - Flushes after a small window or when batch size cap is hit\n    - For multi-item batches, sends query=[...] with mode=\"pack\"\n    - Shares the same response with all enqueued requests\n    \"\"\"\n\n    def __init__(self, call_func=None, enable: bool | None = None, window_ms: int | None = None,\n                 max_batch: int | None = None, budget_ms: int | None = None):\n        self._call = call_func or call_tool_http\n        if enable is None:\n            env_enabled = os.environ.get(\"ROUTER_BATCH_ENABLED\")\n            if env_enabled is None:\n                env_enabled = os.environ.get(\"ROUTER_BATCH_ENABLE\", \"0\")\n            self.enabled = str(env_enabled).strip().lower() in {\"1\", \"true\", \"yes\", \"on\"}\n        else:\n            self.enabled = bool(enable)\n        self.window_ms = int(os.environ.get(\"ROUTER_BATCH_WINDOW_MS\", str(window_ms if window_ms is not None else 100)) or 100)\n        env_max = os.environ.get(\"ROUTER_BATCH_MAX_SIZE\")\n        if env_max is None:\n            env_max = os.environ.get(\"ROUTER_BATCH_MAX\")\n        self.max_batch = int(env_max or (max_batch if max_batch is not None else 8))\n        env_budget = os.environ.get(\"ROUTER_BATCH_LATENCY_BUDGET_MS\")\n        if env_budget is None:\n            env_budget = os.environ.get(\"ROUTER_BATCH_BUDGET_MS\")\n        self.budget_ms = int(env_budget or (budget_ms if budget_ms is not None else 2000))\n        self._lock = threading.RLock()\n        self._groups: dict[str, dict[str, Any]] = {}\n\n    def _should_bypass(self, args: Dict[str, Any]) -> bool:\n        try:\n            if isinstance(args, dict):\n                v = args.get(\"immediate\")\n                if v is not None and str(v).strip().lower() in {\"1\", \"true\", \"yes\", \"on\"}:\n                    return True\n        except Exception:\n            pass\n        if str(os.environ.get(\"ROUTER_BATCH_BYPASS\", \"0\")).strip().lower() in {\"1\", \"true\", \"yes\", \"on\"}:\n            return True\n        try:\n            q = str((args or {}).get(\"query\") or \"\")\n            if \"immediate answer\" in q.lower():\n                return True\n        except Exception:\n            pass\n        return False\n\n    def _norm_query(self, q: str) -> str:\n        try:\n            return re.sub(r\"\\s+\", \" \", str(q or \"\").strip())\n        except Exception:\n            return str(q)\n\n    def _filters_fingerprint(self, args: Dict[str, Any]) -> str:\n        keep = {\n            \"collection\", \"language\", \"under\", \"kind\", \"symbol\", \"ext\",\n            \"path_regex\", \"path_glob\", \"not_glob\", \"not_\", \"case\",\n            \"limit\", \"per_path\", \"include_snippet\",\n        }\n        try:\n            filt = {k: args.get(k) for k in keep if k in args}\n            def _norm(v):\n                if v is None:\n                    return None\n                if isinstance(v, (list, tuple)):\n                    return [str(x) for x in v]\n                return v\n            clean = {k: _norm(v) for k, v in filt.items()}\n            return json.dumps(clean, sort_keys=True, ensure_ascii=False)\n        except Exception:\n            return \"{}\"\n\n    def _group_key(self, base_url: str, args: Dict[str, Any]) -> str:\n        coll = str(args.get(\"collection\") or \"\")\n        fp = self._filters_fingerprint(args)\n        repo = os.getcwd()\n        return f\"{base_url}|{coll}|answer|{fp}|{repo}\"\n\n    def call_or_enqueue(self, base_url: str, tool: str, args: Dict[str, Any], timeout: float = 120.0) -> Dict[str, Any]:\n        if not self.enabled:\n            return self._call(base_url, tool, args, timeout=timeout)\n        if self._should_bypass(args):\n            return self._call(base_url, tool, args, timeout=timeout)\n\n        start_ts = time.time()\n        key = self._group_key(base_url, args or {})\n        norm_q = self._norm_query((args or {}).get(\"query\") or \"\")\n        ev = threading.Event()\n        slot = {\"event\": ev, \"result\": None, \"error\": None, \"query\": norm_q, \"args\": dict(args or {})}\n\n        with self._lock:\n            g = self._groups.get(key)\n            if not g:\n                g = {\n                    \"created\": time.time(),\n                    \"items\": [],\n                    \"timer\": None,\n                }\n                self._groups[key] = g\n            g[\"items\"].append(slot)\n            if g[\"timer\"] is None:\n                delay = max(0.0, float(self.window_ms) / 1000.0)\n                t = threading.Timer(delay, self._flush, args=(key,))\n                g[\"timer\"] = t\n                t.daemon = True\n                t.start()\n            if len(g[\"items\"]) >= self.max_batch:\n                t = g.get(\"timer\")\n                if t:\n                    try:\n                        t.cancel()\n                    except Exception:\n                        pass\n                    g[\"timer\"] = None\n                threading.Thread(target=self._flush, args=(key,), daemon=True).start()\n\n        remain = max(0.05, self.budget_ms / 1000.0)\n        ev.wait(timeout=min(timeout, remain))\n        if not ev.is_set():\n            try:\n                res = self._call(base_url, tool, args, timeout=timeout)\n                slot[\"result\"] = res\n                ev.set()\n                try:\n                    with self._lock:\n                        gg = self._groups.get(key)\n                        if gg:\n                            lst = gg.get(\"items\") or []\n                            if slot in lst:\n                                try:\n                                    lst.remove(slot)\n                                except Exception:\n                                    pass\n                            if not lst:\n                                t2 = gg.get(\"timer\")\n                                if t2:\n                                    try:\n                                        t2.cancel()\n                                    except Exception:\n                                        pass\n                                self._groups.pop(key, None)\n                except Exception:\n                    pass\n                try:\n                    print(json.dumps({\"router\": {\"batch_fallback\": True, \"elapsed_ms\": int((time.time()-start_ts)*1000)}}), file=sys.stderr)\n                except Exception:\n                    pass\n                return res\n            except Exception as e:\n                slot[\"error\"] = e\n                ev.set()\n                raise\n\n        if slot.get(\"error\") is not None:\n            raise slot[\"error\"]\n        return slot.get(\"result\") or {}\n\n    def _flush(self, key: str) -> None:\n        with self._lock:\n            g = self._groups.get(key)\n            if not g:\n                return\n            items = g.get(\"items\") or []\n            g[\"items\"] = []\n            g[\"timer\"] = None\n            if not items:\n                self._groups.pop(key, None)\n                return\n\n        unique_q: list[str] = []\n        seen_q = set()\n        for it in items:\n            q = it.get(\"query\") or \"\"\n            if q not in seen_q:\n                seen_q.add(q)\n                unique_q.append(q)\n        first_args = dict(items[0].get(\"args\") or {})\n        forward = {k: v for k, v in first_args.items() if k not in {\"query\", \"queries\"}}\n        base_url = None\n        try:\n            base_url = key.split(\"|\")[0]\n        except Exception:\n            base_url = HTTP_URL_INDEXER\n\n        started = time.time()\n        results_by_q: Dict[str, Any] = {}\n        errors_by_q: Dict[str, Exception] = {}\n        calls = 0\n        try:\n            import copy as _copy\n        except Exception:\n            _copy = None\n\n        if len(unique_q) > 1:\n            args_all = dict(forward)\n            args_all[\"query\"] = list(unique_q)\n            args_all[\"mode\"] = args_all.get(\"mode\") or \"pack\"\n            try:\n                agg_res = self._call(base_url, \"context_answer\", args_all, timeout=120.0)\n                calls = 1\n                try:\n                    payload = ((agg_res or {}).get(\"result\") or {}).get(\"structuredContent\") or {}\n                    body = (payload.get(\"result\") or {})\n                except Exception:\n                    payload, body = {}, {}\n\n                abq = None\n                try:\n                    abq = body.get(\"answers_by_query\")\n                except Exception:\n                    abq = None\n                if isinstance(abq, list) and abq:\n                    _map: Dict[str, Any] = {}\n                    by_idx = (len(abq) >= len(unique_q))\n                    for i, entry in enumerate(abq):\n                        try:\n                            qv = entry.get(\"query\")\n                            qk = None\n                            if isinstance(qv, list) and qv:\n                                qk = str(qv[0])\n                            elif isinstance(qv, str):\n                                qk = qv\n                        except Exception:\n                            qk = None\n                        entry_key = qk if qk else (unique_q[i] if by_idx and i < len(unique_q) else None)\n                        if not entry_key:\n                            continue\n                        per = _copy.deepcopy(agg_res) if _copy else json.loads(json.dumps(agg_res))\n                        try:\n                            per_body = (per.get(\"result\") or {}).get(\"structuredContent\", {}).get(\"result\", {})\n                        except Exception:\n                            per_body = None\n                        try:\n                            ans_i = str(entry.get(\"answer\") or \"\")\n                            cits_i = entry.get(\"citations\") or []\n                            if per_body is not None:\n                                per_body[\"answer\"] = ans_i\n                                per_body[\"citations\"] = cits_i\n                                per_body[\"query\"] = [entry_key]\n                        except Exception:\n                            pass\n                        _map[str(entry_key)] = per\n                    for uq in unique_q:\n                        if str(uq) in _map:\n                            results_by_q[uq] = _map[str(uq)]\n                    remaining = [uq for uq in unique_q if uq not in results_by_q]\n                else:\n                    remaining = list(unique_q)\n\n                if remaining:\n                    for uq in remaining:\n                        args_i = dict(forward)\n                        args_i[\"query\"] = uq\n                        try:\n                            results_by_q[uq] = self._call(base_url, \"context_answer\", args_i, timeout=120.0)\n                        except Exception as e:\n                            errors_by_q[uq] = e\n                    calls += len(remaining)\n            except Exception as e:\n                for uq in unique_q:\n                    errors_by_q[uq] = e\n                calls = 1\n        else:\n            args1 = dict(forward)\n            args1[\"query\"] = unique_q[0] if unique_q else \"\"\n            try:\n                results_by_q[args1[\"query\"]] = self._call(base_url, \"context_answer\", args1, timeout=120.0)\n            except Exception as e:\n                errors_by_q[args1[\"query\"]] = e\n            calls = 1\n\n        elapsed_ms = int((time.time() - started) * 1000)\n        try:\n            print(json.dumps({\n                \"router\": {\n                    \"batch_flushed\": True,\n                    \"n_items\": len(items),\n                    \"unique_q\": len(unique_q),\n                    \"calls\": int(calls),\n                    \"elapsed_ms\": elapsed_ms,\n                    \"ok\": (len(errors_by_q) == 0),\n                }\n            }), file=sys.stderr)\n        except Exception:\n            pass\n\n        for it in items:\n            q = it.get(\"query\") or \"\"\n            it[\"result\"] = results_by_q.get(q)\n            it[\"error\"] = errors_by_q.get(q)\n            ev = it.get(\"event\")\n            try:\n                if hasattr(ev, \"set\"):\n                    ev.set()\n            except Exception:\n                pass\n        with self._lock:\n            gg = self._groups.get(key)\n            if gg and not gg.get(\"items\"):\n                self._groups.pop(key, None)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___init___27": {
      "name": "__init__",
      "type": "method",
      "start_line": 27,
      "end_line": 47,
      "content_hash": "b3021ec00bc8923ce3c40c5d6208168f5820de04",
      "content": "    def __init__(self, call_func=None, enable: bool | None = None, window_ms: int | None = None,\n                 max_batch: int | None = None, budget_ms: int | None = None):\n        self._call = call_func or call_tool_http\n        if enable is None:\n            env_enabled = os.environ.get(\"ROUTER_BATCH_ENABLED\")\n            if env_enabled is None:\n                env_enabled = os.environ.get(\"ROUTER_BATCH_ENABLE\", \"0\")\n            self.enabled = str(env_enabled).strip().lower() in {\"1\", \"true\", \"yes\", \"on\"}\n        else:\n            self.enabled = bool(enable)\n        self.window_ms = int(os.environ.get(\"ROUTER_BATCH_WINDOW_MS\", str(window_ms if window_ms is not None else 100)) or 100)\n        env_max = os.environ.get(\"ROUTER_BATCH_MAX_SIZE\")\n        if env_max is None:\n            env_max = os.environ.get(\"ROUTER_BATCH_MAX\")\n        self.max_batch = int(env_max or (max_batch if max_batch is not None else 8))\n        env_budget = os.environ.get(\"ROUTER_BATCH_LATENCY_BUDGET_MS\")\n        if env_budget is None:\n            env_budget = os.environ.get(\"ROUTER_BATCH_BUDGET_MS\")\n        self.budget_ms = int(env_budget or (budget_ms if budget_ms is not None else 2000))\n        self._lock = threading.RLock()\n        self._groups: dict[str, dict[str, Any]] = {}",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__should_bypass_49": {
      "name": "_should_bypass",
      "type": "method",
      "start_line": 49,
      "end_line": 65,
      "content_hash": "e3a4f8cac415d7a2fd6f4de78a5f91104298275b",
      "content": "    def _should_bypass(self, args: Dict[str, Any]) -> bool:\n        try:\n            if isinstance(args, dict):\n                v = args.get(\"immediate\")\n                if v is not None and str(v).strip().lower() in {\"1\", \"true\", \"yes\", \"on\"}:\n                    return True\n        except Exception:\n            pass\n        if str(os.environ.get(\"ROUTER_BATCH_BYPASS\", \"0\")).strip().lower() in {\"1\", \"true\", \"yes\", \"on\"}:\n            return True\n        try:\n            q = str((args or {}).get(\"query\") or \"\")\n            if \"immediate answer\" in q.lower():\n                return True\n        except Exception:\n            pass\n        return False",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__norm_query_67": {
      "name": "_norm_query",
      "type": "method",
      "start_line": 67,
      "end_line": 71,
      "content_hash": "18e447036569484376d52c8207c2bc874243b59e",
      "content": "    def _norm_query(self, q: str) -> str:\n        try:\n            return re.sub(r\"\\s+\", \" \", str(q or \"\").strip())\n        except Exception:\n            return str(q)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__filters_fingerprint_73": {
      "name": "_filters_fingerprint",
      "type": "method",
      "start_line": 73,
      "end_line": 90,
      "content_hash": "450f10ff4d8db24db81753d7d872fb5b35516bbf",
      "content": "    def _filters_fingerprint(self, args: Dict[str, Any]) -> str:\n        keep = {\n            \"collection\", \"language\", \"under\", \"kind\", \"symbol\", \"ext\",\n            \"path_regex\", \"path_glob\", \"not_glob\", \"not_\", \"case\",\n            \"limit\", \"per_path\", \"include_snippet\",\n        }\n        try:\n            filt = {k: args.get(k) for k in keep if k in args}\n            def _norm(v):\n                if v is None:\n                    return None\n                if isinstance(v, (list, tuple)):\n                    return [str(x) for x in v]\n                return v\n            clean = {k: _norm(v) for k, v in filt.items()}\n            return json.dumps(clean, sort_keys=True, ensure_ascii=False)\n        except Exception:\n            return \"{}\"",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__norm_81": {
      "name": "_norm",
      "type": "method",
      "start_line": 81,
      "end_line": 86,
      "content_hash": "5774ae3c1f6d1ff819a800e129e36ecf22eef7ae",
      "content": "            def _norm(v):\n                if v is None:\n                    return None\n                if isinstance(v, (list, tuple)):\n                    return [str(x) for x in v]\n                return v",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__group_key_92": {
      "name": "_group_key",
      "type": "method",
      "start_line": 92,
      "end_line": 96,
      "content_hash": "b1f8ab04266c15b2ec9ee4135539a1b23c462b9c",
      "content": "    def _group_key(self, base_url: str, args: Dict[str, Any]) -> str:\n        coll = str(args.get(\"collection\") or \"\")\n        fp = self._filters_fingerprint(args)\n        repo = os.getcwd()\n        return f\"{base_url}|{coll}|answer|{fp}|{repo}\"",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_call_or_enqueue_98": {
      "name": "call_or_enqueue",
      "type": "method",
      "start_line": 98,
      "end_line": 175,
      "content_hash": "313b1e2f946b0a5b074a2645ad14c0b46655216c",
      "content": "    def call_or_enqueue(self, base_url: str, tool: str, args: Dict[str, Any], timeout: float = 120.0) -> Dict[str, Any]:\n        if not self.enabled:\n            return self._call(base_url, tool, args, timeout=timeout)\n        if self._should_bypass(args):\n            return self._call(base_url, tool, args, timeout=timeout)\n\n        start_ts = time.time()\n        key = self._group_key(base_url, args or {})\n        norm_q = self._norm_query((args or {}).get(\"query\") or \"\")\n        ev = threading.Event()\n        slot = {\"event\": ev, \"result\": None, \"error\": None, \"query\": norm_q, \"args\": dict(args or {})}\n\n        with self._lock:\n            g = self._groups.get(key)\n            if not g:\n                g = {\n                    \"created\": time.time(),\n                    \"items\": [],\n                    \"timer\": None,\n                }\n                self._groups[key] = g\n            g[\"items\"].append(slot)\n            if g[\"timer\"] is None:\n                delay = max(0.0, float(self.window_ms) / 1000.0)\n                t = threading.Timer(delay, self._flush, args=(key,))\n                g[\"timer\"] = t\n                t.daemon = True\n                t.start()\n            if len(g[\"items\"]) >= self.max_batch:\n                t = g.get(\"timer\")\n                if t:\n                    try:\n                        t.cancel()\n                    except Exception:\n                        pass\n                    g[\"timer\"] = None\n                threading.Thread(target=self._flush, args=(key,), daemon=True).start()\n\n        remain = max(0.05, self.budget_ms / 1000.0)\n        ev.wait(timeout=min(timeout, remain))\n        if not ev.is_set():\n            try:\n                res = self._call(base_url, tool, args, timeout=timeout)\n                slot[\"result\"] = res\n                ev.set()\n                try:\n                    with self._lock:\n                        gg = self._groups.get(key)\n                        if gg:\n                            lst = gg.get(\"items\") or []\n                            if slot in lst:\n                                try:\n                                    lst.remove(slot)\n                                except Exception:\n                                    pass\n                            if not lst:\n                                t2 = gg.get(\"timer\")\n                                if t2:\n                                    try:\n                                        t2.cancel()\n                                    except Exception:\n                                        pass\n                                self._groups.pop(key, None)\n                except Exception:\n                    pass\n                try:\n                    print(json.dumps({\"router\": {\"batch_fallback\": True, \"elapsed_ms\": int((time.time()-start_ts)*1000)}}), file=sys.stderr)\n                except Exception:\n                    pass\n                return res\n            except Exception as e:\n                slot[\"error\"] = e\n                ev.set()\n                raise\n\n        if slot.get(\"error\") is not None:\n            raise slot[\"error\"]\n        return slot.get(\"result\") or {}",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__flush_177": {
      "name": "_flush",
      "type": "method",
      "start_line": 177,
      "end_line": 319,
      "content_hash": "248140779dd08425729ffad55654f106ef7d6ae4",
      "content": "    def _flush(self, key: str) -> None:\n        with self._lock:\n            g = self._groups.get(key)\n            if not g:\n                return\n            items = g.get(\"items\") or []\n            g[\"items\"] = []\n            g[\"timer\"] = None\n            if not items:\n                self._groups.pop(key, None)\n                return\n\n        unique_q: list[str] = []\n        seen_q = set()\n        for it in items:\n            q = it.get(\"query\") or \"\"\n            if q not in seen_q:\n                seen_q.add(q)\n                unique_q.append(q)\n        first_args = dict(items[0].get(\"args\") or {})\n        forward = {k: v for k, v in first_args.items() if k not in {\"query\", \"queries\"}}\n        base_url = None\n        try:\n            base_url = key.split(\"|\")[0]\n        except Exception:\n            base_url = HTTP_URL_INDEXER\n\n        started = time.time()\n        results_by_q: Dict[str, Any] = {}\n        errors_by_q: Dict[str, Exception] = {}\n        calls = 0\n        try:\n            import copy as _copy\n        except Exception:\n            _copy = None\n\n        if len(unique_q) > 1:\n            args_all = dict(forward)\n            args_all[\"query\"] = list(unique_q)\n            args_all[\"mode\"] = args_all.get(\"mode\") or \"pack\"\n            try:\n                agg_res = self._call(base_url, \"context_answer\", args_all, timeout=120.0)\n                calls = 1\n                try:\n                    payload = ((agg_res or {}).get(\"result\") or {}).get(\"structuredContent\") or {}\n                    body = (payload.get(\"result\") or {})\n                except Exception:\n                    payload, body = {}, {}\n\n                abq = None\n                try:\n                    abq = body.get(\"answers_by_query\")\n                except Exception:\n                    abq = None\n                if isinstance(abq, list) and abq:\n                    _map: Dict[str, Any] = {}\n                    by_idx = (len(abq) >= len(unique_q))\n                    for i, entry in enumerate(abq):\n                        try:\n                            qv = entry.get(\"query\")\n                            qk = None\n                            if isinstance(qv, list) and qv:\n                                qk = str(qv[0])\n                            elif isinstance(qv, str):\n                                qk = qv\n                        except Exception:\n                            qk = None\n                        entry_key = qk if qk else (unique_q[i] if by_idx and i < len(unique_q) else None)\n                        if not entry_key:\n                            continue\n                        per = _copy.deepcopy(agg_res) if _copy else json.loads(json.dumps(agg_res))\n                        try:\n                            per_body = (per.get(\"result\") or {}).get(\"structuredContent\", {}).get(\"result\", {})\n                        except Exception:\n                            per_body = None\n                        try:\n                            ans_i = str(entry.get(\"answer\") or \"\")\n                            cits_i = entry.get(\"citations\") or []\n                            if per_body is not None:\n                                per_body[\"answer\"] = ans_i\n                                per_body[\"citations\"] = cits_i\n                                per_body[\"query\"] = [entry_key]\n                        except Exception:\n                            pass\n                        _map[str(entry_key)] = per\n                    for uq in unique_q:\n                        if str(uq) in _map:\n                            results_by_q[uq] = _map[str(uq)]\n                    remaining = [uq for uq in unique_q if uq not in results_by_q]\n                else:\n                    remaining = list(unique_q)\n\n                if remaining:\n                    for uq in remaining:\n                        args_i = dict(forward)\n                        args_i[\"query\"] = uq\n                        try:\n                            results_by_q[uq] = self._call(base_url, \"context_answer\", args_i, timeout=120.0)\n                        except Exception as e:\n                            errors_by_q[uq] = e\n                    calls += len(remaining)\n            except Exception as e:\n                for uq in unique_q:\n                    errors_by_q[uq] = e\n                calls = 1\n        else:\n            args1 = dict(forward)\n            args1[\"query\"] = unique_q[0] if unique_q else \"\"\n            try:\n                results_by_q[args1[\"query\"]] = self._call(base_url, \"context_answer\", args1, timeout=120.0)\n            except Exception as e:\n                errors_by_q[args1[\"query\"]] = e\n            calls = 1\n\n        elapsed_ms = int((time.time() - started) * 1000)\n        try:\n            print(json.dumps({\n                \"router\": {\n                    \"batch_flushed\": True,\n                    \"n_items\": len(items),\n                    \"unique_q\": len(unique_q),\n                    \"calls\": int(calls),\n                    \"elapsed_ms\": elapsed_ms,\n                    \"ok\": (len(errors_by_q) == 0),\n                }\n            }), file=sys.stderr)\n        except Exception:\n            pass\n\n        for it in items:\n            q = it.get(\"query\") or \"\"\n            it[\"result\"] = results_by_q.get(q)\n            it[\"error\"] = errors_by_q.get(q)\n            ev = it.get(\"event\")\n            try:\n                if hasattr(ev, \"set\"):\n                    ev.set()\n            except Exception:\n                pass\n        with self._lock:\n            gg = self._groups.get(key)\n            if gg and not gg.get(\"items\"):\n                self._groups.pop(key, None)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_get_batch_client_326": {
      "name": "get_batch_client",
      "type": "function",
      "start_line": 326,
      "end_line": 331,
      "content_hash": "71b62af13df07715acfb7b06ba8dc3b077649216",
      "content": "def get_batch_client() -> BatchingContextAnswerClient:\n    \"\"\"Get or create global batch client.\"\"\"\n    global _BATCH_CLIENT\n    if _BATCH_CLIENT is None:\n        _BATCH_CLIENT = BatchingContextAnswerClient()\n    return _BATCH_CLIENT",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}