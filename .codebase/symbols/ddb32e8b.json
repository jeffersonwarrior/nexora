{
  "file_path": "/work/.local/tools/modelscan/providers/anthropic.go",
  "file_hash": "5482b57a2a3cb96b44bff113b11f8183f0d6c7d6",
  "updated_at": "2025-12-26T17:34:20.925678",
  "symbols": {
    "struct_AnthropicProvider_15": {
      "name": "AnthropicProvider",
      "type": "struct",
      "start_line": 15,
      "end_line": 22,
      "content_hash": "254b158602f4cd8cb0e4e5d222cdfd77adcbc4d6",
      "content": "type AnthropicProvider struct {\n\tapiKey    string\n\tbaseURL   string\n\tclient    *http.Client\n\tendpoints []Endpoint\n}\n\n// NewAnthropicProvider creates a new Anthropic provider instance",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_NewAnthropicProvider_23": {
      "name": "NewAnthropicProvider",
      "type": "function",
      "start_line": 23,
      "end_line": 32,
      "content_hash": "66c35b62fbd46baf34124dad5c9110884c6904d4",
      "content": "func NewAnthropicProvider(apiKey string) Provider {\n\treturn &AnthropicProvider{\n\t\tapiKey:  apiKey,\n\t\tbaseURL: \"https://api.anthropic.com/v1\",\n\t\tclient: &http.Client{\n\t\t\tTimeout: 30 * time.Second,\n\t\t},\n\t}\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_init_33": {
      "name": "init",
      "type": "function",
      "start_line": 33,
      "end_line": 37,
      "content_hash": "9dac9ffccf9f4b4b23cd2df6bb6dd382215df8b3",
      "content": "func init() {\n\tRegisterProvider(\"anthropic\", NewAnthropicProvider)\n}\n\n// anthropicModelsResponse represents the response from /v1/models endpoint",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "struct_anthropicModelsResponse_38": {
      "name": "anthropicModelsResponse",
      "type": "struct",
      "start_line": 38,
      "end_line": 44,
      "content_hash": "0e8b9e13400ca08c5e2b04fa3ab73b592090dfb5",
      "content": "type anthropicModelsResponse struct {\n\tData    []anthropicModelInfo `json:\"data\"`\n\tHasMore bool                 `json:\"has_more\"`\n\tFirstID string               `json:\"first_id,omitempty\"`\n\tLastID  string               `json:\"last_id,omitempty\"`\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "struct_anthropicModelInfo_45": {
      "name": "anthropicModelInfo",
      "type": "struct",
      "start_line": 45,
      "end_line": 51,
      "content_hash": "5302af484266c8a4c738317b9cff38055f4f36e2",
      "content": "type anthropicModelInfo struct {\n\tID          string    `json:\"id\"`\n\tDisplayName string    `json:\"display_name\"`\n\tCreatedAt   time.Time `json:\"created_at\"`\n\tType        string    `json:\"type\"`\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_ValidateEndpoints_52": {
      "name": "ValidateEndpoints",
      "type": "method",
      "start_line": 52,
      "end_line": 96,
      "content_hash": "4f505515e5b425e2c99e4e9d838f349dd1b3afce",
      "content": "func (p *AnthropicProvider) ValidateEndpoints(ctx context.Context, verbose bool) error {\n\tendpoints := p.GetEndpoints()\n\n\t// Parallelize endpoint testing for better performance\n\tvar wg sync.WaitGroup\n\tvar mu sync.Mutex // Protect concurrent writes to endpoint status\n\n\tfor i := range endpoints {\n\t\twg.Add(1)\n\t\tgo func(endpoint *Endpoint) {\n\t\t\tdefer wg.Done()\n\n\t\t\tif verbose {\n\t\t\t\tmu.Lock()\n\t\t\t\tfmt.Printf(\"  Testing endpoint: %s %s\\n\", endpoint.Method, endpoint.Path)\n\t\t\t\tmu.Unlock()\n\t\t\t}\n\n\t\t\tstart := time.Now()\n\t\t\terr := p.testEndpoint(ctx, endpoint)\n\t\t\tlatency := time.Since(start)\n\n\t\t\tmu.Lock()\n\t\t\tendpoint.Latency = latency\n\t\t\tif err != nil {\n\t\t\t\tendpoint.Status = StatusFailed\n\t\t\t\tendpoint.Error = err.Error()\n\t\t\t\tif verbose {\n\t\t\t\t\tfmt.Printf(\"    \u2717 Failed: %v\\n\", err)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tendpoint.Status = StatusWorking\n\t\t\t\tif verbose {\n\t\t\t\t\tfmt.Printf(\"    \u2713 Working (%v)\\n\", latency)\n\t\t\t\t}\n\t\t\t}\n\t\t\tmu.Unlock()\n\t\t}(&endpoints[i])\n\t}\n\twg.Wait()\n\n\tp.endpoints = endpoints\n\treturn nil\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_ListModels_97": {
      "name": "ListModels",
      "type": "method",
      "start_line": 97,
      "end_line": 150,
      "content_hash": "5192c8ed4fcb87a3a5d37b0602f7f3255f3cb624",
      "content": "func (p *AnthropicProvider) ListModels(ctx context.Context, verbose bool) ([]Model, error) {\n\tif verbose {\n\t\tfmt.Println(\"  Fetching available models from Anthropic API...\")\n\t}\n\n\t// Call the /v1/models endpoint directly\n\turl := p.baseURL + \"/models\"\n\treq, err := http.NewRequestWithContext(ctx, \"GET\", url, nil)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create request: %w\", err)\n\t}\n\n\treq.Header.Set(\"x-api-key\", p.apiKey)\n\treq.Header.Set(\"anthropic-version\", \"2023-06-01\")\n\n\tresp, err := p.client.Do(req)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to list models: %w\", err)\n\t}\n\tdefer resp.Body.Close()\n\n\tif resp.StatusCode != http.StatusOK {\n\t\tbody, _ := io.ReadAll(resp.Body)\n\t\treturn nil, fmt.Errorf(\"API returned status %d: %s\", resp.StatusCode, string(body))\n\t}\n\n\tvar modelsResp anthropicModelsResponse\n\tif err := json.NewDecoder(resp.Body).Decode(&modelsResp); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to decode response: %w\", err)\n\t}\n\n\t// Map to our Model structure with pricing and capabilities\n\tmodels := make([]Model, 0, len(modelsResp.Data))\n\tfor _, apiModel := range modelsResp.Data {\n\t\tmodel := Model{\n\t\t\tID:          apiModel.ID,\n\t\t\tName:        apiModel.DisplayName,\n\t\t\tDescription: fmt.Sprintf(\"Anthropic Claude model created at %s\", apiModel.CreatedAt.Format(\"2006-01-02\")),\n\t\t\tCreatedAt:   apiModel.CreatedAt.Format(time.RFC3339),\n\t\t}\n\n\t\t// Set pricing and capabilities based on model ID\n\t\tmodel = p.enrichModelDetails(model)\n\t\tmodels = append(models, model)\n\t}\n\n\tif verbose {\n\t\tfmt.Printf(\"  Found %d models\\n\", len(models))\n\t}\n\n\treturn models, nil\n}\n\n// enrichModelDetails adds pricing, context window, and capability information",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_enrichModelDetails_151": {
      "name": "enrichModelDetails",
      "type": "method",
      "start_line": 151,
      "end_line": 222,
      "content_hash": "07cbc9513d991589890cbfd1b194064ddcf9301a",
      "content": "func (p *AnthropicProvider) enrichModelDetails(model Model) Model {\n\t// Set common capabilities for all Claude models\n\tmodel.SupportsImages = true\n\tmodel.SupportsTools = true\n\tmodel.CanStream = true\n\tmodel.CanReason = true\n\n\t// Determine specific details based on model ID\n\tswitch {\n\tcase containsSubstring(model.ID, \"opus-4\"):\n\t\tmodel.CostPer1MIn = 5.00\n\t\tmodel.CostPer1MOut = 25.00\n\t\tmodel.ContextWindow = 200000\n\t\tmodel.MaxTokens = 64000\n\t\tmodel.Categories = []string{\"chat\", \"reasoning\", \"premium\"}\n\n\tcase containsSubstring(model.ID, \"sonnet-4\"):\n\t\tmodel.CostPer1MIn = 3.00\n\t\tmodel.CostPer1MOut = 15.00\n\t\tmodel.ContextWindow = 200000\n\t\tmodel.MaxTokens = 64000\n\t\tmodel.Categories = []string{\"chat\", \"reasoning\", \"balanced\"}\n\n\tcase containsSubstring(model.ID, \"haiku-4\"):\n\t\tmodel.CostPer1MIn = 1.00\n\t\tmodel.CostPer1MOut = 5.00\n\t\tmodel.ContextWindow = 200000\n\t\tmodel.MaxTokens = 64000\n\t\tmodel.Categories = []string{\"chat\", \"fast\", \"cost-effective\"}\n\n\tcase containsSubstring(model.ID, \"opus-3.5\"):\n\t\tmodel.CostPer1MIn = 15.00\n\t\tmodel.CostPer1MOut = 75.00\n\t\tmodel.ContextWindow = 200000\n\t\tmodel.MaxTokens = 4096\n\t\tmodel.Categories = []string{\"chat\", \"premium\", \"legacy\"}\n\n\tcase containsSubstring(model.ID, \"sonnet-3.5\"):\n\t\tmodel.CostPer1MIn = 3.00\n\t\tmodel.CostPer1MOut = 15.00\n\t\tmodel.ContextWindow = 200000\n\t\tmodel.MaxTokens = 8192\n\t\tmodel.Categories = []string{\"chat\", \"balanced\", \"legacy\"}\n\n\tcase containsSubstring(model.ID, \"haiku-3.5\"):\n\t\tmodel.CostPer1MIn = 0.80\n\t\tmodel.CostPer1MOut = 4.00\n\t\tmodel.ContextWindow = 200000\n\t\tmodel.MaxTokens = 4096\n\t\tmodel.Categories = []string{\"chat\", \"fast\", \"legacy\"}\n\n\tdefault:\n\t\t// Default values for unknown models\n\t\tmodel.CostPer1MIn = 3.00\n\t\tmodel.CostPer1MOut = 15.00\n\t\tmodel.ContextWindow = 200000\n\t\tmodel.MaxTokens = 4096\n\t\tmodel.Categories = []string{\"chat\"}\n\t}\n\n\t// Add capabilities metadata\n\tmodel.Capabilities = map[string]string{\n\t\t\"vision\":            \"high\",\n\t\t\"function_calling\":  \"full\",\n\t\t\"json_mode\":         \"supported\",\n\t\t\"streaming\":         \"supported\",\n\t\t\"extended_thinking\": \"supported\",\n\t}\n\n\treturn model\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_GetCapabilities_223": {
      "name": "GetCapabilities",
      "type": "method",
      "start_line": 223,
      "end_line": 241,
      "content_hash": "974a166b0ea12dd29c37466ef1c63acd63439c2c",
      "content": "func (p *AnthropicProvider) GetCapabilities() ProviderCapabilities {\n\treturn ProviderCapabilities{\n\t\tSupportsChat:         true,\n\t\tSupportsFIM:          false,\n\t\tSupportsEmbeddings:   false,\n\t\tSupportsFineTuning:   false,\n\t\tSupportsAgents:       true,\n\t\tSupportsFileUpload:   true,\n\t\tSupportsStreaming:    true,\n\t\tSupportsJSONMode:     true,\n\t\tSupportsVision:       true,\n\t\tSupportsAudio:        false,\n\t\tSupportedParameters:  []string{\"temperature\", \"max_tokens\", \"top_p\", \"top_k\", \"stop_sequences\"},\n\t\tSecurityFeatures:     []string{\"prompt_caching\", \"batch_api\", \"extended_thinking\"},\n\t\tMaxRequestsPerMinute: 50,\n\t\tMaxTokensPerRequest:  200000,\n\t}\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_GetEndpoints_242": {
      "name": "GetEndpoints",
      "type": "method",
      "start_line": 242,
      "end_line": 265,
      "content_hash": "a9018a90736ba6d1924195645d03eedbf04eacec",
      "content": "func (p *AnthropicProvider) GetEndpoints() []Endpoint {\n\treturn []Endpoint{\n\t\t{\n\t\t\tPath:        \"/v1/messages\",\n\t\t\tMethod:      \"POST\",\n\t\t\tDescription: \"Create a message (chat completion)\",\n\t\t\tHeaders: map[string]string{\n\t\t\t\t\"x-api-key\":         p.apiKey,\n\t\t\t\t\"anthropic-version\": \"2023-06-01\",\n\t\t\t\t\"content-type\":      \"application/json\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tPath:        \"/v1/models\",\n\t\t\tMethod:      \"GET\",\n\t\t\tDescription: \"List available models\",\n\t\t\tHeaders: map[string]string{\n\t\t\t\t\"x-api-key\":         p.apiKey,\n\t\t\t\t\"anthropic-version\": \"2023-06-01\",\n\t\t\t},\n\t\t},\n\t}\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_TestModel_266": {
      "name": "TestModel",
      "type": "method",
      "start_line": 266,
      "end_line": 311,
      "content_hash": "146615266e64f346964aa398c77ffbfafbcc59b2",
      "content": "func (p *AnthropicProvider) TestModel(ctx context.Context, modelID string, verbose bool) error {\n\tif verbose {\n\t\tfmt.Printf(\"  Testing model: %s\\n\", modelID)\n\t}\n\n\t// Create test request\n\trequestBody := map[string]interface{}{\n\t\t\"model\":      modelID,\n\t\t\"max_tokens\": 10,\n\t\t\"messages\": []map[string]string{\n\t\t\t{\"role\": \"user\", \"content\": \"Say 'test successful' in 2 words\"},\n\t\t},\n\t}\n\n\tbodyBytes, err := json.Marshal(requestBody)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to marshal request: %w\", err)\n\t}\n\n\treq, err := http.NewRequestWithContext(ctx, \"POST\", p.baseURL+\"/messages\", bytes.NewReader(bodyBytes))\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to create request: %w\", err)\n\t}\n\n\treq.Header.Set(\"x-api-key\", p.apiKey)\n\treq.Header.Set(\"anthropic-version\", \"2023-06-01\")\n\treq.Header.Set(\"content-type\", \"application/json\")\n\n\tresp, err := p.client.Do(req)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"request failed: %w\", err)\n\t}\n\tdefer resp.Body.Close()\n\n\tif resp.StatusCode != http.StatusOK {\n\t\tbody, _ := io.ReadAll(resp.Body)\n\t\treturn fmt.Errorf(\"model test failed with status %d: %s\", resp.StatusCode, string(body))\n\t}\n\n\tif verbose {\n\t\tfmt.Printf(\"    \u2713 Model is working\\n\")\n\t}\n\n\treturn nil\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_testEndpoint_312": {
      "name": "testEndpoint",
      "type": "method",
      "start_line": 312,
      "end_line": 352,
      "content_hash": "658d83fe572c73e9f2385d6470775e340f8d1557",
      "content": "func (p *AnthropicProvider) testEndpoint(ctx context.Context, endpoint *Endpoint) error {\n\turl := p.baseURL + endpoint.Path\n\n\tvar req *http.Request\n\tvar err error\n\n\tif endpoint.Method == \"POST\" {\n\t\t// Test messages endpoint with a minimal request\n\t\tbody := `{\n\t\t\t\"model\": \"claude-sonnet-4-5-20250929\",\n\t\t\t\"max_tokens\": 10,\n\t\t\t\"messages\": [{\"role\": \"user\", \"content\": \"Hi\"}]\n\t\t}`\n\t\treq, err = http.NewRequestWithContext(ctx, endpoint.Method, url, bytes.NewBufferString(body))\n\t} else {\n\t\treq, err = http.NewRequestWithContext(ctx, endpoint.Method, url, nil)\n\t}\n\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to create request: %w\", err)\n\t}\n\n\t// Set headers\n\tfor key, value := range endpoint.Headers {\n\t\treq.Header.Set(key, value)\n\t}\n\n\tresp, err := p.client.Do(req)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"request failed: %w\", err)\n\t}\n\tdefer resp.Body.Close()\n\n\t// Consider 2xx status codes as success\n\tif resp.StatusCode >= 200 && resp.StatusCode < 300 {\n\t\treturn nil\n\t}\n\n\tbody, _ := io.ReadAll(resp.Body)\n\treturn fmt.Errorf(\"endpoint returned status %d: %s\", resp.StatusCode, string(body))\n}",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}