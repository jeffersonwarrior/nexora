{
  "file_path": "/work/context-engine/scripts/ast_analyzer.py",
  "file_hash": "eb51d882f537db095b09a41dbb78263e477ab65f",
  "updated_at": "2025-12-26T17:34:21.460651",
  "symbols": {
    "function__load_ts_language_31": {
      "name": "_load_ts_language",
      "type": "function",
      "start_line": 31,
      "end_line": 59,
      "content_hash": "05e09322b907a239e1a325d52e62f64ce8e3518b",
      "content": "    def _load_ts_language(mod: Any, *, preferred: list[str] | None = None) -> Any | None:\n        \"\"\"Return a tree-sitter Language instance from a per-language package.\n\n        Different packages expose different entrypoints (e.g. language(),\n        language_typescript(), language_tsx()).\n        \"\"\"\n        preferred = preferred or []\n        candidates: list[Any] = []\n        if getattr(mod, \"language\", None) is not None and callable(getattr(mod, \"language\")):\n            candidates.append(getattr(mod, \"language\"))\n        for name in preferred:\n            fn = getattr(mod, name, None)\n            if fn is not None and callable(fn):\n                candidates.append(fn)\n        # Last resort: scan for any callable language* attribute\n        for name in dir(mod):\n            if not name.startswith(\"language\"):\n                continue\n            fn = getattr(mod, name, None)\n            if fn is not None and callable(fn):\n                candidates.append(fn)\n\n        for fn in candidates:\n            try:\n                raw_lang = fn()\n                return raw_lang if isinstance(raw_lang, Language) else Language(raw_lang)\n            except Exception:\n                continue\n        return None",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_CodeSymbol_116": {
      "name": "CodeSymbol",
      "type": "class",
      "start_line": 116,
      "end_line": 128,
      "content_hash": "48dc3a6bdc84b101a31747ce05e1b0356d36aa22",
      "content": "class CodeSymbol:\n    \"\"\"Represents a code symbol (function, class, method, etc).\"\"\"\n    name: str\n    kind: str  # function, class, method, interface, etc.\n    start_line: int\n    end_line: int\n    path: Optional[str] = None  # Fully qualified path (e.g., \"MyClass.method\")\n    docstring: Optional[str] = None\n    signature: Optional[str] = None\n    decorators: List[str] = field(default_factory=list)\n    parent: Optional[str] = None  # Parent class/module\n    complexity: int = 0  # Cyclomatic complexity estimate\n    content_hash: Optional[str] = None",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_CallReference_132": {
      "name": "CallReference",
      "type": "class",
      "start_line": 132,
      "end_line": 137,
      "content_hash": "2c5f25326ca61a6499cda987767d4e5e787443d2",
      "content": "class CallReference:\n    \"\"\"Represents a function/method call.\"\"\"\n    caller: str  # Who is calling\n    callee: str  # What is being called\n    line: int\n    context: str  # e.g., \"function\", \"method\", \"module\"",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_ImportReference_141": {
      "name": "ImportReference",
      "type": "class",
      "start_line": 141,
      "end_line": 147,
      "content_hash": "3cd3cd6db108564875e47f4941eed35fccbd48be",
      "content": "class ImportReference:\n    \"\"\"Represents an import statement.\"\"\"\n    module: str\n    names: List[str]  # Specific imports (empty if import *)\n    line: int\n    alias: Optional[str] = None\n    is_from: bool = False",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_CodeContext_151": {
      "name": "CodeContext",
      "type": "class",
      "start_line": 151,
      "end_line": 160,
      "content_hash": "8d0af218411fca1f6bc56a53bda02949cc69e570",
      "content": "class CodeContext:\n    \"\"\"Complete context for a code chunk.\"\"\"\n    chunk_text: str\n    start_line: int\n    end_line: int\n    symbols: List[CodeSymbol]\n    imports: List[ImportReference]\n    calls: List[CallReference]\n    dependencies: Set[str]  # Modules/files this depends on\n    is_semantic_unit: bool = True  # True if chunk respects boundaries",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_ASTAnalyzer_163": {
      "name": "ASTAnalyzer",
      "type": "class",
      "start_line": 163,
      "end_line": 1388,
      "content_hash": "03c23f9fb6d2b29368225b336a6d28d42268e3e7",
      "content": "class ASTAnalyzer:\n    \"\"\"\n    Advanced AST-based code analyzer for semantic understanding.\n    \n    Features:\n    - Language-aware symbol extraction\n    - Call graph construction\n    - Dependency tracking\n    - Semantic chunking (preserve boundaries)\n    - Cross-reference analysis\n    \"\"\"\n    \n    def __init__(self, use_tree_sitter: bool = True):\n        \"\"\"\n        Initialize AST analyzer.\n        \n        Args:\n            use_tree_sitter: Use tree-sitter when available (fallback to ast module)\n        \"\"\"\n        self.use_tree_sitter = use_tree_sitter and _TS_AVAILABLE\n        self._parsers: Dict[str, Any] = {}\n        \n        # Language support matrix\n        self.supported_languages = {\n            \"python\": {\"ast\": True, \"tree_sitter\": True},\n            \"javascript\": {\"ast\": False, \"tree_sitter\": True},\n            \"typescript\": {\"ast\": False, \"tree_sitter\": True},\n            \"java\": {\"ast\": False, \"tree_sitter\": True},\n            \"go\": {\"ast\": False, \"tree_sitter\": True},\n            \"rust\": {\"ast\": False, \"tree_sitter\": True},\n            \"c\": {\"ast\": False, \"tree_sitter\": True},\n            \"cpp\": {\"ast\": False, \"tree_sitter\": True},\n            \"ruby\": {\"ast\": False, \"tree_sitter\": True},\n        }\n        \n        logger.info(f\"ASTAnalyzer initialized: tree_sitter={self.use_tree_sitter}\")\n    \n    def analyze_file(\n        self, file_path: str, language: str, content: Optional[str] = None\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Analyze a source file and extract semantic information.\n        \n        Args:\n            file_path: Path to the file\n            language: Programming language\n            content: Optional file content (if not provided, read from file)\n        \n        Returns:\n            Dict with symbols, imports, calls, and dependencies\n        \"\"\"\n        if content is None:\n            try:\n                content = Path(file_path).read_text(encoding=\"utf-8\", errors=\"ignore\")\n            except Exception as e:\n                logger.error(f\"Failed to read {file_path}: {e}\")\n                return self._empty_analysis()\n        \n        # Route to appropriate analyzer\n        if language == \"python\":\n            return self._analyze_python(content, file_path)\n        elif language in (\"javascript\", \"typescript\") and self.use_tree_sitter:\n            return self._analyze_js_ts(content, file_path, language)\n        elif language == \"go\" and self.use_tree_sitter:\n            return self._analyze_go(content, file_path)\n        elif language == \"rust\" and self.use_tree_sitter:\n            return self._analyze_rust(content, file_path)\n        elif language == \"java\" and self.use_tree_sitter:\n            return self._analyze_java(content, file_path)\n        elif language in (\"c\", \"cpp\") and self.use_tree_sitter:\n            return self._analyze_c_cpp(content, file_path, language)\n        elif language == \"ruby\" and self.use_tree_sitter:\n            return self._analyze_ruby(content, file_path)\n        else:\n            # Fallback to regex-based analysis\n            return self._analyze_generic(content, file_path, language)\n    \n    def extract_symbols_with_context(\n        self, file_path: str, language: str, content: Optional[str] = None\n    ) -> List[CodeSymbol]:\n        \"\"\"\n        Extract code symbols with full context (docstrings, signatures, etc).\n        \n        Returns:\n            List of CodeSymbol objects with rich metadata\n        \"\"\"\n        analysis = self.analyze_file(file_path, language, content)\n        return analysis.get(\"symbols\", [])\n    \n    def chunk_semantic(\n        self,\n        content: str,\n        language: str,\n        max_lines: int = 120,\n        overlap_lines: int = 20,\n        preserve_boundaries: bool = True\n    ) -> List[CodeContext]:\n        \"\"\"\n        Chunk code semantically, respecting function/class boundaries.\n        \n        Args:\n            content: Source code content\n            language: Programming language\n            max_lines: Maximum lines per chunk\n            overlap_lines: Overlap between chunks\n            preserve_boundaries: Try to keep complete functions/classes together\n        \n        Returns:\n            List of CodeContext objects with semantic chunks\n        \"\"\"\n        if not preserve_boundaries:\n            # Fall back to line-based chunking\n            return self._chunk_lines_simple(content, max_lines, overlap_lines)\n        \n        # Extract symbols\n        analysis = self.analyze_file(\"\", language, content)\n        symbols = analysis.get(\"symbols\", [])\n        \n        if not symbols:\n            # No symbols found, use line-based\n            return self._chunk_lines_simple(content, max_lines, overlap_lines)\n        \n        lines = content.splitlines()\n        chunks = []\n        \n        # Sort symbols by start line\n        symbols.sort(key=lambda s: s.start_line)\n        \n        i = 0\n        while i < len(symbols):\n            symbol = symbols[i]\n            \n            # Calculate chunk extent\n            chunk_start = symbol.start_line\n            chunk_end = symbol.end_line\n            symbols_in_chunk = [symbol]\n            \n            # Try to include adjacent small symbols\n            j = i + 1\n            while j < len(symbols):\n                next_symbol = symbols[j]\n                potential_end = next_symbol.end_line\n                \n                # Check if adding next symbol exceeds max_lines\n                if potential_end - chunk_start > max_lines:\n                    break\n                \n                # Check if next symbol is close enough (within overlap)\n                if next_symbol.start_line - chunk_end > overlap_lines:\n                    break\n                \n                # Include this symbol\n                chunk_end = potential_end\n                symbols_in_chunk.append(next_symbol)\n                j += 1\n            \n            # Create chunk\n            chunk_lines = lines[chunk_start - 1:chunk_end]\n            chunk_text = \"\\n\".join(chunk_lines)\n            \n            # Extract chunk-specific imports and calls\n            chunk_imports = [\n                imp for imp in analysis.get(\"imports\", [])\n                if chunk_start <= imp.line <= chunk_end\n            ]\n            chunk_calls = [\n                call for call in analysis.get(\"calls\", [])\n                if chunk_start <= call.line <= chunk_end\n            ]\n            \n            context = CodeContext(\n                chunk_text=chunk_text,\n                start_line=chunk_start,\n                end_line=chunk_end,\n                symbols=symbols_in_chunk,\n                imports=chunk_imports,\n                calls=chunk_calls,\n                dependencies=self._extract_dependencies(chunk_imports, chunk_calls),\n                is_semantic_unit=True\n            )\n            \n            chunks.append(context)\n            i = j if j > i else i + 1\n        \n        # Handle code not covered by symbols (module-level code, etc)\n        self._fill_gaps(chunks, lines, max_lines, overlap_lines, analysis)\n        \n        return chunks\n    \n    def build_call_graph(self, file_path: str, language: str) -> Dict[str, List[str]]:\n        \"\"\"\n        Build call graph: mapping of caller -> list of callees.\n        \n        Returns:\n            Dict mapping function names to list of functions they call\n        \"\"\"\n        analysis = self.analyze_file(file_path, language)\n        \n        call_graph = defaultdict(list)\n        for call in analysis.get(\"calls\", []):\n            call_graph[call.caller].append(call.callee)\n        \n        return dict(call_graph)\n    \n    def extract_dependencies(\n        self, file_path: str, language: str\n    ) -> Dict[str, List[str]]:\n        \"\"\"\n        Extract file dependencies (imports, includes).\n        \n        Returns:\n            Dict with 'modules' (external) and 'local' (same project) imports\n        \"\"\"\n        analysis = self.analyze_file(file_path, language)\n        imports = analysis.get(\"imports\", [])\n        \n        modules = []\n        local = []\n        \n        for imp in imports:\n            # Simple heuristic: relative imports or without dots are likely local\n            if imp.module.startswith(\".\") or \"/\" in imp.module:\n                local.append(imp.module)\n            else:\n                modules.append(imp.module)\n        \n        return {\n            \"modules\": list(set(modules)),\n            \"local\": list(set(local))\n        }\n    \n    # ---- Python-specific analysis (using ast module) ----\n    \n    def _analyze_python(self, content: str, file_path: str) -> Dict[str, Any]:\n        \"\"\"Analyze Python code using ast module.\"\"\"\n        try:\n            tree = ast.parse(content)\n        except SyntaxError as e:\n            logger.warning(f\"Python syntax error in {file_path}: {e}\")\n            return self._empty_analysis()\n        \n        symbols = []\n        imports = []\n        calls = []\n        \n        # Extract symbols\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                symbol = self._extract_python_function(node, content)\n                symbols.append(symbol)\n            elif isinstance(node, ast.ClassDef):\n                symbol = self._extract_python_class(node, content)\n                symbols.append(symbol)\n        \n        # Extract imports\n        for node in ast.walk(tree):\n            if isinstance(node, ast.Import):\n                for alias in node.names:\n                    imports.append(ImportReference(\n                        module=alias.name,\n                        names=[],\n                        alias=alias.asname,\n                        line=node.lineno,\n                        is_from=False\n                    ))\n            elif isinstance(node, ast.ImportFrom):\n                names = [alias.name for alias in node.names]\n                imports.append(ImportReference(\n                    module=node.module or \"\",\n                    names=names,\n                    alias=None,\n                    line=node.lineno,\n                    is_from=True\n                ))\n        \n        # Extract calls (simplified)\n        for node in ast.walk(tree):\n            if isinstance(node, ast.Call):\n                callee = self._get_call_name(node.func)\n                if callee:\n                    calls.append(CallReference(\n                        caller=\"\",  # Would need parent context\n                        callee=callee,\n                        line=node.lineno,\n                        context=\"call\"\n                    ))\n        \n        return {\n            \"symbols\": symbols,\n            \"imports\": imports,\n            \"calls\": calls,\n            \"language\": \"python\"\n        }\n    \n    def _extract_python_function(self, node: ast.FunctionDef, content: str) -> CodeSymbol:\n        \"\"\"Extract detailed function information from AST node.\"\"\"\n        # Get docstring\n        docstring = ast.get_docstring(node)\n        \n        # Get decorators\n        decorators = [self._get_decorator_name(d) for d in node.decorator_list]\n        \n        # Build signature\n        args = [arg.arg for arg in node.args.args]\n        signature = f\"def {node.name}({', '.join(args)})\"\n        \n        # Calculate complexity (simplified: count branches)\n        complexity = sum(\n            1 for n in ast.walk(node)\n            if isinstance(n, (ast.If, ast.For, ast.While, ast.Try, ast.With))\n        )\n        \n        # Content hash\n        lines = content.splitlines()\n        if node.lineno <= len(lines) and node.end_lineno <= len(lines):\n            func_content = \"\\n\".join(lines[node.lineno - 1:node.end_lineno])\n            content_hash = hashlib.md5(func_content.encode()).hexdigest()[:8]\n        else:\n            content_hash = None\n        \n        return CodeSymbol(\n            name=node.name,\n            kind=\"function\",\n            start_line=node.lineno,\n            end_line=node.end_lineno or node.lineno,\n            docstring=docstring,\n            signature=signature,\n            decorators=decorators,\n            complexity=complexity,\n            content_hash=content_hash\n        )\n    \n    def _extract_python_class(self, node: ast.ClassDef, content: str) -> CodeSymbol:\n        \"\"\"Extract detailed class information from AST node.\"\"\"\n        docstring = ast.get_docstring(node)\n        decorators = [self._get_decorator_name(d) for d in node.decorator_list]\n        \n        # Get base classes\n        bases = [self._get_name(base) for base in node.bases]\n        signature = f\"class {node.name}({', '.join(bases)})\" if bases else f\"class {node.name}\"\n        \n        # Count methods\n        methods = sum(\n            1 for n in node.body\n            if isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef))\n        )\n        \n        return CodeSymbol(\n            name=node.name,\n            kind=\"class\",\n            start_line=node.lineno,\n            end_line=node.end_lineno or node.lineno,\n            docstring=docstring,\n            signature=signature,\n            decorators=decorators,\n            complexity=methods\n        )\n    \n    def _get_decorator_name(self, node: ast.expr) -> str:\n        \"\"\"Extract decorator name from AST node.\"\"\"\n        if isinstance(node, ast.Name):\n            return node.id\n        elif isinstance(node, ast.Call):\n            return self._get_name(node.func)\n        return \"\"\n    \n    def _get_name(self, node: ast.expr) -> str:\n        \"\"\"Extract name from AST expression.\"\"\"\n        if isinstance(node, ast.Name):\n            return node.id\n        elif isinstance(node, ast.Attribute):\n            return f\"{self._get_name(node.value)}.{node.attr}\"\n        return \"\"\n    \n    def _get_call_name(self, node: ast.expr) -> str:\n        \"\"\"Extract function name from call node.\"\"\"\n        if isinstance(node, ast.Name):\n            return node.id\n        elif isinstance(node, ast.Attribute):\n            # Return just the method name for simplicity\n            return node.attr\n        return \"\"\n    \n    # ---- JavaScript/TypeScript analysis (using tree-sitter) ----\n    \n    def _analyze_js_ts(\n        self, content: str, file_path: str, language: str\n    ) -> Dict[str, Any]:\n        \"\"\"Analyze JavaScript/TypeScript using tree-sitter.\"\"\"\n        ts_lang_key = language if language in _TS_LANGUAGES else \"javascript\"\n        parser = self._get_ts_parser(ts_lang_key)\n        if not parser:\n            return self._empty_analysis()\n        \n        try:\n            tree = parser.parse(content.encode(\"utf-8\"))\n            root = tree.root_node\n        except Exception as e:\n            logger.warning(f\"Tree-sitter parse error in {file_path}: {e}\")\n            return self._empty_analysis()\n        \n        symbols = []\n        imports = []\n        calls = []\n        \n        def node_text(n):\n            return content.encode(\"utf-8\")[n.start_byte:n.end_byte].decode(\"utf-8\", errors=\"ignore\")\n        \n        def walk(node, parent_class=None):\n            node_type = node.type\n            \n            # Classes\n            if node_type == \"class_declaration\":\n                name_node = node.child_by_field_name(\"name\")\n                class_name = node_text(name_node) if name_node else \"\"\n                \n                symbols.append(CodeSymbol(\n                    name=class_name,\n                    kind=\"class\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n                \n                # Walk class body\n                for child in node.children:\n                    walk(child, parent_class=class_name)\n                return\n            \n            # Functions\n            if node_type in (\"function_declaration\", \"arrow_function\", \"function_expression\"):\n                name_node = node.child_by_field_name(\"name\")\n                func_name = node_text(name_node) if name_node else \"<anonymous>\"\n                \n                symbols.append(CodeSymbol(\n                    name=func_name,\n                    kind=\"function\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1,\n                    parent=parent_class\n                ))\n            \n            # Methods\n            if node_type == \"method_definition\":\n                name_node = node.child_by_field_name(\"name\")\n                method_name = node_text(name_node) if name_node else \"\"\n                \n                symbols.append(CodeSymbol(\n                    name=method_name,\n                    kind=\"method\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1,\n                    parent=parent_class,\n                    path=f\"{parent_class}.{method_name}\" if parent_class else method_name\n                ))\n            \n            # Imports\n            if node_type == \"import_statement\":\n                source = node.child_by_field_name(\"source\")\n                if source:\n                    module = node_text(source).strip('\"\\'')\n                    imports.append(ImportReference(\n                        module=module,\n                        names=[],\n                        line=node.start_point[0] + 1,\n                        is_from=True\n                    ))\n            \n            # Recurse\n            for child in node.children:\n                walk(child, parent_class)\n        \n        walk(root)\n        \n        return {\n            \"symbols\": symbols,\n            \"imports\": imports,\n            \"calls\": calls,\n            \"language\": language\n        }\n    \n    # ---- Go analysis (using tree-sitter) ----\n    \n    def _analyze_go(self, content: str, file_path: str) -> Dict[str, Any]:\n        \"\"\"Analyze Go using tree-sitter.\"\"\"\n        parser = self._get_ts_parser(\"go\")\n        if not parser:\n            return self._analyze_generic(content, file_path, \"go\")\n        \n        try:\n            tree = parser.parse(content.encode(\"utf-8\"))\n            root = tree.root_node\n        except Exception as e:\n            logger.warning(f\"Tree-sitter parse error in {file_path}: {e}\")\n            return self._analyze_generic(content, file_path, \"go\")\n        \n        symbols = []\n        imports = []\n        calls = []\n        \n        def node_text(n):\n            return content.encode(\"utf-8\")[n.start_byte:n.end_byte].decode(\"utf-8\", errors=\"ignore\")\n        \n        def walk(node, parent_type=None):\n            node_type = node.type\n            \n            # Functions\n            if node_type == \"function_declaration\":\n                name_node = node.child_by_field_name(\"name\")\n                func_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=func_name,\n                    kind=\"function\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n            \n            # Methods\n            elif node_type == \"method_declaration\":\n                name_node = node.child_by_field_name(\"name\")\n                method_name = node_text(name_node) if name_node else \"\"\n                receiver = node.child_by_field_name(\"receiver\")\n                receiver_type = \"\"\n                if receiver:\n                    for child in receiver.children:\n                        if child.type == \"type_identifier\":\n                            receiver_type = node_text(child)\n                            break\n                symbols.append(CodeSymbol(\n                    name=method_name,\n                    kind=\"method\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1,\n                    parent=receiver_type,\n                    path=f\"{receiver_type}.{method_name}\" if receiver_type else method_name\n                ))\n            \n            # Types (struct, interface)\n            elif node_type == \"type_declaration\":\n                for child in node.children:\n                    if child.type == \"type_spec\":\n                        name_node = child.child_by_field_name(\"name\")\n                        type_name = node_text(name_node) if name_node else \"\"\n                        type_node = child.child_by_field_name(\"type\")\n                        kind = \"struct\"\n                        if type_node and type_node.type == \"interface_type\":\n                            kind = \"interface\"\n                        symbols.append(CodeSymbol(\n                            name=type_name,\n                            kind=kind,\n                            start_line=child.start_point[0] + 1,\n                            end_line=child.end_point[0] + 1\n                        ))\n            \n            # Imports\n            elif node_type == \"import_declaration\":\n                for child in node.children:\n                    if child.type == \"import_spec\":\n                        path_node = child.child_by_field_name(\"path\")\n                        if path_node:\n                            module = node_text(path_node).strip('\"')\n                            imports.append(ImportReference(\n                                module=module,\n                                names=[],\n                                line=child.start_point[0] + 1,\n                                is_from=True\n                            ))\n                    elif child.type == \"import_spec_list\":\n                        for spec in child.children:\n                            if spec.type == \"import_spec\":\n                                path_node = spec.child_by_field_name(\"path\")\n                                if path_node:\n                                    module = node_text(path_node).strip('\"')\n                                    imports.append(ImportReference(\n                                        module=module,\n                                        names=[],\n                                        line=spec.start_point[0] + 1,\n                                        is_from=True\n                                    ))\n            \n            # Calls\n            elif node_type == \"call_expression\":\n                func = node.child_by_field_name(\"function\")\n                if func:\n                    name = node_text(func)\n                    base = name.split(\".\")[-1] if \".\" in name else name\n                    if re.match(r\"^[A-Za-z_][A-Za-z0-9_]*$\", base):\n                        calls.append(CallReference(\n                            caller=\"\",\n                            callee=base,\n                            line=node.start_point[0] + 1,\n                            context=\"call\"\n                        ))\n            \n            for child in node.children:\n                walk(child, node_type)\n        \n        walk(root)\n        \n        return {\n            \"symbols\": symbols,\n            \"imports\": imports,\n            \"calls\": calls,\n            \"language\": \"go\"\n        }\n    \n    # ---- Rust analysis (using tree-sitter) ----\n    \n    def _analyze_rust(self, content: str, file_path: str) -> Dict[str, Any]:\n        \"\"\"Analyze Rust using tree-sitter.\"\"\"\n        parser = self._get_ts_parser(\"rust\")\n        if not parser:\n            return self._analyze_generic(content, file_path, \"rust\")\n        \n        try:\n            tree = parser.parse(content.encode(\"utf-8\"))\n            root = tree.root_node\n        except Exception as e:\n            logger.warning(f\"Tree-sitter parse error in {file_path}: {e}\")\n            return self._analyze_generic(content, file_path, \"rust\")\n        \n        symbols = []\n        imports = []\n        calls = []\n        \n        def node_text(n):\n            return content.encode(\"utf-8\")[n.start_byte:n.end_byte].decode(\"utf-8\", errors=\"ignore\")\n        \n        def walk(node, parent_struct=None):\n            node_type = node.type\n            \n            # Functions\n            if node_type == \"function_item\":\n                name_node = node.child_by_field_name(\"name\")\n                func_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=func_name,\n                    kind=\"function\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1,\n                    parent=parent_struct\n                ))\n            \n            # Structs\n            elif node_type == \"struct_item\":\n                name_node = node.child_by_field_name(\"name\")\n                struct_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=struct_name,\n                    kind=\"struct\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n            \n            # Enums\n            elif node_type == \"enum_item\":\n                name_node = node.child_by_field_name(\"name\")\n                enum_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=enum_name,\n                    kind=\"enum\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n            \n            # Traits\n            elif node_type == \"trait_item\":\n                name_node = node.child_by_field_name(\"name\")\n                trait_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=trait_name,\n                    kind=\"trait\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n            \n            # Impl blocks\n            elif node_type == \"impl_item\":\n                type_node = node.child_by_field_name(\"type\")\n                impl_type = node_text(type_node).split(\"<\")[0].strip() if type_node else \"\"\n                for child in node.children:\n                    walk(child, impl_type)\n                return\n            \n            # Use statements\n            elif node_type == \"use_declaration\":\n                arg = node.child_by_field_name(\"argument\")\n                if arg:\n                    imports.append(ImportReference(\n                        module=node_text(arg).strip(),\n                        names=[],\n                        line=node.start_point[0] + 1,\n                        is_from=True\n                    ))\n            \n            # Calls and macros\n            elif node_type in (\"call_expression\", \"macro_invocation\"):\n                func = node.child_by_field_name(\"function\") or node.child_by_field_name(\"macro\")\n                if func:\n                    name = node_text(func)\n                    base = name.split(\"::\")[-1].rstrip(\"!\") if \"::\" in name else name.rstrip(\"!\")\n                    if re.match(r\"^[A-Za-z_][A-Za-z0-9_]*$\", base):\n                        calls.append(CallReference(\n                            caller=\"\",\n                            callee=base,\n                            line=node.start_point[0] + 1,\n                            context=\"call\"\n                        ))\n            \n            for child in node.children:\n                walk(child, parent_struct)\n        \n        walk(root)\n        \n        return {\n            \"symbols\": symbols,\n            \"imports\": imports,\n            \"calls\": calls,\n            \"language\": \"rust\"\n        }\n    \n    # ---- Java analysis (using tree-sitter) ----\n    \n    def _analyze_java(self, content: str, file_path: str) -> Dict[str, Any]:\n        \"\"\"Analyze Java using tree-sitter.\"\"\"\n        parser = self._get_ts_parser(\"java\")\n        if not parser:\n            return self._analyze_generic(content, file_path, \"java\")\n        \n        try:\n            tree = parser.parse(content.encode(\"utf-8\"))\n            root = tree.root_node\n        except Exception as e:\n            logger.warning(f\"Tree-sitter parse error in {file_path}: {e}\")\n            return self._analyze_generic(content, file_path, \"java\")\n        \n        symbols = []\n        imports = []\n        calls = []\n        \n        def node_text(n):\n            return content.encode(\"utf-8\")[n.start_byte:n.end_byte].decode(\"utf-8\", errors=\"ignore\")\n        \n        def walk(node, parent_class=None):\n            node_type = node.type\n            \n            # Classes\n            if node_type == \"class_declaration\":\n                name_node = node.child_by_field_name(\"name\")\n                class_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=class_name,\n                    kind=\"class\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n                for child in node.children:\n                    walk(child, class_name)\n                return\n            \n            # Interfaces\n            elif node_type == \"interface_declaration\":\n                name_node = node.child_by_field_name(\"name\")\n                iface_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=iface_name,\n                    kind=\"interface\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n                for child in node.children:\n                    walk(child, iface_name)\n                return\n            \n            # Methods\n            elif node_type == \"method_declaration\":\n                name_node = node.child_by_field_name(\"name\")\n                method_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=method_name,\n                    kind=\"method\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1,\n                    parent=parent_class,\n                    path=f\"{parent_class}.{method_name}\" if parent_class else method_name\n                ))\n            \n            # Constructors\n            elif node_type == \"constructor_declaration\":\n                name_node = node.child_by_field_name(\"name\")\n                ctor_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=ctor_name,\n                    kind=\"constructor\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1,\n                    parent=parent_class\n                ))\n            \n            # Imports\n            elif node_type == \"import_declaration\":\n                for child in node.children:\n                    if child.type == \"scoped_identifier\" or child.type == \"identifier\":\n                        imports.append(ImportReference(\n                            module=node_text(child),\n                            names=[],\n                            line=node.start_point[0] + 1,\n                            is_from=True\n                        ))\n                        break\n            \n            # Method calls\n            elif node_type == \"method_invocation\":\n                name_node = node.child_by_field_name(\"name\")\n                if name_node:\n                    calls.append(CallReference(\n                        caller=\"\",\n                        callee=node_text(name_node),\n                        line=node.start_point[0] + 1,\n                        context=\"call\"\n                    ))\n            \n            for child in node.children:\n                walk(child, parent_class)\n        \n        walk(root)\n        \n        return {\n            \"symbols\": symbols,\n            \"imports\": imports,\n            \"calls\": calls,\n            \"language\": \"java\"\n        }\n    \n    # ---- C/C++ analysis (using tree-sitter) ----\n    \n    def _analyze_c_cpp(self, content: str, file_path: str, language: str) -> Dict[str, Any]:\n        \"\"\"Analyze C/C++ using tree-sitter.\"\"\"\n        parser = self._get_ts_parser(language)\n        if not parser:\n            return self._analyze_generic(content, file_path, language)\n        \n        try:\n            tree = parser.parse(content.encode(\"utf-8\"))\n            root = tree.root_node\n        except Exception as e:\n            logger.warning(f\"Tree-sitter parse error in {file_path}: {e}\")\n            return self._analyze_generic(content, file_path, language)\n        \n        symbols = []\n        imports = []\n        calls = []\n        \n        def node_text(n):\n            return content.encode(\"utf-8\")[n.start_byte:n.end_byte].decode(\"utf-8\", errors=\"ignore\")\n        \n        def walk(node, parent_class=None):\n            node_type = node.type\n            \n            # Functions\n            if node_type == \"function_definition\":\n                decl = node.child_by_field_name(\"declarator\")\n                func_name = \"\"\n                if decl:\n                    for child in decl.children:\n                        if child.type == \"identifier\":\n                            func_name = node_text(child)\n                            break\n                        elif child.type == \"function_declarator\":\n                            for subchild in child.children:\n                                if subchild.type == \"identifier\":\n                                    func_name = node_text(subchild)\n                                    break\n                if func_name:\n                    symbols.append(CodeSymbol(\n                        name=func_name,\n                        kind=\"function\",\n                        start_line=node.start_point[0] + 1,\n                        end_line=node.end_point[0] + 1,\n                        parent=parent_class\n                    ))\n            \n            # Classes (C++)\n            elif node_type == \"class_specifier\":\n                name_node = node.child_by_field_name(\"name\")\n                class_name = node_text(name_node) if name_node else \"\"\n                if class_name:\n                    symbols.append(CodeSymbol(\n                        name=class_name,\n                        kind=\"class\",\n                        start_line=node.start_point[0] + 1,\n                        end_line=node.end_point[0] + 1\n                    ))\n                    for child in node.children:\n                        walk(child, class_name)\n                    return\n            \n            # Structs\n            elif node_type == \"struct_specifier\":\n                name_node = node.child_by_field_name(\"name\")\n                struct_name = node_text(name_node) if name_node else \"\"\n                if struct_name:\n                    symbols.append(CodeSymbol(\n                        name=struct_name,\n                        kind=\"struct\",\n                        start_line=node.start_point[0] + 1,\n                        end_line=node.end_point[0] + 1\n                    ))\n            \n            # Includes\n            elif node_type == \"preproc_include\":\n                path_node = node.child_by_field_name(\"path\")\n                if path_node:\n                    path = node_text(path_node).strip('<\">').strip()\n                    imports.append(ImportReference(\n                        module=path,\n                        names=[],\n                        line=node.start_point[0] + 1,\n                        is_from=False\n                    ))\n            \n            # Calls\n            elif node_type == \"call_expression\":\n                func = node.child_by_field_name(\"function\")\n                if func:\n                    name = node_text(func)\n                    # Handle namespaced calls like std::cout\n                    base = name.split(\"::\")[-1] if \"::\" in name else name\n                    if re.match(r\"^[A-Za-z_][A-Za-z0-9_]*$\", base):\n                        calls.append(CallReference(\n                            caller=\"\",\n                            callee=base,\n                            line=node.start_point[0] + 1,\n                            context=\"call\"\n                        ))\n            \n            for child in node.children:\n                walk(child, parent_class)\n        \n        walk(root)\n        \n        return {\n            \"symbols\": symbols,\n            \"imports\": imports,\n            \"calls\": calls,\n            \"language\": language\n        }\n    \n    # ---- Ruby analysis (using tree-sitter) ----\n    \n    def _analyze_ruby(self, content: str, file_path: str) -> Dict[str, Any]:\n        \"\"\"Analyze Ruby using tree-sitter.\"\"\"\n        parser = self._get_ts_parser(\"ruby\")\n        if not parser:\n            return self._analyze_generic(content, file_path, \"ruby\")\n        \n        try:\n            tree = parser.parse(content.encode(\"utf-8\"))\n            root = tree.root_node\n        except Exception as e:\n            logger.warning(f\"Tree-sitter parse error in {file_path}: {e}\")\n            return self._analyze_generic(content, file_path, \"ruby\")\n        \n        symbols = []\n        imports = []\n        calls = []\n        \n        def node_text(n):\n            return content.encode(\"utf-8\")[n.start_byte:n.end_byte].decode(\"utf-8\", errors=\"ignore\")\n        \n        def walk(node, parent_class=None):\n            node_type = node.type\n            \n            # Classes\n            if node_type == \"class\":\n                name_node = node.child_by_field_name(\"name\")\n                class_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=class_name,\n                    kind=\"class\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n                for child in node.children:\n                    walk(child, class_name)\n                return\n            \n            # Modules\n            elif node_type == \"module\":\n                name_node = node.child_by_field_name(\"name\")\n                module_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=module_name,\n                    kind=\"module\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n                for child in node.children:\n                    walk(child, module_name)\n                return\n            \n            # Methods\n            elif node_type == \"method\":\n                name_node = node.child_by_field_name(\"name\")\n                method_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=method_name,\n                    kind=\"method\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1,\n                    parent=parent_class,\n                    path=f\"{parent_class}.{method_name}\" if parent_class else method_name\n                ))\n            \n            # Require statements\n            elif node_type == \"call\":\n                method = node.child_by_field_name(\"method\")\n                if method:\n                    method_name = node_text(method)\n                    if method_name in (\"require\", \"require_relative\", \"load\"):\n                        args = node.child_by_field_name(\"arguments\")\n                        if args:\n                            for arg in args.children:\n                                if arg.type == \"string\":\n                                    path = node_text(arg).strip(\"'\\\"\")\n                                    imports.append(ImportReference(\n                                        module=path,\n                                        names=[],\n                                        line=node.start_point[0] + 1,\n                                        is_from=True\n                                    ))\n                                    break\n                    else:\n                        # Regular method call\n                        calls.append(CallReference(\n                            caller=\"\",\n                            callee=method_name,\n                            line=node.start_point[0] + 1,\n                            context=\"call\"\n                        ))\n            \n            # Method calls (method_call node type)\n            elif node_type == \"method_call\":\n                method = node.child_by_field_name(\"method\")\n                if method:\n                    calls.append(CallReference(\n                        caller=\"\",\n                        callee=node_text(method),\n                        line=node.start_point[0] + 1,\n                        context=\"call\"\n                    ))\n            \n            for child in node.children:\n                walk(child, parent_class)\n        \n        walk(root)\n        \n        return {\n            \"symbols\": symbols,\n            \"imports\": imports,\n            \"calls\": calls,\n            \"language\": \"ruby\"\n        }\n    \n    def _get_ts_parser(self, language: str):\n        \"\"\"Get or create tree-sitter parser for language.\n\n        Uses tree-sitter 0.25+ API with pre-loaded Language objects.\n        \"\"\"\n        if language in self._parsers:\n            return self._parsers[language]\n\n        if not _TS_AVAILABLE or language not in _TS_LANGUAGES:\n            return None\n\n        try:\n            lang = _TS_LANGUAGES[language]\n            parser = Parser(lang)\n            self._parsers[language] = parser\n            return parser\n        except Exception as e:\n            logger.warning(f\"Failed to create tree-sitter parser for {language}: {e}\")\n            return None\n    \n    # ---- Generic/fallback analysis ----\n    \n    def _analyze_generic(\n        self, content: str, file_path: str, language: str\n    ) -> Dict[str, Any]:\n        \"\"\"Fallback regex-based analysis for unsupported languages.\"\"\"\n        symbols = []\n        lines = content.splitlines()\n        \n        # Very basic heuristics\n        for i, line in enumerate(lines, 1):\n            # Try to find function-like patterns\n            if re.match(r'^\\s*(def|function|func|fn)\\s+(\\w+)', line):\n                match = re.match(r'^\\s*(?:def|function|func|fn)\\s+(\\w+)', line)\n                if match:\n                    symbols.append(CodeSymbol(\n                        name=match.group(1),\n                        kind=\"function\",\n                        start_line=i,\n                        end_line=i  # Can't determine without parsing\n                    ))\n            \n            # Try to find class-like patterns\n            if re.match(r'^\\s*class\\s+(\\w+)', line):\n                match = re.match(r'^\\s*class\\s+(\\w+)', line)\n                if match:\n                    symbols.append(CodeSymbol(\n                        name=match.group(1),\n                        kind=\"class\",\n                        start_line=i,\n                        end_line=i\n                    ))\n        \n        return {\n            \"symbols\": symbols,\n            \"imports\": [],\n            \"calls\": [],\n            \"language\": language\n        }\n    \n    # ---- Helper methods ----\n    \n    def _empty_analysis(self) -> Dict[str, Any]:\n        \"\"\"Return empty analysis result.\"\"\"\n        return {\n            \"symbols\": [],\n            \"imports\": [],\n            \"calls\": [],\n            \"language\": \"unknown\"\n        }\n    \n    def _chunk_lines_simple(\n        self, content: str, max_lines: int, overlap: int\n    ) -> List[CodeContext]:\n        \"\"\"Simple line-based chunking fallback.\"\"\"\n        lines = content.splitlines()\n        chunks = []\n        \n        i = 0\n        while i < len(lines):\n            chunk_end = min(i + max_lines, len(lines))\n            chunk_lines = lines[i:chunk_end]\n            \n            chunks.append(CodeContext(\n                chunk_text=\"\\n\".join(chunk_lines),\n                start_line=i + 1,\n                end_line=chunk_end,\n                symbols=[],\n                imports=[],\n                calls=[],\n                dependencies=set(),\n                is_semantic_unit=False\n            ))\n            \n            i = chunk_end - overlap if chunk_end < len(lines) else chunk_end\n        \n        return chunks\n    \n    def _fill_gaps(\n        self,\n        chunks: List[CodeContext],\n        lines: List[str],\n        max_lines: int,\n        overlap: int,\n        analysis: Dict[str, Any]\n    ):\n        \"\"\"Fill gaps between symbol chunks with module-level code.\"\"\"\n        if not chunks:\n            return\n        \n        # Find uncovered regions\n        covered = set()\n        for chunk in chunks:\n            covered.update(range(chunk.start_line, chunk.end_line + 1))\n        \n        gaps = []\n        gap_start = None\n        for i in range(1, len(lines) + 1):\n            if i not in covered:\n                if gap_start is None:\n                    gap_start = i\n            else:\n                if gap_start is not None:\n                    gaps.append((gap_start, i - 1))\n                    gap_start = None\n        \n        if gap_start is not None:\n            gaps.append((gap_start, len(lines)))\n        \n        # Create chunks for gaps\n        for start, end in gaps:\n            if end - start + 1 < 3:  # Skip tiny gaps\n                continue\n            \n            gap_lines = lines[start - 1:end]\n            chunks.append(CodeContext(\n                chunk_text=\"\\n\".join(gap_lines),\n                start_line=start,\n                end_line=end,\n                symbols=[],\n                imports=[imp for imp in analysis.get(\"imports\", []) if start <= imp.line <= end],\n                calls=[],\n                dependencies=set(),\n                is_semantic_unit=False\n            ))\n        \n        # Re-sort chunks by start line\n        chunks.sort(key=lambda c: c.start_line)\n    \n    def _extract_dependencies(\n        self, imports: List[ImportReference], calls: List[CallReference]\n    ) -> Set[str]:\n        \"\"\"Extract unique dependencies from imports and calls.\"\"\"\n        deps = set()\n        \n        for imp in imports:\n            deps.add(imp.module)\n            deps.update(imp.names)\n        \n        for call in calls:\n            deps.add(call.callee)\n        \n        return deps",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___init___175": {
      "name": "__init__",
      "type": "method",
      "start_line": 175,
      "end_line": 198,
      "content_hash": "b7e7c5747f2d4e6f530bbf0e6031be67ad25850b",
      "content": "    def __init__(self, use_tree_sitter: bool = True):\n        \"\"\"\n        Initialize AST analyzer.\n        \n        Args:\n            use_tree_sitter: Use tree-sitter when available (fallback to ast module)\n        \"\"\"\n        self.use_tree_sitter = use_tree_sitter and _TS_AVAILABLE\n        self._parsers: Dict[str, Any] = {}\n        \n        # Language support matrix\n        self.supported_languages = {\n            \"python\": {\"ast\": True, \"tree_sitter\": True},\n            \"javascript\": {\"ast\": False, \"tree_sitter\": True},\n            \"typescript\": {\"ast\": False, \"tree_sitter\": True},\n            \"java\": {\"ast\": False, \"tree_sitter\": True},\n            \"go\": {\"ast\": False, \"tree_sitter\": True},\n            \"rust\": {\"ast\": False, \"tree_sitter\": True},\n            \"c\": {\"ast\": False, \"tree_sitter\": True},\n            \"cpp\": {\"ast\": False, \"tree_sitter\": True},\n            \"ruby\": {\"ast\": False, \"tree_sitter\": True},\n        }\n        \n        logger.info(f\"ASTAnalyzer initialized: tree_sitter={self.use_tree_sitter}\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_analyze_file_200": {
      "name": "analyze_file",
      "type": "method",
      "start_line": 200,
      "end_line": 238,
      "content_hash": "4534bfe71d0d36566e3d210aa973cb015627cb4e",
      "content": "    def analyze_file(\n        self, file_path: str, language: str, content: Optional[str] = None\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Analyze a source file and extract semantic information.\n        \n        Args:\n            file_path: Path to the file\n            language: Programming language\n            content: Optional file content (if not provided, read from file)\n        \n        Returns:\n            Dict with symbols, imports, calls, and dependencies\n        \"\"\"\n        if content is None:\n            try:\n                content = Path(file_path).read_text(encoding=\"utf-8\", errors=\"ignore\")\n            except Exception as e:\n                logger.error(f\"Failed to read {file_path}: {e}\")\n                return self._empty_analysis()\n        \n        # Route to appropriate analyzer\n        if language == \"python\":\n            return self._analyze_python(content, file_path)\n        elif language in (\"javascript\", \"typescript\") and self.use_tree_sitter:\n            return self._analyze_js_ts(content, file_path, language)\n        elif language == \"go\" and self.use_tree_sitter:\n            return self._analyze_go(content, file_path)\n        elif language == \"rust\" and self.use_tree_sitter:\n            return self._analyze_rust(content, file_path)\n        elif language == \"java\" and self.use_tree_sitter:\n            return self._analyze_java(content, file_path)\n        elif language in (\"c\", \"cpp\") and self.use_tree_sitter:\n            return self._analyze_c_cpp(content, file_path, language)\n        elif language == \"ruby\" and self.use_tree_sitter:\n            return self._analyze_ruby(content, file_path)\n        else:\n            # Fallback to regex-based analysis\n            return self._analyze_generic(content, file_path, language)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_extract_symbols_with_context_240": {
      "name": "extract_symbols_with_context",
      "type": "method",
      "start_line": 240,
      "end_line": 250,
      "content_hash": "1646e31eaa67963590f47be0e672668e0457fb78",
      "content": "    def extract_symbols_with_context(\n        self, file_path: str, language: str, content: Optional[str] = None\n    ) -> List[CodeSymbol]:\n        \"\"\"\n        Extract code symbols with full context (docstrings, signatures, etc).\n        \n        Returns:\n            List of CodeSymbol objects with rich metadata\n        \"\"\"\n        analysis = self.analyze_file(file_path, language, content)\n        return analysis.get(\"symbols\", [])",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_chunk_semantic_252": {
      "name": "chunk_semantic",
      "type": "method",
      "start_line": 252,
      "end_line": 350,
      "content_hash": "04569be6400d12a5d02db47cf49d1bfad575f1fe",
      "content": "    def chunk_semantic(\n        self,\n        content: str,\n        language: str,\n        max_lines: int = 120,\n        overlap_lines: int = 20,\n        preserve_boundaries: bool = True\n    ) -> List[CodeContext]:\n        \"\"\"\n        Chunk code semantically, respecting function/class boundaries.\n        \n        Args:\n            content: Source code content\n            language: Programming language\n            max_lines: Maximum lines per chunk\n            overlap_lines: Overlap between chunks\n            preserve_boundaries: Try to keep complete functions/classes together\n        \n        Returns:\n            List of CodeContext objects with semantic chunks\n        \"\"\"\n        if not preserve_boundaries:\n            # Fall back to line-based chunking\n            return self._chunk_lines_simple(content, max_lines, overlap_lines)\n        \n        # Extract symbols\n        analysis = self.analyze_file(\"\", language, content)\n        symbols = analysis.get(\"symbols\", [])\n        \n        if not symbols:\n            # No symbols found, use line-based\n            return self._chunk_lines_simple(content, max_lines, overlap_lines)\n        \n        lines = content.splitlines()\n        chunks = []\n        \n        # Sort symbols by start line\n        symbols.sort(key=lambda s: s.start_line)\n        \n        i = 0\n        while i < len(symbols):\n            symbol = symbols[i]\n            \n            # Calculate chunk extent\n            chunk_start = symbol.start_line\n            chunk_end = symbol.end_line\n            symbols_in_chunk = [symbol]\n            \n            # Try to include adjacent small symbols\n            j = i + 1\n            while j < len(symbols):\n                next_symbol = symbols[j]\n                potential_end = next_symbol.end_line\n                \n                # Check if adding next symbol exceeds max_lines\n                if potential_end - chunk_start > max_lines:\n                    break\n                \n                # Check if next symbol is close enough (within overlap)\n                if next_symbol.start_line - chunk_end > overlap_lines:\n                    break\n                \n                # Include this symbol\n                chunk_end = potential_end\n                symbols_in_chunk.append(next_symbol)\n                j += 1\n            \n            # Create chunk\n            chunk_lines = lines[chunk_start - 1:chunk_end]\n            chunk_text = \"\\n\".join(chunk_lines)\n            \n            # Extract chunk-specific imports and calls\n            chunk_imports = [\n                imp for imp in analysis.get(\"imports\", [])\n                if chunk_start <= imp.line <= chunk_end\n            ]\n            chunk_calls = [\n                call for call in analysis.get(\"calls\", [])\n                if chunk_start <= call.line <= chunk_end\n            ]\n            \n            context = CodeContext(\n                chunk_text=chunk_text,\n                start_line=chunk_start,\n                end_line=chunk_end,\n                symbols=symbols_in_chunk,\n                imports=chunk_imports,\n                calls=chunk_calls,\n                dependencies=self._extract_dependencies(chunk_imports, chunk_calls),\n                is_semantic_unit=True\n            )\n            \n            chunks.append(context)\n            i = j if j > i else i + 1\n        \n        # Handle code not covered by symbols (module-level code, etc)\n        self._fill_gaps(chunks, lines, max_lines, overlap_lines, analysis)\n        \n        return chunks",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_build_call_graph_352": {
      "name": "build_call_graph",
      "type": "method",
      "start_line": 352,
      "end_line": 365,
      "content_hash": "284b322d9789a5d9c6de4554a4143f064e203c51",
      "content": "    def build_call_graph(self, file_path: str, language: str) -> Dict[str, List[str]]:\n        \"\"\"\n        Build call graph: mapping of caller -> list of callees.\n        \n        Returns:\n            Dict mapping function names to list of functions they call\n        \"\"\"\n        analysis = self.analyze_file(file_path, language)\n        \n        call_graph = defaultdict(list)\n        for call in analysis.get(\"calls\", []):\n            call_graph[call.caller].append(call.callee)\n        \n        return dict(call_graph)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_extract_dependencies_367": {
      "name": "extract_dependencies",
      "type": "method",
      "start_line": 367,
      "end_line": 392,
      "content_hash": "8786d91516f9dd7736076d48e71fe24031153481",
      "content": "    def extract_dependencies(\n        self, file_path: str, language: str\n    ) -> Dict[str, List[str]]:\n        \"\"\"\n        Extract file dependencies (imports, includes).\n        \n        Returns:\n            Dict with 'modules' (external) and 'local' (same project) imports\n        \"\"\"\n        analysis = self.analyze_file(file_path, language)\n        imports = analysis.get(\"imports\", [])\n        \n        modules = []\n        local = []\n        \n        for imp in imports:\n            # Simple heuristic: relative imports or without dots are likely local\n            if imp.module.startswith(\".\") or \"/\" in imp.module:\n                local.append(imp.module)\n            else:\n                modules.append(imp.module)\n        \n        return {\n            \"modules\": list(set(modules)),\n            \"local\": list(set(local))\n        }",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__analyze_python_396": {
      "name": "_analyze_python",
      "type": "method",
      "start_line": 396,
      "end_line": 455,
      "content_hash": "6a29b0e4a6e5d545629b02bbeec9c32e7c674181",
      "content": "    def _analyze_python(self, content: str, file_path: str) -> Dict[str, Any]:\n        \"\"\"Analyze Python code using ast module.\"\"\"\n        try:\n            tree = ast.parse(content)\n        except SyntaxError as e:\n            logger.warning(f\"Python syntax error in {file_path}: {e}\")\n            return self._empty_analysis()\n        \n        symbols = []\n        imports = []\n        calls = []\n        \n        # Extract symbols\n        for node in ast.walk(tree):\n            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n                symbol = self._extract_python_function(node, content)\n                symbols.append(symbol)\n            elif isinstance(node, ast.ClassDef):\n                symbol = self._extract_python_class(node, content)\n                symbols.append(symbol)\n        \n        # Extract imports\n        for node in ast.walk(tree):\n            if isinstance(node, ast.Import):\n                for alias in node.names:\n                    imports.append(ImportReference(\n                        module=alias.name,\n                        names=[],\n                        alias=alias.asname,\n                        line=node.lineno,\n                        is_from=False\n                    ))\n            elif isinstance(node, ast.ImportFrom):\n                names = [alias.name for alias in node.names]\n                imports.append(ImportReference(\n                    module=node.module or \"\",\n                    names=names,\n                    alias=None,\n                    line=node.lineno,\n                    is_from=True\n                ))\n        \n        # Extract calls (simplified)\n        for node in ast.walk(tree):\n            if isinstance(node, ast.Call):\n                callee = self._get_call_name(node.func)\n                if callee:\n                    calls.append(CallReference(\n                        caller=\"\",  # Would need parent context\n                        callee=callee,\n                        line=node.lineno,\n                        context=\"call\"\n                    ))\n        \n        return {\n            \"symbols\": symbols,\n            \"imports\": imports,\n            \"calls\": calls,\n            \"language\": \"python\"\n        }",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__extract_python_function_457": {
      "name": "_extract_python_function",
      "type": "method",
      "start_line": 457,
      "end_line": 493,
      "content_hash": "06db1d3d55553542d0712d5c4bf6a2ba981af6d4",
      "content": "    def _extract_python_function(self, node: ast.FunctionDef, content: str) -> CodeSymbol:\n        \"\"\"Extract detailed function information from AST node.\"\"\"\n        # Get docstring\n        docstring = ast.get_docstring(node)\n        \n        # Get decorators\n        decorators = [self._get_decorator_name(d) for d in node.decorator_list]\n        \n        # Build signature\n        args = [arg.arg for arg in node.args.args]\n        signature = f\"def {node.name}({', '.join(args)})\"\n        \n        # Calculate complexity (simplified: count branches)\n        complexity = sum(\n            1 for n in ast.walk(node)\n            if isinstance(n, (ast.If, ast.For, ast.While, ast.Try, ast.With))\n        )\n        \n        # Content hash\n        lines = content.splitlines()\n        if node.lineno <= len(lines) and node.end_lineno <= len(lines):\n            func_content = \"\\n\".join(lines[node.lineno - 1:node.end_lineno])\n            content_hash = hashlib.md5(func_content.encode()).hexdigest()[:8]\n        else:\n            content_hash = None\n        \n        return CodeSymbol(\n            name=node.name,\n            kind=\"function\",\n            start_line=node.lineno,\n            end_line=node.end_lineno or node.lineno,\n            docstring=docstring,\n            signature=signature,\n            decorators=decorators,\n            complexity=complexity,\n            content_hash=content_hash\n        )",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__extract_python_class_495": {
      "name": "_extract_python_class",
      "type": "method",
      "start_line": 495,
      "end_line": 519,
      "content_hash": "bbb5725a05f1440558669305ceec46ea47045b44",
      "content": "    def _extract_python_class(self, node: ast.ClassDef, content: str) -> CodeSymbol:\n        \"\"\"Extract detailed class information from AST node.\"\"\"\n        docstring = ast.get_docstring(node)\n        decorators = [self._get_decorator_name(d) for d in node.decorator_list]\n        \n        # Get base classes\n        bases = [self._get_name(base) for base in node.bases]\n        signature = f\"class {node.name}({', '.join(bases)})\" if bases else f\"class {node.name}\"\n        \n        # Count methods\n        methods = sum(\n            1 for n in node.body\n            if isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef))\n        )\n        \n        return CodeSymbol(\n            name=node.name,\n            kind=\"class\",\n            start_line=node.lineno,\n            end_line=node.end_lineno or node.lineno,\n            docstring=docstring,\n            signature=signature,\n            decorators=decorators,\n            complexity=methods\n        )",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__get_decorator_name_521": {
      "name": "_get_decorator_name",
      "type": "method",
      "start_line": 521,
      "end_line": 527,
      "content_hash": "074d386951a077eb19dc13c44cdb14c864153fb4",
      "content": "    def _get_decorator_name(self, node: ast.expr) -> str:\n        \"\"\"Extract decorator name from AST node.\"\"\"\n        if isinstance(node, ast.Name):\n            return node.id\n        elif isinstance(node, ast.Call):\n            return self._get_name(node.func)\n        return \"\"",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__get_name_529": {
      "name": "_get_name",
      "type": "method",
      "start_line": 529,
      "end_line": 535,
      "content_hash": "1fd5ede32a8a90f3e436418e6f478f7d366fa956",
      "content": "    def _get_name(self, node: ast.expr) -> str:\n        \"\"\"Extract name from AST expression.\"\"\"\n        if isinstance(node, ast.Name):\n            return node.id\n        elif isinstance(node, ast.Attribute):\n            return f\"{self._get_name(node.value)}.{node.attr}\"\n        return \"\"",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__get_call_name_537": {
      "name": "_get_call_name",
      "type": "method",
      "start_line": 537,
      "end_line": 544,
      "content_hash": "04f148d7bda77c81e4edc25ea18af54fec879cd6",
      "content": "    def _get_call_name(self, node: ast.expr) -> str:\n        \"\"\"Extract function name from call node.\"\"\"\n        if isinstance(node, ast.Name):\n            return node.id\n        elif isinstance(node, ast.Attribute):\n            # Return just the method name for simplicity\n            return node.attr\n        return \"\"",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__analyze_js_ts_548": {
      "name": "_analyze_js_ts",
      "type": "method",
      "start_line": 548,
      "end_line": 641,
      "content_hash": "b6be12f1bce8187485a51b5ba67d334036d12afa",
      "content": "    def _analyze_js_ts(\n        self, content: str, file_path: str, language: str\n    ) -> Dict[str, Any]:\n        \"\"\"Analyze JavaScript/TypeScript using tree-sitter.\"\"\"\n        ts_lang_key = language if language in _TS_LANGUAGES else \"javascript\"\n        parser = self._get_ts_parser(ts_lang_key)\n        if not parser:\n            return self._empty_analysis()\n        \n        try:\n            tree = parser.parse(content.encode(\"utf-8\"))\n            root = tree.root_node\n        except Exception as e:\n            logger.warning(f\"Tree-sitter parse error in {file_path}: {e}\")\n            return self._empty_analysis()\n        \n        symbols = []\n        imports = []\n        calls = []\n        \n        def node_text(n):\n            return content.encode(\"utf-8\")[n.start_byte:n.end_byte].decode(\"utf-8\", errors=\"ignore\")\n        \n        def walk(node, parent_class=None):\n            node_type = node.type\n            \n            # Classes\n            if node_type == \"class_declaration\":\n                name_node = node.child_by_field_name(\"name\")\n                class_name = node_text(name_node) if name_node else \"\"\n                \n                symbols.append(CodeSymbol(\n                    name=class_name,\n                    kind=\"class\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n                \n                # Walk class body\n                for child in node.children:\n                    walk(child, parent_class=class_name)\n                return\n            \n            # Functions\n            if node_type in (\"function_declaration\", \"arrow_function\", \"function_expression\"):\n                name_node = node.child_by_field_name(\"name\")\n                func_name = node_text(name_node) if name_node else \"<anonymous>\"\n                \n                symbols.append(CodeSymbol(\n                    name=func_name,\n                    kind=\"function\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1,\n                    parent=parent_class\n                ))\n            \n            # Methods\n            if node_type == \"method_definition\":\n                name_node = node.child_by_field_name(\"name\")\n                method_name = node_text(name_node) if name_node else \"\"\n                \n                symbols.append(CodeSymbol(\n                    name=method_name,\n                    kind=\"method\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1,\n                    parent=parent_class,\n                    path=f\"{parent_class}.{method_name}\" if parent_class else method_name\n                ))\n            \n            # Imports\n            if node_type == \"import_statement\":\n                source = node.child_by_field_name(\"source\")\n                if source:\n                    module = node_text(source).strip('\"\\'')\n                    imports.append(ImportReference(\n                        module=module,\n                        names=[],\n                        line=node.start_point[0] + 1,\n                        is_from=True\n                    ))\n            \n            # Recurse\n            for child in node.children:\n                walk(child, parent_class)\n        \n        walk(root)\n        \n        return {\n            \"symbols\": symbols,\n            \"imports\": imports,\n            \"calls\": calls,\n            \"language\": language\n        }",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_node_text_568": {
      "name": "node_text",
      "type": "method",
      "start_line": 568,
      "end_line": 569,
      "content_hash": "acb9075a30b28b5198a859d39c2f641acfaed409",
      "content": "        def node_text(n):\n            return content.encode(\"utf-8\")[n.start_byte:n.end_byte].decode(\"utf-8\", errors=\"ignore\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_walk_571": {
      "name": "walk",
      "type": "method",
      "start_line": 571,
      "end_line": 632,
      "content_hash": "25b638eac1a361c132c36ae42fc1b92b03da17f4",
      "content": "        def walk(node, parent_class=None):\n            node_type = node.type\n            \n            # Classes\n            if node_type == \"class_declaration\":\n                name_node = node.child_by_field_name(\"name\")\n                class_name = node_text(name_node) if name_node else \"\"\n                \n                symbols.append(CodeSymbol(\n                    name=class_name,\n                    kind=\"class\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n                \n                # Walk class body\n                for child in node.children:\n                    walk(child, parent_class=class_name)\n                return\n            \n            # Functions\n            if node_type in (\"function_declaration\", \"arrow_function\", \"function_expression\"):\n                name_node = node.child_by_field_name(\"name\")\n                func_name = node_text(name_node) if name_node else \"<anonymous>\"\n                \n                symbols.append(CodeSymbol(\n                    name=func_name,\n                    kind=\"function\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1,\n                    parent=parent_class\n                ))\n            \n            # Methods\n            if node_type == \"method_definition\":\n                name_node = node.child_by_field_name(\"name\")\n                method_name = node_text(name_node) if name_node else \"\"\n                \n                symbols.append(CodeSymbol(\n                    name=method_name,\n                    kind=\"method\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1,\n                    parent=parent_class,\n                    path=f\"{parent_class}.{method_name}\" if parent_class else method_name\n                ))\n            \n            # Imports\n            if node_type == \"import_statement\":\n                source = node.child_by_field_name(\"source\")\n                if source:\n                    module = node_text(source).strip('\"\\'')\n                    imports.append(ImportReference(\n                        module=module,\n                        names=[],\n                        line=node.start_point[0] + 1,\n                        is_from=True\n                    ))\n            \n            # Recurse\n            for child in node.children:\n                walk(child, parent_class)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__analyze_go_645": {
      "name": "_analyze_go",
      "type": "method",
      "start_line": 645,
      "end_line": 766,
      "content_hash": "ae28a2be74dc98d7822f638267d577308cd198d8",
      "content": "    def _analyze_go(self, content: str, file_path: str) -> Dict[str, Any]:\n        \"\"\"Analyze Go using tree-sitter.\"\"\"\n        parser = self._get_ts_parser(\"go\")\n        if not parser:\n            return self._analyze_generic(content, file_path, \"go\")\n        \n        try:\n            tree = parser.parse(content.encode(\"utf-8\"))\n            root = tree.root_node\n        except Exception as e:\n            logger.warning(f\"Tree-sitter parse error in {file_path}: {e}\")\n            return self._analyze_generic(content, file_path, \"go\")\n        \n        symbols = []\n        imports = []\n        calls = []\n        \n        def node_text(n):\n            return content.encode(\"utf-8\")[n.start_byte:n.end_byte].decode(\"utf-8\", errors=\"ignore\")\n        \n        def walk(node, parent_type=None):\n            node_type = node.type\n            \n            # Functions\n            if node_type == \"function_declaration\":\n                name_node = node.child_by_field_name(\"name\")\n                func_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=func_name,\n                    kind=\"function\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n            \n            # Methods\n            elif node_type == \"method_declaration\":\n                name_node = node.child_by_field_name(\"name\")\n                method_name = node_text(name_node) if name_node else \"\"\n                receiver = node.child_by_field_name(\"receiver\")\n                receiver_type = \"\"\n                if receiver:\n                    for child in receiver.children:\n                        if child.type == \"type_identifier\":\n                            receiver_type = node_text(child)\n                            break\n                symbols.append(CodeSymbol(\n                    name=method_name,\n                    kind=\"method\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1,\n                    parent=receiver_type,\n                    path=f\"{receiver_type}.{method_name}\" if receiver_type else method_name\n                ))\n            \n            # Types (struct, interface)\n            elif node_type == \"type_declaration\":\n                for child in node.children:\n                    if child.type == \"type_spec\":\n                        name_node = child.child_by_field_name(\"name\")\n                        type_name = node_text(name_node) if name_node else \"\"\n                        type_node = child.child_by_field_name(\"type\")\n                        kind = \"struct\"\n                        if type_node and type_node.type == \"interface_type\":\n                            kind = \"interface\"\n                        symbols.append(CodeSymbol(\n                            name=type_name,\n                            kind=kind,\n                            start_line=child.start_point[0] + 1,\n                            end_line=child.end_point[0] + 1\n                        ))\n            \n            # Imports\n            elif node_type == \"import_declaration\":\n                for child in node.children:\n                    if child.type == \"import_spec\":\n                        path_node = child.child_by_field_name(\"path\")\n                        if path_node:\n                            module = node_text(path_node).strip('\"')\n                            imports.append(ImportReference(\n                                module=module,\n                                names=[],\n                                line=child.start_point[0] + 1,\n                                is_from=True\n                            ))\n                    elif child.type == \"import_spec_list\":\n                        for spec in child.children:\n                            if spec.type == \"import_spec\":\n                                path_node = spec.child_by_field_name(\"path\")\n                                if path_node:\n                                    module = node_text(path_node).strip('\"')\n                                    imports.append(ImportReference(\n                                        module=module,\n                                        names=[],\n                                        line=spec.start_point[0] + 1,\n                                        is_from=True\n                                    ))\n            \n            # Calls\n            elif node_type == \"call_expression\":\n                func = node.child_by_field_name(\"function\")\n                if func:\n                    name = node_text(func)\n                    base = name.split(\".\")[-1] if \".\" in name else name\n                    if re.match(r\"^[A-Za-z_][A-Za-z0-9_]*$\", base):\n                        calls.append(CallReference(\n                            caller=\"\",\n                            callee=base,\n                            line=node.start_point[0] + 1,\n                            context=\"call\"\n                        ))\n            \n            for child in node.children:\n                walk(child, node_type)\n        \n        walk(root)\n        \n        return {\n            \"symbols\": symbols,\n            \"imports\": imports,\n            \"calls\": calls,\n            \"language\": \"go\"\n        }",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_node_text_662": {
      "name": "node_text",
      "type": "method",
      "start_line": 662,
      "end_line": 663,
      "content_hash": "acb9075a30b28b5198a859d39c2f641acfaed409",
      "content": "        def node_text(n):\n            return content.encode(\"utf-8\")[n.start_byte:n.end_byte].decode(\"utf-8\", errors=\"ignore\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_walk_665": {
      "name": "walk",
      "type": "method",
      "start_line": 665,
      "end_line": 757,
      "content_hash": "d352efe571deacf093bb70b3af833121afb53126",
      "content": "        def walk(node, parent_type=None):\n            node_type = node.type\n            \n            # Functions\n            if node_type == \"function_declaration\":\n                name_node = node.child_by_field_name(\"name\")\n                func_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=func_name,\n                    kind=\"function\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n            \n            # Methods\n            elif node_type == \"method_declaration\":\n                name_node = node.child_by_field_name(\"name\")\n                method_name = node_text(name_node) if name_node else \"\"\n                receiver = node.child_by_field_name(\"receiver\")\n                receiver_type = \"\"\n                if receiver:\n                    for child in receiver.children:\n                        if child.type == \"type_identifier\":\n                            receiver_type = node_text(child)\n                            break\n                symbols.append(CodeSymbol(\n                    name=method_name,\n                    kind=\"method\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1,\n                    parent=receiver_type,\n                    path=f\"{receiver_type}.{method_name}\" if receiver_type else method_name\n                ))\n            \n            # Types (struct, interface)\n            elif node_type == \"type_declaration\":\n                for child in node.children:\n                    if child.type == \"type_spec\":\n                        name_node = child.child_by_field_name(\"name\")\n                        type_name = node_text(name_node) if name_node else \"\"\n                        type_node = child.child_by_field_name(\"type\")\n                        kind = \"struct\"\n                        if type_node and type_node.type == \"interface_type\":\n                            kind = \"interface\"\n                        symbols.append(CodeSymbol(\n                            name=type_name,\n                            kind=kind,\n                            start_line=child.start_point[0] + 1,\n                            end_line=child.end_point[0] + 1\n                        ))\n            \n            # Imports\n            elif node_type == \"import_declaration\":\n                for child in node.children:\n                    if child.type == \"import_spec\":\n                        path_node = child.child_by_field_name(\"path\")\n                        if path_node:\n                            module = node_text(path_node).strip('\"')\n                            imports.append(ImportReference(\n                                module=module,\n                                names=[],\n                                line=child.start_point[0] + 1,\n                                is_from=True\n                            ))\n                    elif child.type == \"import_spec_list\":\n                        for spec in child.children:\n                            if spec.type == \"import_spec\":\n                                path_node = spec.child_by_field_name(\"path\")\n                                if path_node:\n                                    module = node_text(path_node).strip('\"')\n                                    imports.append(ImportReference(\n                                        module=module,\n                                        names=[],\n                                        line=spec.start_point[0] + 1,\n                                        is_from=True\n                                    ))\n            \n            # Calls\n            elif node_type == \"call_expression\":\n                func = node.child_by_field_name(\"function\")\n                if func:\n                    name = node_text(func)\n                    base = name.split(\".\")[-1] if \".\" in name else name\n                    if re.match(r\"^[A-Za-z_][A-Za-z0-9_]*$\", base):\n                        calls.append(CallReference(\n                            caller=\"\",\n                            callee=base,\n                            line=node.start_point[0] + 1,\n                            context=\"call\"\n                        ))\n            \n            for child in node.children:\n                walk(child, node_type)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__analyze_rust_770": {
      "name": "_analyze_rust",
      "type": "method",
      "start_line": 770,
      "end_line": 881,
      "content_hash": "4e2c62002d0f6ff501517d1654a5184fbab528ac",
      "content": "    def _analyze_rust(self, content: str, file_path: str) -> Dict[str, Any]:\n        \"\"\"Analyze Rust using tree-sitter.\"\"\"\n        parser = self._get_ts_parser(\"rust\")\n        if not parser:\n            return self._analyze_generic(content, file_path, \"rust\")\n        \n        try:\n            tree = parser.parse(content.encode(\"utf-8\"))\n            root = tree.root_node\n        except Exception as e:\n            logger.warning(f\"Tree-sitter parse error in {file_path}: {e}\")\n            return self._analyze_generic(content, file_path, \"rust\")\n        \n        symbols = []\n        imports = []\n        calls = []\n        \n        def node_text(n):\n            return content.encode(\"utf-8\")[n.start_byte:n.end_byte].decode(\"utf-8\", errors=\"ignore\")\n        \n        def walk(node, parent_struct=None):\n            node_type = node.type\n            \n            # Functions\n            if node_type == \"function_item\":\n                name_node = node.child_by_field_name(\"name\")\n                func_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=func_name,\n                    kind=\"function\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1,\n                    parent=parent_struct\n                ))\n            \n            # Structs\n            elif node_type == \"struct_item\":\n                name_node = node.child_by_field_name(\"name\")\n                struct_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=struct_name,\n                    kind=\"struct\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n            \n            # Enums\n            elif node_type == \"enum_item\":\n                name_node = node.child_by_field_name(\"name\")\n                enum_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=enum_name,\n                    kind=\"enum\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n            \n            # Traits\n            elif node_type == \"trait_item\":\n                name_node = node.child_by_field_name(\"name\")\n                trait_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=trait_name,\n                    kind=\"trait\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n            \n            # Impl blocks\n            elif node_type == \"impl_item\":\n                type_node = node.child_by_field_name(\"type\")\n                impl_type = node_text(type_node).split(\"<\")[0].strip() if type_node else \"\"\n                for child in node.children:\n                    walk(child, impl_type)\n                return\n            \n            # Use statements\n            elif node_type == \"use_declaration\":\n                arg = node.child_by_field_name(\"argument\")\n                if arg:\n                    imports.append(ImportReference(\n                        module=node_text(arg).strip(),\n                        names=[],\n                        line=node.start_point[0] + 1,\n                        is_from=True\n                    ))\n            \n            # Calls and macros\n            elif node_type in (\"call_expression\", \"macro_invocation\"):\n                func = node.child_by_field_name(\"function\") or node.child_by_field_name(\"macro\")\n                if func:\n                    name = node_text(func)\n                    base = name.split(\"::\")[-1].rstrip(\"!\") if \"::\" in name else name.rstrip(\"!\")\n                    if re.match(r\"^[A-Za-z_][A-Za-z0-9_]*$\", base):\n                        calls.append(CallReference(\n                            caller=\"\",\n                            callee=base,\n                            line=node.start_point[0] + 1,\n                            context=\"call\"\n                        ))\n            \n            for child in node.children:\n                walk(child, parent_struct)\n        \n        walk(root)\n        \n        return {\n            \"symbols\": symbols,\n            \"imports\": imports,\n            \"calls\": calls,\n            \"language\": \"rust\"\n        }",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_node_text_787": {
      "name": "node_text",
      "type": "method",
      "start_line": 787,
      "end_line": 788,
      "content_hash": "acb9075a30b28b5198a859d39c2f641acfaed409",
      "content": "        def node_text(n):\n            return content.encode(\"utf-8\")[n.start_byte:n.end_byte].decode(\"utf-8\", errors=\"ignore\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_walk_790": {
      "name": "walk",
      "type": "method",
      "start_line": 790,
      "end_line": 872,
      "content_hash": "c0a705d005113857d34ca42bc1441d336d17b70a",
      "content": "        def walk(node, parent_struct=None):\n            node_type = node.type\n            \n            # Functions\n            if node_type == \"function_item\":\n                name_node = node.child_by_field_name(\"name\")\n                func_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=func_name,\n                    kind=\"function\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1,\n                    parent=parent_struct\n                ))\n            \n            # Structs\n            elif node_type == \"struct_item\":\n                name_node = node.child_by_field_name(\"name\")\n                struct_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=struct_name,\n                    kind=\"struct\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n            \n            # Enums\n            elif node_type == \"enum_item\":\n                name_node = node.child_by_field_name(\"name\")\n                enum_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=enum_name,\n                    kind=\"enum\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n            \n            # Traits\n            elif node_type == \"trait_item\":\n                name_node = node.child_by_field_name(\"name\")\n                trait_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=trait_name,\n                    kind=\"trait\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n            \n            # Impl blocks\n            elif node_type == \"impl_item\":\n                type_node = node.child_by_field_name(\"type\")\n                impl_type = node_text(type_node).split(\"<\")[0].strip() if type_node else \"\"\n                for child in node.children:\n                    walk(child, impl_type)\n                return\n            \n            # Use statements\n            elif node_type == \"use_declaration\":\n                arg = node.child_by_field_name(\"argument\")\n                if arg:\n                    imports.append(ImportReference(\n                        module=node_text(arg).strip(),\n                        names=[],\n                        line=node.start_point[0] + 1,\n                        is_from=True\n                    ))\n            \n            # Calls and macros\n            elif node_type in (\"call_expression\", \"macro_invocation\"):\n                func = node.child_by_field_name(\"function\") or node.child_by_field_name(\"macro\")\n                if func:\n                    name = node_text(func)\n                    base = name.split(\"::\")[-1].rstrip(\"!\") if \"::\" in name else name.rstrip(\"!\")\n                    if re.match(r\"^[A-Za-z_][A-Za-z0-9_]*$\", base):\n                        calls.append(CallReference(\n                            caller=\"\",\n                            callee=base,\n                            line=node.start_point[0] + 1,\n                            context=\"call\"\n                        ))\n            \n            for child in node.children:\n                walk(child, parent_struct)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__analyze_java_885": {
      "name": "_analyze_java",
      "type": "method",
      "start_line": 885,
      "end_line": 994,
      "content_hash": "0aff408b463983c0d8c2aa2847503e50b8433c11",
      "content": "    def _analyze_java(self, content: str, file_path: str) -> Dict[str, Any]:\n        \"\"\"Analyze Java using tree-sitter.\"\"\"\n        parser = self._get_ts_parser(\"java\")\n        if not parser:\n            return self._analyze_generic(content, file_path, \"java\")\n        \n        try:\n            tree = parser.parse(content.encode(\"utf-8\"))\n            root = tree.root_node\n        except Exception as e:\n            logger.warning(f\"Tree-sitter parse error in {file_path}: {e}\")\n            return self._analyze_generic(content, file_path, \"java\")\n        \n        symbols = []\n        imports = []\n        calls = []\n        \n        def node_text(n):\n            return content.encode(\"utf-8\")[n.start_byte:n.end_byte].decode(\"utf-8\", errors=\"ignore\")\n        \n        def walk(node, parent_class=None):\n            node_type = node.type\n            \n            # Classes\n            if node_type == \"class_declaration\":\n                name_node = node.child_by_field_name(\"name\")\n                class_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=class_name,\n                    kind=\"class\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n                for child in node.children:\n                    walk(child, class_name)\n                return\n            \n            # Interfaces\n            elif node_type == \"interface_declaration\":\n                name_node = node.child_by_field_name(\"name\")\n                iface_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=iface_name,\n                    kind=\"interface\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n                for child in node.children:\n                    walk(child, iface_name)\n                return\n            \n            # Methods\n            elif node_type == \"method_declaration\":\n                name_node = node.child_by_field_name(\"name\")\n                method_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=method_name,\n                    kind=\"method\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1,\n                    parent=parent_class,\n                    path=f\"{parent_class}.{method_name}\" if parent_class else method_name\n                ))\n            \n            # Constructors\n            elif node_type == \"constructor_declaration\":\n                name_node = node.child_by_field_name(\"name\")\n                ctor_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=ctor_name,\n                    kind=\"constructor\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1,\n                    parent=parent_class\n                ))\n            \n            # Imports\n            elif node_type == \"import_declaration\":\n                for child in node.children:\n                    if child.type == \"scoped_identifier\" or child.type == \"identifier\":\n                        imports.append(ImportReference(\n                            module=node_text(child),\n                            names=[],\n                            line=node.start_point[0] + 1,\n                            is_from=True\n                        ))\n                        break\n            \n            # Method calls\n            elif node_type == \"method_invocation\":\n                name_node = node.child_by_field_name(\"name\")\n                if name_node:\n                    calls.append(CallReference(\n                        caller=\"\",\n                        callee=node_text(name_node),\n                        line=node.start_point[0] + 1,\n                        context=\"call\"\n                    ))\n            \n            for child in node.children:\n                walk(child, parent_class)\n        \n        walk(root)\n        \n        return {\n            \"symbols\": symbols,\n            \"imports\": imports,\n            \"calls\": calls,\n            \"language\": \"java\"\n        }",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_node_text_902": {
      "name": "node_text",
      "type": "method",
      "start_line": 902,
      "end_line": 903,
      "content_hash": "acb9075a30b28b5198a859d39c2f641acfaed409",
      "content": "        def node_text(n):\n            return content.encode(\"utf-8\")[n.start_byte:n.end_byte].decode(\"utf-8\", errors=\"ignore\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_walk_905": {
      "name": "walk",
      "type": "method",
      "start_line": 905,
      "end_line": 985,
      "content_hash": "3bccd42d3962fdd6352484b670641d6b9b1ea3c6",
      "content": "        def walk(node, parent_class=None):\n            node_type = node.type\n            \n            # Classes\n            if node_type == \"class_declaration\":\n                name_node = node.child_by_field_name(\"name\")\n                class_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=class_name,\n                    kind=\"class\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n                for child in node.children:\n                    walk(child, class_name)\n                return\n            \n            # Interfaces\n            elif node_type == \"interface_declaration\":\n                name_node = node.child_by_field_name(\"name\")\n                iface_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=iface_name,\n                    kind=\"interface\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n                for child in node.children:\n                    walk(child, iface_name)\n                return\n            \n            # Methods\n            elif node_type == \"method_declaration\":\n                name_node = node.child_by_field_name(\"name\")\n                method_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=method_name,\n                    kind=\"method\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1,\n                    parent=parent_class,\n                    path=f\"{parent_class}.{method_name}\" if parent_class else method_name\n                ))\n            \n            # Constructors\n            elif node_type == \"constructor_declaration\":\n                name_node = node.child_by_field_name(\"name\")\n                ctor_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=ctor_name,\n                    kind=\"constructor\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1,\n                    parent=parent_class\n                ))\n            \n            # Imports\n            elif node_type == \"import_declaration\":\n                for child in node.children:\n                    if child.type == \"scoped_identifier\" or child.type == \"identifier\":\n                        imports.append(ImportReference(\n                            module=node_text(child),\n                            names=[],\n                            line=node.start_point[0] + 1,\n                            is_from=True\n                        ))\n                        break\n            \n            # Method calls\n            elif node_type == \"method_invocation\":\n                name_node = node.child_by_field_name(\"name\")\n                if name_node:\n                    calls.append(CallReference(\n                        caller=\"\",\n                        callee=node_text(name_node),\n                        line=node.start_point[0] + 1,\n                        context=\"call\"\n                    ))\n            \n            for child in node.children:\n                walk(child, parent_class)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__analyze_c_cpp_998": {
      "name": "_analyze_c_cpp",
      "type": "method",
      "start_line": 998,
      "end_line": 1108,
      "content_hash": "3e49b006b7dbacaa20f9724ece8c6bd74534dc00",
      "content": "    def _analyze_c_cpp(self, content: str, file_path: str, language: str) -> Dict[str, Any]:\n        \"\"\"Analyze C/C++ using tree-sitter.\"\"\"\n        parser = self._get_ts_parser(language)\n        if not parser:\n            return self._analyze_generic(content, file_path, language)\n        \n        try:\n            tree = parser.parse(content.encode(\"utf-8\"))\n            root = tree.root_node\n        except Exception as e:\n            logger.warning(f\"Tree-sitter parse error in {file_path}: {e}\")\n            return self._analyze_generic(content, file_path, language)\n        \n        symbols = []\n        imports = []\n        calls = []\n        \n        def node_text(n):\n            return content.encode(\"utf-8\")[n.start_byte:n.end_byte].decode(\"utf-8\", errors=\"ignore\")\n        \n        def walk(node, parent_class=None):\n            node_type = node.type\n            \n            # Functions\n            if node_type == \"function_definition\":\n                decl = node.child_by_field_name(\"declarator\")\n                func_name = \"\"\n                if decl:\n                    for child in decl.children:\n                        if child.type == \"identifier\":\n                            func_name = node_text(child)\n                            break\n                        elif child.type == \"function_declarator\":\n                            for subchild in child.children:\n                                if subchild.type == \"identifier\":\n                                    func_name = node_text(subchild)\n                                    break\n                if func_name:\n                    symbols.append(CodeSymbol(\n                        name=func_name,\n                        kind=\"function\",\n                        start_line=node.start_point[0] + 1,\n                        end_line=node.end_point[0] + 1,\n                        parent=parent_class\n                    ))\n            \n            # Classes (C++)\n            elif node_type == \"class_specifier\":\n                name_node = node.child_by_field_name(\"name\")\n                class_name = node_text(name_node) if name_node else \"\"\n                if class_name:\n                    symbols.append(CodeSymbol(\n                        name=class_name,\n                        kind=\"class\",\n                        start_line=node.start_point[0] + 1,\n                        end_line=node.end_point[0] + 1\n                    ))\n                    for child in node.children:\n                        walk(child, class_name)\n                    return\n            \n            # Structs\n            elif node_type == \"struct_specifier\":\n                name_node = node.child_by_field_name(\"name\")\n                struct_name = node_text(name_node) if name_node else \"\"\n                if struct_name:\n                    symbols.append(CodeSymbol(\n                        name=struct_name,\n                        kind=\"struct\",\n                        start_line=node.start_point[0] + 1,\n                        end_line=node.end_point[0] + 1\n                    ))\n            \n            # Includes\n            elif node_type == \"preproc_include\":\n                path_node = node.child_by_field_name(\"path\")\n                if path_node:\n                    path = node_text(path_node).strip('<\">').strip()\n                    imports.append(ImportReference(\n                        module=path,\n                        names=[],\n                        line=node.start_point[0] + 1,\n                        is_from=False\n                    ))\n            \n            # Calls\n            elif node_type == \"call_expression\":\n                func = node.child_by_field_name(\"function\")\n                if func:\n                    name = node_text(func)\n                    # Handle namespaced calls like std::cout\n                    base = name.split(\"::\")[-1] if \"::\" in name else name\n                    if re.match(r\"^[A-Za-z_][A-Za-z0-9_]*$\", base):\n                        calls.append(CallReference(\n                            caller=\"\",\n                            callee=base,\n                            line=node.start_point[0] + 1,\n                            context=\"call\"\n                        ))\n            \n            for child in node.children:\n                walk(child, parent_class)\n        \n        walk(root)\n        \n        return {\n            \"symbols\": symbols,\n            \"imports\": imports,\n            \"calls\": calls,\n            \"language\": language\n        }",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_node_text_1015": {
      "name": "node_text",
      "type": "method",
      "start_line": 1015,
      "end_line": 1016,
      "content_hash": "acb9075a30b28b5198a859d39c2f641acfaed409",
      "content": "        def node_text(n):\n            return content.encode(\"utf-8\")[n.start_byte:n.end_byte].decode(\"utf-8\", errors=\"ignore\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_walk_1018": {
      "name": "walk",
      "type": "method",
      "start_line": 1018,
      "end_line": 1099,
      "content_hash": "4c4a39588b0fa9c1b5b692371e29e5706ea58fe6",
      "content": "        def walk(node, parent_class=None):\n            node_type = node.type\n            \n            # Functions\n            if node_type == \"function_definition\":\n                decl = node.child_by_field_name(\"declarator\")\n                func_name = \"\"\n                if decl:\n                    for child in decl.children:\n                        if child.type == \"identifier\":\n                            func_name = node_text(child)\n                            break\n                        elif child.type == \"function_declarator\":\n                            for subchild in child.children:\n                                if subchild.type == \"identifier\":\n                                    func_name = node_text(subchild)\n                                    break\n                if func_name:\n                    symbols.append(CodeSymbol(\n                        name=func_name,\n                        kind=\"function\",\n                        start_line=node.start_point[0] + 1,\n                        end_line=node.end_point[0] + 1,\n                        parent=parent_class\n                    ))\n            \n            # Classes (C++)\n            elif node_type == \"class_specifier\":\n                name_node = node.child_by_field_name(\"name\")\n                class_name = node_text(name_node) if name_node else \"\"\n                if class_name:\n                    symbols.append(CodeSymbol(\n                        name=class_name,\n                        kind=\"class\",\n                        start_line=node.start_point[0] + 1,\n                        end_line=node.end_point[0] + 1\n                    ))\n                    for child in node.children:\n                        walk(child, class_name)\n                    return\n            \n            # Structs\n            elif node_type == \"struct_specifier\":\n                name_node = node.child_by_field_name(\"name\")\n                struct_name = node_text(name_node) if name_node else \"\"\n                if struct_name:\n                    symbols.append(CodeSymbol(\n                        name=struct_name,\n                        kind=\"struct\",\n                        start_line=node.start_point[0] + 1,\n                        end_line=node.end_point[0] + 1\n                    ))\n            \n            # Includes\n            elif node_type == \"preproc_include\":\n                path_node = node.child_by_field_name(\"path\")\n                if path_node:\n                    path = node_text(path_node).strip('<\">').strip()\n                    imports.append(ImportReference(\n                        module=path,\n                        names=[],\n                        line=node.start_point[0] + 1,\n                        is_from=False\n                    ))\n            \n            # Calls\n            elif node_type == \"call_expression\":\n                func = node.child_by_field_name(\"function\")\n                if func:\n                    name = node_text(func)\n                    # Handle namespaced calls like std::cout\n                    base = name.split(\"::\")[-1] if \"::\" in name else name\n                    if re.match(r\"^[A-Za-z_][A-Za-z0-9_]*$\", base):\n                        calls.append(CallReference(\n                            caller=\"\",\n                            callee=base,\n                            line=node.start_point[0] + 1,\n                            context=\"call\"\n                        ))\n            \n            for child in node.children:\n                walk(child, parent_class)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__analyze_ruby_1112": {
      "name": "_analyze_ruby",
      "type": "method",
      "start_line": 1112,
      "end_line": 1224,
      "content_hash": "2d2fd4560a1f733081739a5bf347780db59387e8",
      "content": "    def _analyze_ruby(self, content: str, file_path: str) -> Dict[str, Any]:\n        \"\"\"Analyze Ruby using tree-sitter.\"\"\"\n        parser = self._get_ts_parser(\"ruby\")\n        if not parser:\n            return self._analyze_generic(content, file_path, \"ruby\")\n        \n        try:\n            tree = parser.parse(content.encode(\"utf-8\"))\n            root = tree.root_node\n        except Exception as e:\n            logger.warning(f\"Tree-sitter parse error in {file_path}: {e}\")\n            return self._analyze_generic(content, file_path, \"ruby\")\n        \n        symbols = []\n        imports = []\n        calls = []\n        \n        def node_text(n):\n            return content.encode(\"utf-8\")[n.start_byte:n.end_byte].decode(\"utf-8\", errors=\"ignore\")\n        \n        def walk(node, parent_class=None):\n            node_type = node.type\n            \n            # Classes\n            if node_type == \"class\":\n                name_node = node.child_by_field_name(\"name\")\n                class_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=class_name,\n                    kind=\"class\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n                for child in node.children:\n                    walk(child, class_name)\n                return\n            \n            # Modules\n            elif node_type == \"module\":\n                name_node = node.child_by_field_name(\"name\")\n                module_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=module_name,\n                    kind=\"module\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n                for child in node.children:\n                    walk(child, module_name)\n                return\n            \n            # Methods\n            elif node_type == \"method\":\n                name_node = node.child_by_field_name(\"name\")\n                method_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=method_name,\n                    kind=\"method\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1,\n                    parent=parent_class,\n                    path=f\"{parent_class}.{method_name}\" if parent_class else method_name\n                ))\n            \n            # Require statements\n            elif node_type == \"call\":\n                method = node.child_by_field_name(\"method\")\n                if method:\n                    method_name = node_text(method)\n                    if method_name in (\"require\", \"require_relative\", \"load\"):\n                        args = node.child_by_field_name(\"arguments\")\n                        if args:\n                            for arg in args.children:\n                                if arg.type == \"string\":\n                                    path = node_text(arg).strip(\"'\\\"\")\n                                    imports.append(ImportReference(\n                                        module=path,\n                                        names=[],\n                                        line=node.start_point[0] + 1,\n                                        is_from=True\n                                    ))\n                                    break\n                    else:\n                        # Regular method call\n                        calls.append(CallReference(\n                            caller=\"\",\n                            callee=method_name,\n                            line=node.start_point[0] + 1,\n                            context=\"call\"\n                        ))\n            \n            # Method calls (method_call node type)\n            elif node_type == \"method_call\":\n                method = node.child_by_field_name(\"method\")\n                if method:\n                    calls.append(CallReference(\n                        caller=\"\",\n                        callee=node_text(method),\n                        line=node.start_point[0] + 1,\n                        context=\"call\"\n                    ))\n            \n            for child in node.children:\n                walk(child, parent_class)\n        \n        walk(root)\n        \n        return {\n            \"symbols\": symbols,\n            \"imports\": imports,\n            \"calls\": calls,\n            \"language\": \"ruby\"\n        }",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_node_text_1129": {
      "name": "node_text",
      "type": "method",
      "start_line": 1129,
      "end_line": 1130,
      "content_hash": "acb9075a30b28b5198a859d39c2f641acfaed409",
      "content": "        def node_text(n):\n            return content.encode(\"utf-8\")[n.start_byte:n.end_byte].decode(\"utf-8\", errors=\"ignore\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_walk_1132": {
      "name": "walk",
      "type": "method",
      "start_line": 1132,
      "end_line": 1215,
      "content_hash": "1e834b4f17cf42957a6d576aca6013bc4f3661cd",
      "content": "        def walk(node, parent_class=None):\n            node_type = node.type\n            \n            # Classes\n            if node_type == \"class\":\n                name_node = node.child_by_field_name(\"name\")\n                class_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=class_name,\n                    kind=\"class\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n                for child in node.children:\n                    walk(child, class_name)\n                return\n            \n            # Modules\n            elif node_type == \"module\":\n                name_node = node.child_by_field_name(\"name\")\n                module_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=module_name,\n                    kind=\"module\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1\n                ))\n                for child in node.children:\n                    walk(child, module_name)\n                return\n            \n            # Methods\n            elif node_type == \"method\":\n                name_node = node.child_by_field_name(\"name\")\n                method_name = node_text(name_node) if name_node else \"\"\n                symbols.append(CodeSymbol(\n                    name=method_name,\n                    kind=\"method\",\n                    start_line=node.start_point[0] + 1,\n                    end_line=node.end_point[0] + 1,\n                    parent=parent_class,\n                    path=f\"{parent_class}.{method_name}\" if parent_class else method_name\n                ))\n            \n            # Require statements\n            elif node_type == \"call\":\n                method = node.child_by_field_name(\"method\")\n                if method:\n                    method_name = node_text(method)\n                    if method_name in (\"require\", \"require_relative\", \"load\"):\n                        args = node.child_by_field_name(\"arguments\")\n                        if args:\n                            for arg in args.children:\n                                if arg.type == \"string\":\n                                    path = node_text(arg).strip(\"'\\\"\")\n                                    imports.append(ImportReference(\n                                        module=path,\n                                        names=[],\n                                        line=node.start_point[0] + 1,\n                                        is_from=True\n                                    ))\n                                    break\n                    else:\n                        # Regular method call\n                        calls.append(CallReference(\n                            caller=\"\",\n                            callee=method_name,\n                            line=node.start_point[0] + 1,\n                            context=\"call\"\n                        ))\n            \n            # Method calls (method_call node type)\n            elif node_type == \"method_call\":\n                method = node.child_by_field_name(\"method\")\n                if method:\n                    calls.append(CallReference(\n                        caller=\"\",\n                        callee=node_text(method),\n                        line=node.start_point[0] + 1,\n                        context=\"call\"\n                    ))\n            \n            for child in node.children:\n                walk(child, parent_class)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__get_ts_parser_1226": {
      "name": "_get_ts_parser",
      "type": "method",
      "start_line": 1226,
      "end_line": 1244,
      "content_hash": "f55c49ea06de440d620b337a9b8a7f60faec7844",
      "content": "    def _get_ts_parser(self, language: str):\n        \"\"\"Get or create tree-sitter parser for language.\n\n        Uses tree-sitter 0.25+ API with pre-loaded Language objects.\n        \"\"\"\n        if language in self._parsers:\n            return self._parsers[language]\n\n        if not _TS_AVAILABLE or language not in _TS_LANGUAGES:\n            return None\n\n        try:\n            lang = _TS_LANGUAGES[language]\n            parser = Parser(lang)\n            self._parsers[language] = parser\n            return parser\n        except Exception as e:\n            logger.warning(f\"Failed to create tree-sitter parser for {language}: {e}\")\n            return None",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__analyze_generic_1248": {
      "name": "_analyze_generic",
      "type": "method",
      "start_line": 1248,
      "end_line": 1284,
      "content_hash": "2ad52dc202e672fb14b767389c032715e56a494a",
      "content": "    def _analyze_generic(\n        self, content: str, file_path: str, language: str\n    ) -> Dict[str, Any]:\n        \"\"\"Fallback regex-based analysis for unsupported languages.\"\"\"\n        symbols = []\n        lines = content.splitlines()\n        \n        # Very basic heuristics\n        for i, line in enumerate(lines, 1):\n            # Try to find function-like patterns\n            if re.match(r'^\\s*(def|function|func|fn)\\s+(\\w+)', line):\n                match = re.match(r'^\\s*(?:def|function|func|fn)\\s+(\\w+)', line)\n                if match:\n                    symbols.append(CodeSymbol(\n                        name=match.group(1),\n                        kind=\"function\",\n                        start_line=i,\n                        end_line=i  # Can't determine without parsing\n                    ))\n            \n            # Try to find class-like patterns\n            if re.match(r'^\\s*class\\s+(\\w+)', line):\n                match = re.match(r'^\\s*class\\s+(\\w+)', line)\n                if match:\n                    symbols.append(CodeSymbol(\n                        name=match.group(1),\n                        kind=\"class\",\n                        start_line=i,\n                        end_line=i\n                    ))\n        \n        return {\n            \"symbols\": symbols,\n            \"imports\": [],\n            \"calls\": [],\n            \"language\": language\n        }",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__empty_analysis_1288": {
      "name": "_empty_analysis",
      "type": "method",
      "start_line": 1288,
      "end_line": 1295,
      "content_hash": "015f1540b0e9338571f079e87119faf0f07ee4ef",
      "content": "    def _empty_analysis(self) -> Dict[str, Any]:\n        \"\"\"Return empty analysis result.\"\"\"\n        return {\n            \"symbols\": [],\n            \"imports\": [],\n            \"calls\": [],\n            \"language\": \"unknown\"\n        }",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__chunk_lines_simple_1297": {
      "name": "_chunk_lines_simple",
      "type": "method",
      "start_line": 1297,
      "end_line": 1322,
      "content_hash": "543917aa610d86b995a2203205a5b6cf495c870b",
      "content": "    def _chunk_lines_simple(\n        self, content: str, max_lines: int, overlap: int\n    ) -> List[CodeContext]:\n        \"\"\"Simple line-based chunking fallback.\"\"\"\n        lines = content.splitlines()\n        chunks = []\n        \n        i = 0\n        while i < len(lines):\n            chunk_end = min(i + max_lines, len(lines))\n            chunk_lines = lines[i:chunk_end]\n            \n            chunks.append(CodeContext(\n                chunk_text=\"\\n\".join(chunk_lines),\n                start_line=i + 1,\n                end_line=chunk_end,\n                symbols=[],\n                imports=[],\n                calls=[],\n                dependencies=set(),\n                is_semantic_unit=False\n            ))\n            \n            i = chunk_end - overlap if chunk_end < len(lines) else chunk_end\n        \n        return chunks",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__fill_gaps_1324": {
      "name": "_fill_gaps",
      "type": "method",
      "start_line": 1324,
      "end_line": 1373,
      "content_hash": "192751044229ee827cc244786cfa60103758f095",
      "content": "    def _fill_gaps(\n        self,\n        chunks: List[CodeContext],\n        lines: List[str],\n        max_lines: int,\n        overlap: int,\n        analysis: Dict[str, Any]\n    ):\n        \"\"\"Fill gaps between symbol chunks with module-level code.\"\"\"\n        if not chunks:\n            return\n        \n        # Find uncovered regions\n        covered = set()\n        for chunk in chunks:\n            covered.update(range(chunk.start_line, chunk.end_line + 1))\n        \n        gaps = []\n        gap_start = None\n        for i in range(1, len(lines) + 1):\n            if i not in covered:\n                if gap_start is None:\n                    gap_start = i\n            else:\n                if gap_start is not None:\n                    gaps.append((gap_start, i - 1))\n                    gap_start = None\n        \n        if gap_start is not None:\n            gaps.append((gap_start, len(lines)))\n        \n        # Create chunks for gaps\n        for start, end in gaps:\n            if end - start + 1 < 3:  # Skip tiny gaps\n                continue\n            \n            gap_lines = lines[start - 1:end]\n            chunks.append(CodeContext(\n                chunk_text=\"\\n\".join(gap_lines),\n                start_line=start,\n                end_line=end,\n                symbols=[],\n                imports=[imp for imp in analysis.get(\"imports\", []) if start <= imp.line <= end],\n                calls=[],\n                dependencies=set(),\n                is_semantic_unit=False\n            ))\n        \n        # Re-sort chunks by start line\n        chunks.sort(key=lambda c: c.start_line)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__extract_dependencies_1375": {
      "name": "_extract_dependencies",
      "type": "method",
      "start_line": 1375,
      "end_line": 1388,
      "content_hash": "42d47ecaa7c7f29329354451aeba0a2e2fe77301",
      "content": "    def _extract_dependencies(\n        self, imports: List[ImportReference], calls: List[CallReference]\n    ) -> Set[str]:\n        \"\"\"Extract unique dependencies from imports and calls.\"\"\"\n        deps = set()\n        \n        for imp in imports:\n            deps.add(imp.module)\n            deps.update(imp.names)\n        \n        for call in calls:\n            deps.add(call.callee)\n        \n        return deps",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_get_ast_analyzer_1395": {
      "name": "get_ast_analyzer",
      "type": "function",
      "start_line": 1395,
      "end_line": 1403,
      "content_hash": "bf707a41df5b4972a3ed26b2e6792573c952bfb7",
      "content": "def get_ast_analyzer(reset: bool = False) -> ASTAnalyzer:\n    \"\"\"Get or create global AST analyzer instance.\"\"\"\n    global _analyzer\n    \n    if _analyzer is None or reset:\n        use_ts = os.environ.get(\"USE_TREE_SITTER\", \"1\").lower() in {\"1\", \"true\", \"yes\", \"on\"}\n        _analyzer = ASTAnalyzer(use_tree_sitter=use_ts)\n    \n    return _analyzer",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_extract_symbols_1407": {
      "name": "extract_symbols",
      "type": "function",
      "start_line": 1407,
      "end_line": 1410,
      "content_hash": "67aea02c604e11c19536bab1fca15e254e2ed86e",
      "content": "def extract_symbols(file_path: str, language: str) -> List[CodeSymbol]:\n    \"\"\"Extract symbols from a file.\"\"\"\n    analyzer = get_ast_analyzer()\n    return analyzer.extract_symbols_with_context(file_path, language)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_chunk_code_semantically_1413": {
      "name": "chunk_code_semantically",
      "type": "function",
      "start_line": 1413,
      "end_line": 1438,
      "content_hash": "8d5e0b53d7a11044d090c0fb56b51b08ced730c8",
      "content": "def chunk_code_semantically(\n    content: str,\n    language: str,\n    max_lines: int = 120,\n    overlap: int = 20\n) -> List[Dict[str, Any]]:\n    \"\"\"\n    Chunk code semantically, returning simplified dicts for indexing.\n    \n    Returns list of dicts compatible with existing chunking interface.\n    \"\"\"\n    analyzer = get_ast_analyzer()\n    contexts = analyzer.chunk_semantic(content, language, max_lines, overlap)\n    \n    # Convert to simple dict format\n    return [\n        {\n            \"text\": ctx.chunk_text,\n            \"start\": ctx.start_line,\n            \"end\": ctx.end_line,\n            \"is_semantic\": ctx.is_semantic_unit,\n            \"symbols\": [s.name for s in ctx.symbols],\n            \"symbol_types\": [s.kind for s in ctx.symbols]\n        }\n        for ctx in contexts\n    ]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}