{
  "file_path": "/work/context-engine/tests/test_rerank_recursive.py",
  "file_hash": "e8910d27a8067bd9da10f923c8d6ab6a34050ec5",
  "updated_at": "2025-12-26T17:34:21.607435",
  "symbols": {
    "class_TestTinyScorer_29": {
      "name": "TestTinyScorer",
      "type": "class",
      "start_line": 29,
      "end_line": 56,
      "content_hash": "1d3512011c505258ea14a1407f40bcbdcf4850a6",
      "content": "class TestTinyScorer:\n    \"\"\"Tests for the tiny scoring network.\"\"\"\n    \n    def test_forward_shape(self):\n        \"\"\"Scorer should produce correct output shape.\"\"\"\n        scorer = TinyScorer(dim=64, hidden_dim=128)\n        \n        query_emb = np.random.randn(64).astype(np.float32)\n        doc_embs = np.random.randn(5, 64).astype(np.float32)\n        z = np.random.randn(64).astype(np.float32)\n        \n        scores = scorer.forward(query_emb, doc_embs, z)\n        \n        assert scores.shape == (5,)\n        assert scores.dtype == np.float32\n    \n    def test_forward_deterministic(self):\n        \"\"\"Same inputs should produce same outputs.\"\"\"\n        scorer = TinyScorer(dim=64)\n        \n        query_emb = np.random.randn(64).astype(np.float32)\n        doc_embs = np.random.randn(3, 64).astype(np.float32)\n        z = np.random.randn(64).astype(np.float32)\n        \n        scores1 = scorer.forward(query_emb, doc_embs, z)\n        scores2 = scorer.forward(query_emb, doc_embs, z)\n        \n        np.testing.assert_array_almost_equal(scores1, scores2)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_forward_shape_32": {
      "name": "test_forward_shape",
      "type": "method",
      "start_line": 32,
      "end_line": 43,
      "content_hash": "5e4a5d8bd2b99455e070a2c64738f9fed9f814d9",
      "content": "    def test_forward_shape(self):\n        \"\"\"Scorer should produce correct output shape.\"\"\"\n        scorer = TinyScorer(dim=64, hidden_dim=128)\n        \n        query_emb = np.random.randn(64).astype(np.float32)\n        doc_embs = np.random.randn(5, 64).astype(np.float32)\n        z = np.random.randn(64).astype(np.float32)\n        \n        scores = scorer.forward(query_emb, doc_embs, z)\n        \n        assert scores.shape == (5,)\n        assert scores.dtype == np.float32",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_forward_deterministic_45": {
      "name": "test_forward_deterministic",
      "type": "method",
      "start_line": 45,
      "end_line": 56,
      "content_hash": "4bc4c754ceed24e01a72e574284ecebb4ed15ada",
      "content": "    def test_forward_deterministic(self):\n        \"\"\"Same inputs should produce same outputs.\"\"\"\n        scorer = TinyScorer(dim=64)\n        \n        query_emb = np.random.randn(64).astype(np.float32)\n        doc_embs = np.random.randn(3, 64).astype(np.float32)\n        z = np.random.randn(64).astype(np.float32)\n        \n        scores1 = scorer.forward(query_emb, doc_embs, z)\n        scores2 = scorer.forward(query_emb, doc_embs, z)\n        \n        np.testing.assert_array_almost_equal(scores1, scores2)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_TestLatentRefiner_59": {
      "name": "TestLatentRefiner",
      "type": "class",
      "start_line": 59,
      "end_line": 87,
      "content_hash": "85e3937940f78007836927a45478df0e29d97704",
      "content": "class TestLatentRefiner:\n    \"\"\"Tests for latent state refinement.\"\"\"\n    \n    def test_refine_shape(self):\n        \"\"\"Refiner should produce latent of same dimension.\"\"\"\n        refiner = LatentRefiner(dim=64)\n        \n        z = np.random.randn(64).astype(np.float32)\n        query_emb = np.random.randn(64).astype(np.float32)\n        doc_embs = np.random.randn(5, 64).astype(np.float32)\n        scores = np.random.randn(5).astype(np.float32)\n        \n        z_refined = refiner.refine(z, query_emb, doc_embs, scores)\n        \n        assert z_refined.shape == (64,)\n    \n    def test_refine_normalized(self):\n        \"\"\"Refined latent should be unit normalized.\"\"\"\n        refiner = LatentRefiner(dim=64)\n        \n        z = np.random.randn(64).astype(np.float32)\n        query_emb = np.random.randn(64).astype(np.float32)\n        doc_embs = np.random.randn(5, 64).astype(np.float32)\n        scores = np.random.randn(5).astype(np.float32)\n        \n        z_refined = refiner.refine(z, query_emb, doc_embs, scores)\n        \n        norm = np.linalg.norm(z_refined)\n        assert abs(norm - 1.0) < 1e-5",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_refine_shape_62": {
      "name": "test_refine_shape",
      "type": "method",
      "start_line": 62,
      "end_line": 73,
      "content_hash": "7a2dc062934bd61470ab7d8e7613a4e6daf10de1",
      "content": "    def test_refine_shape(self):\n        \"\"\"Refiner should produce latent of same dimension.\"\"\"\n        refiner = LatentRefiner(dim=64)\n        \n        z = np.random.randn(64).astype(np.float32)\n        query_emb = np.random.randn(64).astype(np.float32)\n        doc_embs = np.random.randn(5, 64).astype(np.float32)\n        scores = np.random.randn(5).astype(np.float32)\n        \n        z_refined = refiner.refine(z, query_emb, doc_embs, scores)\n        \n        assert z_refined.shape == (64,)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_refine_normalized_75": {
      "name": "test_refine_normalized",
      "type": "method",
      "start_line": 75,
      "end_line": 87,
      "content_hash": "d30552a427fbbca246a8972ac75b03dca7c3c1cc",
      "content": "    def test_refine_normalized(self):\n        \"\"\"Refined latent should be unit normalized.\"\"\"\n        refiner = LatentRefiner(dim=64)\n        \n        z = np.random.randn(64).astype(np.float32)\n        query_emb = np.random.randn(64).astype(np.float32)\n        doc_embs = np.random.randn(5, 64).astype(np.float32)\n        scores = np.random.randn(5).astype(np.float32)\n        \n        z_refined = refiner.refine(z, query_emb, doc_embs, scores)\n        \n        norm = np.linalg.norm(z_refined)\n        assert abs(norm - 1.0) < 1e-5",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_TestConfidenceEstimator_90": {
      "name": "TestConfidenceEstimator",
      "type": "class",
      "start_line": 90,
      "end_line": 194,
      "content_hash": "eb0fa3abf34a1e4c54a0c7bd8f5e4d1b761ba8a1",
      "content": "class TestConfidenceEstimator:\n    \"\"\"Tests for early stopping logic.\"\"\"\n\n    def test_no_stop_on_first_iteration(self):\n        \"\"\"Should not stop on first iteration.\"\"\"\n        estimator = ConfidenceEstimator()\n\n        state = RefinementState(\n            z=np.zeros(64),\n            scores=np.array([0.5, 0.3, 0.1]),\n            iteration=0\n        )\n        state.score_history = [state.scores]\n\n        assert not estimator.should_stop(state)\n\n    def test_stop_on_convergence(self):\n        \"\"\"Should stop when top-k rankings stabilize.\"\"\"\n        estimator = ConfidenceEstimator()\n\n        state = RefinementState(\n            z=np.zeros(64),\n            scores=np.array([0.5, 0.3, 0.1]),\n            iteration=2\n        )\n        # Same scores twice = converged\n        state.score_history = [\n            np.array([0.5, 0.3, 0.1]),\n            np.array([0.5, 0.3, 0.1])\n        ]\n\n        assert estimator.should_stop(state)\n\n    def test_single_candidate(self):\n        \"\"\"Should handle single candidate without crashing.\"\"\"\n        estimator = ConfidenceEstimator()\n\n        state = RefinementState(\n            z=np.zeros(64),\n            scores=np.array([0.5]),\n            iteration=2\n        )\n        state.score_history = [\n            np.array([0.4]),\n            np.array([0.5])\n        ]\n\n        # Should not crash and should stop (single element = stable ranking)\n        result = estimator.should_stop(state)\n        assert isinstance(result, bool)\n\n    def test_flipping_order_resets_patience(self):\n        \"\"\"Flipping ranking order should reset stability count.\"\"\"\n        estimator = ConfidenceEstimator(patience=2)\n\n        state = RefinementState(\n            z=np.zeros(64),\n            scores=np.array([0.3, 0.5, 0.1]),  # Order: 1, 0, 2\n            iteration=1\n        )\n        state.score_history = [\n            np.array([0.5, 0.3, 0.1]),  # Order: 0, 1, 2\n            np.array([0.3, 0.5, 0.1])   # Order: 1, 0, 2 (flipped!)\n        ]\n\n        # Flipped order = not stable, should not stop\n        assert not estimator.should_stop(state)\n        assert estimator._stable_count == 0\n\n    def test_patience_respected(self):\n        \"\"\"Should require patience consecutive stable iterations to stop.\"\"\"\n        estimator = ConfidenceEstimator(patience=3)\n\n        state = RefinementState(\n            z=np.zeros(64),\n            scores=np.array([0.5, 0.3, 0.1]),\n            iteration=1\n        )\n\n        # First stable iteration\n        state.score_history = [\n            np.array([0.5, 0.3, 0.1]),\n            np.array([0.5, 0.3, 0.1])\n        ]\n        assert not estimator.should_stop(state)\n        assert estimator._stable_count == 1\n\n        # Second stable iteration\n        state.score_history.append(np.array([0.5, 0.3, 0.1]))\n        assert not estimator.should_stop(state)\n        assert estimator._stable_count == 2\n\n        # Third stable iteration - now should stop\n        state.score_history.append(np.array([0.5, 0.3, 0.1]))\n        assert estimator.should_stop(state)\n        assert estimator._stable_count == 3\n\n    def test_reset_clears_state(self):\n        \"\"\"Reset should clear stability count.\"\"\"\n        estimator = ConfidenceEstimator(patience=2)\n        estimator._stable_count = 5\n\n        estimator.reset()\n\n        assert estimator._stable_count == 0",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_no_stop_on_first_iteration_93": {
      "name": "test_no_stop_on_first_iteration",
      "type": "method",
      "start_line": 93,
      "end_line": 104,
      "content_hash": "a520763035b01ee4033a8bf45f83d71b84244946",
      "content": "    def test_no_stop_on_first_iteration(self):\n        \"\"\"Should not stop on first iteration.\"\"\"\n        estimator = ConfidenceEstimator()\n\n        state = RefinementState(\n            z=np.zeros(64),\n            scores=np.array([0.5, 0.3, 0.1]),\n            iteration=0\n        )\n        state.score_history = [state.scores]\n\n        assert not estimator.should_stop(state)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_stop_on_convergence_106": {
      "name": "test_stop_on_convergence",
      "type": "method",
      "start_line": 106,
      "end_line": 121,
      "content_hash": "5ba67c5a09ee9b02df7eab93b00892777cd8ecbd",
      "content": "    def test_stop_on_convergence(self):\n        \"\"\"Should stop when top-k rankings stabilize.\"\"\"\n        estimator = ConfidenceEstimator()\n\n        state = RefinementState(\n            z=np.zeros(64),\n            scores=np.array([0.5, 0.3, 0.1]),\n            iteration=2\n        )\n        # Same scores twice = converged\n        state.score_history = [\n            np.array([0.5, 0.3, 0.1]),\n            np.array([0.5, 0.3, 0.1])\n        ]\n\n        assert estimator.should_stop(state)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_single_candidate_123": {
      "name": "test_single_candidate",
      "type": "method",
      "start_line": 123,
      "end_line": 139,
      "content_hash": "171ea17543cf35926670dba10832d849255f21b8",
      "content": "    def test_single_candidate(self):\n        \"\"\"Should handle single candidate without crashing.\"\"\"\n        estimator = ConfidenceEstimator()\n\n        state = RefinementState(\n            z=np.zeros(64),\n            scores=np.array([0.5]),\n            iteration=2\n        )\n        state.score_history = [\n            np.array([0.4]),\n            np.array([0.5])\n        ]\n\n        # Should not crash and should stop (single element = stable ranking)\n        result = estimator.should_stop(state)\n        assert isinstance(result, bool)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_flipping_order_resets_patience_141": {
      "name": "test_flipping_order_resets_patience",
      "type": "method",
      "start_line": 141,
      "end_line": 157,
      "content_hash": "f11462e1fcef6728ab80d489f08fbf9e6cdf4b81",
      "content": "    def test_flipping_order_resets_patience(self):\n        \"\"\"Flipping ranking order should reset stability count.\"\"\"\n        estimator = ConfidenceEstimator(patience=2)\n\n        state = RefinementState(\n            z=np.zeros(64),\n            scores=np.array([0.3, 0.5, 0.1]),  # Order: 1, 0, 2\n            iteration=1\n        )\n        state.score_history = [\n            np.array([0.5, 0.3, 0.1]),  # Order: 0, 1, 2\n            np.array([0.3, 0.5, 0.1])   # Order: 1, 0, 2 (flipped!)\n        ]\n\n        # Flipped order = not stable, should not stop\n        assert not estimator.should_stop(state)\n        assert estimator._stable_count == 0",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_patience_respected_159": {
      "name": "test_patience_respected",
      "type": "method",
      "start_line": 159,
      "end_line": 185,
      "content_hash": "97364eb87802c0e5b1f4455d007d370d94fa572a",
      "content": "    def test_patience_respected(self):\n        \"\"\"Should require patience consecutive stable iterations to stop.\"\"\"\n        estimator = ConfidenceEstimator(patience=3)\n\n        state = RefinementState(\n            z=np.zeros(64),\n            scores=np.array([0.5, 0.3, 0.1]),\n            iteration=1\n        )\n\n        # First stable iteration\n        state.score_history = [\n            np.array([0.5, 0.3, 0.1]),\n            np.array([0.5, 0.3, 0.1])\n        ]\n        assert not estimator.should_stop(state)\n        assert estimator._stable_count == 1\n\n        # Second stable iteration\n        state.score_history.append(np.array([0.5, 0.3, 0.1]))\n        assert not estimator.should_stop(state)\n        assert estimator._stable_count == 2\n\n        # Third stable iteration - now should stop\n        state.score_history.append(np.array([0.5, 0.3, 0.1]))\n        assert estimator.should_stop(state)\n        assert estimator._stable_count == 3",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_reset_clears_state_187": {
      "name": "test_reset_clears_state",
      "type": "method",
      "start_line": 187,
      "end_line": 194,
      "content_hash": "c07614b88e6df8ffe6b4286a02585c8b58a22b40",
      "content": "    def test_reset_clears_state(self):\n        \"\"\"Reset should clear stability count.\"\"\"\n        estimator = ConfidenceEstimator(patience=2)\n        estimator._stable_count = 5\n\n        estimator.reset()\n\n        assert estimator._stable_count == 0",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_TestRecursiveReranker_197": {
      "name": "TestRecursiveReranker",
      "type": "class",
      "start_line": 197,
      "end_line": 241,
      "content_hash": "35277cb8c0919646ce018d3d2eaab47c7bcdde09",
      "content": "class TestRecursiveReranker:\n    \"\"\"Tests for the main recursive reranker.\"\"\"\n    \n    def test_rerank_returns_same_count(self):\n        \"\"\"Reranker should return same number of candidates.\"\"\"\n        reranker = RecursiveReranker(n_iterations=2, dim=64)\n        \n        candidates = [\n            {\"path\": \"a.py\", \"symbol\": \"func_a\", \"code\": \"def a(): pass\"},\n            {\"path\": \"b.py\", \"symbol\": \"func_b\", \"code\": \"def b(): pass\"},\n            {\"path\": \"c.py\", \"symbol\": \"func_c\", \"code\": \"def c(): pass\"},\n        ]\n        \n        results = reranker.rerank(\"search query\", candidates)\n        \n        assert len(results) == 3\n    \n    def test_rerank_adds_metadata(self):\n        \"\"\"Reranked results should have recursive metadata.\"\"\"\n        reranker = RecursiveReranker(n_iterations=2, dim=64)\n        \n        candidates = [\n            {\"path\": \"a.py\", \"symbol\": \"func_a\", \"code\": \"def a(): pass\"},\n        ]\n        \n        results = reranker.rerank(\"query\", candidates)\n        \n        assert \"recursive_score\" in results[0]\n        assert \"recursive_rank\" in results[0]\n        assert \"recursive_iterations\" in results[0]\n        assert \"score_trajectory\" in results[0]\n    \n    def test_rerank_preserves_original_fields(self):\n        \"\"\"Original candidate fields should be preserved.\"\"\"\n        reranker = RecursiveReranker(n_iterations=2, dim=64)\n        \n        candidates = [\n            {\"path\": \"a.py\", \"symbol\": \"func_a\", \"code\": \"def a(): pass\", \"custom\": \"value\"},\n        ]\n        \n        results = reranker.rerank(\"query\", candidates)\n        \n        assert results[0][\"path\"] == \"a.py\"\n        assert results[0][\"symbol\"] == \"func_a\"\n        assert results[0][\"custom\"] == \"value\"",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_rerank_returns_same_count_200": {
      "name": "test_rerank_returns_same_count",
      "type": "method",
      "start_line": 200,
      "end_line": 212,
      "content_hash": "185543d45a904b28adfb8818ef0514a968497cae",
      "content": "    def test_rerank_returns_same_count(self):\n        \"\"\"Reranker should return same number of candidates.\"\"\"\n        reranker = RecursiveReranker(n_iterations=2, dim=64)\n        \n        candidates = [\n            {\"path\": \"a.py\", \"symbol\": \"func_a\", \"code\": \"def a(): pass\"},\n            {\"path\": \"b.py\", \"symbol\": \"func_b\", \"code\": \"def b(): pass\"},\n            {\"path\": \"c.py\", \"symbol\": \"func_c\", \"code\": \"def c(): pass\"},\n        ]\n        \n        results = reranker.rerank(\"search query\", candidates)\n        \n        assert len(results) == 3",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_rerank_adds_metadata_214": {
      "name": "test_rerank_adds_metadata",
      "type": "method",
      "start_line": 214,
      "end_line": 227,
      "content_hash": "8528ad8d914a8a006146791faf8875858c391cb1",
      "content": "    def test_rerank_adds_metadata(self):\n        \"\"\"Reranked results should have recursive metadata.\"\"\"\n        reranker = RecursiveReranker(n_iterations=2, dim=64)\n        \n        candidates = [\n            {\"path\": \"a.py\", \"symbol\": \"func_a\", \"code\": \"def a(): pass\"},\n        ]\n        \n        results = reranker.rerank(\"query\", candidates)\n        \n        assert \"recursive_score\" in results[0]\n        assert \"recursive_rank\" in results[0]\n        assert \"recursive_iterations\" in results[0]\n        assert \"score_trajectory\" in results[0]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_rerank_preserves_original_fields_229": {
      "name": "test_rerank_preserves_original_fields",
      "type": "method",
      "start_line": 229,
      "end_line": 241,
      "content_hash": "58a8d04dcd4d481a2d6f2666d1bd9c14493d2932",
      "content": "    def test_rerank_preserves_original_fields(self):\n        \"\"\"Original candidate fields should be preserved.\"\"\"\n        reranker = RecursiveReranker(n_iterations=2, dim=64)\n        \n        candidates = [\n            {\"path\": \"a.py\", \"symbol\": \"func_a\", \"code\": \"def a(): pass\", \"custom\": \"value\"},\n        ]\n        \n        results = reranker.rerank(\"query\", candidates)\n        \n        assert results[0][\"path\"] == \"a.py\"\n        assert results[0][\"symbol\"] == \"func_a\"\n        assert results[0][\"custom\"] == \"value\"",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_TestCosineAlphaScheduler_244": {
      "name": "TestCosineAlphaScheduler",
      "type": "class",
      "start_line": 244,
      "end_line": 285,
      "content_hash": "19e91535ac18b1d29e24a26131d92d56905b632e",
      "content": "class TestCosineAlphaScheduler:\n    \"\"\"Tests for the cosine alpha scheduler.\"\"\"\n\n    def test_schedule_length(self):\n        \"\"\"Schedule should match n_iterations.\"\"\"\n        from scripts.rerank_recursive import CosineAlphaScheduler\n        \n        scheduler = CosineAlphaScheduler(n_iterations=5)\n        schedule = scheduler.get_schedule()\n        \n        assert len(schedule) == 5\n\n    def test_schedule_decreasing(self):\n        \"\"\"Alpha should decrease over iterations (cosine decay).\"\"\"\n        from scripts.rerank_recursive import CosineAlphaScheduler\n        \n        scheduler = CosineAlphaScheduler(n_iterations=3, alpha_max=0.7, alpha_min=0.3)\n        schedule = scheduler.get_schedule()\n        \n        assert schedule[0] > schedule[1] > schedule[2]\n        assert abs(schedule[0] - 0.7) < 0.01  # First should be alpha_max\n        assert abs(schedule[2] - 0.3) < 0.01  # Last should be alpha_min\n\n    def test_schedule_bounds(self):\n        \"\"\"All alpha values should be within [alpha_min, alpha_max].\"\"\"\n        from scripts.rerank_recursive import CosineAlphaScheduler\n        \n        scheduler = CosineAlphaScheduler(n_iterations=10, alpha_max=0.8, alpha_min=0.2)\n        schedule = scheduler.get_schedule()\n        \n        for alpha in schedule:\n            assert 0.2 <= alpha <= 0.8\n\n    def test_single_iteration(self):\n        \"\"\"Single iteration should return middle value.\"\"\"\n        from scripts.rerank_recursive import CosineAlphaScheduler\n        \n        scheduler = CosineAlphaScheduler(n_iterations=1, alpha_max=0.8, alpha_min=0.2)\n        schedule = scheduler.get_schedule()\n        \n        assert len(schedule) == 1\n        assert abs(schedule[0] - 0.5) < 0.01  # Should be (0.8 + 0.2) / 2",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_schedule_length_247": {
      "name": "test_schedule_length",
      "type": "method",
      "start_line": 247,
      "end_line": 254,
      "content_hash": "728598871a7faada1730d95bea12b2d0dd2f3015",
      "content": "    def test_schedule_length(self):\n        \"\"\"Schedule should match n_iterations.\"\"\"\n        from scripts.rerank_recursive import CosineAlphaScheduler\n        \n        scheduler = CosineAlphaScheduler(n_iterations=5)\n        schedule = scheduler.get_schedule()\n        \n        assert len(schedule) == 5",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_schedule_decreasing_256": {
      "name": "test_schedule_decreasing",
      "type": "method",
      "start_line": 256,
      "end_line": 265,
      "content_hash": "9491f89da2a3ac2b5b872b31b556c3594cb3afc0",
      "content": "    def test_schedule_decreasing(self):\n        \"\"\"Alpha should decrease over iterations (cosine decay).\"\"\"\n        from scripts.rerank_recursive import CosineAlphaScheduler\n        \n        scheduler = CosineAlphaScheduler(n_iterations=3, alpha_max=0.7, alpha_min=0.3)\n        schedule = scheduler.get_schedule()\n        \n        assert schedule[0] > schedule[1] > schedule[2]\n        assert abs(schedule[0] - 0.7) < 0.01  # First should be alpha_max\n        assert abs(schedule[2] - 0.3) < 0.01  # Last should be alpha_min",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_schedule_bounds_267": {
      "name": "test_schedule_bounds",
      "type": "method",
      "start_line": 267,
      "end_line": 275,
      "content_hash": "427222e3414a7027a2b4aebba7b9290175d4fc6a",
      "content": "    def test_schedule_bounds(self):\n        \"\"\"All alpha values should be within [alpha_min, alpha_max].\"\"\"\n        from scripts.rerank_recursive import CosineAlphaScheduler\n        \n        scheduler = CosineAlphaScheduler(n_iterations=10, alpha_max=0.8, alpha_min=0.2)\n        schedule = scheduler.get_schedule()\n        \n        for alpha in schedule:\n            assert 0.2 <= alpha <= 0.8",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_single_iteration_277": {
      "name": "test_single_iteration",
      "type": "method",
      "start_line": 277,
      "end_line": 285,
      "content_hash": "c9bc7c13f39772af3720b534cf73f0ab0ae9d92f",
      "content": "    def test_single_iteration(self):\n        \"\"\"Single iteration should return middle value.\"\"\"\n        from scripts.rerank_recursive import CosineAlphaScheduler\n        \n        scheduler = CosineAlphaScheduler(n_iterations=1, alpha_max=0.8, alpha_min=0.2)\n        schedule = scheduler.get_schedule()\n        \n        assert len(schedule) == 1\n        assert abs(schedule[0] - 0.5) < 0.01  # Should be (0.8 + 0.2) / 2",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_TestLearnedAlphaWeights_288": {
      "name": "TestLearnedAlphaWeights",
      "type": "class",
      "start_line": 288,
      "end_line": 322,
      "content_hash": "7a25a0bf73836c7ce3b52d057cc18a3d73d7f7b8",
      "content": "class TestLearnedAlphaWeights:\n    \"\"\"Tests for the learnable alpha weights.\"\"\"\n\n    def test_init_alpha(self):\n        \"\"\"Initial alpha should match init_alpha parameter.\"\"\"\n        from scripts.rerank_recursive import LearnedAlphaWeights\n        \n        learned = LearnedAlphaWeights(n_iterations=3, init_alpha=0.6)\n        schedule = learned.get_schedule()\n        \n        for alpha in schedule:\n            assert abs(alpha - 0.6) < 0.01\n\n    def test_get_alpha_clamped(self):\n        \"\"\"get_alpha should clamp to valid iteration range.\"\"\"\n        from scripts.rerank_recursive import LearnedAlphaWeights\n        \n        learned = LearnedAlphaWeights(n_iterations=3)\n        \n        # Should not crash for out-of-range iterations\n        alpha_neg = learned.get_alpha(-1)\n        alpha_over = learned.get_alpha(100)\n        \n        assert 0 < alpha_neg < 1\n        assert 0 < alpha_over < 1\n\n    def test_alpha_in_valid_range(self):\n        \"\"\"All alpha values should be in (0, 1) due to sigmoid.\"\"\"\n        from scripts.rerank_recursive import LearnedAlphaWeights\n        \n        learned = LearnedAlphaWeights(n_iterations=5, init_alpha=0.5)\n        schedule = learned.get_schedule()\n        \n        for alpha in schedule:\n            assert 0 < alpha < 1",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_init_alpha_291": {
      "name": "test_init_alpha",
      "type": "method",
      "start_line": 291,
      "end_line": 299,
      "content_hash": "e4137bd4dc1f4f631228fe18e363209cefc1daa8",
      "content": "    def test_init_alpha(self):\n        \"\"\"Initial alpha should match init_alpha parameter.\"\"\"\n        from scripts.rerank_recursive import LearnedAlphaWeights\n        \n        learned = LearnedAlphaWeights(n_iterations=3, init_alpha=0.6)\n        schedule = learned.get_schedule()\n        \n        for alpha in schedule:\n            assert abs(alpha - 0.6) < 0.01",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_get_alpha_clamped_301": {
      "name": "test_get_alpha_clamped",
      "type": "method",
      "start_line": 301,
      "end_line": 312,
      "content_hash": "402a1844230d6e44b8bf765e845ebc646a92de2d",
      "content": "    def test_get_alpha_clamped(self):\n        \"\"\"get_alpha should clamp to valid iteration range.\"\"\"\n        from scripts.rerank_recursive import LearnedAlphaWeights\n        \n        learned = LearnedAlphaWeights(n_iterations=3)\n        \n        # Should not crash for out-of-range iterations\n        alpha_neg = learned.get_alpha(-1)\n        alpha_over = learned.get_alpha(100)\n        \n        assert 0 < alpha_neg < 1\n        assert 0 < alpha_over < 1",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_alpha_in_valid_range_314": {
      "name": "test_alpha_in_valid_range",
      "type": "method",
      "start_line": 314,
      "end_line": 322,
      "content_hash": "07bf064c70a9d65415c498f6ffef53c3b647742a",
      "content": "    def test_alpha_in_valid_range(self):\n        \"\"\"All alpha values should be in (0, 1) due to sigmoid.\"\"\"\n        from scripts.rerank_recursive import LearnedAlphaWeights\n        \n        learned = LearnedAlphaWeights(n_iterations=5, init_alpha=0.5)\n        schedule = learned.get_schedule()\n        \n        for alpha in schedule:\n            assert 0 < alpha < 1",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_TestAlphaIntegration_325": {
      "name": "TestAlphaIntegration",
      "type": "class",
      "start_line": 325,
      "end_line": 371,
      "content_hash": "56689eb011d740626cbab874b105aa3171e3c94d",
      "content": "class TestAlphaIntegration:\n    \"\"\"Tests for alpha scheduler integration with reranker.\"\"\"\n\n    def test_alpha_trajectory_in_output(self):\n        \"\"\"Reranked results should include alpha_trajectory.\"\"\"\n        reranker = RecursiveReranker(n_iterations=3, dim=64)\n        \n        candidates = [\n            {\"path\": \"a.py\", \"code\": \"def a(): pass\"},\n        ]\n        \n        results = reranker.rerank(\"query\", candidates)\n        \n        assert \"alpha_trajectory\" in results[0]\n        assert isinstance(results[0][\"alpha_trajectory\"], list)\n        assert len(results[0][\"alpha_trajectory\"]) > 0\n\n    def test_custom_scheduler(self):\n        \"\"\"Should accept custom alpha scheduler.\"\"\"\n        from scripts.rerank_recursive import LearnedAlphaWeights\n        \n        custom_scheduler = LearnedAlphaWeights(n_iterations=2, init_alpha=0.4)\n        reranker = RecursiveReranker(n_iterations=2, dim=64, alpha_scheduler=custom_scheduler)\n        \n        candidates = [\n            {\"path\": \"a.py\", \"code\": \"def a(): pass\"},\n        ]\n        \n        results = reranker.rerank(\"query\", candidates)\n        \n        # Alpha should be close to 0.4 (our custom init)\n        for alpha in results[0][\"alpha_trajectory\"]:\n            assert abs(alpha - 0.4) < 0.1\n\n    def test_alpha_trajectory_matches_iterations(self):\n        \"\"\"Alpha trajectory length should match actual iterations run.\"\"\"\n        reranker = RecursiveReranker(n_iterations=3, dim=64, early_stop=False)\n        \n        candidates = [\n            {\"path\": \"a.py\", \"code\": \"def a(): pass\"},\n            {\"path\": \"b.py\", \"code\": \"def b(): pass\"},\n        ]\n        \n        results = reranker.rerank(\"query\", candidates)\n        \n        # With early_stop=False, should run all iterations\n        assert len(results[0][\"alpha_trajectory\"]) == results[0][\"recursive_iterations\"]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_alpha_trajectory_in_output_328": {
      "name": "test_alpha_trajectory_in_output",
      "type": "method",
      "start_line": 328,
      "end_line": 340,
      "content_hash": "242d3cb027611d54a973a41fbae6ea7e3ea4a717",
      "content": "    def test_alpha_trajectory_in_output(self):\n        \"\"\"Reranked results should include alpha_trajectory.\"\"\"\n        reranker = RecursiveReranker(n_iterations=3, dim=64)\n        \n        candidates = [\n            {\"path\": \"a.py\", \"code\": \"def a(): pass\"},\n        ]\n        \n        results = reranker.rerank(\"query\", candidates)\n        \n        assert \"alpha_trajectory\" in results[0]\n        assert isinstance(results[0][\"alpha_trajectory\"], list)\n        assert len(results[0][\"alpha_trajectory\"]) > 0",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_custom_scheduler_342": {
      "name": "test_custom_scheduler",
      "type": "method",
      "start_line": 342,
      "end_line": 357,
      "content_hash": "979c3a1316d0469303ce4db4f9e7607a1db79bba",
      "content": "    def test_custom_scheduler(self):\n        \"\"\"Should accept custom alpha scheduler.\"\"\"\n        from scripts.rerank_recursive import LearnedAlphaWeights\n        \n        custom_scheduler = LearnedAlphaWeights(n_iterations=2, init_alpha=0.4)\n        reranker = RecursiveReranker(n_iterations=2, dim=64, alpha_scheduler=custom_scheduler)\n        \n        candidates = [\n            {\"path\": \"a.py\", \"code\": \"def a(): pass\"},\n        ]\n        \n        results = reranker.rerank(\"query\", candidates)\n        \n        # Alpha should be close to 0.4 (our custom init)\n        for alpha in results[0][\"alpha_trajectory\"]:\n            assert abs(alpha - 0.4) < 0.1",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_test_alpha_trajectory_matches_iterations_359": {
      "name": "test_alpha_trajectory_matches_iterations",
      "type": "method",
      "start_line": 359,
      "end_line": 371,
      "content_hash": "3e8479dc7cf392cd6e4ee169e1ca8cac46873011",
      "content": "    def test_alpha_trajectory_matches_iterations(self):\n        \"\"\"Alpha trajectory length should match actual iterations run.\"\"\"\n        reranker = RecursiveReranker(n_iterations=3, dim=64, early_stop=False)\n        \n        candidates = [\n            {\"path\": \"a.py\", \"code\": \"def a(): pass\"},\n            {\"path\": \"b.py\", \"code\": \"def b(): pass\"},\n        ]\n        \n        results = reranker.rerank(\"query\", candidates)\n        \n        # With early_stop=False, should run all iterations\n        assert len(results[0][\"alpha_trajectory\"]) == results[0][\"recursive_iterations\"]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}