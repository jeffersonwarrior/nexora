{
  "file_path": "/work/internal/indexer/embeddings.go",
  "file_hash": "4cf29dd257632dd2f9901ec35d2b222245ac86a9",
  "updated_at": "2025-12-26T17:34:24.508422",
  "symbols": {
    "struct_Embedding_18": {
      "name": "Embedding",
      "type": "struct",
      "start_line": 18,
      "end_line": 26,
      "content_hash": "6f6ec6b061c1e6554b10c774ef868b0b79f20856",
      "content": "type Embedding struct {\n\tID       string    `json:\"id\"`\n\tType     string    `json:\"type\"` // function, struct, interface, variable, comment\n\tText     string    `json:\"text\"`\n\tVector   []float32 `json:\"vector\"`\n\tMetadata MetaData  `json:\"metadata\"`\n\tCreated  time.Time `json:\"created\"`\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "struct_MetaData_27": {
      "name": "MetaData",
      "type": "struct",
      "start_line": 27,
      "end_line": 35,
      "content_hash": "080e3612fe10e0e3d9a0286dd54b59e713e47fae",
      "content": "type MetaData struct {\n\tPackage    string `json:\"package\"`\n\tFile       string `json:\"file\"`\n\tLine       int    `json:\"line\"`\n\tComplexity int    `json:\"complexity\"`\n\tPublic     bool   `json:\"public\"`\n}\n\n// EmbeddingProvider interface for different embedding models",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "interface_EmbeddingProvider_36": {
      "name": "EmbeddingProvider",
      "type": "interface",
      "start_line": 36,
      "end_line": 41,
      "content_hash": "efe42b990fee6570eacd2402bdf34f00ab37a75a",
      "content": "type EmbeddingProvider interface {\n\tGenerateEmbedding(ctx context.Context, text string) ([]float32, error)\n\tName() string\n}\n\n// OpenAIProvider uses OpenAI's embedding API",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "struct_OpenAIProvider_42": {
      "name": "OpenAIProvider",
      "type": "struct",
      "start_line": 42,
      "end_line": 47,
      "content_hash": "53a8acf3c2dfa91e3a1aab058395e48f4d3864e4",
      "content": "type OpenAIProvider struct {\n\tapiKey  string\n\tmodel   string\n\tbaseURL string\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_NewOpenAIProvider_48": {
      "name": "NewOpenAIProvider",
      "type": "function",
      "start_line": 48,
      "end_line": 61,
      "content_hash": "7c5fa472aa87b9cad8c1cb859b9216e3a2b8a95a",
      "content": "func NewOpenAIProvider(apiKey, baseURL, model string) *OpenAIProvider {\n\tif model == \"\" {\n\t\tmodel = \"text-embedding-3-small\"\n\t}\n\tif baseURL == \"\" {\n\t\tbaseURL = \"https://api.openai.com/v1\"\n\t}\n\treturn &OpenAIProvider{\n\t\tapiKey:  apiKey,\n\t\tmodel:   model,\n\t\tbaseURL: baseURL,\n\t}\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_Name_62": {
      "name": "Name",
      "type": "method",
      "start_line": 62,
      "end_line": 65,
      "content_hash": "876ca121d9a08dee77cc5988f38a0d0081bb88da",
      "content": "func (p *OpenAIProvider) Name() string {\n\treturn \"openai-\" + p.model\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_GenerateEmbedding_66": {
      "name": "GenerateEmbedding",
      "type": "method",
      "start_line": 66,
      "end_line": 72,
      "content_hash": "b9fc9367e35d28f91605dd4a109696767821fa25",
      "content": "func (p *OpenAIProvider) GenerateEmbedding(ctx context.Context, text string) ([]float32, error) {\n\t// Mock implementation for now - in production, would call OpenAI API\n\t// Return a simple hash-based embedding for demo purposes\n\treturn generateMockEmbedding(text), nil\n}\n\n// LocalProvider uses local embedding models",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "struct_LocalProvider_73": {
      "name": "LocalProvider",
      "type": "struct",
      "start_line": 73,
      "end_line": 77,
      "content_hash": "3288f6d549343bd21e5de27d7f2200be5529b840",
      "content": "type LocalProvider struct {\n\tmodel string\n\tpath  string\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_NewLocalProvider_78": {
      "name": "NewLocalProvider",
      "type": "function",
      "start_line": 78,
      "end_line": 87,
      "content_hash": "bbbd7581bbecd78e221b332a06e206c070734d23",
      "content": "func NewLocalProvider(model, path string) *LocalProvider {\n\tif model == \"\" {\n\t\tmodel = \"all-minilm:l6-v2\"\n\t}\n\treturn &LocalProvider{\n\t\tmodel: model,\n\t\tpath:  path,\n\t}\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_Name_88": {
      "name": "Name",
      "type": "method",
      "start_line": 88,
      "end_line": 91,
      "content_hash": "010d18e50f67132509f9400becc9c6a1850bad37",
      "content": "func (p *LocalProvider) Name() string {\n\treturn \"local-\" + p.model\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_GenerateEmbedding_92": {
      "name": "GenerateEmbedding",
      "type": "method",
      "start_line": 92,
      "end_line": 97,
      "content_hash": "5bad91c0661d75300b990682663eb3535eb8cb6a",
      "content": "func (p *LocalProvider) GenerateEmbedding(ctx context.Context, text string) ([]float32, error) {\n\t// Mock implementation - would call local model via exec or HTTP\n\treturn generateMockEmbedding(text), nil\n}\n\n// MistralProvider uses Mistral AI's embedding API with advanced features",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "struct_MistralProvider_98": {
      "name": "MistralProvider",
      "type": "struct",
      "start_line": 98,
      "end_line": 106,
      "content_hash": "81aae53ffe87497f73fefdad21a0e48b3118e1aa",
      "content": "type MistralProvider struct {\n\tapiKey      string\n\tmodel       string\n\tbaseURL     string\n\tclient      *http.Client\n\tmodelConfig MistralModelConfig\n}\n\n// MistralModelConfig holds configuration specific to each model",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "struct_MistralModelConfig_107": {
      "name": "MistralModelConfig",
      "type": "struct",
      "start_line": 107,
      "end_line": 135,
      "content_hash": "f8d4ee308fca86e8ea3c09fd505a419edb8b6068",
      "content": "type MistralModelConfig struct {\n\tMaxTokens     int      `json:\"max_tokens\"`\n\tEmbeddingDims int      `json:\"embedding_dims\"`\n\tInputPrice    float64  `json:\"input_price_per_1k\"`\n\tCapabilities  []string `json:\"capabilities\"`\n}\n\n// Model configurations for all supported Mistral models\nvar mistralModelConfigs = map[string]MistralModelConfig{\n\tMistralModelMistralLarge3: {\n\t\tMaxTokens:     131072,\n\t\tEmbeddingDims: 1536,\n\t\tInputPrice:    0.3,\n\t\tCapabilities:  []string{\"reasoning\", \"analysis\", \"embeddings\", \"large-context\"},\n\t},\n\tMistralModelMinistral3: {\n\t\tMaxTokens:     65536,\n\t\tEmbeddingDims: 1024,\n\t\tInputPrice:    0.025,\n\t\tCapabilities:  []string{\"fast\", \"efficient\", \"embeddings\"},\n\t},\n\tMistralModelEmbed: {\n\t\tMaxTokens:     8000,\n\t\tEmbeddingDims: 1024,\n\t\tInputPrice:    0.01,\n\t\tCapabilities:  []string{\"embeddings-only\", \"fast\"},\n\t},\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_NewMistralProvider_136": {
      "name": "NewMistralProvider",
      "type": "function",
      "start_line": 136,
      "end_line": 160,
      "content_hash": "349b7666b94a1a7db9302f1082a53eec16a331b2",
      "content": "func NewMistralProvider(apiKey, model string) *MistralProvider {\n\tif model == \"\" {\n\t\tmodel = MistralModelEmbed // Use embedding-optimized model by default\n\t}\n\tif apiKey == \"\" {\n\t\tapiKey = os.Getenv(\"MISTRAL_API_KEY\")\n\t}\n\n\tconfig, exists := mistralModelConfigs[model]\n\tif !exists {\n\t\tslog.Warn(\"Unknown Mistral model, using default config\", \"model\", model)\n\t\tconfig = mistralModelConfigs[MistralModelEmbed]\n\t}\n\n\treturn &MistralProvider{\n\t\tapiKey:  apiKey,\n\t\tmodel:   model,\n\t\tbaseURL: \"https://api.mistral.ai/v1\",\n\t\tclient: &http.Client{\n\t\t\tTimeout: 60 * time.Second, // Increased timeout for large models\n\t\t},\n\t\tmodelConfig: config,\n\t}\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_Name_161": {
      "name": "Name",
      "type": "method",
      "start_line": 161,
      "end_line": 164,
      "content_hash": "faf9d4753ae6e45957896a09285de2772e7dc319",
      "content": "func (p *MistralProvider) Name() string {\n\treturn \"mistral-\" + p.model\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_GenerateEmbedding_165": {
      "name": "GenerateEmbedding",
      "type": "method",
      "start_line": 165,
      "end_line": 200,
      "content_hash": "7a3dff8e9b65a7e16097cb42c2bab95449c3ca9f",
      "content": "func (p *MistralProvider) GenerateEmbedding(ctx context.Context, text string) ([]float32, error) {\n\tif p.apiKey == \"\" {\n\t\treturn nil, fmt.Errorf(\"no Mistral API key provided. Set the MISTRAL_API_KEY environment variable\")\n\t}\n\n\t// Validate model capabilities\n\tif !p.modelSupportsEmbeddings() {\n\t\treturn nil, fmt.Errorf(\"model %s does not support embeddings\", p.model)\n\t}\n\n\t// Prepare request with model-specific optimizations\n\treqBody := p.buildEmbeddingRequest(text)\n\n\tjsonData, err := json.Marshal(reqBody)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to marshal request: %w\", err)\n\t}\n\n\t// Create HTTP request with retry logic\n\tembedding, err := p.makeEmbeddingRequestWithRetry(ctx, jsonData, 3)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Validate embedding dimensions\n\texpectedDims := p.modelConfig.EmbeddingDims\n\tif len(embedding) != expectedDims {\n\t\tslog.Warn(\"Embedding dimension mismatch\",\n\t\t\t\"expected\", expectedDims,\n\t\t\t\"actual\", len(embedding),\n\t\t\t\"model\", p.model)\n\t}\n\n\treturn embedding, nil\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_modelSupportsEmbeddings_201": {
      "name": "modelSupportsEmbeddings",
      "type": "method",
      "start_line": 201,
      "end_line": 210,
      "content_hash": "8c077f165581fecd23ee583c26ea9232916e5e50",
      "content": "func (p *MistralProvider) modelSupportsEmbeddings() bool {\n\tcapabilities := p.modelConfig.Capabilities\n\tfor _, cap := range capabilities {\n\t\tif cap == \"embeddings\" || cap == \"embeddings-only\" {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_buildEmbeddingRequest_211": {
      "name": "buildEmbeddingRequest",
      "type": "method",
      "start_line": 211,
      "end_line": 229,
      "content_hash": "55a649ba529d37851b8740ac84d0398bc669f374",
      "content": "func (p *MistralProvider) buildEmbeddingRequest(text string) map[string]any {\n\treqBody := map[string]any{\n\t\t\"input\": text,\n\t\t\"model\": p.model,\n\t}\n\n\t// Add model-specific optimizations\n\tswitch p.model {\n\tcase MistralModelMistralLarge3:\n\t\t// For large models, we can request higher precision\n\t\treqBody[\"encoding_format\"] = \"float\"\n\t\treqBody[\"output_dimension\"] = p.modelConfig.EmbeddingDims\n\tdefault:\n\t\treqBody[\"encoding_format\"] = \"float\"\n\t}\n\n\treturn reqBody\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_makeEmbeddingRequestWithRetry_230": {
      "name": "makeEmbeddingRequestWithRetry",
      "type": "method",
      "start_line": 230,
      "end_line": 263,
      "content_hash": "3f3a2fd3488d7465678c08b58e061b802f913dcf",
      "content": "func (p *MistralProvider) makeEmbeddingRequestWithRetry(ctx context.Context, jsonData []byte, maxRetries int) ([]float32, error) {\n\tvar lastErr error\n\n\tfor attempt := 0; attempt <= maxRetries; attempt++ {\n\t\tif attempt > 0 {\n\t\t\t// Exponential backoff\n\t\t\tbackoff := time.Duration(1<<uint(attempt-1)) * time.Second\n\t\t\tslog.Debug(\"Retrying Mistral API request\", \"attempt\", attempt, \"backoff\", backoff)\n\n\t\t\tselect {\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn nil, ctx.Err()\n\t\t\tcase <-time.After(backoff):\n\t\t\t}\n\t\t}\n\n\t\tembedding, err := p.makeEmbeddingRequest(ctx, jsonData)\n\t\tif err == nil {\n\t\t\treturn embedding, nil\n\t\t}\n\n\t\tlastErr = err\n\n\t\t// Don't retry on certain errors\n\t\tif strings.Contains(err.Error(), \"401\") || // Unauthorized\n\t\t\tstrings.Contains(err.Error(), \"400\") || // Bad request\n\t\t\tstrings.Contains(err.Error(), \"404\") { // Model not found\n\t\t\tbreak\n\t\t}\n\t}\n\n\treturn nil, fmt.Errorf(\"failed after %d attempts: %w\", maxRetries+1, lastErr)\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_makeEmbeddingRequest_264": {
      "name": "makeEmbeddingRequest",
      "type": "method",
      "start_line": 264,
      "end_line": 328,
      "content_hash": "3bee252a59de049ef658e18d057c3ca02714da4a",
      "content": "func (p *MistralProvider) makeEmbeddingRequest(ctx context.Context, jsonData []byte) ([]float32, error) {\n\treq, err := http.NewRequestWithContext(ctx, \"POST\", p.baseURL+\"/embeddings\", bytes.NewBuffer(jsonData))\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create request: %w\", err)\n\t}\n\n\treq.Header.Set(\"Content-Type\", \"application/json\")\n\treq.Header.Set(\"Authorization\", \"Bearer \"+p.apiKey)\n\treq.Header.Set(\"User-Agent\", \"Nexora-Indexer/1.0\")\n\n\t// Send request\n\tresp, err := p.client.Do(req)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to send request: %w\", err)\n\t}\n\tdefer resp.Body.Close()\n\n\t// Read response\n\tbody, err := io.ReadAll(resp.Body)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to read response: %w\", err)\n\t}\n\n\tif resp.StatusCode != http.StatusOK {\n\t\treturn nil, fmt.Errorf(\"API request failed with status %d: %s\", resp.StatusCode, string(body))\n\t}\n\n\t// Parse response\n\tvar result struct {\n\t\tData []struct {\n\t\t\tEmbedding []float32 `json:\"embedding\"`\n\t\t\tIndex     int       `json:\"index\"`\n\t\t\tObject    string    `json:\"object\"`\n\t\t} `json:\"data\"`\n\t\tModel  string `json:\"model\"`\n\t\tObject string `json:\"object\"`\n\t\tUsage  struct {\n\t\t\tPromptTokens     int     `json:\"prompt_tokens\"`\n\t\t\tCompletionTokens int     `json:\"completion_tokens\"`\n\t\t\tTotalTokens      int     `json:\"total_tokens\"`\n\t\t\tPromptAudioSec   float64 `json:\"prompt_audio_seconds\"`\n\t\t} `json:\"usage\"`\n\t}\n\n\tif err := json.Unmarshal(body, &result); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to parse response: %w\", err)\n\t}\n\n\tif len(result.Data) == 0 {\n\t\treturn nil, fmt.Errorf(\"no embeddings returned\")\n\t}\n\n\t// Log usage for cost tracking\n\tif result.Usage.TotalTokens > 0 {\n\t\tcost := float64(result.Usage.PromptTokens) / 1000.0 * p.modelConfig.InputPrice\n\t\tslog.Debug(\"Mistral API usage\",\n\t\t\t\"model\", p.model,\n\t\t\t\"tokens\", result.Usage.PromptTokens,\n\t\t\t\"cost\", fmt.Sprintf(\"$%.4f\", cost))\n\t}\n\n\treturn result.Data[0].Embedding, nil\n}\n\n// GetModelInfo returns information about the current model",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_GetModelInfo_329": {
      "name": "GetModelInfo",
      "type": "method",
      "start_line": 329,
      "end_line": 333,
      "content_hash": "271a1cf357dba1e16f683978a9c123b831a1e49a",
      "content": "func (p *MistralProvider) GetModelInfo() MistralModelConfig {\n\treturn p.modelConfig\n}\n\n// SupportsBatchEmbeddings checks if the model supports batch processing",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_SupportsBatchEmbeddings_334": {
      "name": "SupportsBatchEmbeddings",
      "type": "method",
      "start_line": 334,
      "end_line": 339,
      "content_hash": "f25e4415b24934b13b36da27c8415174751f006f",
      "content": "func (p *MistralProvider) SupportsBatchEmbeddings() bool {\n\t// All Mistral models support batch embeddings\n\treturn true\n}\n\n// GenerateBatchEmbeddings generates embeddings for multiple texts efficiently",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_GenerateBatchEmbeddings_340": {
      "name": "GenerateBatchEmbeddings",
      "type": "method",
      "start_line": 340,
      "end_line": 365,
      "content_hash": "70801eeb6761edd79e4b60f5e15ab5a9e262591c",
      "content": "func (p *MistralProvider) GenerateBatchEmbeddings(ctx context.Context, texts []string) ([][]float32, error) {\n\tif p.apiKey == \"\" {\n\t\t// Fallback to individual mock embeddings\n\t\tembeddings := make([][]float32, len(texts))\n\t\tfor i, text := range texts {\n\t\t\tembeddings[i] = generateMockEmbedding(text)\n\t\t}\n\t\treturn embeddings, nil\n\t}\n\n\t// For batch requests, we can't use the single embedding response\n\t// Instead, we should make individual requests for each text as fallback\n\tslog.Warn(\"Batch embedding request not properly implemented, falling back to individual requests\")\n\tembeddings := make([][]float32, len(texts))\n\tfor i, text := range texts {\n\t\tsingleEmbedding, err := p.GenerateEmbedding(ctx, text)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to generate embedding for text %d: %w\", i, err)\n\t\t}\n\t\tembeddings[i] = singleEmbedding\n\t}\n\n\treturn embeddings, nil\n}\n\n// ValidateAPIKey checks if the provided API key is valid",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_ValidateAPIKey_366": {
      "name": "ValidateAPIKey",
      "type": "method",
      "start_line": 366,
      "end_line": 387,
      "content_hash": "42d82b453983f50243e33c0d27095e9a0fc555f1",
      "content": "func (p *MistralProvider) ValidateAPIKey(ctx context.Context) bool {\n\tif p.apiKey == \"\" {\n\t\treturn false\n\t}\n\n\t// Make a minimal request to validate the API key\n\ttestText := \"test\"\n\treqBody := map[string]any{\n\t\t\"input\": testText,\n\t\t\"model\": p.model,\n\t}\n\n\tjsonData, err := json.Marshal(reqBody)\n\tif err != nil {\n\t\treturn false\n\t}\n\n\t_, err = p.makeEmbeddingRequest(ctx, jsonData)\n\treturn err == nil\n}\n\n// GetPricingInfo returns pricing information",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_GetPricingInfo_388": {
      "name": "GetPricingInfo",
      "type": "method",
      "start_line": 388,
      "end_line": 405,
      "content_hash": "46d7f61b15272f22f34fda00b16270db82d786ca",
      "content": "func (p *MistralProvider) GetPricingInfo() map[string]any {\n\treturn map[string]any{\n\t\t\"model\":              p.model,\n\t\t\"input_price_per_1k\": p.modelConfig.InputPrice,\n\t\t\"max_tokens\":         p.modelConfig.MaxTokens,\n\t\t\"embedding_dims\":     p.modelConfig.EmbeddingDims,\n\t\t\"capabilities\":       p.modelConfig.Capabilities,\n\t}\n}\n\n// Mistral model constants\nconst (\n\tMistralModelMistralLarge3 = \"mistral-large-3-25-12\"\n\tMistralModelMinistral3    = \"ministral-3-14b-25-12\"\n\tMistralModelEmbed         = \"mistral-embed\"\n)\n\n// Optimization helpers for different use cases",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_OptimizeForCodeSearch_406": {
      "name": "OptimizeForCodeSearch",
      "type": "function",
      "start_line": 406,
      "end_line": 409,
      "content_hash": "5cbd4e9b617728eb18aaa1c68d71a1f3622a3d97",
      "content": "func OptimizeForCodeSearch() string {\n\treturn MistralModelMinistral3\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_OptimizeForSpeed_410": {
      "name": "OptimizeForSpeed",
      "type": "function",
      "start_line": 410,
      "end_line": 413,
      "content_hash": "8d6dddc3b5b635405e2ed4310059838f2d41e897",
      "content": "func OptimizeForSpeed() string {\n\treturn MistralModelMinistral3\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_OptimizeForQuality_414": {
      "name": "OptimizeForQuality",
      "type": "function",
      "start_line": 414,
      "end_line": 417,
      "content_hash": "065221b696c06ff04558d0a2a55c20e0bc6a997a",
      "content": "func OptimizeForQuality() string {\n\treturn MistralModelMistralLarge3\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_OptimizeForCost_418": {
      "name": "OptimizeForCost",
      "type": "function",
      "start_line": 418,
      "end_line": 421,
      "content_hash": "815fea6b395f4b59e791f92d7387e80a425e392f",
      "content": "func OptimizeForCost() string {\n\treturn MistralModelEmbed\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_GetAllSupportedModels_422": {
      "name": "GetAllSupportedModels",
      "type": "function",
      "start_line": 422,
      "end_line": 430,
      "content_hash": "5d828e9e6905486ac00b275991e5e3cae61ab0aa",
      "content": "func GetAllSupportedModels() []string {\n\treturn []string{\n\t\tMistralModelMistralLarge3,\n\t\tMistralModelMinistral3,\n\t\tMistralModelEmbed,\n\t}\n}\n\n// EmbeddingEngine handles the creation and storage of embeddings",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "struct_EmbeddingEngine_431": {
      "name": "EmbeddingEngine",
      "type": "struct",
      "start_line": 431,
      "end_line": 436,
      "content_hash": "30ebaca14cd132d39fe6f944cd9cced770628e03",
      "content": "type EmbeddingEngine struct {\n\tprovider EmbeddingProvider\n\tindexer  *Indexer\n\tctx      context.Context\n}\n",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_NewEmbeddingEngine_437": {
      "name": "NewEmbeddingEngine",
      "type": "function",
      "start_line": 437,
      "end_line": 445,
      "content_hash": "073ae3899df7f69468fb1c4b0478fe167b449e58",
      "content": "func NewEmbeddingEngine(provider EmbeddingProvider, indexer *Indexer) *EmbeddingEngine {\n\treturn &EmbeddingEngine{\n\t\tprovider: provider,\n\t\tindexer:  indexer,\n\t\tctx:      context.Background(),\n\t}\n}\n\n// GenerateEmbedding creates an embedding for the given text",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_GenerateEmbedding_446": {
      "name": "GenerateEmbedding",
      "type": "method",
      "start_line": 446,
      "end_line": 450,
      "content_hash": "ebf447d467d8102d0066af9e3ce505145dfefff3",
      "content": "func (e *EmbeddingEngine) GenerateEmbedding(ctx context.Context, text string) ([]float32, error) {\n\treturn e.provider.GenerateEmbedding(ctx, text)\n}\n\n// GenerateSymbolEmbeddings creates embeddings for all symbols",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_GenerateSymbolEmbeddings_451": {
      "name": "GenerateSymbolEmbeddings",
      "type": "method",
      "start_line": 451,
      "end_line": 494,
      "content_hash": "4df91c5e4fc7faf02b84a138626af3ca9f4e13c8",
      "content": "func (e *EmbeddingEngine) GenerateSymbolEmbeddings(ctx context.Context, symbols []Symbol) ([]Embedding, error) {\n\tembeddings := make([]Embedding, 0, len(symbols))\n\n\tfor _, symbol := range symbols {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil, ctx.Err()\n\t\tdefault:\n\t\t}\n\n\t\t// Create rich text for embedding\n\t\ttext := e.createEmbeddingText(symbol)\n\t\tif text == \"\" {\n\t\t\tcontinue\n\t\t}\n\n\t\tvector, err := e.provider.GenerateEmbedding(ctx, text)\n\t\tif err != nil {\n\t\t\tslog.Warn(\"Failed to generate embedding\", \"symbol\", symbol.Name, \"error\", err)\n\t\t\tcontinue\n\t\t}\n\n\t\tembedding := Embedding{\n\t\t\tID:     symbol.Name,\n\t\t\tType:   symbol.Type,\n\t\t\tText:   text,\n\t\t\tVector: vector,\n\t\t\tMetadata: MetaData{\n\t\t\t\tPackage:    symbol.Package,\n\t\t\t\tFile:       symbol.File,\n\t\t\t\tLine:       symbol.Line,\n\t\t\t\tComplexity: e.calculateComplexity(symbol),\n\t\t\t\tPublic:     symbol.Public,\n\t\t\t},\n\t\t\tCreated: time.Now(),\n\t\t}\n\n\t\tembeddings = append(embeddings, embedding)\n\t}\n\n\treturn embeddings, nil\n}\n\n// createEmbeddingText builds rich text for better semantic understanding",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_createEmbeddingText_495": {
      "name": "createEmbeddingText",
      "type": "method",
      "start_line": 495,
      "end_line": 554,
      "content_hash": "5b140dec82e5dced42930eba2286667c50d2fddf",
      "content": "func (e *EmbeddingEngine) createEmbeddingText(symbol Symbol) string {\n\tvar parts []string\n\n\t// Add documentation\n\tif symbol.Doc != \"\" {\n\t\tparts = append(parts, \"Documentation: \"+symbol.Doc)\n\t}\n\n\t// Add signature\n\tif symbol.Signature != \"\" {\n\t\tparts = append(parts, \"Signature: \"+symbol.Signature)\n\t}\n\n\t// Add function body context for functions\n\tif symbol.Type == \"func\" || symbol.Type == \"method\" {\n\t\tparts = append(parts, \"Type: Function\")\n\t\tif symbol.Params != nil {\n\t\t\tvar paramDesc []string\n\t\t\tfor _, param := range symbol.Params {\n\t\t\t\tif param.Name != \"\" {\n\t\t\t\t\tparamDesc = append(paramDesc, fmt.Sprintf(\"%s %s\", param.Name, param.Type))\n\t\t\t\t} else {\n\t\t\t\t\tparamDesc = append(paramDesc, param.Type)\n\t\t\t\t}\n\t\t\t}\n\t\t\tparts = append(parts, \"Parameters: \"+strings.Join(paramDesc, \", \"))\n\t\t}\n\t\tif symbol.Returns != nil {\n\t\t\tparts = append(parts, \"Returns: \"+strings.Join(symbol.Returns, \", \"))\n\t\t}\n\t}\n\n\t// Add type-specific information\n\tswitch symbol.Type {\n\tcase \"struct\":\n\t\tparts = append(parts, \"Type: Struct\")\n\t\tif symbol.Fields != nil {\n\t\t\tvar fieldDesc []string\n\t\t\tfor _, field := range symbol.Fields {\n\t\t\t\tfieldDesc = append(fieldDesc, fmt.Sprintf(\"%s %s\", field.Name, field.Type))\n\t\t\t}\n\t\t\tparts = append(parts, \"Fields: \"+strings.Join(fieldDesc, \", \"))\n\t\t}\n\tcase \"interface\":\n\t\tparts = append(parts, \"Type: Interface\")\n\t\tif symbol.Methods != nil {\n\t\t\tparts = append(parts, \"Methods: \"+strings.Join(symbol.Methods, \", \"))\n\t\t}\n\tcase \"var\", \"const\":\n\t\tparts = append(parts, fmt.Sprintf(\"Type: %s\", strings.Title(symbol.Type)))\n\t}\n\n\t// Add package context\n\tparts = append(parts, fmt.Sprintf(\"Package: %s\", symbol.Package))\n\tparts = append(parts, fmt.Sprintf(\"File: %s:%d\", symbol.File, symbol.Line))\n\n\treturn strings.Join(parts, \"\\n\")\n}\n\n// calculateComplexity estimates code complexity",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_calculateComplexity_555": {
      "name": "calculateComplexity",
      "type": "method",
      "start_line": 555,
      "end_line": 583,
      "content_hash": "3e4e496797b82308b9d6eecbeb702daf6c3b0705",
      "content": "func (e *EmbeddingEngine) calculateComplexity(symbol Symbol) int {\n\tcomplexity := 1 // base complexity\n\n\tswitch symbol.Type {\n\tcase \"func\", \"method\":\n\t\t// Complexity based on number of parameters and return values\n\t\tcomplexity += len(symbol.Params) + len(symbol.Returns)\n\t\t// If we have function calls, add complexity\n\t\tcomplexity += len(symbol.Calls)\n\tcase \"struct\":\n\t\tcomplexity += len(symbol.Fields)\n\tcase \"interface\":\n\t\tcomplexity += len(symbol.Methods)\n\t}\n\n\t// Add complexity for public symbols\n\tif symbol.Public {\n\t\tcomplexity++\n\t}\n\n\t// Add complexity for detailed documentation\n\tif symbol.Doc != \"\" && len(strings.Fields(symbol.Doc)) > 10 {\n\t\tcomplexity += 2\n\t}\n\n\treturn complexity\n}\n\n// SearchSimilar finds similar code using vector similarity",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_SearchSimilar_584": {
      "name": "SearchSimilar",
      "type": "method",
      "start_line": 584,
      "end_line": 597,
      "content_hash": "2be938504f6aaa0dde5348aa108739a6af1b05ca",
      "content": "func (e *EmbeddingEngine) SearchSimilar(ctx context.Context, query string, limit int) ([]Embedding, error) {\n\t// Generate embedding for query\n\tqueryVector, err := e.provider.GenerateEmbedding(ctx, query)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to generate query embedding: %w\", err)\n\t}\n\n\t// Get all embeddings from storage\n\tallEmbeddings, err := e.indexer.GetAllEmbeddings(ctx)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to get embeddings: %w\", err)\n\t}\n\n\t// Calculate similarity scores",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "struct_scoredEmbedding_598": {
      "name": "scoredEmbedding",
      "type": "struct",
      "start_line": 598,
      "end_line": 635,
      "content_hash": "bcd805b1b5c5f594371f03221094f9ea029a1630",
      "content": "\ttype scoredEmbedding struct {\n\t\tembedding Embedding\n\t\tscore     float32\n\t}\n\n\tscored := make([]scoredEmbedding, 0, len(allEmbeddings))\n\tfor _, emb := range allEmbeddings {\n\t\tscore := e.cosineSimilarity(queryVector, emb.Vector)\n\t\tif score > 0.1 { // Threshold for relevance\n\t\t\tscored = append(scored, scoredEmbedding{\n\t\t\t\tembedding: emb,\n\t\t\t\tscore:     score,\n\t\t\t})\n\t\t}\n\t}\n\n\t// Sort by score\n\tfor i := 0; i < len(scored)-1; i++ {\n\t\tfor j := i + 1; j < len(scored); j++ {\n\t\t\tif scored[i].score < scored[j].score {\n\t\t\t\tscored[i], scored[j] = scored[j], scored[i]\n\t\t\t}\n\t\t}\n\t}\n\n\t// Return top results\n\tresult := make([]Embedding, 0, limit)\n\tfor i, s := range scored {\n\t\tif i >= limit {\n\t\t\tbreak\n\t\t}\n\t\tresult = append(result, s.embedding)\n\t}\n\n\treturn result, nil\n}\n\n// cosineSimilarity calculates the cosine similarity between two vectors",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_cosineSimilarity_636": {
      "name": "cosineSimilarity",
      "type": "method",
      "start_line": 636,
      "end_line": 655,
      "content_hash": "3921b99c3eae984043bf2ebbfbc1966403923336",
      "content": "func (e *EmbeddingEngine) cosineSimilarity(a, b []float32) float32 {\n\tif len(a) != len(b) {\n\t\treturn 0\n\t}\n\n\tvar dotProduct, normA, normB float32\n\tfor i := 0; i < len(a); i++ {\n\t\tdotProduct += a[i] * b[i]\n\t\tnormA += a[i] * a[i]\n\t\tnormB += b[i] * b[i]\n\t}\n\n\tif normA == 0 || normB == 0 {\n\t\treturn 0\n\t}\n\n\treturn dotProduct / (float32(math.Sqrt(float64(normA)) * math.Sqrt(float64(normB))))\n}\n\n// Mock embedding generation for development",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_generateMockEmbedding_656": {
      "name": "generateMockEmbedding",
      "type": "function",
      "start_line": 656,
      "end_line": 675,
      "content_hash": "e6a73380c423b50b8a977c7acf1c1ea24dbaf311",
      "content": "func generateMockEmbedding(text string) []float32 {\n\t// Simple hash-based embedding for demo purposes\n\t// In production, this would use actual embedding models\n\tdimensions := 384 // Standard embedding size\n\tvector := make([]float32, dimensions)\n\n\t// Generate deterministic pseudo-random vector based on text\n\thash := 0\n\tfor _, char := range text {\n\t\thash = hash*31 + int(char)\n\t}\n\tseed := uint64(hash)\n\n\tfor i := 0; i < dimensions; i++ {\n\t\tseed = seed*1103515245 + 12345\n\t\tvector[i] = float32((seed>>16)&0xFF) / 255.0\n\t}\n\n\treturn vector\n}",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}