{
  "file_path": "/work/internal/indexer/performance_test.go",
  "file_hash": "252acd3511db6c7ce8289b10628a1427d12a4874",
  "updated_at": "2025-12-26T17:34:23.876849",
  "symbols": {
    "struct_PerformanceBenchmark_14": {
      "name": "PerformanceBenchmark",
      "type": "struct",
      "start_line": 14,
      "end_line": 21,
      "content_hash": "07fc7c469dad37013d368060e99250d41751c9fa",
      "content": "type PerformanceBenchmark struct {\n\tctx        context.Context\n\tindexer    *Indexer\n\tparser     *ASTParser\n\tembeddings *EmbeddingEngine\n}\n\n// NewPerformanceBenchmark creates a new performance benchmark",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_NewPerformanceBenchmark_22": {
      "name": "NewPerformanceBenchmark",
      "type": "function",
      "start_line": 22,
      "end_line": 41,
      "content_hash": "4b67cb1cf22373fbf1c7519afa38317285eaea13",
      "content": "func NewPerformanceBenchmark(ctx context.Context) (*PerformanceBenchmark, error) {\n\t// Create in-memory indexer for testing\n\tindexer, err := NewIndexer(\":memory:\")\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create indexer: %w\", err)\n\t}\n\n\tparser := NewASTParser()\n\tprovider := NewLocalProvider(\"mock\", \"\")\n\tembeddings := NewEmbeddingEngine(provider, indexer)\n\n\treturn &PerformanceBenchmark{\n\t\tctx:        ctx,\n\t\tindexer:    indexer,\n\t\tparser:     parser,\n\t\tembeddings: embeddings,\n\t}, nil\n}\n\n// BenchmarkResult holds performance benchmark results",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "struct_BenchmarkResult_42": {
      "name": "BenchmarkResult",
      "type": "struct",
      "start_line": 42,
      "end_line": 52,
      "content_hash": "59b398812171915eba78abae67d0d71b447dd988",
      "content": "type BenchmarkResult struct {\n\tName           string        `json:\"name\"`\n\tOperationCount int           `json:\"operation_count\"`\n\tDuration       time.Duration `json:\"duration\"`\n\tThroughput     float64       `json:\"throughput\"` // Operations per second\n\tMemoryUsage    int64         `json:\"memory_usage_bytes\"`\n\tSuccess        bool          `json:\"success\"`\n\tError          string        `json:\"error,omitempty\"`\n}\n\n// BenchmarkSuite holds multiple benchmark results",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "struct_BenchmarkSuite_53": {
      "name": "BenchmarkSuite",
      "type": "struct",
      "start_line": 53,
      "end_line": 59,
      "content_hash": "4f8219f816c64f57f3a3d462082bd6ec2aef8896",
      "content": "type BenchmarkSuite struct {\n\tBenchmarks []BenchmarkResult `json:\"benchmarks\"`\n\tTotalTime  time.Duration     `json:\"total_time\"`\n\tCompleted  time.Time         `json:\"completed_at\"`\n}\n\n// RunAllBenchmarks executes the complete performance test suite",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_RunAllBenchmarks_60": {
      "name": "RunAllBenchmarks",
      "type": "method",
      "start_line": 60,
      "end_line": 94,
      "content_hash": "ac6d0d313a02d7173f54f98da4d488788b45a5a1",
      "content": "func (pb *PerformanceBenchmark) RunAllBenchmarks() *BenchmarkSuite {\n\tslog.Info(\"Starting performance benchmark suite\")\n\n\tvar results []BenchmarkResult\n\tstart := time.Now()\n\n\t// Benchmark 1: Parsing performance\n\tresults = append(results, pb.benchmarkParsing())\n\n\t// Benchmark 2: Indexing performance\n\tresults = append(results, pb.benchmarkIndexing())\n\n\t// Benchmark 3: Query performance\n\tresults = append(results, pb.benchmarkQuerying())\n\n\t// Benchmark 4: Embedding performance\n\tresults = append(results, pb.benchmarkEmbeddings())\n\n\t// Benchmark 5: Concurrency performance\n\tresults = append(results, pb.benchmarkConcurrency())\n\n\tsuite := &BenchmarkSuite{\n\t\tBenchmarks: results,\n\t\tTotalTime:  time.Since(start),\n\t\tCompleted:  time.Now(),\n\t}\n\n\tslog.Info(\"Performance benchmark suite completed\",\n\t\t\"benchmarks\", len(results),\n\t\t\"total_duration\", suite.TotalTime)\n\n\treturn suite\n}\n\n// benchmarkParsing tests AST parsing speed",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_benchmarkParsing_95": {
      "name": "benchmarkParsing",
      "type": "method",
      "start_line": 95,
      "end_line": 127,
      "content_hash": "399fcc0e352b612e5994f0a42a66d9ba66e7fc48",
      "content": "func (pb *PerformanceBenchmark) benchmarkParsing() BenchmarkResult {\n\tstart := time.Now()\n\n\t// Parse the indexer directory multiple times\n\titerations := 10\n\ttotalFiles := 0\n\n\tfor range iterations {\n\t\tsymbols, err := pb.parser.ParseDirectory(pb.ctx, \"/home/nexora/internal/indexer\")\n\t\tif err != nil {\n\t\t\treturn BenchmarkResult{\n\t\t\t\tName:     \"Parser_AST\",\n\t\t\t\tError:    fmt.Sprintf(\"Parse failed: %v\", err),\n\t\t\t\tDuration: time.Since(start),\n\t\t\t\tSuccess:  false,\n\t\t\t}\n\t\t}\n\t\ttotalFiles += len(symbols)\n\t}\n\n\tduration := time.Since(start)\n\tthroughput := float64(totalFiles) / duration.Seconds()\n\n\treturn BenchmarkResult{\n\t\tName:           \"Parser_AST\",\n\t\tOperationCount: totalFiles,\n\t\tDuration:       duration,\n\t\tThroughput:     throughput,\n\t\tSuccess:        true,\n\t}\n}\n\n// benchmarkIndexing tests symbol storage speed",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_benchmarkIndexing_128": {
      "name": "benchmarkIndexing",
      "type": "method",
      "start_line": 128,
      "end_line": 168,
      "content_hash": "226a552dac88e483e96d4d1abd93b343f23b6078",
      "content": "func (pb *PerformanceBenchmark) benchmarkIndexing() BenchmarkResult {\n\tstart := time.Now()\n\n\t// Parse symbols once\n\tsymbols, err := pb.parser.ParseDirectory(pb.ctx, \"/home/nexora/internal/indexer\")\n\tif err != nil {\n\t\treturn BenchmarkResult{\n\t\t\tName:     \"Indexing_Storage\",\n\t\t\tError:    fmt.Sprintf(\"Parse failed: %v\", err),\n\t\t\tDuration: time.Since(start),\n\t\t\tSuccess:  false,\n\t\t}\n\t}\n\n\t// Store symbols multiple times\n\titerations := 5\n\tfor range iterations {\n\t\terr := pb.indexer.StoreSymbols(pb.ctx, symbols)\n\t\tif err != nil {\n\t\t\treturn BenchmarkResult{\n\t\t\t\tName:     \"Indexing_Storage\",\n\t\t\t\tError:    fmt.Sprintf(\"Store failed: %v\", err),\n\t\t\t\tDuration: time.Since(start),\n\t\t\t\tSuccess:  false,\n\t\t\t}\n\t\t}\n\t}\n\n\tduration := time.Since(start)\n\tthroughput := float64(len(symbols)*iterations) / duration.Seconds()\n\n\treturn BenchmarkResult{\n\t\tName:           \"Indexing_Storage\",\n\t\tOperationCount: len(symbols) * iterations,\n\t\tDuration:       duration,\n\t\tThroughput:     throughput,\n\t\tSuccess:        true,\n\t}\n}\n\n// benchmarkQuerying tests search speed",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_benchmarkQuerying_169": {
      "name": "benchmarkQuerying",
      "type": "method",
      "start_line": 169,
      "end_line": 219,
      "content_hash": "9f609c3f119c0d5d4c229c021077524a694c2f7f",
      "content": "func (pb *PerformanceBenchmark) benchmarkQuerying() BenchmarkResult {\n\tstart := time.Now()\n\n\t// Index some data first\n\tsymbols, err := pb.parser.ParseDirectory(pb.ctx, \"/home/nexora/internal/indexer\")\n\tif err != nil {\n\t\treturn BenchmarkResult{\n\t\t\tName:     \"Query_Search\",\n\t\t\tError:    fmt.Sprintf(\"Parse failed: %v\", err),\n\t\t\tDuration: time.Since(start),\n\t\t\tSuccess:  false,\n\t\t}\n\t}\n\n\tif err := pb.indexer.StoreSymbols(pb.ctx, symbols); err != nil {\n\t\treturn BenchmarkResult{\n\t\t\tName:     \"Query_Search\",\n\t\t\tError:    fmt.Sprintf(\"Store failed: %v\", err),\n\t\t\tDuration: time.Since(start),\n\t\t\tSuccess:  false,\n\t\t}\n\t}\n\n\t// Perform many searches\n\tqueryStart := time.Now()\n\titerations := 100\n\tfor i := range iterations {\n\t\t_, err := pb.indexer.SearchSymbols(pb.ctx, fmt.Sprintf(\"test_query_%d\", i), 10)\n\t\tif err != nil {\n\t\t\treturn BenchmarkResult{\n\t\t\t\tName:     \"Query_Search\",\n\t\t\t\tError:    fmt.Sprintf(\"Query failed: %v\", err),\n\t\t\t\tDuration: time.Since(start),\n\t\t\t\tSuccess:  false,\n\t\t\t}\n\t\t}\n\t}\n\n\tduration := time.Since(queryStart)\n\tthroughput := float64(iterations) / duration.Seconds()\n\n\treturn BenchmarkResult{\n\t\tName:           \"Query_Search\",\n\t\tOperationCount: iterations,\n\t\tDuration:       duration,\n\t\tThroughput:     throughput,\n\t\tSuccess:        true,\n\t}\n}\n\n// benchmarkEmbeddings tests embedding generation speed",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_benchmarkEmbeddings_220": {
      "name": "benchmarkEmbeddings",
      "type": "method",
      "start_line": 220,
      "end_line": 262,
      "content_hash": "dd4df5f03d95c753692aecff1cc72d9bc5d5a890",
      "content": "func (pb *PerformanceBenchmark) benchmarkEmbeddings() BenchmarkResult {\n\tstart := time.Now()\n\n\t// Get some symbols\n\tsymbols, err := pb.parser.ParseDirectory(pb.ctx, \"/home/nexora/internal/indexer\")\n\tif err != nil {\n\t\treturn BenchmarkResult{\n\t\t\tName:     \"Embeddings_Generation\",\n\t\t\tError:    fmt.Sprintf(\"Parse failed: %v\", err),\n\t\t\tDuration: time.Since(start),\n\t\t\tSuccess:  false,\n\t\t}\n\t}\n\n\t// Limit symbols for testing\n\tif len(symbols) > 50 {\n\t\tsymbols = symbols[:50]\n\t}\n\n\t// Generate embeddings\n\tembeddings, err := pb.embeddings.GenerateSymbolEmbeddings(pb.ctx, symbols)\n\tif err != nil {\n\t\treturn BenchmarkResult{\n\t\t\tName:     \"Embeddings_Generation\",\n\t\t\tError:    fmt.Sprintf(\"Embedding failed: %v\", err),\n\t\t\tDuration: time.Since(start),\n\t\t\tSuccess:  false,\n\t\t}\n\t}\n\n\tduration := time.Since(start)\n\tthroughput := float64(len(embeddings)) / duration.Seconds()\n\n\treturn BenchmarkResult{\n\t\tName:           \"Embeddings_Generation\",\n\t\tOperationCount: len(embeddings),\n\t\tDuration:       duration,\n\t\tThroughput:     throughput,\n\t\tSuccess:        true,\n\t}\n}\n\n// benchmarkConcurrency tests concurrent operations",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_benchmarkConcurrency_263": {
      "name": "benchmarkConcurrency",
      "type": "method",
      "start_line": 263,
      "end_line": 339,
      "content_hash": "274892ba53aea40359b4e10012b4e600e07d02e5",
      "content": "func (pb *PerformanceBenchmark) benchmarkConcurrency() BenchmarkResult {\n\tstart := time.Now()\n\n\t// Index some data first\n\tsymbols, err := pb.parser.ParseDirectory(pb.ctx, \"/home/nexora/internal/indexer\")\n\tif err != nil {\n\t\treturn BenchmarkResult{\n\t\t\tName:     \"Concurrency_Operations\",\n\t\t\tError:    fmt.Sprintf(\"Parse failed: %v\", err),\n\t\t\tDuration: time.Since(start),\n\t\t\tSuccess:  false,\n\t\t}\n\t}\n\n\tif err := pb.indexer.StoreSymbols(pb.ctx, symbols); err != nil {\n\t\treturn BenchmarkResult{\n\t\t\tName:     \"Concurrency_Operations\",\n\t\t\tError:    fmt.Sprintf(\"Store failed: %v\", err),\n\t\t\tDuration: time.Since(start),\n\t\t\tSuccess:  false,\n\t\t}\n\t}\n\n\t// Test concurrent operations\n\tvar wg sync.WaitGroup\n\terrors := make(chan error, 20)\n\n\t// Concurrent writes\n\tfor i := 0; i < 5; i++ {\n\t\twg.Add(1)\n\t\tgo func(id int) {\n\t\t\tdefer wg.Done()\n\t\t\terr := pb.indexer.StoreSymbols(pb.ctx, symbols[:10])\n\t\t\tif err != nil {\n\t\t\t\terrors <- fmt.Errorf(\"concurrent write %d failed: %w\", id, err)\n\t\t\t}\n\t\t}(i)\n\t}\n\n\t// Concurrent reads\n\tfor i := 0; i < 10; i++ {\n\t\twg.Add(1)\n\t\tgo func(id int) {\n\t\t\tdefer wg.Done()\n\t\t\t_, err := pb.indexer.SearchSymbols(pb.ctx, fmt.Sprintf(\"query_%d\", id), 5)\n\t\t\tif err != nil {\n\t\t\t\terrors <- fmt.Errorf(\"concurrent read %d failed: %w\", id, err)\n\t\t\t}\n\t\t}(i)\n\t}\n\n\twg.Wait()\n\tclose(errors)\n\n\t// Count errors\n\terrorCount := 0\n\tfor err := range errors {\n\t\terrorCount++\n\t\tslog.Warn(\"Concurrency error\", \"error\", err)\n\t}\n\n\tduration := time.Since(start)\n\tthroughput := float64(15) / duration.Seconds() // 5 writes + 10 reads\n\n\tsuccess := errorCount == 0\n\n\treturn BenchmarkResult{\n\t\tName:           \"Concurrency_Operations\",\n\t\tOperationCount: 15,\n\t\tDuration:       duration,\n\t\tThroughput:     throughput,\n\t\tSuccess:        success,\n\t\tError:          fmt.Sprintf(\"%d errors occurred\", errorCount),\n\t}\n}\n\n// PrintReport formats and prints a performance report",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_PrintReport_340": {
      "name": "PrintReport",
      "type": "method",
      "start_line": 340,
      "end_line": 387,
      "content_hash": "4f7d14ba946c4d1e705988c2adc4cb58949402c9",
      "content": "func (suite *BenchmarkSuite) PrintReport() {\n\tfmt.Println(\"\\n\u26a1 PERFORMANCE BENCHMARK REPORT\")\n\tfmt.Println(\"==============================\")\n\tfmt.Printf(\"Total Benchmark Time: %v\\n\", suite.TotalTime)\n\tfmt.Printf(\"Completed At: %s\\n\", suite.Completed.Format(time.RFC3339))\n\tfmt.Printf(\"Benchmarks Run: %d\\n\", len(suite.Benchmarks))\n\n\tfmt.Println(\"\\nDetailed Results:\")\n\tfor _, result := range suite.Benchmarks {\n\t\tstatus := \"\u2705 PASS\"\n\t\tif !result.Success {\n\t\t\tstatus = \"\u274c FAIL\"\n\t\t}\n\n\t\tfmt.Printf(\"  %s %s\\n\", status, result.Name)\n\t\tfmt.Printf(\"    Operations: %d\\n\", result.OperationCount)\n\t\tfmt.Printf(\"    Duration: %v\\n\", result.Duration)\n\t\tfmt.Printf(\"    Throughput: %.2f ops/sec\\n\", result.Throughput)\n\n\t\tif result.Error != \"\" {\n\t\t\tfmt.Printf(\"    Error: %s\\n\", result.Error)\n\t\t}\n\t\tfmt.Println()\n\t}\n\n\t// Performance summary\n\tvar avgThroughput float64\n\tvar successfulTests int\n\n\tfor _, result := range suite.Benchmarks {\n\t\tif result.Success {\n\t\t\tsuccessfulTests++\n\t\t\tavgThroughput += result.Throughput\n\t\t}\n\t}\n\n\tif successfulTests > 0 {\n\t\tavgThroughput /= float64(successfulTests)\n\t}\n\n\tfmt.Println(\"\ud83d\udcca Performance Summary:\")\n\tfmt.Printf(\"  Success Rate: %d/%d (%.1f%%)\\n\",\n\t\tsuccessfulTests, len(suite.Benchmarks),\n\t\tfloat64(successfulTests)/float64(len(suite.Benchmarks))*100)\n\tfmt.Printf(\"  Average Throughput: %.2f ops/sec\\n\", avgThroughput)\n}\n\n// Close cleans up resources",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_Close_388": {
      "name": "Close",
      "type": "method",
      "start_line": 388,
      "end_line": 394,
      "content_hash": "16dd29cfc8451573a389e78a813f10bd3d6434aa",
      "content": "func (pb *PerformanceBenchmark) Close() {\n\tif pb.indexer != nil {\n\t\tpb.indexer.Close()\n\t}\n}\n\n// RunPerformanceTests is the main entry point for performance testing",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_RunPerformanceTests_395": {
      "name": "RunPerformanceTests",
      "type": "function",
      "start_line": 395,
      "end_line": 416,
      "content_hash": "9d924f1d969d776fcaa5156b92ac9a5655fa0b8c",
      "content": "func RunPerformanceTests(ctx context.Context) error {\n\tbenchmark, err := NewPerformanceBenchmark(ctx)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to create benchmark: %w\", err)\n\t}\n\tdefer benchmark.Close()\n\n\t// Run benchmarks\n\tsuite := benchmark.RunAllBenchmarks()\n\n\t// Print report\n\tsuite.PrintReport()\n\n\t// Return error if any benchmarks failed\n\tfor _, result := range suite.Benchmarks {\n\t\tif !result.Success {\n\t\t\treturn fmt.Errorf(\"performance benchmarks failed\")\n\t\t}\n\t}\n\n\treturn nil\n}",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}