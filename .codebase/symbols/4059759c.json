{
  "file_path": "/work/context-engine/scripts/rerank_recursive/alpha_scheduler.py",
  "file_hash": "0d209f1f7f4760f61aeb8e9444f2e41176f67009",
  "updated_at": "2025-12-26T17:34:22.668635",
  "symbols": {
    "class_CosineAlphaScheduler_19": {
      "name": "CosineAlphaScheduler",
      "type": "class",
      "start_line": 19,
      "end_line": 60,
      "content_hash": "f718404a4cc6eadb155abcf6c7b9e8c887a1cee6",
      "content": "class CosineAlphaScheduler:\n    \"\"\"Fixed cosine schedule for alpha values.\n    \n    \u03b1 = alpha_min + (alpha_max - alpha_min) * (1 + cos(\u03c0 * i / (n-1))) / 2\n    \n    This gives higher \u03b1 early (trust new scores more) and lower \u03b1 later\n    (rely more on refined estimates).\n    \"\"\"\n    \n    def __init__(\n        self,\n        n_iterations: int = 3,\n        alpha_max: float = 0.7,\n        alpha_min: float = 0.3,\n    ):\n        self.n_iterations = max(1, n_iterations)\n        self.alpha_max = alpha_max\n        self.alpha_min = alpha_min\n        # Pre-compute schedule\n        self._schedule = self._compute_schedule()\n    \n    def _compute_schedule(self) -> List[float]:\n        \"\"\"Compute the full schedule.\"\"\"\n        if self.n_iterations == 1:\n            return [(self.alpha_max + self.alpha_min) / 2]\n        \n        schedule = []\n        for i in range(self.n_iterations):\n            # Cosine decay from alpha_max to alpha_min\n            progress = i / (self.n_iterations - 1)\n            alpha = self.alpha_min + (self.alpha_max - self.alpha_min) * (1 + np.cos(np.pi * progress)) / 2\n            schedule.append(float(alpha))\n        return schedule\n    \n    def get_alpha(self, iteration: int) -> float:\n        \"\"\"Get alpha for a specific iteration (0-indexed).\"\"\"\n        idx = max(0, min(iteration, len(self._schedule) - 1))\n        return self._schedule[idx]\n    \n    def get_schedule(self) -> List[float]:\n        \"\"\"Get the full schedule.\"\"\"\n        return self._schedule.copy()",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___init___28": {
      "name": "__init__",
      "type": "method",
      "start_line": 28,
      "end_line": 38,
      "content_hash": "6c02efed2fb825a8b5e97777d81546428c4bfcfb",
      "content": "    def __init__(\n        self,\n        n_iterations: int = 3,\n        alpha_max: float = 0.7,\n        alpha_min: float = 0.3,\n    ):\n        self.n_iterations = max(1, n_iterations)\n        self.alpha_max = alpha_max\n        self.alpha_min = alpha_min\n        # Pre-compute schedule\n        self._schedule = self._compute_schedule()",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__compute_schedule_40": {
      "name": "_compute_schedule",
      "type": "method",
      "start_line": 40,
      "end_line": 51,
      "content_hash": "833c7b50cc9d3ffeca85f8a288f14d1b8f674be7",
      "content": "    def _compute_schedule(self) -> List[float]:\n        \"\"\"Compute the full schedule.\"\"\"\n        if self.n_iterations == 1:\n            return [(self.alpha_max + self.alpha_min) / 2]\n        \n        schedule = []\n        for i in range(self.n_iterations):\n            # Cosine decay from alpha_max to alpha_min\n            progress = i / (self.n_iterations - 1)\n            alpha = self.alpha_min + (self.alpha_max - self.alpha_min) * (1 + np.cos(np.pi * progress)) / 2\n            schedule.append(float(alpha))\n        return schedule",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_get_alpha_53": {
      "name": "get_alpha",
      "type": "method",
      "start_line": 53,
      "end_line": 56,
      "content_hash": "667246828d226c25832ddd9145e58bce1d2fdf97",
      "content": "    def get_alpha(self, iteration: int) -> float:\n        \"\"\"Get alpha for a specific iteration (0-indexed).\"\"\"\n        idx = max(0, min(iteration, len(self._schedule) - 1))\n        return self._schedule[idx]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_get_schedule_58": {
      "name": "get_schedule",
      "type": "method",
      "start_line": 58,
      "end_line": 60,
      "content_hash": "c8f478fec4fa652bd76cce51f6466ea7e7fd73a8",
      "content": "    def get_schedule(self) -> List[float]:\n        \"\"\"Get the full schedule.\"\"\"\n        return self._schedule.copy()",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "class_LearnedAlphaWeights_63": {
      "name": "LearnedAlphaWeights",
      "type": "class",
      "start_line": 63,
      "end_line": 298,
      "content_hash": "99c01e9694f104d57bc209361ac6b33a12e71325",
      "content": "class LearnedAlphaWeights:\n    \"\"\"Learnable per-iteration alpha weights with persistence.\n    \n    Uses sigmoid(raw_weight) to keep alpha in (0, 1).\n    Learns optimal blending through gradient descent on ranking loss.\n    \"\"\"\n    \n    WEIGHTS_DIR = os.environ.get(\"RERANKER_WEIGHTS_DIR\", \"/tmp/rerank_weights\")\n    WEIGHTS_RELOAD_INTERVAL = float(os.environ.get(\"RERANKER_WEIGHTS_RELOAD_INTERVAL\", \"60\"))\n    \n    def __init__(\n        self,\n        n_iterations: int = 3,\n        init_alpha: float = 0.5,\n        lr: float = 0.01,\n    ):\n        self.n_iterations = max(1, n_iterations)\n        self.lr = lr\n        self._collection = \"default\"\n        self._weights_path = self._get_weights_path(\"default\")\n        self._weights_mtime = 0.0\n        self._last_reload_check = 0.0\n        self._weights_loaded = False\n        self._update_count = 0\n        self._version = 0\n        \n        # Initialize raw weights such that sigmoid(raw) = init_alpha\n        # sigmoid(x) = init_alpha => x = logit(init_alpha)\n        init_raw = np.log(init_alpha / (1 - init_alpha + 1e-8))\n        self.raw_weights = np.full(self.n_iterations, init_raw, dtype=np.float32)\n        self._momentum = np.zeros_like(self.raw_weights)\n        \n        # Try to load saved weights\n        if os.path.exists(self._weights_path):\n            try:\n                self._load_weights()\n            except Exception as e:\n                from scripts.logger import get_logger\n                get_logger(__name__).warning(f\"LearnedAlphaWeights: failed to load: {e}\")\n    \n    @staticmethod\n    def _sanitize_collection(collection: str) -> str:\n        return \"\".join(c if c.isalnum() or c in \"-_\" else \"_\" for c in collection)\n    \n    def _get_weights_path(self, collection: str) -> str:\n        safe_name = self._sanitize_collection(collection)\n        return os.path.join(self.WEIGHTS_DIR, f\"alpha_{safe_name}.npz\")\n    \n    def set_collection(self, collection: str):\n        \"\"\"Set collection and load corresponding weights.\"\"\"\n        self._collection = collection\n        self._weights_path = self._get_weights_path(collection)\n        if os.path.exists(self._weights_path):\n            try:\n                self._load_weights()\n            except Exception:\n                pass\n    \n    def _sigmoid(self, x: np.ndarray) -> np.ndarray:\n        \"\"\"Numerically stable sigmoid.\"\"\"\n        return np.where(\n            x >= 0,\n            1 / (1 + np.exp(-x)),\n            np.exp(x) / (1 + np.exp(x))\n        )\n    \n    def _sigmoid_grad(self, sigmoid_val: np.ndarray) -> np.ndarray:\n        \"\"\"Gradient of sigmoid: \u03c3(x) * (1 - \u03c3(x)).\"\"\"\n        return sigmoid_val * (1 - sigmoid_val)\n    \n    def get_alpha(self, iteration: int) -> float:\n        \"\"\"Get alpha for a specific iteration (0-indexed).\"\"\"\n        self.maybe_reload_weights()\n        idx = max(0, min(iteration, len(self.raw_weights) - 1))\n        return float(self._sigmoid(self.raw_weights[idx]))\n    \n    def get_schedule(self) -> List[float]:\n        \"\"\"Get alpha values for all iterations.\"\"\"\n        return [float(a) for a in self._sigmoid(self.raw_weights)]\n    \n    def maybe_reload_weights(self):\n        \"\"\"Hot-reload weights if changed on disk.\"\"\"\n        now = time.time()\n        if now - self._last_reload_check < self.WEIGHTS_RELOAD_INTERVAL:\n            return\n        self._last_reload_check = now\n        try:\n            if os.path.exists(self._weights_path):\n                mtime = os.path.getmtime(self._weights_path)\n                if mtime > self._weights_mtime:\n                    self._load_weights()\n        except Exception:\n            pass\n    \n    def learn_from_ranking_loss(\n        self,\n        iteration: int,\n        blended_scores: np.ndarray,\n        teacher_scores: np.ndarray,\n        new_scores: Optional[np.ndarray] = None,\n        prev_scores: Optional[np.ndarray] = None,\n    ) -> float:\n        \"\"\"Learn alpha to minimize ranking difference with teacher.\n        \n        Uses pairwise ranking loss: if teacher prefers A over B, reduce loss\n        when our blended scores also prefer A over B.\n        \n        Args:\n            iteration: Which iteration's alpha to update\n            blended_scores: (n_docs,) our blended scores at this iteration\n            teacher_scores: (n_docs,) ground truth scores\n            new_scores: (n_docs,) optional - the \"new\" signal before blending\n            prev_scores: (n_docs,) optional - the \"previous\" signal before blending\n            \n        Returns:\n            Gradient magnitude (for logging)\n        \"\"\"\n        if len(blended_scores) < 2:\n            return 0.0\n        \n        idx = max(0, min(iteration, len(self.raw_weights) - 1))\n        alpha = self._sigmoid(self.raw_weights[idx:idx+1])[0]\n        \n        # Compute ranking agreement\n        our_order = np.argsort(-blended_scores)\n        teacher_order = np.argsort(-teacher_scores)\n        \n        # Count top-k mismatches\n        k = min(3, len(blended_scores))\n        n_mismatches = np.sum(our_order[:k] != teacher_order[:k])\n        \n        if n_mismatches == 0:\n            return 0.0  # Perfect match, no update needed\n        \n        # Determine gradient direction based on which signal would have helped\n        grad_direction = 1.0  # Default: increase alpha (trust new scores more)\n        \n        if new_scores is not None and prev_scores is not None:\n            # Compare: would higher alpha (more new_scores) or lower alpha (more prev_scores) help?\n            new_order = np.argsort(-new_scores)\n            prev_order = np.argsort(-prev_scores)\n            \n            # Count how many top-k matches each signal has with teacher\n            new_matches = np.sum(new_order[:k] == teacher_order[:k])\n            prev_matches = np.sum(prev_order[:k] == teacher_order[:k])\n            \n            if prev_matches > new_matches:\n                # Previous scores are better aligned with teacher \u2192 decrease alpha\n                grad_direction = -1.0\n            elif new_matches > prev_matches:\n                # New scores are better aligned with teacher \u2192 increase alpha\n                grad_direction = 1.0\n            else:\n                # Tie: small nudge toward middle (alpha=0.5)\n                grad_direction = 0.5 - alpha  # Pull toward 0.5\n        \n        # Gradient through sigmoid, scaled by mismatches and direction\n        sigmoid_grad = self._sigmoid_grad(np.array([alpha]))[0]\n        grad = n_mismatches * 0.1 * sigmoid_grad * grad_direction\n        \n        # Momentum SGD\n        momentum = 0.9\n        self._momentum[idx] = momentum * self._momentum[idx] + grad\n        self.raw_weights[idx] -= self.lr * self._momentum[idx]\n        \n        # Clamp to reasonable range (alpha between ~0.1 and ~0.9)\n        self.raw_weights[idx] = np.clip(self.raw_weights[idx], -2.2, 2.2)\n        \n        self._update_count += 1\n        if self._update_count % 50 == 0:\n            self._save_weights()\n        \n        return abs(grad)\n    \n    def _load_weights(self):\n        \"\"\"Load weights from disk.\"\"\"\n        import fcntl\n        lock_path = self._weights_path + \".lock\"\n        try:\n            os.makedirs(os.path.dirname(lock_path) or \".\", exist_ok=True)\n            with open(lock_path, \"w\") as lock_file:\n                fcntl.flock(lock_file.fileno(), fcntl.LOCK_SH)\n                data = np.load(self._weights_path)\n                loaded_weights = data[\"raw_weights\"]\n                # Handle dimension mismatch gracefully\n                if len(loaded_weights) == len(self.raw_weights):\n                    self.raw_weights = loaded_weights.astype(np.float32)\n                else:\n                    # Resize: copy what we can, init rest\n                    min_len = min(len(loaded_weights), len(self.raw_weights))\n                    self.raw_weights[:min_len] = loaded_weights[:min_len].astype(np.float32)\n                self._version = int(data.get(\"version\", 0))\n                fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)\n            self._weights_mtime = os.path.getmtime(self._weights_path)\n            self._weights_loaded = True\n            self._momentum = np.zeros_like(self.raw_weights)\n        except Exception as e:\n            from scripts.logger import get_logger\n            get_logger(__name__).warning(f\"LearnedAlphaWeights: load failed: {e}\")\n    \n    def _save_weights(self):\n        \"\"\"Save weights atomically.\"\"\"\n        import fcntl\n        os.makedirs(self.WEIGHTS_DIR, exist_ok=True)\n        lock_path = self._weights_path + \".lock\"\n        tmp_path = self._weights_path.replace(\".npz\", \".tmp.npz\")\n        self._version += 1\n        try:\n            with open(lock_path, \"w\") as lock_file:\n                fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX)\n                np.savez(\n                    tmp_path,\n                    raw_weights=self.raw_weights,\n                    version=self._version,\n                    n_iterations=self.n_iterations,\n                )\n                os.replace(tmp_path, self._weights_path)\n                fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)\n            self._weights_mtime = os.path.getmtime(self._weights_path)\n        except Exception as e:\n            from scripts.logger import get_logger\n            get_logger(__name__).warning(f\"LearnedAlphaWeights: save failed: {e}\")\n            if os.path.exists(tmp_path):\n                try:\n                    os.remove(tmp_path)\n                except Exception:\n                    pass\n    \n    def get_metrics(self) -> Dict[str, Any]:\n        \"\"\"Get current metrics for logging.\"\"\"\n        return {\n            \"collection\": self._collection,\n            \"version\": self._version,\n            \"update_count\": self._update_count,\n            \"alphas\": self.get_schedule(),\n        }",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method___init___73": {
      "name": "__init__",
      "type": "method",
      "start_line": 73,
      "end_line": 101,
      "content_hash": "259edb358342e64f2fb7524de7900b669138d365",
      "content": "    def __init__(\n        self,\n        n_iterations: int = 3,\n        init_alpha: float = 0.5,\n        lr: float = 0.01,\n    ):\n        self.n_iterations = max(1, n_iterations)\n        self.lr = lr\n        self._collection = \"default\"\n        self._weights_path = self._get_weights_path(\"default\")\n        self._weights_mtime = 0.0\n        self._last_reload_check = 0.0\n        self._weights_loaded = False\n        self._update_count = 0\n        self._version = 0\n        \n        # Initialize raw weights such that sigmoid(raw) = init_alpha\n        # sigmoid(x) = init_alpha => x = logit(init_alpha)\n        init_raw = np.log(init_alpha / (1 - init_alpha + 1e-8))\n        self.raw_weights = np.full(self.n_iterations, init_raw, dtype=np.float32)\n        self._momentum = np.zeros_like(self.raw_weights)\n        \n        # Try to load saved weights\n        if os.path.exists(self._weights_path):\n            try:\n                self._load_weights()\n            except Exception as e:\n                from scripts.logger import get_logger\n                get_logger(__name__).warning(f\"LearnedAlphaWeights: failed to load: {e}\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__sanitize_collection_104": {
      "name": "_sanitize_collection",
      "type": "method",
      "start_line": 104,
      "end_line": 105,
      "content_hash": "cdbd85077085baad363b24f06dafd0ea2c67f8d3",
      "content": "    def _sanitize_collection(collection: str) -> str:\n        return \"\".join(c if c.isalnum() or c in \"-_\" else \"_\" for c in collection)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__get_weights_path_107": {
      "name": "_get_weights_path",
      "type": "method",
      "start_line": 107,
      "end_line": 109,
      "content_hash": "6867a3b2508e3a126dfa7ad705a53557b635a433",
      "content": "    def _get_weights_path(self, collection: str) -> str:\n        safe_name = self._sanitize_collection(collection)\n        return os.path.join(self.WEIGHTS_DIR, f\"alpha_{safe_name}.npz\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_set_collection_111": {
      "name": "set_collection",
      "type": "method",
      "start_line": 111,
      "end_line": 119,
      "content_hash": "4dae7da98f3091db4d26c907c21a25aa337d6f9d",
      "content": "    def set_collection(self, collection: str):\n        \"\"\"Set collection and load corresponding weights.\"\"\"\n        self._collection = collection\n        self._weights_path = self._get_weights_path(collection)\n        if os.path.exists(self._weights_path):\n            try:\n                self._load_weights()\n            except Exception:\n                pass",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__sigmoid_121": {
      "name": "_sigmoid",
      "type": "method",
      "start_line": 121,
      "end_line": 127,
      "content_hash": "44618ab33bb6f5d221c4d3369850fd6fe46535fd",
      "content": "    def _sigmoid(self, x: np.ndarray) -> np.ndarray:\n        \"\"\"Numerically stable sigmoid.\"\"\"\n        return np.where(\n            x >= 0,\n            1 / (1 + np.exp(-x)),\n            np.exp(x) / (1 + np.exp(x))\n        )",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__sigmoid_grad_129": {
      "name": "_sigmoid_grad",
      "type": "method",
      "start_line": 129,
      "end_line": 131,
      "content_hash": "fc172dd9629eb3967b2c9f5d0fb08ed1e10d51d4",
      "content": "    def _sigmoid_grad(self, sigmoid_val: np.ndarray) -> np.ndarray:\n        \"\"\"Gradient of sigmoid: \u03c3(x) * (1 - \u03c3(x)).\"\"\"\n        return sigmoid_val * (1 - sigmoid_val)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_get_alpha_133": {
      "name": "get_alpha",
      "type": "method",
      "start_line": 133,
      "end_line": 137,
      "content_hash": "d2ed29eb2f9cb6b5de3b02c310d032af550e3dd3",
      "content": "    def get_alpha(self, iteration: int) -> float:\n        \"\"\"Get alpha for a specific iteration (0-indexed).\"\"\"\n        self.maybe_reload_weights()\n        idx = max(0, min(iteration, len(self.raw_weights) - 1))\n        return float(self._sigmoid(self.raw_weights[idx]))",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_get_schedule_139": {
      "name": "get_schedule",
      "type": "method",
      "start_line": 139,
      "end_line": 141,
      "content_hash": "a633f5d35acbb10aa3eabf1d8f64328b2fc09f7b",
      "content": "    def get_schedule(self) -> List[float]:\n        \"\"\"Get alpha values for all iterations.\"\"\"\n        return [float(a) for a in self._sigmoid(self.raw_weights)]",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_maybe_reload_weights_143": {
      "name": "maybe_reload_weights",
      "type": "method",
      "start_line": 143,
      "end_line": 155,
      "content_hash": "2ec831f79b0142610969dbf315632bbf3af1ec67",
      "content": "    def maybe_reload_weights(self):\n        \"\"\"Hot-reload weights if changed on disk.\"\"\"\n        now = time.time()\n        if now - self._last_reload_check < self.WEIGHTS_RELOAD_INTERVAL:\n            return\n        self._last_reload_check = now\n        try:\n            if os.path.exists(self._weights_path):\n                mtime = os.path.getmtime(self._weights_path)\n                if mtime > self._weights_mtime:\n                    self._load_weights()\n        except Exception:\n            pass",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_learn_from_ranking_loss_157": {
      "name": "learn_from_ranking_loss",
      "type": "method",
      "start_line": 157,
      "end_line": 235,
      "content_hash": "61e61b0c8e85830f1226680135676d8908871357",
      "content": "    def learn_from_ranking_loss(\n        self,\n        iteration: int,\n        blended_scores: np.ndarray,\n        teacher_scores: np.ndarray,\n        new_scores: Optional[np.ndarray] = None,\n        prev_scores: Optional[np.ndarray] = None,\n    ) -> float:\n        \"\"\"Learn alpha to minimize ranking difference with teacher.\n        \n        Uses pairwise ranking loss: if teacher prefers A over B, reduce loss\n        when our blended scores also prefer A over B.\n        \n        Args:\n            iteration: Which iteration's alpha to update\n            blended_scores: (n_docs,) our blended scores at this iteration\n            teacher_scores: (n_docs,) ground truth scores\n            new_scores: (n_docs,) optional - the \"new\" signal before blending\n            prev_scores: (n_docs,) optional - the \"previous\" signal before blending\n            \n        Returns:\n            Gradient magnitude (for logging)\n        \"\"\"\n        if len(blended_scores) < 2:\n            return 0.0\n        \n        idx = max(0, min(iteration, len(self.raw_weights) - 1))\n        alpha = self._sigmoid(self.raw_weights[idx:idx+1])[0]\n        \n        # Compute ranking agreement\n        our_order = np.argsort(-blended_scores)\n        teacher_order = np.argsort(-teacher_scores)\n        \n        # Count top-k mismatches\n        k = min(3, len(blended_scores))\n        n_mismatches = np.sum(our_order[:k] != teacher_order[:k])\n        \n        if n_mismatches == 0:\n            return 0.0  # Perfect match, no update needed\n        \n        # Determine gradient direction based on which signal would have helped\n        grad_direction = 1.0  # Default: increase alpha (trust new scores more)\n        \n        if new_scores is not None and prev_scores is not None:\n            # Compare: would higher alpha (more new_scores) or lower alpha (more prev_scores) help?\n            new_order = np.argsort(-new_scores)\n            prev_order = np.argsort(-prev_scores)\n            \n            # Count how many top-k matches each signal has with teacher\n            new_matches = np.sum(new_order[:k] == teacher_order[:k])\n            prev_matches = np.sum(prev_order[:k] == teacher_order[:k])\n            \n            if prev_matches > new_matches:\n                # Previous scores are better aligned with teacher \u2192 decrease alpha\n                grad_direction = -1.0\n            elif new_matches > prev_matches:\n                # New scores are better aligned with teacher \u2192 increase alpha\n                grad_direction = 1.0\n            else:\n                # Tie: small nudge toward middle (alpha=0.5)\n                grad_direction = 0.5 - alpha  # Pull toward 0.5\n        \n        # Gradient through sigmoid, scaled by mismatches and direction\n        sigmoid_grad = self._sigmoid_grad(np.array([alpha]))[0]\n        grad = n_mismatches * 0.1 * sigmoid_grad * grad_direction\n        \n        # Momentum SGD\n        momentum = 0.9\n        self._momentum[idx] = momentum * self._momentum[idx] + grad\n        self.raw_weights[idx] -= self.lr * self._momentum[idx]\n        \n        # Clamp to reasonable range (alpha between ~0.1 and ~0.9)\n        self.raw_weights[idx] = np.clip(self.raw_weights[idx], -2.2, 2.2)\n        \n        self._update_count += 1\n        if self._update_count % 50 == 0:\n            self._save_weights()\n        \n        return abs(grad)",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__load_weights_237": {
      "name": "_load_weights",
      "type": "method",
      "start_line": 237,
      "end_line": 261,
      "content_hash": "cad6edc9f43a6091b7cc2062d552241954713389",
      "content": "    def _load_weights(self):\n        \"\"\"Load weights from disk.\"\"\"\n        import fcntl\n        lock_path = self._weights_path + \".lock\"\n        try:\n            os.makedirs(os.path.dirname(lock_path) or \".\", exist_ok=True)\n            with open(lock_path, \"w\") as lock_file:\n                fcntl.flock(lock_file.fileno(), fcntl.LOCK_SH)\n                data = np.load(self._weights_path)\n                loaded_weights = data[\"raw_weights\"]\n                # Handle dimension mismatch gracefully\n                if len(loaded_weights) == len(self.raw_weights):\n                    self.raw_weights = loaded_weights.astype(np.float32)\n                else:\n                    # Resize: copy what we can, init rest\n                    min_len = min(len(loaded_weights), len(self.raw_weights))\n                    self.raw_weights[:min_len] = loaded_weights[:min_len].astype(np.float32)\n                self._version = int(data.get(\"version\", 0))\n                fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)\n            self._weights_mtime = os.path.getmtime(self._weights_path)\n            self._weights_loaded = True\n            self._momentum = np.zeros_like(self.raw_weights)\n        except Exception as e:\n            from scripts.logger import get_logger\n            get_logger(__name__).warning(f\"LearnedAlphaWeights: load failed: {e}\")",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method__save_weights_263": {
      "name": "_save_weights",
      "type": "method",
      "start_line": 263,
      "end_line": 289,
      "content_hash": "171519b32efcf29368ce9ad63959de040c915fa8",
      "content": "    def _save_weights(self):\n        \"\"\"Save weights atomically.\"\"\"\n        import fcntl\n        os.makedirs(self.WEIGHTS_DIR, exist_ok=True)\n        lock_path = self._weights_path + \".lock\"\n        tmp_path = self._weights_path.replace(\".npz\", \".tmp.npz\")\n        self._version += 1\n        try:\n            with open(lock_path, \"w\") as lock_file:\n                fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX)\n                np.savez(\n                    tmp_path,\n                    raw_weights=self.raw_weights,\n                    version=self._version,\n                    n_iterations=self.n_iterations,\n                )\n                os.replace(tmp_path, self._weights_path)\n                fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)\n            self._weights_mtime = os.path.getmtime(self._weights_path)\n        except Exception as e:\n            from scripts.logger import get_logger\n            get_logger(__name__).warning(f\"LearnedAlphaWeights: save failed: {e}\")\n            if os.path.exists(tmp_path):\n                try:\n                    os.remove(tmp_path)\n                except Exception:\n                    pass",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "method_get_metrics_291": {
      "name": "get_metrics",
      "type": "method",
      "start_line": 291,
      "end_line": 298,
      "content_hash": "be43c572b3291ce251cf3877ba0435a9e84d4dae",
      "content": "    def get_metrics(self) -> Dict[str, Any]:\n        \"\"\"Get current metrics for logging.\"\"\"\n        return {\n            \"collection\": self._collection,\n            \"version\": self._version,\n            \"update_count\": self._update_count,\n            \"alphas\": self.get_schedule(),\n        }",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}