{
  "file_path": "/work/context-engine/scripts/mcp_impl/context_search.py",
  "file_hash": "7a59793a003266bf19fd1b6c62d0131b9fee9a9a",
  "updated_at": "2025-12-26T17:34:24.348468",
  "symbols": {
    "function__context_search_impl_44": {
      "name": "_context_search_impl",
      "type": "function",
      "start_line": 44,
      "end_line": 1254,
      "content_hash": "fdfddd8b8d3c94c627cc8a0f90315e9f6cf0b443",
      "content": "async def _context_search_impl(\n    # Core query + limits\n    query: Any = None,\n    limit: Any = None,\n    per_path: Any = None,\n    # Include memory hits and blending controls\n    include_memories: Any = None,\n    memory_weight: Any = None,\n    per_source_limits: Any = None,  # e.g., {\"code\": 5, \"memory\": 3}\n    # Pass-through structured filters (same as repo_search)\n    include_snippet: Any = None,\n    context_lines: Any = None,\n    rerank_enabled: Any = None,\n    rerank_top_n: Any = None,\n    rerank_return_m: Any = None,\n    rerank_timeout_ms: Any = None,\n    highlight_snippet: Any = None,\n    collection: Any = None,\n    language: Any = None,\n    under: Any = None,\n    kind: Any = None,\n    symbol: Any = None,\n    path_regex: Any = None,\n    path_glob: Any = None,\n    not_glob: Any = None,\n    ext: Any = None,\n    not_: Any = None,\n    case: Any = None,\n    session: Any = None,\n    compact: Any = None,\n    # Repo scoping (cross-codebase isolation)\n    repo: Any = None,  # str, list[str], or \"*\" to search all repos\n    # Output format\n    output_format: Any = None,  # \"json\" (default) or \"toon\" for token-efficient format\n    kwargs: Any = None,\n    # Injected dependencies from facade\n    *,\n    repo_search_fn: Any = None,  # async callable for repo_search\n    get_embedding_model_fn: Any = None,  # callable for _get_embedding_model\n) -> Dict[str, Any]:\n    \"\"\"Blend code search results with memory-store entries (notes, docs) for richer context.\n\n    When to use:\n    - You want code spans plus relevant memories in one response.\n    - Prefer repo_search for code-only; use context_answer when you need an LLM-written answer.\n\n    Key parameters:\n    - query: str or list[str]\n    - include_memories: bool (opt-in). If true, queries the memory collection and merges with code results.\n    - memory_weight: float (default 1.0). Scales memory scores relative to code.\n    - per_source_limits: dict, e.g. {\"code\": 5, \"memory\": 3}\n    - All repo_search filters are supported and passed through.\n    - output_format: \"json\" (default) or \"toon\" for token-efficient TOON format.\n    - rerank_enabled: bool (default true). ONNX reranker is ON by default for better relevance.\n    - repo: str or list[str]. Filter by repo name(s). Use \"*\" to search all repos (disable auto-filter).\n      By default, auto-detects current repo from CURRENT_REPO env and filters to it.\n\n    Returns:\n    - {\"results\": [{\"source\": \"code\"| \"memory\", ...}, ...], \"total\": N[, \"memory_note\": str]}\n    - In compact mode, results are reduced to lightweight records.\n\n    Example:\n    - include_memories=true, per_source_limits={\"code\": 6, \"memory\": 2}, path_glob=\"docs/**\"\n    \"\"\"\n    # Unwrap kwargs if MCP client sent everything in a single kwargs string\n    if kwargs and not query and not limit:\n        # If all named params are None and kwargs has content, assume wrapped call\n        query = kwargs.get(\"query\", query)\n        limit = kwargs.get(\"limit\", limit)\n        per_path = kwargs.get(\"per_path\", per_path)\n        include_memories = kwargs.get(\"include_memories\", include_memories)\n        memory_weight = kwargs.get(\"memory_weight\", memory_weight)\n        per_source_limits = kwargs.get(\"per_source_limits\", per_source_limits)\n        include_snippet = kwargs.get(\"include_snippet\", include_snippet)\n        context_lines = kwargs.get(\"context_lines\", context_lines)\n        rerank_enabled = kwargs.get(\"rerank_enabled\", rerank_enabled)\n        rerank_top_n = kwargs.get(\"rerank_top_n\", rerank_top_n)\n        rerank_return_m = kwargs.get(\"rerank_return_m\", rerank_return_m)\n        rerank_timeout_ms = kwargs.get(\"rerank_timeout_ms\", rerank_timeout_ms)\n        highlight_snippet = kwargs.get(\"highlight_snippet\", highlight_snippet)\n        collection = kwargs.get(\"collection\", collection)\n        language = kwargs.get(\"language\", language)\n        under = kwargs.get(\"under\", under)\n        kind = kwargs.get(\"kind\", kind)\n        symbol = kwargs.get(\"symbol\", symbol)\n        path_regex = kwargs.get(\"path_regex\", path_regex)\n        path_glob = kwargs.get(\"path_glob\", path_glob)\n        not_glob = kwargs.get(\"not_glob\", not_glob)\n        ext = kwargs.get(\"ext\", ext)\n        not_ = kwargs.get(\"not_\", not_)\n        case = kwargs.get(\"case\", case)\n        compact = kwargs.get(\"compact\", compact)\n\n    # Unwrap nested payloads that some MCP clients send (kwargs/arguments fields or json strings)\n    def _maybe_dict(val: Any) -> Dict[str, Any]:\n        if isinstance(val, dict):\n            return val\n        if isinstance(val, str) and _looks_jsonish_string(val):\n            parsed = _maybe_parse_jsonish(val)\n            if isinstance(parsed, dict):\n                return parsed\n        return {}\n\n    payloads: List[Dict[str, Any]] = []\n    if isinstance(kwargs, dict):\n        arg_payload = _maybe_dict(kwargs.get(\"arguments\"))\n        if arg_payload:\n            payloads.append(arg_payload)\n        nested_kwargs = _extract_kwargs_payload(kwargs)\n        if nested_kwargs:\n            payloads.append(nested_kwargs)\n    for payload in payloads:\n        if not isinstance(payload, dict):\n            continue\n        if (\n            query is None or (isinstance(query, str) and query.strip() == \"\")\n        ) and payload.get(\"query\") is not None:\n            query = payload.get(\"query\")\n        if (\n            query is None or (isinstance(query, str) and query.strip() == \"\")\n        ) and payload.get(\"queries\") is not None:\n            query = payload.get(\"queries\")\n        if (\n            limit is None or (isinstance(limit, str) and limit.strip() == \"\")\n        ) and payload.get(\"limit\") is not None:\n            limit = payload.get(\"limit\")\n        if (\n            per_path is None\n            or (isinstance(per_path, str) and str(per_path).strip() == \"\")\n        ) and payload.get(\"per_path\") is not None:\n            per_path = payload.get(\"per_path\")\n        if include_memories is None and payload.get(\"include_memories\") is not None:\n            include_memories = payload.get(\"include_memories\")\n        if include_memories is None and payload.get(\"includeMemories\") is not None:\n            include_memories = payload.get(\"includeMemories\")\n        if memory_weight is None and payload.get(\"memory_weight\") is not None:\n            memory_weight = payload.get(\"memory_weight\")\n        if memory_weight is None and payload.get(\"memoryWeight\") is not None:\n            memory_weight = payload.get(\"memoryWeight\")\n        if per_source_limits is None and payload.get(\"per_source_limits\") is not None:\n            per_source_limits = payload.get(\"per_source_limits\")\n        if per_source_limits is None and payload.get(\"perSourceLimits\") is not None:\n            per_source_limits = payload.get(\"perSourceLimits\")\n        if (include_snippet is None or include_snippet == \"\") and payload.get(\n            \"include_snippet\"\n        ) is not None:\n            include_snippet = payload.get(\"include_snippet\")\n        if (include_snippet is None or include_snippet == \"\") and payload.get(\n            \"includeSnippet\"\n        ) is not None:\n            include_snippet = payload.get(\"includeSnippet\")\n        if (\n            context_lines is None\n            or (isinstance(context_lines, str) and context_lines.strip() == \"\")\n        ) and payload.get(\"context_lines\") is not None:\n            context_lines = payload.get(\"context_lines\")\n        if (\n            context_lines is None\n            or (isinstance(context_lines, str) and context_lines.strip() == \"\")\n        ) and payload.get(\"contextLines\") is not None:\n            context_lines = payload.get(\"contextLines\")\n        if (rerank_enabled is None or rerank_enabled == \"\") and payload.get(\n            \"rerank_enabled\"\n        ) is not None:\n            rerank_enabled = payload.get(\"rerank_enabled\")\n        if (rerank_enabled is None or rerank_enabled == \"\") and payload.get(\n            \"rerankEnabled\"\n        ) is not None:\n            rerank_enabled = payload.get(\"rerankEnabled\")\n        if (\n            rerank_top_n is None\n            or (isinstance(rerank_top_n, str) and rerank_top_n.strip() == \"\")\n        ) and payload.get(\"rerank_top_n\") is not None:\n            rerank_top_n = payload.get(\"rerank_top_n\")\n        if (\n            rerank_top_n is None\n            or (isinstance(rerank_top_n, str) and rerank_top_n.strip() == \"\")\n        ) and payload.get(\"rerankTopN\") is not None:\n            rerank_top_n = payload.get(\"rerankTopN\")\n        if (\n            rerank_return_m is None\n            or (isinstance(rerank_return_m, str) and rerank_return_m.strip() == \"\")\n        ) and payload.get(\"rerank_return_m\") is not None:\n            rerank_return_m = payload.get(\"rerank_return_m\")\n        if (\n            rerank_return_m is None\n            or (isinstance(rerank_return_m, str) and rerank_return_m.strip() == \"\")\n        ) and payload.get(\"rerankReturnM\") is not None:\n            rerank_return_m = payload.get(\"rerankReturnM\")\n        if (\n            rerank_timeout_ms is None\n            or (isinstance(rerank_timeout_ms, str) and rerank_timeout_ms.strip() == \"\")\n        ) and payload.get(\"rerank_timeout_ms\") is not None:\n            rerank_timeout_ms = payload.get(\"rerank_timeout_ms\")\n        if (\n            rerank_timeout_ms is None\n            or (isinstance(rerank_timeout_ms, str) and rerank_timeout_ms.strip() == \"\")\n        ) and payload.get(\"rerankTimeoutMs\") is not None:\n            rerank_timeout_ms = payload.get(\"rerankTimeoutMs\")\n        if (highlight_snippet is None or highlight_snippet == \"\") and payload.get(\n            \"highlight_snippet\"\n        ) is not None:\n            highlight_snippet = payload.get(\"highlight_snippet\")\n        if (highlight_snippet is None or highlight_snippet == \"\") and payload.get(\n            \"highlightSnippet\"\n        ) is not None:\n            highlight_snippet = payload.get(\"highlightSnippet\")\n        if (\n            collection is None\n            or (isinstance(collection, str) and collection.strip() == \"\")\n        ) and payload.get(\"collection\") is not None:\n            collection = payload.get(\"collection\")\n        if (\n            language is None or (isinstance(language, str) and language.strip() == \"\")\n        ) and payload.get(\"language\") is not None:\n            language = payload.get(\"language\")\n        if (\n            under is None or (isinstance(under, str) and under.strip() == \"\")\n        ) and payload.get(\"under\") is not None:\n            under = payload.get(\"under\")\n        if (\n            kind is None or (isinstance(kind, str) and kind.strip() == \"\")\n        ) and payload.get(\"kind\") is not None:\n            kind = payload.get(\"kind\")\n        if (\n            symbol is None or (isinstance(symbol, str) and symbol.strip() == \"\")\n        ) and payload.get(\"symbol\") is not None:\n            symbol = payload.get(\"symbol\")\n        if (\n            path_regex is None\n            or (isinstance(path_regex, str) and path_regex.strip() == \"\")\n        ) and payload.get(\"path_regex\") is not None:\n            path_regex = payload.get(\"path_regex\")\n        if (\n            path_regex is None\n            or (isinstance(path_regex, str) and path_regex.strip() == \"\")\n        ) and payload.get(\"pathRegex\") is not None:\n            path_regex = payload.get(\"pathRegex\")\n        if (\n            path_glob is None\n            or (isinstance(path_glob, str) and str(path_glob).strip() == \"\")\n        ) and payload.get(\"path_glob\") is not None:\n            path_glob = payload.get(\"path_glob\")\n        if (\n            path_glob is None\n            or (isinstance(path_glob, str) and str(path_glob).strip() == \"\")\n        ) and payload.get(\"pathGlob\") is not None:\n            path_glob = payload.get(\"pathGlob\")\n        if (\n            not_glob is None\n            or (isinstance(not_glob, str) and str(not_glob).strip() == \"\")\n        ) and payload.get(\"not_glob\") is not None:\n            not_glob = payload.get(\"not_glob\")\n        if (\n            not_glob is None\n            or (isinstance(not_glob, str) and str(not_glob).strip() == \"\")\n        ) and payload.get(\"notGlob\") is not None:\n            not_glob = payload.get(\"notGlob\")\n        if (\n            ext is None or (isinstance(ext, str) and ext.strip() == \"\")\n        ) and payload.get(\"ext\") is not None:\n            ext = payload.get(\"ext\")\n        if (\n            not_ is None or (isinstance(not_, str) and not_.strip() == \"\")\n        ) and payload.get(\"not\") is not None:\n            not_ = payload.get(\"not\")\n        if (\n            not_ is None or (isinstance(not_, str) and not_.strip() == \"\")\n        ) and payload.get(\"not_\") is not None:\n            not_ = payload.get(\"not_\")\n        if (\n            case is None or (isinstance(case, str) and case.strip() == \"\")\n        ) and payload.get(\"case\") is not None:\n            case = payload.get(\"case\")\n        if (\n            compact is None or (isinstance(compact, str) and compact.strip() == \"\")\n        ) and payload.get(\"compact\") is not None:\n            compact = payload.get(\"compact\")\n\n    # Leniency: absorb nested 'kwargs' JSON payload some clients send (string or dict)\n    try:\n        _extra = _extract_kwargs_payload(kwargs)\n        if _extra:\n            if (query is None) or (isinstance(query, str) and query.strip() == \"\"):\n                query = _extra.get(\"query\") or _extra.get(\"queries\") or query\n            if (limit in (None, \"\")) and (_extra.get(\"limit\") is not None):\n                limit = _extra.get(\"limit\")\n            if (per_path in (None, \"\")) and (_extra.get(\"per_path\") is not None):\n                per_path = _extra.get(\"per_path\")\n            # Memory blending controls\n            if include_memories is None and (\n                (_extra.get(\"include_memories\") is not None)\n                or (_extra.get(\"includeMemories\") is not None)\n            ):\n                include_memories = _extra.get(\n                    \"include_memories\", _extra.get(\"includeMemories\")\n                )\n            if memory_weight is None and (\n                (_extra.get(\"memory_weight\") is not None)\n                or (_extra.get(\"memoryWeight\") is not None)\n            ):\n                memory_weight = _extra.get(\"memory_weight\", _extra.get(\"memoryWeight\"))\n            if per_source_limits is None and (\n                (_extra.get(\"per_source_limits\") is not None)\n                or (_extra.get(\"perSourceLimits\") is not None)\n            ):\n                per_source_limits = _extra.get(\n                    \"per_source_limits\", _extra.get(\"perSourceLimits\")\n                )\n            # Passthrough search filters\n            if (include_snippet in (None, \"\")) and (\n                _extra.get(\"include_snippet\") is not None\n            ):\n                include_snippet = _extra.get(\"include_snippet\")\n            if (context_lines in (None, \"\")) and (\n                _extra.get(\"context_lines\") is not None\n            ):\n                context_lines = _extra.get(\"context_lines\")\n            if (rerank_enabled in (None, \"\")) and (\n                _extra.get(\"rerank_enabled\") is not None\n            ):\n                rerank_enabled = _extra.get(\"rerank_enabled\")\n            if (rerank_top_n in (None, \"\")) and (\n                _extra.get(\"rerank_top_n\") is not None\n            ):\n                rerank_top_n = _extra.get(\"rerank_top_n\")\n            if (rerank_return_m in (None, \"\")) and (\n                _extra.get(\"rerank_return_m\") is not None\n            ):\n                rerank_return_m = _extra.get(\"rerank_return_m\")\n            if (rerank_timeout_ms in (None, \"\")) and (\n                _extra.get(\"rerank_timeout_ms\") is not None\n            ):\n                rerank_timeout_ms = _extra.get(\"rerank_timeout_ms\")\n            if (highlight_snippet in (None, \"\")) and (\n                _extra.get(\"highlight_snippet\") is not None\n            ):\n                highlight_snippet = _extra.get(\"highlight_snippet\")\n            if (\n                collection is None\n                or (isinstance(collection, str) and collection.strip() == \"\")\n            ) and _extra.get(\"collection\"):\n                collection = _extra.get(\"collection\")\n            if (\n                language is None\n                or (isinstance(language, str) and language.strip() == \"\")\n            ) and _extra.get(\"language\"):\n                language = _extra.get(\"language\")\n            if (\n                under is None or (isinstance(under, str) and under.strip() == \"\")\n            ) and _extra.get(\"under\"):\n                under = _extra.get(\"under\")\n            if (\n                kind is None or (isinstance(kind, str) and kind.strip() == \"\")\n            ) and _extra.get(\"kind\"):\n                kind = _extra.get(\"kind\")\n            if (\n                symbol is None or (isinstance(symbol, str) and symbol.strip() == \"\")\n            ) and _extra.get(\"symbol\"):\n                symbol = _extra.get(\"symbol\")\n            if (\n                path_regex is None\n                or (isinstance(path_regex, str) and path_regex.strip() == \"\")\n            ) and _extra.get(\"path_regex\"):\n                path_regex = _extra.get(\"path_regex\")\n            if (path_glob in (None, \"\")) and (_extra.get(\"path_glob\") is not None):\n                path_glob = _extra.get(\"path_glob\")\n            if (not_glob in (None, \"\")) and (_extra.get(\"not_glob\") is not None):\n                not_glob = _extra.get(\"not_glob\")\n            if (\n                ext is None or (isinstance(ext, str) and ext.strip() == \"\")\n            ) and _extra.get(\"ext\"):\n                ext = _extra.get(\"ext\")\n            if (not_ is None or (isinstance(not_, str) and not_.strip() == \"\")) and (\n                _extra.get(\"not\") or _extra.get(\"not_\")\n            ):\n                not_ = _extra.get(\"not\") or _extra.get(\"not_\")\n            if (\n                case is None or (isinstance(case, str) and case.strip() == \"\")\n            ) and _extra.get(\"case\"):\n                case = _extra.get(\"case\")\n            if (compact in (None, \"\")) and (_extra.get(\"compact\") is not None):\n                compact = _extra.get(\"compact\")\n    except Exception:\n        pass\n\n    # Normalize inputs\n    coll = (collection or _default_collection()) or \"\"\n    mcoll = (os.environ.get(\"MEMORY_COLLECTION_NAME\") or coll) or \"\"\n    use_sse_memory = str(os.environ.get(\"MEMORY_SSE_ENABLED\", \"false\")).lower() in (\n        \"1\",\n        \"true\",\n        \"yes\",\n    )\n    # Auto-detect memory collection if not explicitly set\n    if include_memories and not os.environ.get(\"MEMORY_COLLECTION_NAME\"):\n        try:\n            from qdrant_client import QdrantClient  # type: ignore\n\n            # Optional: disable auto-detect and/or use cached result\n            if str(os.environ.get(\"MEMORY_AUTODETECT\", \"1\")).lower() not in (\n                \"1\",\n                \"true\",\n                \"yes\",\n                \"on\",\n            ):\n                raise RuntimeError(\"auto-detect disabled\")\n            import time\n\n            ttl = float(os.environ.get(\"MEMORY_COLLECTION_TTL_SECS\", \"300\") or 300)\n            if (\n                _MEM_COLL_CACHE[\"name\"]\n                and (time.time() - float(_MEM_COLL_CACHE[\"ts\"] or 0.0)) < ttl\n            ):\n                mcoll = _MEM_COLL_CACHE[\"name\"]\n                raise RuntimeError(\"use cache\")\n            client = QdrantClient(\n                url=QDRANT_URL,\n                api_key=os.environ.get(\"QDRANT_API_KEY\"),\n                timeout=float(os.environ.get(\"QDRANT_TIMEOUT\", \"20\") or 20),\n            )\n            info = await asyncio.to_thread(client.get_collections)\n            best_name = None\n            best_hits = -1\n            for c in info.collections:\n                name = getattr(c, \"name\", None)\n                if not name:\n                    continue\n                # Sample a small page for memory-like payloads\n                try:\n                    pts, _ = await asyncio.to_thread(\n                        lambda: client.scroll(\n                            collection_name=name,\n                            with_payload=True,\n                            with_vectors=False,\n                            limit=300,\n                        )\n                    )\n                    hits = 0\n                    for pt in pts:\n                        pl = getattr(pt, \"payload\", {}) or {}\n                        md = pl.get(\"metadata\") or {}\n                        path = md.get(\"path\")\n                        content = (\n                            pl.get(\"content\")\n                            or pl.get(\"text\")\n                            or pl.get(\"information\")\n                            or md.get(\"information\")\n                        )\n                        if not path and content:\n                            hits += 1\n                    if hits > best_hits:\n                        best_hits = hits\n                        best_name = name\n                except Exception:\n                    continue\n            if best_name and best_hits > 0:\n                mcoll = best_name\n                try:\n                    import time\n\n                    _MEM_COLL_CACHE[\"name\"] = best_name\n                    _MEM_COLL_CACHE[\"ts\"] = time.time()\n                except Exception:\n                    pass\n        except Exception:\n            pass\n\n    try:\n        lim = int(limit) if (limit is not None and str(limit).strip() != \"\") else 10\n    except (ValueError, TypeError):\n        lim = 10\n    try:\n        per_path_val = (\n            int(per_path)\n            if (per_path is not None and str(per_path).strip() != \"\")\n            else 2\n        )\n    except (ValueError, TypeError):\n        per_path_val = 2\n\n    # Normalize queries to list (accept q/text aliases)\n    queries: List[str] = []\n    if query is None or (isinstance(query, str) and query.strip() == \"\"):\n        q_alt = kwargs.get(\"q\") or kwargs.get(\"text\")\n        if q_alt is not None:\n            query = q_alt\n    if isinstance(query, (list, tuple)):\n        queries = [str(q).strip() for q in query if str(q).strip()]\n    elif isinstance(query, str):\n        queries = _to_str_list_relaxed(query)\n    elif query is not None and str(query).strip() != \"\":\n        queries = [str(query).strip()]\n\n    # Accept common alias keys and camelCase from clients\n    if kwargs and (limit is None or (isinstance(limit, str) and limit.strip() == \"\")) and (\n        \"top_k\" in kwargs\n    ):\n        limit = kwargs.get(\"top_k\")\n    if kwargs and include_memories is None and (\"includeMemories\" in kwargs):\n        include_memories = kwargs.get(\"includeMemories\")\n    if kwargs and memory_weight is None and (\"memoryWeight\" in kwargs):\n        memory_weight = kwargs.get(\"memoryWeight\")\n    if kwargs and per_source_limits is None and (\"perSourceLimits\" in kwargs):\n        per_source_limits = kwargs.get(\"perSourceLimits\")\n\n    # Smart defaults inspired by stored preferences, but without external calls\n    compact_raw = compact\n    smart_compact = False\n    if len(queries) > 1 and (\n        compact_raw is None\n        or (isinstance(compact_raw, str) and compact_raw.strip() == \"\")\n    ):\n        smart_compact = True\n    # If snippets are requested, disable compact to preserve snippet field\n    if include_snippet and str(include_snippet).lower() not in (\"\", \"false\", \"0\", \"no\"):\n        smart_compact = False\n        compact_raw = False\n    eff_compact = (\n        True if (smart_compact or (str(compact_raw).lower() == \"true\")) else False\n    )\n\n    # Per-source limits\n    code_limit = lim\n    mem_limit = 0\n    include_mem = False\n    if include_memories is not None and str(include_memories).lower() in (\n        \"true\",\n        \"1\",\n        \"yes\",\n    ):  # opt-in\n        include_mem = True\n        # Parse per_source_limits if provided; accept JSON-ish strings as well\n        code_limit = lim\n        mem_limit = min(3, lim)  # sensible default\n        try:\n            psl = per_source_limits\n            # Some clients stringify payloads; parse if JSON-ish\n            if isinstance(psl, str) and _looks_jsonish_string(psl):\n                _ps = _maybe_parse_jsonish(psl)\n                if isinstance(_ps, dict):\n                    psl = _ps\n            if isinstance(psl, dict):\n                code_limit = int(psl.get(\"code\", code_limit))\n                mem_limit = int(psl.get(\"memory\", mem_limit))\n        except (ValueError, TypeError):\n            pass\n\n    # First: run code search via internal repo_search for consistent behavior\n    code_res = await repo_search_fn(\n        query=queries if len(queries) > 1 else (queries[0] if queries else \"\"),\n        limit=code_limit,\n        per_path=per_path_val,\n        include_snippet=include_snippet,\n        context_lines=context_lines,\n        rerank_enabled=rerank_enabled,\n        rerank_top_n=rerank_top_n,\n        rerank_return_m=rerank_return_m,\n        rerank_timeout_ms=rerank_timeout_ms,\n        highlight_snippet=highlight_snippet,\n        collection=coll,\n        language=language,\n        under=under,\n        kind=kind,\n        symbol=symbol,\n        path_regex=path_regex,\n        path_glob=path_glob,\n        not_glob=not_glob,\n        ext=ext,\n        not_=not_,\n        case=case,\n        compact=False,\n        repo=repo,  # Cross-codebase isolation\n        session=session,\n    )\n\n    # Optional debug\n    if os.environ.get(\"DEBUG_CONTEXT_SEARCH\"):\n        try:\n            logger.debug(\n                \"DBG_CTX_SRCH_START\",\n                extra={\n                    \"queries\": queries,\n                    \"coll\": coll,\n                    \"limit\": int(code_limit),\n                    \"per_path\": int(per_path_val),\n                },\n            )\n        except Exception:\n            pass\n\n    # Shape code results to a common schema\n    code_hits: List[Dict[str, Any]] = []\n    if isinstance(code_res, dict):\n        items = code_res.get(\"results\") or code_res.get(\"data\") or code_res.get(\"items\")\n        # If compact mode was used, results may be a list; support both shapes\n        items = items if items is not None else code_res.get(\"results\", code_res)\n    else:\n        items = code_res\n    # Normalize list\n    if isinstance(items, list):\n        for r in items:\n            if isinstance(r, dict):\n                ch = {\n                    \"source\": \"code\",\n                    \"score\": float(r.get(\"score\") or r.get(\"s\") or 0.0),\n                    \"path\": r.get(\"path\"),\n                    \"symbol\": r.get(\"symbol\", \"\"),\n                    \"start_line\": r.get(\"start_line\"),\n                    \"end_line\": r.get(\"end_line\"),\n                    \"_raw\": r,\n                }\n                code_hits.append(ch)\n    # More debug after shaping\n    if os.environ.get(\"DEBUG_CONTEXT_SEARCH\"):\n        try:\n            logger.debug(\n                \"DBG_CTX_SRCH_CODE_RES\",\n                extra={\n                    \"type\": type(code_res).__name__,\n                    \"has_results\": bool(\n                        isinstance(code_res, dict)\n                        and isinstance(code_res.get(\"results\"), list)\n                    ),\n                    \"len_results\": (\n                        len(code_res.get(\"results\"))\n                        if isinstance(code_res, dict)\n                        and isinstance(code_res.get(\"results\"), list)\n                        else None\n                    ),\n                    \"code_hits\": len(code_hits),\n                },\n            )\n        except Exception:\n            pass\n\n    # HTTP fallback: if still empty, call our own repo_search over HTTP (safeguarded)\n    used_http_fallback = False\n    if not code_hits:\n        try:\n            from scripts.mcp_router import call_tool_http  # type: ignore\n\n            base = (\n                os.environ.get(\"MCP_INDEXER_HTTP_URL\") or \"http://localhost:8003/mcp\"\n            ).rstrip(\"/\")\n            http_args = {\n                \"query\": (\n                    queries if len(queries) > 1 else (queries[0] if queries else \"\")\n                ),\n                \"limit\": int(code_limit),\n                \"per_path\": int(per_path_val),\n                \"include_snippet\": bool(include_snippet),\n                \"context_lines\": int(context_lines)\n                if context_lines not in (None, \"\")\n                else 2,\n                \"collection\": coll,\n                \"language\": language or \"\",\n                \"under\": under or \"\",\n                \"kind\": kind or \"\",\n                \"symbol\": symbol or \"\",\n                \"path_regex\": path_regex or \"\",\n                \"path_glob\": path_glob or [],\n                \"not_glob\": not_glob or [],\n                \"ext\": ext or \"\",\n                \"not\": not_ or \"\",\n                \"case\": case or \"\",\n                \"compact\": bool(eff_compact),\n            }\n            timeout = float(os.environ.get(\"CONTEXT_SEARCH_HTTP_TIMEOUT\", \"20\") or 20)\n            resp = await asyncio.to_thread(\n                lambda: call_tool_http(base, \"repo_search\", http_args, timeout=timeout)\n            )\n            r = ((resp.get(\"result\") or {}).get(\"structuredContent\") or {}).get(\n                \"result\"\n            ) or {}\n            http_items = r.get(\"results\") or []\n            if isinstance(http_items, list):\n                for obj in http_items:\n                    if isinstance(obj, dict):\n                        code_hits.append(\n                            {\n                                \"source\": \"code\",\n                                \"score\": float(obj.get(\"score\") or obj.get(\"s\") or 0.0),\n                                \"path\": obj.get(\"path\"),\n                                \"symbol\": obj.get(\"symbol\", \"\"),\n                                \"start_line\": int(obj.get(\"start_line\") or 0),\n                                \"end_line\": int(obj.get(\"end_line\") or 0),\n                                \"_raw\": obj,\n                            }\n                        )\n            used_http_fallback = True\n            if os.environ.get(\"DEBUG_CONTEXT_SEARCH\"):\n                try:\n                    logger.debug(\n                        \"DBG_CTX_SRCH_HTTP_FALLBACK\", extra={\"count\": len(code_hits)}\n                    )\n                except Exception:\n                    pass\n        except Exception:\n            pass\n\n    # Fallback: if internal repo_search yielded no code hits, try direct in-process hybrid search\n    used_hybrid_fallback = False\n    if not code_hits and queries:\n        try:\n            from scripts.hybrid_search import run_hybrid_search  # type: ignore\n\n            model_name = os.environ.get(\"EMBEDDING_MODEL\", \"BAAI/bge-base-en-v1.5\")\n            model = get_embedding_model_fn(model_name) if get_embedding_model_fn else None\n            items2 = run_hybrid_search(\n                queries=queries,\n                limit=int(code_limit),\n                per_path=int(per_path_val),\n                language=language or None,\n                under=under or None,\n                kind=kind or None,\n                symbol=symbol or None,\n                ext=ext or None,\n                not_filter=not_ or None,\n                case=case or None,\n                path_regex=path_regex or None,\n                path_glob=path_glob or None,\n                not_glob=not_glob or None,\n                expand=str(os.environ.get(\"HYBRID_EXPAND\", \"0\")).strip().lower()\n                in {\"1\", \"true\", \"yes\", \"on\"},\n                model=model,\n                collection=coll,\n            )\n            if isinstance(items2, list):\n                for obj in items2:\n                    if isinstance(obj, dict):\n                        code_hits.append(\n                            {\n                                \"source\": \"code\",\n                                \"score\": float(obj.get(\"score\") or obj.get(\"s\") or 0.0),\n                                \"path\": obj.get(\"path\"),\n                                \"symbol\": obj.get(\"symbol\", \"\"),\n                                \"start_line\": int(obj.get(\"start_line\") or 0),\n                                \"end_line\": int(obj.get(\"end_line\") or 0),\n                                \"_raw\": obj,\n                            }\n                        )\n            used_hybrid_fallback = True\n        except Exception:\n            pass\n\n    # Option A: Query the memory MCP server over SSE and blend results (real integration)\n    mem_hits: List[Dict[str, Any]] = []\n    memory_note: str = \"\"\n    if include_mem and mem_limit > 0 and queries and use_sse_memory:\n        try:\n            # Import the FastMCP client if available; record a helpful note otherwise\n            try:\n                from fastmcp import Client  # use FastMCP client for SSE interop\n            except ImportError:\n                memory_note = \"SSE memory disabled: fastmcp client not installed\"\n                raise\n            import asyncio\n\n            timeout = float(os.environ.get(\"MEMORY_MCP_TIMEOUT\", \"6\"))\n            base_url = os.environ.get(\"MEMORY_MCP_URL\") or \"http://mcp:8000/sse\"\n            # Best-effort: poll memory MCP /readyz on its health port to avoid init race\n            try:\n                from urllib.parse import urlparse\n                import urllib.request, time\n\n                ready_attempts = int(\n                    os.environ.get(\"MEMORY_MCP_READY_RETRIES\", \"5\") or 5\n                )\n                ready_backoff = float(\n                    os.environ.get(\"MEMORY_MCP_READY_BACKOFF\", \"0.2\") or 0.2\n                )\n                health_port = int(\n                    os.environ.get(\"MEMORY_MCP_HEALTH_PORT\", \"18000\") or 18000\n                )\n                pu = urlparse(base_url)\n                host = pu.hostname or \"mcp\"\n                scheme = pu.scheme or \"http\"\n                readyz = f\"{scheme}://{host}:{health_port}/readyz\"\n\n                def _poll_ready():\n                    for i in range(max(1, ready_attempts)):\n                        try:\n                            with urllib.request.urlopen(readyz, timeout=1.5) as r:\n                                if getattr(r, \"status\", 200) == 200:\n                                    return True\n                        except Exception:\n                            time.sleep(ready_backoff * (i + 1))\n                    return False\n\n                try:\n                    await asyncio.to_thread(_poll_ready)\n                except Exception:\n                    pass\n            except Exception:\n                pass\n\n            async with Client(base_url) as c:\n                tools = None\n                attempts = int(os.environ.get(\"MEMORY_MCP_LIST_RETRIES\", \"3\") or 3)\n                backoff = float(os.environ.get(\"MEMORY_MCP_LIST_BACKOFF\", \"0.2\") or 0.2)\n                last_err = None\n                for i in range(max(1, attempts)):\n                    try:\n                        tools = await asyncio.wait_for(c.list_tools(), timeout=timeout)\n                        if tools:\n                            break\n                    except Exception as e:\n                        last_err = e\n                        try:\n                            await asyncio.sleep(backoff * (i + 1))\n                        except Exception:\n                            pass\n                if tools is None:\n                    raise last_err or RuntimeError(\n                        \"list_tools failed before initialization\"\n                    )\n                tool_name = None\n                # Prefer canonical names\n                for t in tools:\n                    tn = (getattr(t, \"name\", None) or \"\").strip()\n                    tl = tn.lower()\n                    if tl in (\"find\", \"memory.find\"):\n                        tool_name = tn\n                        break\n                if tool_name is None:\n                    for t in tools:\n                        tn = (getattr(t, \"name\", None) or \"\").strip()\n                        if \"find\" in tn.lower():\n                            tool_name = tn\n                            break\n                if tool_name:\n                    qtext = \" \".join([q for q in queries if q]).strip() or queries[0]\n                    arg_variants: List[Dict[str, Any]] = [\n                        {\"query\": qtext, \"limit\": mem_limit, \"collection\": mcoll},\n                        {\"q\": qtext, \"limit\": mem_limit, \"collection\": mcoll},\n                        {\"text\": qtext, \"limit\": mem_limit, \"collection\": mcoll},\n                    ]\n                    res_obj = None\n                    for args in arg_variants:\n                        try:\n                            res_obj = await asyncio.wait_for(\n                                c.call_tool(tool_name, args), timeout=timeout\n                            )\n                            break\n                        except Exception:\n                            continue\n                    if res_obj is not None:\n                        # Normalize FastMCP result content -> rd-like dict\n                        rd = {\"content\": []}\n                        try:\n                            for item in getattr(res_obj, \"content\", []) or []:\n                                txt = getattr(item, \"text\", None)\n                                if isinstance(txt, str):\n                                    rd[\"content\"].append({\"type\": \"text\", \"text\": txt})\n                        except Exception:\n                            rd = {}\n\n                        # Parse common MCP tool result shapes\n                        def push_text(\n                            txt: str,\n                            md: Dict[str, Any] | None = None,\n                            score: float | int | None = None,\n                        ):\n                            if not txt:\n                                return\n                            mem_hits.append(\n                                {\n                                    \"source\": \"memory\",\n                                    \"score\": float(score or 1.0),\n                                    \"content\": txt,\n                                    \"metadata\": (md or {}),\n                                }\n                            )\n\n                        if isinstance(rd, dict):\n                            cont = rd.get(\"content\")\n                            if isinstance(cont, list):\n                                for c in cont:\n                                    try:\n                                        ctype = c.get(\"type\")\n                                        if ctype == \"text\" and isinstance(\n                                            c.get(\"text\"), str\n                                        ):\n                                            push_text(c[\"text\"], {})\n                                        elif ctype == \"json\":\n                                            j = c.get(\"json\")\n                                            if isinstance(j, list):\n                                                for it in j:\n                                                    if isinstance(it, dict):\n                                                        push_text(\n                                                            str(\n                                                                it.get(\"text\")\n                                                                or it.get(\"content\")\n                                                                or it.get(\"information\")\n                                                                or \"\"\n                                                            ),\n                                                            it.get(\"metadata\") or {},\n                                                            it.get(\"score\") or 1.0,\n                                                        )\n                                            elif isinstance(j, dict):\n                                                items = (\n                                                    j.get(\"results\")\n                                                    or j.get(\"items\")\n                                                    or j.get(\"memories\")\n                                                    or j.get(\"data\")\n                                                )\n                                                if isinstance(items, list):\n                                                    for it in items:\n                                                        if isinstance(it, dict):\n                                                            push_text(\n                                                                str(\n                                                                    it.get(\"text\")\n                                                                    or it.get(\"content\")\n                                                                    or it.get(\n                                                                        \"information\"\n                                                                    )\n                                                                    or \"\"\n                                                                ),\n                                                                it.get(\"metadata\")\n                                                                or {},\n                                                                it.get(\"score\") or 1.0,\n                                                            )\n                                    except Exception:\n                                        continue\n                            # Fallback if provider returns flat dict\n                            if not mem_hits:\n                                items = rd.get(\"results\") or rd.get(\"items\")\n                                if isinstance(items, list):\n                                    for it in items:\n                                        if isinstance(it, dict):\n                                            push_text(\n                                                str(\n                                                    it.get(\"text\")\n                                                    or it.get(\"content\")\n                                                    or it.get(\"information\")\n                                                    or \"\"\n                                                ),\n                                                it.get(\"metadata\") or {},\n                                                it.get(\"score\") or 1.0,\n                                            )\n        except Exception:\n            pass\n\n    # If SSE memory didn\u2019t yield hits, try local Qdrant memory-like retrieval as fallback\n    if include_mem and mem_limit > 0 and not mem_hits and queries:\n        try:\n            from qdrant_client import QdrantClient  # type: ignore\n\n            from scripts.utils import sanitize_vector_name  # local util\n\n            client = QdrantClient(\n                url=QDRANT_URL,\n                api_key=os.environ.get(\"QDRANT_API_KEY\"),\n                timeout=float(os.environ.get(\"QDRANT_TIMEOUT\", \"20\") or 20),\n            )\n            model_name = os.environ.get(\"EMBEDDING_MODEL\", \"BAAI/bge-base-en-v1.5\")\n            vec_name = sanitize_vector_name(model_name)\n            model = get_embedding_model_fn(model_name) if get_embedding_model_fn else None\n\n            qtext = \" \".join([q for q in queries if q]).strip() or queries[0]\n            v = next(model.embed([qtext])).tolist()\n            k = max(mem_limit, 5)\n            res = await asyncio.to_thread(\n                lambda: client.search(\n                    collection_name=mcoll,\n                    query_vector={\"name\": vec_name, \"vector\": v},\n                    limit=k,\n                    with_payload=True,\n                )\n            )\n            for pt in res:\n                payload = getattr(pt, \"payload\", {}) or {}\n                md = payload.get(\"metadata\") or {}\n                path = str(md.get(\"path\") or \"\")\n                start_line = md.get(\"start_line\")\n                end_line = md.get(\"end_line\")\n                content = (\n                    payload.get(\"content\")\n                    or payload.get(\"text\")\n                    or payload.get(\"information\")\n                    or md.get(\"information\")\n                )\n                kind = (md.get(\"kind\") or payload.get(\"kind\") or \"\").lower()\n                source_tag = (md.get(\"source\") or payload.get(\"source\") or \"\").lower()\n                flagged = kind in (\n                    \"memory\",\n                    \"preference\",\n                    \"note\",\n                    \"policy\",\n                    \"infra\",\n                    \"chat\",\n                ) or source_tag in (\"memory\", \"chat\")\n                is_memory_like = (\n                    (not path)\n                    or (start_line in (None, 0) and end_line in (None, 0))\n                    or flagged\n                )\n                if is_memory_like and content:\n                    mem_hits.append(\n                        {\n                            \"source\": \"memory\",\n                            \"score\": float(getattr(pt, \"score\", 0.0) or 0.0),\n                            \"content\": content,\n                            \"metadata\": md,\n                        }\n                    )\n        except Exception:  # pragma: no cover\n            pass\n\n    # Fallback: lightweight substring scan over a capped scroll if vector name mismatch\n    if include_mem and mem_limit > 0 and not mem_hits and queries:\n        try:\n            from qdrant_client import QdrantClient  # type: ignore\n\n            client = QdrantClient(\n                url=QDRANT_URL,\n                api_key=os.environ.get(\"QDRANT_API_KEY\"),\n                timeout=float(os.environ.get(\"QDRANT_TIMEOUT\", \"20\") or 20),\n            )\n            import re\n\n            terms = [str(t).lower() for t in queries if t]\n            tokens = set()\n            for t in terms:\n                tokens.update([w for w in re.split(r\"[^a-z0-9_]+\", t) if len(w) >= 3])\n            if not tokens:\n                tokens = set(terms)\n            checked = 0\n            cap = 2000\n            page = None\n            while len(mem_hits) < mem_limit and checked < cap:\n                sc, page = await asyncio.to_thread(\n                    lambda: client.scroll(\n                        collection_name=mcoll,\n                        with_payload=True,\n                        with_vectors=False,\n                        limit=500,\n                        offset=page,\n                    )\n                )\n                if not sc:\n                    break\n                for pt in sc:\n                    payload = getattr(pt, \"payload\", {}) or {}\n                    md = payload.get(\"metadata\") or {}\n                    path = str(md.get(\"path\") or \"\")\n                    start_line = md.get(\"start_line\")\n                    end_line = md.get(\"end_line\")\n                    content = (\n                        payload.get(\"content\")\n                        or payload.get(\"text\")\n                        or payload.get(\"information\")\n                        or md.get(\"information\")\n                    )\n                    kind = (md.get(\"kind\") or payload.get(\"kind\") or \"\").lower()\n                    source_tag = (\n                        md.get(\"source\") or payload.get(\"source\") or \"\"\n                    ).lower()\n                    flagged = kind in (\n                        \"memory\",\n                        \"preference\",\n                        \"note\",\n                        \"policy\",\n                        \"infra\",\n                        \"chat\",\n                    ) or source_tag in (\"memory\", \"chat\")\n                    is_memory_like = (\n                        (not path)\n                        or (start_line in (None, 0) and end_line in (None, 0))\n                        or flagged\n                    )\n                    if not (is_memory_like and content):\n                        continue\n                    low = str(content).lower()\n                    if any(tok in low for tok in tokens):\n                        mem_hits.append(\n                            {\n                                \"source\": \"memory\",\n                                \"score\": 0.5,  # nominal score for substring match; blended via memory_weight\n                                \"content\": content,\n                                \"metadata\": md,\n                            }\n                        )\n                        if len(mem_hits) >= mem_limit:\n                            break\n                checked += len(sc)\n        except Exception:\n            pass\n\n    # Blend results\n    try:\n        mw = (\n            float(memory_weight)\n            if (memory_weight is not None and str(memory_weight).strip() != \"\")\n            else 0.3\n        )\n    except (ValueError, TypeError):\n        mw = 0.3\n\n    # Build per-source lists with adjusted scores\n    code_scored = [{**h, \"score\": float(h.get(\"score\", 0.0))} for h in code_hits]\n    mem_scored = [{**h, \"score\": float(h.get(\"score\", 0.0)) * mw} for h in mem_hits]\n\n    # Enforce per-source limits before final slice so callers actually get memory hits\n    if include_mem and mem_limit > 0:\n        code_scored.sort(key=lambda x: -float(x.get(\"score\", 0.0)))\n        mem_scored.sort(key=lambda x: -float(x.get(\"score\", 0.0)))\n        m_keep = min(len(mem_scored), mem_limit, lim)\n        sel_mem = mem_scored[:m_keep]\n        c_keep = max(0, min(len(code_scored), code_limit, lim - m_keep))\n        sel_code = code_scored[:c_keep]\n        blended = sel_code + sel_mem\n        blended.sort(\n            key=lambda x: (\n                -float(x.get(\"score\", 0.0)),\n                x.get(\"source\", \"\"),\n                str(x.get(\"path\", \"\")),\n            )\n        )\n        # No need to slice again; sel_code+sel_mem already <= lim\n    else:\n        blended = code_scored\n        blended.sort(\n            key=lambda x: (\n                -float(x.get(\"score\", 0.0)),\n                x.get(\"source\", \"\"),\n                str(x.get(\"path\", \"\")),\n            )\n        )\n        blended = blended[:lim]\n\n    # Compact shaping if requested\n    if eff_compact:\n        compacted: List[Dict[str, Any]] = []\n        for b in blended:\n            if b.get(\"source\") == \"code\":\n                compacted.append(\n                    {\n                        \"source\": \"code\",\n                        \"path\": b.get(\"path\"),\n                        \"start_line\": b.get(\"start_line\") or 0,\n                        \"end_line\": b.get(\"end_line\") or 0,\n                    }\n                )\n            else:\n                compacted.append(\n                    {\n                        \"source\": \"memory\",\n                        \"content\": (b.get(\"content\") or \"\")[:500],\n                    }\n                )\n        ret = {\"results\": compacted, \"total\": len(compacted)}\n        if memory_note:\n            ret[\"memory_note\"] = memory_note\n        ret[\"diag\"] = {\n            \"code_hits\": len(code_hits),\n            \"mem_hits\": len(mem_hits),\n            \"used_http_fallback\": bool(locals().get(\"used_http_fallback\", False)),\n            \"used_hybrid_fallback\": bool(locals().get(\"used_hybrid_fallback\", False)),\n        }\n        ret[\"args\"] = {\n            \"queries\": queries,\n            \"collection\": coll,\n            \"limit\": int(code_limit),\n            \"per_path\": int(per_path_val),\n            \"include_memories\": bool(include_mem),\n            \"memory_weight\": float(mw),\n            \"include_snippet\": bool(include_snippet),\n            \"context_lines\": int(context_lines)\n            if context_lines not in (None, \"\")\n            else 2,\n            \"compact\": bool(eff_compact),\n        }\n        try:\n            if isinstance(code_res, dict):\n                ret[\"diag\"][\"rerank\"] = {\n                    \"used_rerank\": bool(code_res.get(\"used_rerank\")),\n                    \"counters\": code_res.get(\"rerank_counters\") or {},\n                }\n        except Exception:\n            pass\n        # Apply TOON formatting if requested or enabled globally\n        if _should_use_toon(output_format):\n            return _format_context_results_as_toon(ret, compact=True)\n        return ret\n\n    ret = {\"results\": blended, \"total\": len(blended)}\n    if memory_note:\n        ret[\"memory_note\"] = memory_note\n    ret[\"diag\"] = {\n        \"code_hits\": len(code_hits),\n        \"mem_hits\": len(mem_hits),\n        \"used_http_fallback\": bool(locals().get(\"used_http_fallback\", False)),\n        \"used_hybrid_fallback\": bool(locals().get(\"used_hybrid_fallback\", False)),\n    }\n    ret[\"args\"] = {\n        \"queries\": queries,\n        \"collection\": coll,\n        \"limit\": int(code_limit),\n        \"per_path\": int(per_path_val),\n        \"include_memories\": bool(include_mem),\n        \"memory_weight\": float(mw),\n        \"include_snippet\": bool(include_snippet),\n        \"context_lines\": int(context_lines) if context_lines not in (None, \"\") else 2,\n        \"compact\": bool(eff_compact),\n    }\n    # Apply TOON formatting if requested or enabled globally (use context-aware encoder for memory support)\n    if _should_use_toon(output_format):\n        return _format_context_results_as_toon(ret, compact=bool(eff_compact))\n    return ret",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function__maybe_dict_138": {
      "name": "_maybe_dict",
      "type": "function",
      "start_line": 138,
      "end_line": 145,
      "content_hash": "da5a2f43b4bb5ae38e08097a356b4e707aac2841",
      "content": "    def _maybe_dict(val: Any) -> Dict[str, Any]:\n        if isinstance(val, dict):\n            return val\n        if isinstance(val, str) and _looks_jsonish_string(val):\n            parsed = _maybe_parse_jsonish(val)\n            if isinstance(parsed, dict):\n                return parsed\n        return {}",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function__poll_ready_824": {
      "name": "_poll_ready",
      "type": "function",
      "start_line": 824,
      "end_line": 832,
      "content_hash": "1a1675f42a356e64827fc1977b2bd3b68b34ba00",
      "content": "                def _poll_ready():\n                    for i in range(max(1, ready_attempts)):\n                        try:\n                            with urllib.request.urlopen(readyz, timeout=1.5) as r:\n                                if getattr(r, \"status\", 200) == 200:\n                                    return True\n                        except Exception:\n                            time.sleep(ready_backoff * (i + 1))\n                    return False",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    },
    "function_push_text_903": {
      "name": "push_text",
      "type": "function",
      "start_line": 903,
      "end_line": 917,
      "content_hash": "ff03e10c2ebdcd95e038dea9b2076e9e471562af",
      "content": "                        def push_text(\n                            txt: str,\n                            md: Dict[str, Any] | None = None,\n                            score: float | int | None = None,\n                        ):\n                            if not txt:\n                                return\n                            mem_hits.append(\n                                {\n                                    \"source\": \"memory\",\n                                    \"score\": float(score or 1.0),\n                                    \"content\": txt,\n                                    \"metadata\": (md or {}),\n                                }\n                            )",
      "pseudo": "",
      "tags": [],
      "qdrant_ids": []
    }
  }
}