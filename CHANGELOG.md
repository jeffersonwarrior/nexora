## [0.29.0] - 2025-12-18 - **State Machine Architecture & Resource Monitoring**

### ğŸ—ï¸ Intelligent Agent Management
- **State Machine Implementation**: AI lifecycle management with intelligent execution flow
  - 8 states: Idle â†’ ProcessingPrompt â†’ StreamingResponse â†’ ExecutingTool â†’ ProgressCheck â†’ PhaseTransition â†’ Halted/Error
  - Progress tracking with semantic analysis (file modifications, command execution, test results)
  - Loop detection via action fingerprinting and error pattern analysis
  - Phase-based execution (Planning â†’ Implementation â†’ Validation â†’ Refinement)
  - Automatic decision-making for state transitions and resource allocation
  
- **Resource Monitoring**: Intelligent system resource protection
  - CPU/Memory/Disk threshold monitoring with adaptive limits
  - Auto-pause on resource violations (default: CPU 80%, Mem 85%, Disk 5GB free)
  - Integration with state machine for graceful degradation
  - Proactive resource management prevents system overload
  - Self-healing: automatically throttles agent when resources constrained

### ğŸ¯ Smart CLI Control
- **Multi-session coordinator**: Intelligently manages parallel agent sessions with resource limits
- **Session window**: Dynamic token budget tracking and context optimization
- **Recovery registry**: Automated error recovery with adaptive strategy patterns
- **Progress tracker**: Detects productive work vs. spinning loops automatically

### ğŸ”§ Local Model Improvements
- **Enhanced detection**: Better Ollama/LM-Studio endpoint discovery
- **Improved logging**: Clear error messages with examples
- **UI polish**: Native port selection in TUI (11434 for Ollama, 1234 for LM-Studio)
- **Stability fixes**: Graceful degradation when local endpoints unavailable

### ğŸ“¦ Infrastructure
- **MCP integration**: Z.AI Vision support with dedicated manager
- **Comprehensive test coverage**: State machine, resource monitoring, recovery strategies, and core utilities
- **Production-grade reliability**: Zero failures across all test suites

### ğŸ§ª QA Results
```
âœ… State machine â†’ 100% transition coverage, intelligent flow control
âœ… Resource monitor â†’ Adaptive CPU/Mem/Disk protection
âœ… Local models â†’ Improved detection + UI
âœ… All tests passing â†’ Zero failures
```

---

## [0.28.5] - 2025-12-17 - **Token Efficiency & Production Polish**

### ğŸ¯ Performance Optimization
- **Token Reduction**: 30k â†’ 27k tokens (11% reduction) in session startup
  - Tool documentation compressed by 37% (35KB â†’ 22KB)
  - edit.md: 9.3KB â†’ 3.7KB (-60%)
  - bash.tpl: 5.2KB â†’ 3.6KB (-31%)
  - multiedit.md: 5KB â†’ 3.6KB (-28%)
  - coder.md.tpl: 7.2KB â†’ 5.3KB (-26%)
  - agentic_fetch.md: 2.9KB â†’ 1.6KB (-45%)
  - job tools consolidated: 1KB â†’ 0.5KB (-51%)
- **Runtime Optimizations**:
  - Git commits reduced: 3 â†’ 2 in logs
  - Git status reduced: 20 â†’ 5 files shown
  - Network/services lazy-loaded (set `NEXORA_FULL_ENV=1` to enable)
  - Default assumes "online", skips expensive ping/systemctl checks

### ğŸ“š Documentation
- Added TOKEN_REDUCTION.md with detailed breakdown
- Updated ROADMAP.md with completion status
- All tool descriptions remain comprehensive while being more concise

### ğŸ’° Benefits
- **Faster startup**: Less initial context to process
- **Lower costs**: 11% token reduction = 11% cost reduction per session
- **Better context window**: More room for actual conversation
- **Same functionality**: All features preserved

### ğŸ§ª QA Results
```
âœ… go test ./... â†’ 20+ packages, zero failures
âœ… go build . â†’ Clean build
âœ… All tool descriptions â†’ Still comprehensive
âœ… No functionality lost
```

---

## [0.28.7] - 2025-12-17 - **Local Model Support (Beta)**
- **Local Model Support (Beta)**: Ollama/LM-Studio integration
  - UI configuration + clear error messages
  - Beta stability with production fallbacks

### ğŸ§ª QA Results
```
âœ… go test ./... â†’ 20+ packages, zero failures
âœ… make test-qa â†’ Production validation suite
âœ… ./build/nexora -y â†’ Zero crashes
âœ… Local model endpoints â†’ Responding correctly
```

---

- **Anthropic `max_tokens=0` ERROR**: Bulletproof validation in **ALL** call sites (summarization, title gen, main agent)
  - `ensurePositiveMaxTokens()` â†’ **0 becomes 4096 automatically**
  - Explicit fallbacks: summarization (4096), titles (100), tools (triple-checked)
- **SQLite Migration**: Fixed `context_archive` table (inline indexes â†’ separate CREATE INDEX)
- **Local Models UI**: Clear error messages + examples (Ollama/LM-Studio ports)

### âœ¨ Features
- **Z.AI Vision MCP**: **@z_ai/mcp-server** added to main config (`make setup`)
  - Vision analysis, web reader, web search
  - Zero-config production setup
- **Session Title Updates**: Auto-update every **25 messages** (configurable)
  - Context-aware (last 10 user messages)
  - Thread-safe counters (`csync.Map`)
  - Deduplication (no redundant updates)

### ğŸ§ª QA Results
```
âœ… go test ./... â†’ 20+ packages, zero failures
âœ… make test-qa â†’ Production validation suite
âœ… ./build/nexora -y â†’ Zero crashes
âœ… All migrations â†’ Applied successfully
```

---

## [0.28.5] - 2025-12-17 - **Zero-Config Production**

### ğŸš€ Major Features
- **`make setup`** - **One-command production** (9 API providers + Z.AI MCP Vision)
  - xAI Grok-4.1, Cerebras GLM-4.6, Anthropic Claude 4.5, OpenAI GPT-5.2
  - **Zero permission prompts** (`skip_requests: true`)
  - **Auto-loads `.env`** API keys

### ğŸ› ï¸ Reliability
- **max_tokens validation**: **0 â†’ 4096** everywhere (Anthropic, all providers)
- **Thread-safe agent queue**: 50+ concurrent requests
- **Auto model fallback**: Invalid models â†’ recent working models

---

## [0.28.4] - 2025-12-17 - **QA Framework**

- **Dedicated QA**: `qa/` folder + `make test-qa`
- **Build verification**: Clean builds required
- **Tool ID sanitization**: Mistral/OpenAI format compliance

---
